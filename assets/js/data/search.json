[ { "title": "软件研发体验调查报告 2022", "url": "/posts/2023-01-28/devops-survey-2022/", "categories": "Tech", "tags": "engineering", "date": "2023-01-28 00:00:00 +0800", "snippet": "在 2022 年 12 月初，我们发起了部门内软件研发体验年度调查问卷，有 324 位同学参与了调查并贡献了自己的想法，大约占总人数比的 50%，基本反应了当前部门的软件研发现状，分析报告如下。第一部分：团队概况开始部分主要统计了参与人员的分布情况，从角色、定位、工作经验以及团队规模了解目前研发部门的基本状况。开发团队人员占据了 80%的人员比例，UX 和 Support 都没有参与本次问卷...", "content": "在 2022 年 12 月初，我们发起了部门内软件研发体验年度调查问卷，有 324 位同学参与了调查并贡献了自己的想法，大约占总人数比的 50%，基本反应了当前部门的软件研发现状，分析报告如下。第一部分：团队概况开始部分主要统计了参与人员的分布情况，从角色、定位、工作经验以及团队规模了解目前研发部门的基本状况。开发团队人员占据了 80%的人员比例，UX 和 Support 都没有参与本次问卷。管理层和独立贡献者刚好二八开，是一个符合预期的团队结构。从工作经验看，10 年工作经验以内的同事占据了 85%人员比例，按时间推算他们应该都是 90 后，他们是团队的中坚力量。从团队规模的答案看，发现一个有趣的现象，接近 45%的人认为平时自己会跟 13 个人以上频繁打交道，说明平时大家协作沟通成本非常高。按照亚马逊推荐的两个披萨团队理论，一个敏捷的团队不应该超过 8 个人，否则沟通效率会积极下降。从本次调查结果中应该反思，到底是什么原因导致大家需要和如此多人频繁合作？我们还可以做一些有意思的交叉分析，看看独立贡献者和管理层的年龄分布大概是怎么样的。结果也还是意料之中，不过可能因为有一些脏数据导致了小小的误差。第二部分：软件交付体验第二部分主要为了了解软件交付体验的状况和存在的问题。从问卷结果看，85%以上的同学认为自己所在的项目组的软件交付体验还 OK，这不仅是每个团队在工程卓越上的努力的结果，也是公司在软件交付投入的效果。当然这并不能说明我们做得已经很好了，抱怨和吐槽的声音还是很响亮的。针对影响交付体验的因素，这是一个开放性话题，我们对大家的抱怨和吐槽做了归类，展示如下。可以看出来，需求管理的好不好，是改善软件交付体验的关键。当然，需求清晰不变更，这是理想的世界，现实世界里是不存在的。外在的环境一直在变化，我们应该做的是用开放和拥抱变化的心态去预期和处理可能的变更和风险，在不确定性中寻找确定性。比如敏捷开发中多用迭代、快速寻求反馈的思想，尽可能早发现错误并敢于调整方向和做出取舍。在持续交付中践行 DevOps 理念，尽可能将软件交付过程中的手工重复部分自动化掉，多用标准化的工具，这样才能减少需求频繁变更和手工重复的痛苦。我们能确定的是，不变的只有变化。在《认知觉醒》一书中提到，人的一生就是一场“消除模糊”的游戏，具体事情一旦变模糊，边界就会无限扩大，唯一的办法就是正视它、拆解它。第三部分：研发效率部分这一部分主要为了了解每个工程师的工作效率和瓶颈因素。问题偏主观，不过从结果上看，还是有解决 90%的同学认为自己的工作效率还挺好的，对目前的工作难度和结果还算满意。对于大家的开放式吐槽，我们将答案做了归类，结果展示如下。从分类后的结果看，上下文切换是大家公认的效率杀手。所谓的上下文切换，可以换个说法叫无法专注。你本来要做 A，临时来个 B。你本来要看书的，手机亮了起来。很多时候事情没做完就是因为你不知不觉被切换到了另外一个场景，大家抱怨比较多的就是临时任务，没计划的安排，突然老板叫去开会等等，不一而足。其次就是跨团队合作，毕竟每个团队都有自己的目标和优先级，相对于合作而言，当然还是先想办法让自己的团队完成任务活下来。孙子兵法有云，上下同欲者胜。我们需要思考，怎么样才能让上下游团队跟自己有共同目标，步调一致，这对每个人都是一个不小的挑战。作为独立贡献者，想要提高自己的价值就必须想办法专注于最重要的事情，绩效还是以结果为导向的。作为团队管理者，更应该思考，怎样帮助下属减少上下文切换，怎样高效跨部门合作。第四部分：如果你有超能力如果你有超能力可以改变软件研发过程中的任何部分，你希望改变什么？答案当然就很天马行空，不过也颇有趣味。从底层逻辑看，我们希望改变的东西无非几种：文化、流程、工具、协作或者其他。所以针对这个开放性的问题的答案，我们也做了归类，得出这样的结论。流程上的优化是大家最希望看到的，复杂的流程一定程度上是为了帮助企业规避风险，但带来的效率降低也是很可怕的。在这个方面企业只能尽可能去平衡优化的利弊，并不能直接简化或者消除流程，尽可能用自动化的方式去降低手动执行的代价。第五部分：技术工具推荐为了发现好用的技术和工具，避免重复造轮子，我们专门设计了这样两个问题。 在公司内部，你有什么好用的技术，工具，流程或实践可以让大家去尝试？ 在公司外部，你有什么好用的技术，工具，流程或实践可以让大家去尝试？ 以上答案仅供参考查阅，相信在软件研发领域也没有什么银弹，很多时候还是需要根据自身情况量体裁衣，别人说好用放你这不一定行，一个组织里最可贵的还是人才梯队的培养，《从优秀到卓越》里有这样一句话，卓越的管理者知道要先找到合适的人上车，而不是先想好车要开到哪里。第六部分：尾声在做这样的调查的同时，我们也很担心不能得到大家的支持，毕竟每个问题都需要仔细思考后才能回答，就算回答了也不一定马上能带来什么改变。但是我们真心希望每个人都能在一个阶段结束后（比如年底）花一些时间去回顾和思考成长和不足。我们还是冒昧问了大家这样一个问题。很高兴看到有接近 70%的同学还是支持这样的调查的，毛主席说了，没有调查就没有发言权。这样的调查更多是为了明白我们现在在哪，我们最大的痛点在哪，我们可以改进什么，用数据和事实去思考比用感觉去思考更可靠。问卷被 584 人浏览过，平均完成时间 13 分钟，其实并不需要很多时间。新的一年开始了，人类最重要的能力就是反思和改进，希望这样一份研究报告对你有所启发，对你和你团队工作有所帮助。最后，我们也祝愿每个团队有更大的成就，我们一起拥抱变化，走向卓越。彩蛋：金句摘选此部分摘录了开放性问题的一些精彩回答，与君共赏。问：阻碍需求流畅交付的主要因素是什么？答：需求会膨胀答：需求感觉自己被理解了，其实并没有答：有些需求没买票乱插队答：项目年纪很大，亲戚很多问：影响我工作效率的主要因素是什么？答：时间太碎了，总是被打断答：上下游响应不及时，甚至不响答：精神欠佳，身体欠安答：友军的 bug 太多了答：没有文档，找不到人，我新来的答：开发两分钟，部署两小时问：如果你有超能力，你希望改变什么？答：不是所有用户需求都要做的答：老板拍板的魄力，别让下面人猜来猜去答：开箱即用的开发环境，大大的 CPU 和内存答：瞬间打包发布，越快越好，快到极致答：别突如其来，别说变就变答：都有责任心，没有甩锅的心态答：专业专注，氛围融洽问：对研发效能的改进，你有何建议？答：一起讨论代码，一起提高产品质量答：流程更规范，需求更详尽答：使用科学的衡量标准答：统一基础框架和平台，确保稳定性和可靠性答：减少开发人员在非开发工作上的时间投入答：听取意见并改进，不要局限在小圈子里" }, { "title": "熟练的开发", "url": "/posts/2023-01-14/productive-developer/", "categories": "Tech", "tags": "engineering", "date": "2023-01-14 00:00:00 +0800", "snippet": "高级打工人可能有什么特点？大致列一下，部分内容来自网络。熟练人员经过多年的积累加上自己的代码片段的总结，在完成大多少代码时基本不需要查资料。而一般的开发人员在开发过程中会花掉很多时间去查找各种资料。熟练人员注意代码复用，并且时刻注意重构和抽取公用代码，甚至会维护自己的武器库。一般开发人员是代码拷来拷去完成功能。熟练人员非常注意查找，定位，标签等各种快捷键的使用，定位查找方便快捷，IDE 环境...", "content": "高级打工人可能有什么特点？大致列一下，部分内容来自网络。熟练人员经过多年的积累加上自己的代码片段的总结，在完成大多少代码时基本不需要查资料。而一般的开发人员在开发过程中会花掉很多时间去查找各种资料。熟练人员注意代码复用，并且时刻注意重构和抽取公用代码，甚至会维护自己的武器库。一般开发人员是代码拷来拷去完成功能。熟练人员非常注意查找，定位，标签等各种快捷键的使用，定位查找方便快捷，IDE 环境也根据习惯定义到最方便状态。熟练人员编码前先思考清楚整个流程，在头脑或纸张上规划好整个实现方式和方法函数的划分。一般人员想到哪里写到哪里。熟练人员写了 50 行以上或更多代码才 Debug 一两次，一般人员写了几行代码就要 Debug 多次，完全通过 Debug 来验证代码正确性。熟练人员注重代码的质量，单元测试和可维护性，注重各种业务逻辑的验证和边界条件的校验。一般人员只注重简单功能的简单完成。熟练人员提交测试的代码 BUG 很少，返工工作量很小。一般开发人员由于自测不完善 BUG 较多，造成大量的返工工作量。熟练人员合理分配自己的时间，规划好每天工作任务，开发过程非常专注。一般开发人员一心多用，边开发边聊天。熟练人员善于知识的总结和积累，形成自我的知识库，能用自己的语言来分享经验。熟练人员善于发现问题，分析不足而自我持续改进。一般人员需要在外力干预下被迫改进。熟练人员重点会对业务进行深刻理解，针对用户场景进行分析设计。一般开发人员考虑的是开发的语言和工具。熟练人员善于从各种影响自己开发效率的因素中挤时间，善于总结开发过程中的经验得失。而一般人员则不善于这种总结，只是觉得时间不够。熟练人员会有全局思维和视野，关注结果和影响，不会卡死在牛角尖里。而一般人员会陷入过度设计和局部优化。以上，共勉。" }, { "title": "2022年，再见", "url": "/posts/2022-12-28/goodbye-2022/", "categories": "Life", "tags": "Reading", "date": "2022-12-28 00:00:00 +0800", "snippet": "全是一些琐事。一月元旦在崇礼滑雪跨年，见到了真正的大雪山，还有马上要进行冬奥会的滑雪赛道，上面有我摔过留下的屁股印子。路过北京想爬起来去看升国旗，看公众号说大概是早上 5 点多，嗯，不算太早。不想北京的早上那么冷，算了，看看升起来以后的国旗就好。借了同事的大疆无人机在公园飞，手冻僵了，电池没电了，最后飞机也炸了，不过在五千米高空看上海还是挺好玩的。去大橙子家过年，第二天就下雪了，狗子好像并不...", "content": "全是一些琐事。一月元旦在崇礼滑雪跨年，见到了真正的大雪山，还有马上要进行冬奥会的滑雪赛道，上面有我摔过留下的屁股印子。路过北京想爬起来去看升国旗，看公众号说大概是早上 5 点多，嗯，不算太早。不想北京的早上那么冷，算了，看看升起来以后的国旗就好。借了同事的大疆无人机在公园飞，手冻僵了，电池没电了，最后飞机也炸了，不过在五千米高空看上海还是挺好玩的。去大橙子家过年，第二天就下雪了，狗子好像并不怕冷，在雪地里乱跑。年里大橙子神奇地带了一大家子人去 KTV 里包场，我以为老一辈人并不喜欢这种环境，没想到他们才是真正的 K 歌之王。发现很容易忘事情，今年买了一个日记本，打算重新开始记日记。上一次日记可能是在大学时代写的。二月年前我们在公司墙上贴了上面这幅漫画，大家笑了笑，年后再说，年后再说。年后回来发现，年前有些事不做，年后也没必要做了，一年有一年的事。二月梅花开的正好，现在住在大公园附件幸福感上升不少，走 15 分钟路就可以去赏鹅赏花赏咕咕。今年的春也挺早的，花开好了一大片，可能咕咕看多了，做事也更喜欢鸽了。大天鹅还是很优雅的，可能你没见过未成年的天鹅，那叫一个丑，怪不得有丑小鸭要变白天鹅的童话故事。看下面这三个孩子们，是不是丑哭了。大橙子开始上一些播音课，每天都在读顺口溜，报菜名，我现在也会了一点：“蒸羊羔，蒸熊掌，蒸鹿尾儿，烧花鸭，烧子鹅，炉猪，炉鸭，酱鸡，腊肉…”。我还会十八愁：“狼也愁，虎也愁，象也愁，鹿也愁，骡子也愁马也愁，羊也愁，牛也愁，狗也愁，猪也愁，鸭子也愁鹅也愁。”三月三月初上海开始用封闭有疫情感染的小区，感觉情况有点严重了，不过我还是正常去单位上班，路上人少了很多。三月中旬，我们也开始居家办公了，中午吃完饭大橙子说出去溜溜？我说好。路边的樱花也开了，不过没想到，这一溜就是上海封城前的最后一溜，再从小区出来，都已经到了夏天最热的时候。有一天我去丢垃圾，在小区门口看见有卖草莓的车，就顺手买了一篮子草莓，回来跟大橙子说，这一篮子 50 块，好贵啊。她说，你就知道写代码，你去买菜群里看看，150 块都不一定能买到你这篮子草莓，原来是我不食人间烟火。偶然发现煎牛排挺容易做的，也挺好吃的，很香，但我只吃十分熟的。四月封控进入最狂热阶段，家里屯的吃的基本都吃完了，居委会也找不到人，社区几乎进入瘫痪阶段，不过核酸检查没有瘫痪，大家还是还是能在固定时间听到有人大喇叭喊：“下楼做核酸，24 号楼请下楼做核酸。”朋友圈晒的或者是核酸队伍，或者是抗原照片，或者是政府发放的物资，或者是各路大神的厨艺比拼，家里买了很久的大米终于吃完了。发现家里还有个健身环，不错，拿起来练练，挺好玩，没想到这游戏做的还挺用心的，吃灰了一年多的 Switch 又派上了用场。刚买回来大橙子只喜欢玩马里奥，而且还只玩免费送的那几关，女娃子的快乐就那么简单。大橙子开始瘦了，比大学时的她还瘦。我开始胖了，比去年的我还胖。五月人工设岗检查核酸没那么勤了，不过抗原几乎是天天做，那时不知道为什么奥密克戎隔离了那么久还是没有消灭掉，到了年底才知道，这东西的传染性是无敌的强。在家办公忙里偷闲，借着吃饭的空档期把《三国演义》看了，以前挺不喜欢电视剧的，总觉得看电视浪费时间，不想却错过了那么多名场面和欢乐时光。今年还看了《朱元璋》，《大明 1566》，《潜伏》，《大宅门》，历史题材在文字上展现有事并不生动甚至枯燥，优秀的演员却可以让死去的人物活起来。五月各个小区开始发放临时出入证了，凭出入证可以外出溜达一个小时。我早上拿了一张通行证去逛了一圈公园，路上门面全都关着，透过玻璃门窗可以看到大多数店里的花草都干了，路上零星一两个人可能跟我一样，都是出来长长见识的，这是一个被暂停了快三个月的上海。路边的铜像也不知道被谁戴上了口罩，没人不知道新冠病毒不厉害，但也不知道新冠病毒是怎么个厉害法，因为身边认识的没一个人感染过。六月终于解封了。马路上多了很多核酸亭，走 5 分钟就能碰到一个。每个门店前面都贴了一张二维码，叫场所码，进门需要先扫一扫。这个月的电视剧里也开始出现这样的弹幕：“核酸异常，抓起来。” “不是绿码，不能放行。” “没有 48 小时核酸，不允许通行。”大家放出来了，和朋友约了海底捞，大家都想要报复性消费一下，但吃着吃着就理性了很多。封控了这么久，上海有很多行业早就撑不住了，有些人解封后就要离开魔都，还能好好吃饭就不错了，报复不报复都不重要了。七月七月荷花开了，晚上也很凉快，可以去夜跑了，还好疫情没让我们错过这个夏天。尤其是傍晚，在光线刚刚好的时候，随手都可以拍出很漂亮的照片。大橙子做了一个小手术，手术完了吃了三倍分量的菜饭，我终于相信她才是一个真正的干饭人。她曾经说过，路边的垃圾桶倒了，是因为没吃饱饿的。我为了提高打字速度，开始学习盲打主键盘上的数字键，还尝试把全拼换成双拼。结论是，能盲打小键盘数字还是很有用的，显著提高工作效率。至于双拼嘛，没比全拼快多少。八月周末下午拖了一个野餐垫来到公园，对着天空躺到天黑。据说冥想可以让人觉得快乐和自由，心静下来了，时间也就静下来了，蚊子却渐渐多起来了。从读书会拿到一套《明朝那些事》，没想到还挺有意思。一共有 9 册，明朝总共 276 年，16 个皇帝。没看历史前，觉得自己挺文盲的，看了一点历史后，觉得自己更文盲了。还是要多读书。组里来了个实习的小妹妹，人很机灵，也很努力。00 后是潜力无限的一代人，可能今后几年经济形势不会像前面两年那么乐观，但是年轻人会更优秀。大橙子想用我的电脑，我给她写了一份使用说明书，被她批评了一通，什么狗屁玩意，说我的电脑是不是藏了小秘密不想给她用，我天地良心。不知道为什么我在日记里写了这么一个冷笑话：“宝贝，我想给你整个世界” “行，你整吧。”团建去玩瓷艺，有捏杯子的，有捏烟灰缸的，也有捏泥菩萨的，一大群成年人居然花钱在一起玩泥巴，不过快乐就好。九月刚搬到浦东就知道附近有个浦东图书馆，一直想去坐坐，主要是想蹭空调。九月终于抽时间去预约了入馆，没想到还挺难抢的，跟我有一样想法的人肯定不少。大橙子说，里面的空调真舒服，温度刚合适，你看大家睡的多香。最近有点迷上王阳明，翻了几本关于他的书，被描写的像是一个神话人物。心学其实也是哲学，知行合一，先知而后行，听上去挺简单，但其实非常难。认知和行动在大多数人身上很难得到统一，道理我都懂，真正做起来就不行。你看，日记才写到 3 月就停了。中秋节，大橙子的计划是邀请她的小姐妹们来上海轰趴的，她已经准备好了一年多了，可是因为这可恶的疫情这能无限往后推迟。最后，我们到青岛小包子家，在海边搭帐篷，吃烧烤。青岛的啤酒节好像也没办起来，沿街都是各式各样的啤酒店，就是不营业。去崂山逛了一圈，满山烟雾缭绕，还在朋友圈发了几张图，配上了 “我来问道五无余说，云在青山水在瓶。” 的词。因为最近看陈宝国老师演的嘉靖皇帝很上头。这个月找了一个敏捷教练来带我们组，没想到教练的方法还真的挺多。他还告诉我，要给别人留足够的空间，沉默也是一种处理问题的方式。我要学的东西还很多。十月黄金周还是窝在上海，不过这次不一样，我们去当了一回游客。去了外滩，去了野生动物园，去了博物馆，哪里人多去哪里，可能是因为前面几个月太不热闹了吧。这个月几乎每个周末都跑去图书馆吹空调，眼见路边的树叶从绿色变成黄色，马上就要入秋了，可是还热的要死。也不知道图书馆怎么想的，明明挺好的冷风就变成热风了，外面很热，里面也很热，不想让人好好学习。不过大橙子说挺好，热点你睡觉不容易着凉。前面把电脑升级了，这个月又把家里宽带升级了，现在没有理由说家里电脑卡网络卡导致工作效率不高了，我自己把路堵死了。1024 程序员节朋友圈好热闹，不过我觉得自己已经很久没写代码了，这一两个月只是改改文档和配置，不像是一个纯粹的程序员了。这个月换了新老板，但是单位和组都没换，在同样的位置也能体验不一样的工作风格和内容。十一月大橙子的侄女不知道怎么突然和大橙子亲近起来，每天都打视频电话和她过家家，家里所有的玩具都被拿出来排排站，起名字，喝水，上学校。小孩子的世界和时间真单纯。这个月庆祝了同事 A 的十年服务奖，同事 B 的十五年服务奖，一个人能在一个公司工作十多年，真的是很不容易的事情。很想去找地方看银杏落叶，但上海这个鬼天气，这个月就没有秋高气爽的感觉。全国的疫情又开始起来了，很多省份都红了，好几个地方闹得很凶。上海反倒成了控制的很好的城市，不过好像没人记得今年三月到六月在这发生过的事。还没到年底，老板已经开始放出各种消息，今年的行情很不好，请做好心理准备。这个月几乎每两天就跑 5 公里，跑了一个多月，然后一斤也没瘦 ​。运动不见得能减肥，因为吃得太多。十二月才过一周，全国就放开了疫情管控，这下好了，老百姓突然慌了。选了半天的团建活动，最后大家决定一起去撸猫馆打桌游。不知道为什么程序员都喜欢猫，虽然我没养，但我也想要一只。虽然疫情已经放开了，听说办公室里阳了一个还是挺担心的，老板说先回家大家跑的一个比一个快，还是小命要紧。第三周的某一天，大橙子阳了，我嘲笑她到时候就只能躺在床上哎呀呀了，没想到哎呀呀的是我，有三天笑不出来，捏哪都疼。阳康以后，我以为自己又可以了，谁知道每天都能睡到 11 点不醒，下午还打瞌睡，老年生活莫非就是如此这般？2022 年总结不出好听的话，只愿今日浮云散，明月照人来。" }, { "title": "如何有效授权", "url": "/posts/2022-09-04/delegating/", "categories": "Management", "tags": "coaching", "date": "2022-09-04 00:00:00 +0800", "snippet": "先说一个故事。如果今年的业务目标是卖 50 辆汽车，有 4 个团队的销售成绩分别如下。 团队名称 下属业绩 主管业绩 A 25 辆 25 辆 B 35 辆 15 辆 C 40 辆 10 辆 ...", "content": "先说一个故事。如果今年的业务目标是卖 50 辆汽车，有 4 个团队的销售成绩分别如下。 团队名称 下属业绩 主管业绩 A 25 辆 25 辆 B 35 辆 15 辆 C 40 辆 10 辆 D 50 辆 0 辆 哪个团队的主管最优秀？可能你会问怎么定义优秀，那也请你思考一下怎么样才算是一个优秀的主管。在现实社会中，团队 A 的主管往往不是一个称职的主管，尽管他真的很强也很卖力。团队 B 的主管可能也没尽到主管的职责。团队 C 的主管在完成管理工作的同时还具备不错的业务实操能力。团队 D 的主管往往被认为是一个优秀的管理者。为什么那么累还得了差评管理和业务实操关心的重点并不一样。当我们在一线搬砖时，我们需要考虑搬砖的效率和质量，搬得越多越好，搬得越快越好，搬过来的砖都没有破损，质量杠杠的，那老板一定会对我竖起大拇指。当我们开始管理团队时，我们需要考虑部门间的沟通，团队内的配合，人才的培养和留用，下属的状态和绩效。你是很优秀了，可是他们怎么办？了解员工的成熟度如果做到有效授权" }, { "title": "简单一点", "url": "/posts/2022-09-03/simplify/", "categories": "Tech", "tags": "design, SRE", "date": "2022-09-03 00:00:00 +0800", "snippet": "A designer knows he has achieved perfection not when there is nothing left to add, but when there is nothing left to take away. (Antoine de Saint-Exupery)一个设计师知道，完美不是在没办法添加更多功能时获得，而是在没有办法去掉任何东西时获得。...", "content": "A designer knows he has achieved perfection not when there is nothing left to add, but when there is nothing left to take away. (Antoine de Saint-Exupery)一个设计师知道，完美不是在没办法添加更多功能时获得，而是在没有办法去掉任何东西时获得。—— 埃克苏佩里软件系统本质是动态的和不稳定，只有死掉的系统才是绝对稳定的。简单带来可靠简单带来高效简单有时是奢望" }, { "title": "上帝没来", "url": "/posts/2022-08-27/your-god/", "categories": "Life", "tags": "god", "date": "2022-08-27 00:00:00 +0800", "snippet": "这是一个你也许听过的寓言故事。有个虔诚的教徒遭遇洪水，他站在屋顶，望着脚下的洪流，祈求上帝的拯救。不一会，有一群人拽着绳子从水中艰难前进，有人说，跟我们走，牵着绳子一起走，他看着没腰的洪水，不敢下来，拒绝了对方的好意，说，你们先走吧，上帝会拯救我的。过了一会，又有几个人划着小船路过，说跳到船里来，我带你走。他看着在水面上摇晃不停的小船和汹涌的浪花，心惊胆战，拒绝了对方的好意，说，你们先走吧，...", "content": "这是一个你也许听过的寓言故事。有个虔诚的教徒遭遇洪水，他站在屋顶，望着脚下的洪流，祈求上帝的拯救。不一会，有一群人拽着绳子从水中艰难前进，有人说，跟我们走，牵着绳子一起走，他看着没腰的洪水，不敢下来，拒绝了对方的好意，说，你们先走吧，上帝会拯救我的。过了一会，又有几个人划着小船路过，说跳到船里来，我带你走。他看着在水面上摇晃不停的小船和汹涌的浪花，心惊胆战，拒绝了对方的好意，说，你们先走吧，上帝会拯救我的。又过了一会，一架直升机在他的头顶路过，上面的人放下绳梯大喊，快上来，马上上来。但他看着风中摇曳不定的绳梯和与狂风搏斗中不断摇摆的飞机，仍然下不了决心，他说，你们先走吧，上帝会拯救我的。洪水淹没了他，他见到了上帝，愤愤的说，我是如此的虔诚，发出最忠实的祷告，您却没有救我。上帝说，我明明派了三拨人去救你，都被你拒绝了。他以为的上帝使者，是带着翅膀，划破黑暗，伸给他宽阔结实的臂膀，但现实并不是。上帝会身穿金甲圣衣，脚踏五彩祥云，在万众瞩目的场合从天而降，救你于水火？醒醒吧。我们遇到过一些人，他们可能自身问题一大堆，但某句话让你突然意识到了生命的真谛。我们遇到过一些人，他们可能很严厉甚至苛刻，但让你认识到社会的残酷和自己的不足。我们遇到过一些人，他们可能不在乎你面子也没有耐心，但给了你机会去尝试和担当。我们遇到过一些人，他们可能很渣很烂，你被迫选择离开但却开启了一段新的旅程。你可以相信上帝，但他不会来。" }, { "title": "Coach 的套路：GROW & ORID", "url": "/posts/2022-07-31/grow-and-orid/", "categories": "Management", "tags": "coach", "date": "2022-07-31 00:00:00 +0800", "snippet": "Coach 时经常会用到一些谈话的套路。GROWGROW 可以用来启发他人自主思考、分析、选择和解决问题。Goal首先要明确目标是什么，然后才有以后得故事。Reality其次认清现实是什么，自己在哪里，离目标还差多远。Options/Obstacles要实现目标的方法有哪些？还有哪些障碍？Will把可行的方法变成行动和执行步骤，一步一步接近目标。ORID焦点讨论法，严谨有层次的提问架构。Ob...", "content": "Coach 时经常会用到一些谈话的套路。GROWGROW 可以用来启发他人自主思考、分析、选择和解决问题。Goal首先要明确目标是什么，然后才有以后得故事。Reality其次认清现实是什么，自己在哪里，离目标还差多远。Options/Obstacles要实现目标的方法有哪些？还有哪些障碍？Will把可行的方法变成行动和执行步骤，一步一步接近目标。ORID焦点讨论法，严谨有层次的提问架构。Objective客观性问题，发生了什么事情。Reflective内心感受，直觉反应是什么。Interpretive诠释性问题，这件事的价值、意义是什么。Decisional决定性问题，找到行动步骤，下决心去做什么。" }, { "title": "A 雇佣 A，B 雇佣 C", "url": "/posts/2022-07-28/a-hires-a/", "categories": "Management", "tags": "talent", "date": "2022-07-28 00:00:00 +0800", "snippet": "这是一个可悲但真实的故事。A 雇佣 A，B 雇佣 C。 只要你仔细观察身边的人，你就会发现，好像真就是那么回事。为什么呢？AA 代表那些最优秀的人，领域里的佼佼者。A 很清楚自己的地位，他们有信心在任何情况下表现出色，因为他们就是这样的人。他们不害怕其他高能力的人，他们相信自己的水平取决自己做的事情，跟外部因素只有一点关系。A 好像也更喜欢和 A 合作，和 A 竞争，因为 A 明白，只有超越...", "content": "这是一个可悲但真实的故事。A 雇佣 A，B 雇佣 C。 只要你仔细观察身边的人，你就会发现，好像真就是那么回事。为什么呢？AA 代表那些最优秀的人，领域里的佼佼者。A 很清楚自己的地位，他们有信心在任何情况下表现出色，因为他们就是这样的人。他们不害怕其他高能力的人，他们相信自己的水平取决自己做的事情，跟外部因素只有一点关系。A 好像也更喜欢和 A 合作，和 A 竞争，因为 A 明白，只有超越其他的 A，才能证明自己是真正的 A。BB 能力也不错，忠诚肯干，公司里大部分劳动力都是 B。B 并没有做错什么，人生哪来那么多大风大浪，我努力做好自己的工作，拿到我应有的回报。有时候 B 也会有意识发现，自己其实是可以成为 A 的。但是，当 B 被安排去招聘时，他们往往会有很多心理活动。太强的人我怎么管？我的竞争优势是什么？我能管理什么样的人？这时候，他们大概会把 Offer 发给一个明显不如他的人，下意识地。C我们都知道 C，他们在最好的情况下，能力也是有限的。不过在面试时，不太容易被发现。在面试时，他们有最好的一面，B 也极力推荐这会是一个很有潜力的员工。B 不希望自己造成了一个招聘事故。C 通常把自己的不成功归咎于外部因素，也就是他们以外的因素，他们不能控制的因素。反正不是我的错，我已经做了所有我应该做的事情，都怪他她它。有什么后果？如果持续让 A 负责招聘工作，公司大概有一个趋势，优秀的人才越来越多，交付结果要求也越来越高。是的，通俗地说，越来越卷了。但最后卷死所有的竞争对手后，你就可以吃掉所有蛋糕。如果持续让 B 负责招聘工作，A 可能会开始离开，B 变成 A，C 变成 B。随着时间的推移，员工的质量越来越差，公司竞争力越来越差，社会开始毒打公司，公司开始裁员。有什么办法？找到谁是 A，谁是 B，谁是 C。其实找到 A 并没那么容易。让正确的人，做正确的事。说起来容易，做起来难。" }, { "title": "吃掉那只青蛙", "url": "/posts/2022-07-26/eat-the-frog/", "categories": "Management", "tags": "time management", "date": "2022-07-26 00:00:00 +0800", "snippet": "青蛙，代表最重要的事情，而次要的事情，我们用蝌蚪来代替。每天早上，我们需要知道，今天要吃掉哪些青蛙。尤其重要的是，我们要勇敢地吃掉最大最丑的青蛙。当然不是硬吃，而是有方法地吃，吃青蛙需要专注，需要技巧，需要勇气。巨大的青蛙需要拆碎了吃，也许一年只能吃一只青蛙，这只青蛙让你记住它的名字，津津乐道。每天花大量的时间在少数青蛙上，没人能一下子对付一大群青蛙。青蛙和蝌蚪需要科学地管理，我们需要给青蛙...", "content": "青蛙，代表最重要的事情，而次要的事情，我们用蝌蚪来代替。每天早上，我们需要知道，今天要吃掉哪些青蛙。尤其重要的是，我们要勇敢地吃掉最大最丑的青蛙。当然不是硬吃，而是有方法地吃，吃青蛙需要专注，需要技巧，需要勇气。巨大的青蛙需要拆碎了吃，也许一年只能吃一只青蛙，这只青蛙让你记住它的名字，津津乐道。每天花大量的时间在少数青蛙上，没人能一下子对付一大群青蛙。青蛙和蝌蚪需要科学地管理，我们需要给青蛙建立一个“池子”，给蝌蚪建立一个“池子”，这样它们就不会乱跳乱跑，打乱你的思绪。哪些青蛙可能已经不用管了，哪些蝌蚪可能变成青蛙。平时工作生活中，大大小小的事，是青蛙，还是蝌蚪？或者什么都不是，那何必去操心，让它去吧。如果你必须吃掉一只青蛙，就算你一直坐在那盯着它也无济于事。开始动筷子吧。" }, { "title": "公开演讲的一些心得", "url": "/posts/2022-07-24/public-speech/", "categories": "Life", "tags": "Speech", "date": "2022-07-24 00:00:00 +0800", "snippet": "做过不少次公开演讲，罗列一下心得，也当时给自己做个备忘。演讲思维演讲思维核心要解决的是自己的问题和别人的问题。自己的问题我是谁，我为什么来做这个演讲？我想要达到什么样的效果和目的。只有你说服自己了，才会有信心站到更多人的面前。对于我来说，我做演讲通常可以用两个原因来解释。其一，公开的演讲可以锻炼我的逻辑思维能力，语言组织能力和沟通表达能力。其二，我希望通过公开的演讲或者分享来让自己更深刻地掌...", "content": "做过不少次公开演讲，罗列一下心得，也当时给自己做个备忘。演讲思维演讲思维核心要解决的是自己的问题和别人的问题。自己的问题我是谁，我为什么来做这个演讲？我想要达到什么样的效果和目的。只有你说服自己了，才会有信心站到更多人的面前。对于我来说，我做演讲通常可以用两个原因来解释。其一，公开的演讲可以锻炼我的逻辑思维能力，语言组织能力和沟通表达能力。其二，我希望通过公开的演讲或者分享来让自己更深刻地掌握一种知识，知识的习得有三个层次，理解知识，运用知识，分享知识。在公开分享之后可能达到一个很深刻的程度。解决完自己的问题后，我们来解决别人的问题。别人的问题听众是谁，为什么来听你的演讲？他们希望获得什么，这个演讲能给我带来什么？作为演讲者要深刻去理解听众的痛点，换位思考，有同理心。越是在重要的场合这样的思考要做的越多，可以找一些核心听众去做访谈，看看他们想要什么，期望是什么样子的。早点做准备拿到第一手反馈，惊喜不是通过保密来得到的，而是通过反复改进得到的。在没开始正式的演讲讲，可以找到一些你信得过的听众提前收集反馈，提前修正问题，公开演讲不是闭卷大考，而是反复批改的开卷作业。演讲模板这个万能的演讲模板来自于《即兴演讲》这本书，很容易套用。其实我更建议在准备演讲前先用思维导图把观点和逻辑关系整理清楚，然后再考虑写稿子。很多时候逻辑清楚了，稿子也没那么重要。抓手意味着你需要有一个不错的切入点，能吸引到听众的注意力，可能是一些拉近距离的寒暄，或者吊人胃口的问题，亦或者一个小故事，能抓住听众就对了。要点演讲的时间是比较短的，要开门见山，当抓住听众后，就要有足够分量的观点让他们继续听下去，所以说重点。结构体用结构化的方式来表达你的观点，有很多可以顺手拈来的结构题，比如： 第一第二第三点 首先其次加最后 过去现在和将来 远处近处和眼前反正能让听众感知到你是有逻辑的，有顺序的，有规律的表达方式，都是可以称之为结构体。结构体可以帮助听众更好理解你的观点，预测你的观点，认同你的观点。呼吁行动大家来了不能只是听一听，演讲的目的更多还是要带来行动。如果你的观点不能让大家有行动的欲望，那么这个观点对别人有什么意义？想想下面的句式你能不能用到自己的稿子里： 我们希望…… 让大家一起…… 我们需要只要改变…… 从今天起，我们可以……刻意练习没有人天生讲话就流利无比，多一些练习罢了。什么样的联系才最有效？刻意练习。在刻意练习里，你需要获得反馈，接受不完美的自己。请尝试做下面这些事： 对着镜子尝试讲话，表达观点，让自己开起来更自然 把自己的演讲片段录下来，反复重听，听到自己不觉得难受为止 寻找可以信赖的伙伴，演讲给他们听，让他们给你建议刻意练习就是找到真正的问题，修正这些问题。" }, { "title": "博客相关的一些记录", "url": "/posts/2022-07-23/blog-tools/", "categories": "Other", "tags": "Blog", "date": "2022-07-23 00:00:00 +0800", "snippet": "一些 Tips 和工具，总是会用得到的。图片自动上传在 Markdown 里贴图片总是很烦，PicGo 可以解决这个问题。工具地址：https://github.com/Molunerfinn/PicGo设置好图床后（我用 Github 仓库）就可以用快捷键截图和上传。在不少编辑器里也默认继承了 PicGo，比如 Typora 或者妙言。编辑器现在主要用 VSCode，因为有插件可以帮忙格式...", "content": "一些 Tips 和工具，总是会用得到的。图片自动上传在 Markdown 里贴图片总是很烦，PicGo 可以解决这个问题。工具地址：https://github.com/Molunerfinn/PicGo设置好图床后（我用 Github 仓库）就可以用快捷键截图和上传。在不少编辑器里也默认继承了 PicGo，比如 Typora 或者妙言。编辑器现在主要用 VSCode，因为有插件可以帮忙格式化和高亮，顺便带 Terminal 写好了之后提交更方便一些。访问测速检查博客从各个地区访问的速度。工具地址：https://www.17ce.com/页面速度优化提供页面加载速度诊断报告和优化建议，来自 Google。工具地址：https://pagespeed.web.dev/report?url=https%3A%2F%2Ftobyqin.cn%2F评论系统方便给静态页面博客添加评论功能，基于 GitHub Disscussion。工具地址：https://giscus.app/其他用到的工具 Vercel 比 GitHub Pages 快一点点 https://vercel.com/ Cloudflare Email 自动转发所有域名邮件 Cloudflare Pages 提供 CDN 加速，可以自定义域名。比如我将 PicGo 上传到 GitHub 的图片仓库托管过去，顺便加了个域名。 图片仓库：https://github.com/tobyqin/img CDN 加速后自定义域名：https://image.tobyqin.cn/" }, { "title": "拉姆斯菲尔德和他的规则", "url": "/posts/2022-07-21/rumsfeld-rules/", "categories": "Management", "tags": "Life, Growth, Leadership", "date": "2022-07-21 00:00:00 +0800", "snippet": "唐纳德・亨利・拉姆斯菲尔德（Donald Henry Rumsfeld，1932—2021），出生于美国芝加哥，德裔美国政治家，美国前国防部长。拉姆斯菲尔德是第一个曾两度出任美国国防部长的人，1975 年至 1977 年在福特政府中出任该职，当时是美国历史上最年轻的国防部长。他写过一本关于自己的书，叫 《拉姆斯菲尔德的规则：在商业，政治，战争和人生中的领导力》，非常精炼地总结了他一生中遵循的...", "content": "唐纳德・亨利・拉姆斯菲尔德（Donald Henry Rumsfeld，1932—2021），出生于美国芝加哥，德裔美国政治家，美国前国防部长。拉姆斯菲尔德是第一个曾两度出任美国国防部长的人，1975 年至 1977 年在福特政府中出任该职，当时是美国历史上最年轻的国防部长。他写过一本关于自己的书，叫 《拉姆斯菲尔德的规则：在商业，政治，战争和人生中的领导力》，非常精炼地总结了他一生中遵循的规则，我在这里列举并尝试翻译，欢迎留言指正，希望对你有所启发和帮助。已知未知There are known knowns. These are things we know that we know. There are known unknowns. That is to say, there are things that we know we don’t know. But there are also unknown unknowns. There are things we don’t know we don’t know.有些事情我们知道自己知道。有些事情我们知道自己不知道。但是记住，有些事情我们并不知道我们不知道，保持谦虚和谨慎是每个管理者应该有的态度。优秀的人A’s hire A’s. B’s hire C’s. If you want to find out which managers are A’s and which are B’s, take a hard look at the teams that surround them.优秀的人会雇佣更优秀的人，不那么优秀的人会雇佣更不那么优秀的人。怎么才能知道哪些管理者是优秀的哪些是不那么优秀的？仔细观察他的团队和他身边的人你就会有答案。度量改进What you measure improves. By measuring or inspecting, you instinctively act and make decisions in ways that make you more likely to achieve the desired result.你度量什么就会改进什么。通过度量和观察，你会本能地去做出反应和决策，这样可以让你更有可能达到你想要的目标。面对错误Bad news doesn’t get better with time. If you have fouled up something, it’s best to tell the boss fast.坏消息不会越来越好，只会越来越坏。如果你已经搞砸了一些事，最好立刻告诉你的老板。头脑清醒Those who write and speak clearly—free of jargon and cant—are most likely to be the ones who think clearly and are therefore indispensable for good decision-making and sound policy.那些能写清楚和说清楚事情的人 —— 没有行话和拐弯抹角 —— 他们可能是是那些思维最清晰的人。这样的人对做出明智的决策和制定健全的制度至关重要。不同的声音If everyone in the room seems convinced of the brilliance of an idea, it may be a sign that the organization would benefit from more dissent and debate.如果房间里每个人看起来都相信一个想法完美无比，无懈可击，这可能表明组织里更需要异议和辩论。人更重要Without the best people in place, the best ideas don’t matter.没有找到最合适的人，再好的想法也没有任何价值。The most motivated employees believe in the why of what they are doing.最有动力的员工知道自己为什么要做这些事，这些事能给他带来什么价值和意义。好的想法Some of the best ideas can come from the sparks and thoughts generated during lively discussions around a conference table or lunch conversation among people who have opposing views.一些最好的想法可能来自于会议桌上激烈的讨论，或者持有相反的观点的人之间的午餐对话。争论可以碰撞出不可思议的火花。重要的事If you are working from your inbox, you are working on other people’s priorities.如果你从收件箱开始工作，其实你是从别人的优先级开始工作。If you don’t know what your top three priorities are, you don’t have priorities.如果你不知最重要的三件事是什么，说明你对重要性没有概念。控制和自由Don’t “over control” like a novice pilot. Stay loose enough from the flow that you can observe and calibrate.不要像一个新手飞行员那样过度控制你所能控制的。保持足够自由，这样你才能去观察和调整自己的姿态。自愿跟随Leadership is by consent, not command. A leader must persuade.领导力是让别人同意和自愿跟随，而不是通过命令让他人跟随。作为领导者必须能说服别人，私下的接触和交流对塑造领导力也至关重要。探索和试错Find out what people are working on, what their worries are, what they are wondering about, and what ideas they might have. Learning new things and forging new relationships takes time for a leader, but it is well worth it.了解人们正在做什么，他们担心什么，他们想要什么，他们有什么想法。对于领导者来说，学习新的东西和建立新的关系都需要时间，但这是非常值得去做的事情。Trial and error are the essence of discovery. Your organization should be hospitable to both.尝试和犯错是探索的本质，你的组织应该鼓励和支持这样的行为。The most successful organizations create an environment that is hospitable to risk-taking, innovation, and creativity.最成功的组织会去创造了一个适合冒险、创新和创造的环境。简单才高效Reduce layers of management. They put distance between the top of an organization and the customers.减少管理的层级，更少的管理层级可以缩短你和真正的客户之间的距离。Prudent managers prune regularly.谨慎的管理者会定期给自己做减法，并不是越多越好。指导后走开A useful lesson for managers is to provide your troops guidance, but then step out of the way and let them do their jobs. If you’ve picked the right people, and trained them well, chances are they will succeed.对于管理者来说，最有用的建议是提供指导，然后让开，让他们去完成自己的工作。如果你选择了合适的人，给他们良好的训练，他们会走向成功。" }, { "title": "战略性思维", "url": "/posts/2022-07-19/strategic-thinking/", "categories": "Management", "tags": "growth, strategy, thinking", "date": "2022-07-19 00:00:00 +0800", "snippet": "关于战略性思维总结的林林总总，说人话来解释。《孙子兵法》里也提到了战略，就一句话：“胜可知，而不可为。”什么是战略性思维战略性思维（strategic thinking）其实就是提高观察问题、思考问题、分析问题和解决问题的高度，提高到战略层面。其实说白了就是思维方式的转变，思考问题更需要关注： 全局性 长远性 根本性目标是为了给个体或者组织提供长远的规划和指导，旨在谋求长远生存和整体利...", "content": "关于战略性思维总结的林林总总，说人话来解释。《孙子兵法》里也提到了战略，就一句话：“胜可知，而不可为。”什么是战略性思维战略性思维（strategic thinking）其实就是提高观察问题、思考问题、分析问题和解决问题的高度，提高到战略层面。其实说白了就是思维方式的转变，思考问题更需要关注： 全局性 长远性 根本性目标是为了给个体或者组织提供长远的规划和指导，旨在谋求长远生存和整体利益（活的更久，活的更好）。这个思维过程包括五个步骤。再换成人话，战略性思维就是聊未来，把未知的东西聊成不可怕的东西，聊成能把握的东西，聊成对自己或者组织有利的东西。老板经常问我，5 年后我想做什么。其实他可能想问的是，5 年后我还能做什么，还能给公司带来什么价值。如果没有价值，我就是一个弃子。什么是批判性思维批判性思维在英文里叫做 critical thinking，换人话就是怼人的思维。当然这个怼是要有事实、证据、观察结果支撑的，需要严谨的思考。批判性思维通常讲究证据、理性、怀疑和不带偏见的评估，用在别人身上不一定好使，因为大家都讨厌被怼。不过为了长远的利益和及时止损，批判性思维还是很有必要，医生说，早发现早治疗早康复。等到扁鹊见蔡桓公的时候，已经没得救了。批判性思维和战略性思维息息相关，通常只有敢于挑战和怀疑当前现实的人，才会去忧虑未来，规划未来。现在的就业情况真的很好吗？公司真的在赚钱吗？会不会明天就把我裁了呢？为什么裁我不裁你？小朋友你有很多问号嘛。批判性思维的关键： 独立思考，保持理性的分析思考 反思质疑，基于事实而非偏见，敢于提问 开放包容，接纳和认可不同的观点养成战略性思维的习惯战略性思维就是要有战斗的感觉，有危机感，如果你现在感觉很爽，那么可能还需要再被社会毒打一段时间才会去思考生存的问题。我们需要经常毒打自己，问自己很难回答的问题，比如： 五年后公司会倒闭吗，做什么业务最赚钱？ 十年后我在哪，我想要干嘛，我在干嘛？ 明天会发生什么，下个月会发生什么，年底会发生什么？ 这个行业还行不行，公司还有没有奔头，奔头在哪里？ 怎么才能让自己不被优化，和我们公司竞争的对手更强了还是更秃了？ 我们的优势还是优势吗，竞争对手又整了什么新武器，明天用户会抛弃我们吗？问这些问题其实不是解题的关键，关键是预测最有可能发生的事情，然后去构造出最有利的场景。场景想象和角色扮演战略性思维需要很强的想象力，想象未来各种可怕或者美丽的场景。当然不是天马行空，而是基于批判性思维的事实，去想象那些最可能发生的场景，最希望发生的场景，然后溜进去进行角色扮演。这时候的你有点像一个有时空穿梭能力的超人，去到最可能发生的未来偷看现在的作业答案。 你期望未来发生什么 - 方向？ 发生的事情是什么样子的 - 细节？ 你的干系人会有什么感受 - 影响？ 你会采取什么措施 - 行动？ 干系人会有什么反应 - 反馈？ 干系人会怎么思考你的行动 - 结果？要从后往前看，最重要的干系人在未来世界的感受和反应，是我们在角色扮演里要思考的问题。如果只是你一个人去到未来，那平时多睡觉，做做梦就行了，不需要上升到战略的高度。战略性沟通和协作什么样的沟通才算是战略性沟通呢？面向未来，勾画路径。 你希望别人知道什么？ 你希望别人感受到什么？ 你希望别人相信什么？ 你希望别人怎么行动？我们常说，人们都是先看见才相信，而不是先相信再看见。其实我们判断的依据是自己认为的事实，如果我觉得某件事是事实，那么我就会以它为基础而采取行动，当然眼见为实会更有说服力，为什么我们能让别人相信你口中的未来是可信的呢？因为你去过未来，你还在未来完成了角色扮演。去过未来的你，需要告诉其他人你知道的，你感受到，你看见的。如果有人相信你，这也是他的未来。" }, { "title": "手机当做 PC 或者 Mac 的摄像头", "url": "/posts/2022-07-18/phone-as-webcam/", "categories": "Tech", "tags": "Tech, Tips, Camera", "date": "2022-07-18 00:00:00 +0800", "snippet": "电脑上没有摄像头，可是开会需要用，用手机开屏幕太小，找到一些软件可以解决这个问题。虚拟摄像头 OBS官网：https://obsproject.com/开源免费的虚拟摄像头，有很多专业的功能，可以模拟场景，声音，视频等等。我不需要那么多功能，只要模拟一个摄像头就行，选择一张自己的大头照或者一段小视频做虚拟摄像头的内容就行。使用方式： 新建场景 添加摄像头数据来源，照片或者视频，如果选视频...", "content": "电脑上没有摄像头，可是开会需要用，用手机开屏幕太小，找到一些软件可以解决这个问题。虚拟摄像头 OBS官网：https://obsproject.com/开源免费的虚拟摄像头，有很多专业的功能，可以模拟场景，声音，视频等等。我不需要那么多功能，只要模拟一个摄像头就行，选择一张自己的大头照或者一段小视频做虚拟摄像头的内容就行。使用方式： 新建场景 添加摄像头数据来源，照片或者视频，如果选视频记得在属性里设置循环 调整转场，如何切换这些数据来源 启动虚拟摄像机然后就可以在 zoom 里选择和使用这个虚拟摄像头了。如果看不到就重启一下 zoom 或者电脑再试试。手机或者 iPad 当摄像头 iriun官网：https://iriun.com/需要手机先安装 app，然后打开 app 等待电脑端 app 启动，如果设备在同一个 wifi 内就可以看到手机摄像头了。非常简单易用，最强大的是还可以调用手机端的麦克风，这样电脑耳机都不用接了，省事。备用方案 neuralcam live官网：https://neural.cam/live/这个 app 貌似也能用，不过不太稳定，一会又一会没有，必须要连接数据线才可以，自从我找到第二个选项后就没管它了，放在这权当备忘。" }, { "title": "猫和狗的领导力", "url": "/posts/2022-07-15/leadership-of-cat-and-dog/", "categories": "Management", "tags": "Life, Leadership", "date": "2022-07-15 00:00:00 +0800", "snippet": "这天，猫和狗在公司的茶水间相遇，聊了会天。猫：“狗子，我想到一个问题。一个团队中不同的人定位是否一定要相同？比如有些人就喜欢安安静静，有些人就喜欢张扬些。”狗：“每个人定位不一样，你看我们团队有温顺的金毛，有活泼的柯基，还有不知好歹的泰迪。在一个组织里就应该多提倡多元化和包容性。”猫：“那只会卖萌好像也不行吧？”狗：“的确，越往上走，软硬技能都要跟上，可以有侧重，但不能完全偏科。”猫：“你说...", "content": "这天，猫和狗在公司的茶水间相遇，聊了会天。猫：“狗子，我想到一个问题。一个团队中不同的人定位是否一定要相同？比如有些人就喜欢安安静静，有些人就喜欢张扬些。”狗：“每个人定位不一样，你看我们团队有温顺的金毛，有活泼的柯基，还有不知好歹的泰迪。在一个组织里就应该多提倡多元化和包容性。”猫：“那只会卖萌好像也不行吧？”狗：“的确，越往上走，软硬技能都要跟上，可以有侧重，但不能完全偏科。”猫：“你说的往上走是走管理路线吧？并不是所有的猫和狗都想做管理的。”狗：“往上走不一定都是走到管理层，比如你做卖萌界的技术专家，领域专家，难道真的只是卖萌吗？肯定是要有一定的领导力和影响力的。”猫：“领导力是什么？必须要带着别的猫和狗才是好的领导力吗？我自己兢兢业业做事情，不求多时尚，但是非常熟练和专业，这算不算领导力？”狗：“如果领导力是一个公式，输出的值关键看你穿进去的参数。”猫：“什么意思？”狗：“这个公式大概长这样：leadership = func(a, b, c, d)”猫：“你太狗了，啥都要写成代码。”狗：“先别管我狗不狗，你说说这公式里都有啥参数？”猫：“我觉得吧，应该有乖巧的态度，卖萌的专业度，行业的影响力，正直的人品啊不，是猫品。”狗：“很不错，不过我觉得你列举的几个参数都是虚的。”猫：“哪些是虚的？”狗：“态度虚不虚？猫品虚不虚？”猫：“好像也不虚呀……”狗：“那你敢说别的猫态度不好吗？她们的猫品不好吗？他们的绩效你打猫品太差信不信她们挠你。”猫：“这么说的确这些是偏主观的判断。那你觉得领导力公式里应该有什么参数？”狗：“我从书上看来的，加上自己浅薄的理解，我觉得这个公式里需要三个参数。”猫：“哪三个参数？”狗：“领导力 = func(榜样, 决策, 价值观)”狗补充道：“榜样就是成为别人的标杆，决策就是帮助组织做出选择承担责任，价值观就是明白组织的目标。”猫：“我觉得榜样这个参数也很虚啊。”狗：“你的专业度，态度，业务能力都是榜样的参数，如果榜样也是一个公式的话，可能是这样的。”狗：“榜样 = max(态度, 专业度, 业务能力...)”狗：“我们当然都想要所有参数都打满的狗，但无奈这样的狗太少了。所以只能找某一个方面里最值得大家学习的先锋和榜样。当然我们还要考虑组织里需要什么的狗，不能都是一个类型的，不仅卷还不健康。”猫：“所以前面说的兢兢业业卖萌但是不爱说话也可以是一个好榜样？”狗：“是的，但要看组织是不是需要这样的狗。”猫：“当然需要啦！至少我们猫界里是需要的。我们需要踏实做事的猫榜样，也需要有号召力的猫榜样，还需要有创新能力的猫榜样。”狗：“我相信你说的应该不是某一只猫能这么厉害。”猫：“对的！不同的猫做不同的榜样。那决策呢？为什么是领导力的一部分。”狗：“你想想但凡伟大的领袖，是不是都做过伟大的决策？那么一只被大家尊敬的榜样猫，如果它不帮助大家做决策，大家凭什么信任它？如果它做的决策不经过脑子，你会选这样的猫做领导吗？”猫：“哦，我大概懂了。在你有足够能力的时候，就应该去承担足够的责任。”狗：“是的。”猫：“那价值观呢？这个也挺虚的啊。”狗：“在老板的眼里，这个最不虚。”猫：“为什么呀？”狗：“老板的目标是啥？公司的目标是啥？你怎么样才能给公司创造价值？”猫：“我们早上 9 点开始卖萌，下午 6 点停止卖萌，兢兢业业，没毛病啊。我们公司不就是卖萌维生的吗？”狗：“那为什么我们卖萌而不卖春夏秋冬虫夏草呢？”猫：“我好像知道了，老板说过，为了公司的生存他的窝都抵押过。他也说过，未来我们要做世界上最能卖萌的一个公司，现在公司里除了猫和狗，还有别的可爱小动物也会被招进来。”狗：“你的领悟能力很不错嘛。”猫：“所以价值观就是对公司的目标和战略的理解和分解能力，如果不去思考这个问题咱顶多也就是个高级宠物。”狗：“你想太多的话，老板会不会觉得你在妄测圣意？”猫：“你又把我带沟里了，你太狗了。我觉得领导力还需要另外一个参数。”狗：“说说看？”猫：“勇气，或者叫厚脸皮。”" }, { "title": "架构设计原则", "url": "/posts/2022-07-10/architecture-principles/", "categories": "Tech", "tags": "Tech, Architecture", "date": "2022-07-10 00:00:00 +0800", "snippet": "摘录自《架构及未来》中的一小部分内容。理想情况下，架构原则将基于高层次的目标决策，架构原则应该和公司的发展愿景和使命相符。目标可能会随着时间的推移而改变，因为原则应该广泛支持未来和当前的目标。原则应该极可能体现 SMART 特性，不过原则一般不受时间限制，SMART 中的 T 缩写是 Test，原则应该可以用来测试设计，验证它是否符合要求。 Specified: 具体的，原则不应该被混淆在...", "content": "摘录自《架构及未来》中的一小部分内容。理想情况下，架构原则将基于高层次的目标决策，架构原则应该和公司的发展愿景和使命相符。目标可能会随着时间的推移而改变，因为原则应该广泛支持未来和当前的目标。原则应该极可能体现 SMART 特性，不过原则一般不受时间限制，SMART 中的 T 缩写是 Test，原则应该可以用来测试设计，验证它是否符合要求。 Specified: 具体的，原则不应该被混淆在它的措辞中。 Measurable: 可度量的，原则不应包含“无限”这样的词汇。 Attainable: 可达到的，原则应该是鼓舞人心的，但能够被设计和现实。 Realizable: 现实的，团队应该有能力达成目标。 Testable: 可测试的，原则应该可以用来测试设计。另外架构原则需要得到团队的任何，应该考虑与团队一起来制定。原则的数量要控制好，确保容易记忆并增加利用率，建议不超过 15 个。15 个架构原则源自于 AKF 官方网站。 N+1 设计。永远不少于两个，通常为 三个。 回滚设计。确保系统能回滚到之前发布的任何版本。 禁用设计。能够关闭任何发布的功能。 监控设计。在设计阶段必须考虑监控，而不是实施后补充。 多活数据中心。不要被一个数据中心限制住。 使用成熟技术。只用确实好用的技术。 异步设计。只有在绝对必要时进行同步调用。 无状态设计。只有业务确实需要时才使用状态。 水平扩展而非垂直升级。永远不要依赖更大更快的系统。 至少有两个步骤的前瞻性。在扩展性问题发生前考虑好下一步行动计划。 非核心则购买。如果不是你擅长的，也提供不了差异化竞争优势则直接购买。 使用商品化硬件。在大多数情况下，便宜的最好。 小构建，小发布，快试错。全部研发要小构建，不断迭代，快速成长。 隔离故障。通过断路避免故障传播和交叉影响。 自动化。如果机器可以做，就不要依赖于人。更多细节可以查看这里。责任矩阵最后，团队在制定和修改原则过程中应该遵循 RASCI 责任矩阵。 R - Responsible - 谁来执行这个任务？ A - Accountable (also Approver) - 谁来审批或者说谁对最终结果负责？ S - Support - 谁在这个任务中提供支持？ C - Consulted - 谁可以提供有价值的建议或者帮助？ I - Informed - 谁应该被通知到任务的进度和结果？JAD &amp; ARBJoint Architecture Design 联合架构设计和 Architecture Review Board 架构审查委员会是积极推动架构设计的两个过程。JAD 是一个协同设计的过程，所有工程人员共同设计和开发一些符合架构原则的新功能。ARB 负责选择和决定每一个新功能或者业务领域的架构，在架构设计得到最终签署之前，要由该委员会确定其符合公司所有的架构原则和业界的最佳实践。JAD 团队中应该包括一名未来负责开发的软件工程师，一位架构师，至少一位运维工程师，产品经理和质量保证工程师，每个人都会给团队带来独特的知识、观点、经验和目标，和团队里其他人可以互补。ARB 的组成最重要的考虑因素是个人特质。首先，必须是组织里受到尊敬的人，他们的地位、任期或者在特定领域的技术业务知识受到人们的尊重。特定位置的人参与，可以确保 ARB 的决定受到广泛尊重。ARB 需要合适的人做出正确的决定，并赋予最终决定的权力。ARB 需要高管的参与，ARB 的参与者要展示自己的专长。ARB 的活动应当被视为每个成员的额外工作。因为 ARB 的工作是自愿的，你可以修改永久或者临时会员的身份。所有的 ARB 应该探讨 ARB 的目的，ARB 审查应只授予那些有充分准备的项目。" }, { "title": "折腾一下小米路由器", "url": "/posts/2022-05-07/miwifi-ax1800-clash/", "categories": "Life", "tags": "Router", "date": "2022-05-07 00:00:00 +0800", "snippet": "折腾一下小米路由器，让家里的网络更通畅一点。 路由器型号：小米 AX1800降级并打开 ssh小米 AX1800 可通过降级固件版本至 1.0.378 版本后开启 SSH。 固件地址： http://cdn.cnbj1.fds.api.mi-img.com/xiaoqiang/rom/rm1800/miwifi_rm1800_firmware_ed621_1.0.378.bin固件下载后...", "content": "折腾一下小米路由器，让家里的网络更通畅一点。 路由器型号：小米 AX1800降级并打开 ssh小米 AX1800 可通过降级固件版本至 1.0.378 版本后开启 SSH。 固件地址： http://cdn.cnbj1.fds.api.mi-img.com/xiaoqiang/rom/rm1800/miwifi_rm1800_firmware_ed621_1.0.378.bin固件下载后在管理界面找到系统升级，选择本地文件升级即可。注意，最好要清除用户配置，否则后面可能会有很多坑，只能重头再来。比如我就遇到了下面这些错误，重新恢复出厂后再拿 ssh 和 root 就自动修复的。遇到过的错误：cp: can't stat '/etc/dnsmasq.d/*': No such file or directory/etc/mixbox/apps/kms/scripts/kms.sh: line 1: can't create /tmp/etc/dnsmasq.d/kms.conf: nonexistent directory# clash-ash: clash: not found降级成功后建议在初始化引导里把固件更新关掉，避免功能失效。登录小米路由管理页面，地址栏 url 里面找到 stok 后面字符串替换掉下面 url 里面的 stok。a. 获取 SSH 权限http://192.168.31.1/cgi-bin/luci/;stok=&lt;STOK&gt;/api/misystem/set_config_iotdev?bssid=Xiaomi&amp;user_id=longdike&amp;ssid=-h%3B%20nvram%20set%20ssh_en%3D1%3B%20nvram%20commit%3B%20sed%20-i%20's%2Fchannel%3D.*%2Fchannel%3D%5C%22debug%5C%22%2Fg'%20%2Fetc%2Finit.d%2Fdropbear%3B%20%2Fetc%2Finit.d%2Fdropbear%20start%3Bb. 修改 root 用户密码为 adminhttp://192.168.31.1/cgi-bin/luci/;stok=&lt;STOK&gt;/api/misystem/set_config_iotdev?bssid=Xiaomi&amp;user_id=longdike&amp;ssid=-h%3B%20echo%20-e%20'admin%5Cnadmin'%20%7C%20passwd%20root%3B需要修改为其他密码自行替换 url 中 admin 部分。复制上面编辑好的 URL 到浏览器地址栏中，然后回车确认，看到以下提示已经成功了。{ \"code\": 0 }好了，已经获取了 SSH 权限，并且修改了 ROOT 用户的登录密码，默认是 admin。通过 ssh 连接路由器即可。$ ssh root@192.168.31.1root@192.168.31.1's password:BusyBox v1.25.1 (2020-11-02 11:05:47 UTC) built-in shell (ash) ----------------------------------------------------- Welcome to XiaoQiang! ----------------------------------------------------- $$$$$$\\ $$$$$$$\\ $$$$$$$$\\ $$\\ $$\\ $$$$$$\\ $$\\ $$\\ $$ __$$\\ $$ __$$\\ $$ _____| $$ | $$ | $$ __$$\\ $$ | $$ | $$ / $$ |$$ | $$ |$$ | $$ | $$ | $$ / $$ |$$ |$$ / $$$$$$$$ |$$$$$$$ |$$$$$\\ $$ | $$ | $$ | $$ |$$$$$ / $$ __$$ |$$ __$$&lt; $$ __| $$ | $$ | $$ | $$ |$$ $$&lt; $$ | $$ |$$ | $$ |$$ | $$ | $$ | $$ | $$ |$$ |\\$$\\ $$ | $$ |$$ | $$ |$$$$$$$$\\ $$$$$$$$$ | $$$$$$ |$$ | \\$$\\ \\__| \\__|\\__| \\__|\\________| \\_________/ \\______/ \\__| \\__|安装配置 ShellClash官方地址：https://github.com/juewuy/ShellClash在路由器的 Shell 界面下输入：#fastgit.org加速export url='https://raw.fastgit.org/juewuy/ShellClash/master' &amp;&amp; sh -c \"$(curl -kfsSl $url/install.sh)\" &amp;&amp; source /etc/profile &amp;&gt; /dev/null#GitHub源export url='https://raw.githubusercontent.com/juewuy/ShellClash/master' &amp;&amp; sh -c \"$(curl -kfsSl $url/install.sh)\" &amp;&amp; source /etc/profile &amp;&gt; /dev/null#jsDelivrCDN源export url='https://cdn.jsdelivr.net/gh/juewuy/ShellClash@master' &amp;&amp; sh -c \"$(curl -kfsSl $url/install.sh)\" &amp;&amp; source /etc/profile &amp;&gt; /dev/null如果安装失败不是因为网络原因，大概就是因为路由器有了奇奇怪怪的问题，建议直接恢复出厂，再来一遍，不需要多次时间。安装完毕后就，就可以配置，里面有个小坑爬了很久。 1 启动/重启clash服务 2 clash功能设置 3 停止clash服务 4 禁用clash开机启动 5 设置定时任务 6 导入配置文件 7 clash进阶设置 8 其他工具 9 更新/卸载选择 6 导入配置文件，进入下面菜单。 1 在线生成Clash配置文件 2 导入Clash配置文件链接 3 还原配置文件 4 更新配置文件 5 设置自动更新选择 1 在线生成Clash配置文件，进入下面菜单。 1 开始生成配置文件（原文件将被备份） 2 设置节点过滤关键字 3 设置节点筛选关键字 4 选取在线配置规则模版 5 选取在线生成服务器 0 撤销输入并返回上级菜单注意，在这里不能直接选菜单 1，必须要先输入一个链接，再按菜单 1，这样才能生成配置文件。比如这样：...-----------------------------------------------请直接输入第1个链接或对应数字选项 &gt; vmess://xxxx我用的是 v2ray 的 vmess 协议，配置文件生成后服务就可以正常启动。如果你的路线没问题，服务启动后连接到路由器的任意设备就可以开始畅通无阻了。小贴士 在高级菜单还可以配置定时重启，自己摸索一下就好。 ShellClash 可以安装网页管理面板，管理地址： http://192.168.31.1/clash/ 在管理面板里可以找到配置菜单，开启局域网 HTTP PROXY 和 SOCKS5 PROXY。（好像有 bug，重启后配置丢失） 在管理面板里可以根据服务类型修改代理规则，比如微软全家桶都走代理，这样 OneNote 和 OneDrive 就好用了。 在管理面板里可以监控连接，可以实时看到访问的服务到底走的是代理还是直连。 clash 功能比较复杂，找到一个官网，但也没太看懂是怎么工作的，相关资料不是太多。 https://lancellc.gitbook.io/clash/ https://github.com/Dreamacro/clash安装配置 mixbox官方地址：https://github.com/monlor/MIXBOX-ARCHIVE安装命令如下。# ghproxy 源一键安装命令【NEW】export MB_URL=https://ghproxy.com/https://raw.githubusercontent.com/monlor/mbfiles/master &amp;&amp; sh -c \"$(curl -kfsSl ${MB_URL}/install.sh)\" &amp;&amp; source /etc/profile &amp;&gt; /dev/null# github 源一键安装命令export MB_URL=https://raw.githubusercontent.com/monlor/mbfiles/master &amp;&amp; sh -c \"$(curl -kfsSl ${MB_URL}/install.sh)\" &amp;&amp; source /etc/profile &amp;&gt; /dev/null# jsdelivr 源一键安装命令export MB_URL=https://cdn.jsdelivr.net/gh/monlor/mbfiles &amp;&amp; sh -c \"$(curl -kfsSl ${MB_URL}/install.sh)\" &amp;&amp; source /etc/profile &amp;&gt; /dev/null注意，确定安装目录前最好确认一下路由器的磁盘空间，如果安装到 /etc 目录很容出现磁盘满的问题。# df -hFilesystem Size Used Available Use% Mounted onmtd:ubi_rootfs 19.3M 19.3M 0 100% /romtmpfs 95.0M 0 95.0M 0% /sys/fs/cgrouptmpfs 95.0M 2.1M 92.8M 2% /tmp/dev/ubi0_2 14.2M 700.0K 12.8M 5% /overlayoverlayfs:/overlay 14.2M 700.0K 12.8M 5% /ubi1_0 15.7M 4.3M 10.6M 29% /dataubi1_0 15.7M 4.3M 10.6M 29% /userdiskoverlayfs:/overlay 14.2M 700.0K 12.8M 5% /userdisk/dataubi1_0 15.7M 4.3M 10.6M 29% /etctmpfs 512.0K 0 512.0K 0% /devoverlayfs:/overlay 14.2M 700.0K 12.8M 5% /userdisk/appdata/chroot_file/liboverlayfs:/overlay 14.2M 700.0K 12.8M 5% /userdisk/appdata/chroot_file/usr/lib通过上面的命令结果，我们知道 /tmp 目录空间最大，但是也不能选，因为它属于 tmpfs， 这是一块虚拟内存，重启后数据就会丢失。AX1800 只有 16M 内存，只能放在 /etc 目录里随便玩玩。*************************************** ***** MIXBOX 工具箱 ********************************************当前版本：[0.1.9.13]\t最新版本：[0.1.9.13]设备型号：[RM1800] \t核心温度：[53°C]***************************************00. 返回主菜单01. aliddns[动态将你的路由器IP绑定到域名] [未安装]02. aliyundrivefuse[阿里云盘 FUSE 磁盘挂载] [未安装]03. aria2[Linux下一款高效的下载工具] [未安装]04. baidupcs[第三方百度网盘web客户端，基于Go语言] [未安装]05. dms[dms是一款DLNA数字媒体服务器] [未安装]06. dropbear[移植小米的SSH功能到工具箱] [未安装]07. easyexplorer[一款跨设备的P2P文件同步工具] [未安装]08. entware[一款开源且强大的包管理工具，许多功能都通过它来实现] [未安装]09. fastdick[迅雷快鸟，宽带提速工具] [未安装]10. filebrowser[Web文件浏览器] [未安装]11. firewall[防火墙端口开放插件] [未安装]12. frpc[内网穿透工具，相对于ngrok资源占用较多] [未安装]13. frps[内网穿透工具Frp服务端] [未安装]14. httpfile[搭建简单的web文件浏览页面] [未安装]15. jetbrains[快速搭建JetBrains激活服务器] [未安装]16. kms[快速搭建Windows、Office激活服务器] [未安装]17. kodexplorer[可道云，在线文档管理器，需要entware环境] [未安装]18. koolproxy[简单，快速屏蔽网页或视频广告，TG：https://t.me/joinchat/AAAAAD-tO7GPvfOU131_vg] [未安装]19. lingmaxdns[DNS优化插件，类似SmartDNS] [未安装]20. miwifi[小米路由器系统管理，修改samba禁用系统更新等] [未安装]21. ngrok[轻量级的内网穿透工具] [未安装]22. npc[一款轻量级、高性能、功能强大的内网穿透代理服务器] [未安装]23. pptpd[简单但并不安全的VPN服务器] [未安装]24. qiandao[koolshare merlin 自动签到程序] [未安装]25. shadowsocks[最好的翻墙工具，没有之一，还可以加速国内外游戏] [未安装]26. smartdns[DNS加速工具，从多个上游DNS服务器查询，避免DS污染] [未安装]27. ssserver[快速搭建ss服务端程序] [未安装]28. tinyproxy[轻量级的Http代理工具] [未安装]29. transmission[一款BT下载神器] [未安装]30. ttyd[网页ssh工具，可在网页上执行 shell] [未安装]31. verysync[基于p2p的文件同步工具，局域网同步速度快] [未安装]32. vsftpd[快速搭建Ftp服务器，局域网文件共享] [未安装]33. webd[一款只有40k大小的mini个人网盘] [未安装]34. webshell[网页ssh工具，可在网页上管理路由器] [未安装]35. zerotier[一款非常简单易用的内网穿透工具] [未安装]看上去能玩的东西挺多，暂时没爬坑，后续再说。顺便提一下，mixbox 里集成的 shadowsocks 其实并不好用： 需要占用不少空间，etc 目录安装不下。 v2ray 支持不友好，我尝试好多方法还是没成功。 启动不成功，github 还类似的问题不少。" }, { "title": "努力是自己的事情", "url": "/posts/2022-05-05/do-it-anyway/", "categories": "Life", "tags": "Poem, Culture", "date": "2022-05-05 00:00:00 +0800", "snippet": "努力说到底，都是是自己的事情。分享一首来自于修女 Month Teresa 的诗《Do it anyway》。Do it anyway People are often unreasonable, irrational, and self-centered. Forgive them anyway. 人们不讲道理、思想谬误、以自我为中心。无论如何，还是原谅他们。 If you are ...", "content": "努力说到底，都是是自己的事情。分享一首来自于修女 Month Teresa 的诗《Do it anyway》。Do it anyway People are often unreasonable, irrational, and self-centered. Forgive them anyway. 人们不讲道理、思想谬误、以自我为中心。无论如何，还是原谅他们。 If you are kind, people may accuse you of selfish, ulterior motives. Be kind anyway. 如果你友善，人们会说你自私自利，别有用心。无论如何，还是要友善。 If you are successful, you will win some unfaithful friends and some genuine enemies. Succeed anyway. 如果你成功了，身边都是假的朋友和真的敌人。无论如何，还是要成功。 If you are honest and sincere people may deceive you. Be honest and sincere anyway. 如果你诚实坦率，可能会让你更容易受到欺骗和伤害。无论如何，还是要诚实坦率。 What you spend years creating, others could destroy overnight. Create anyway. 你耗费数年所建造的一切可能顷刻之间就可以被人毁灭。无论如何，还是要建造。 If you find serenity and happiness, some may be jealous. Be happy anyway. 如果你找到了平静和幸福，有些人可能会嫉妒你。无论如何，还是要幸福。 The good you do today, will often be forgotten. Do good anyway. 今天做的好事，往往会被人忘记。无论如何，还是要做好事。 Give the best you have, and it will never be enough. Give your best anyway. 将你所拥有最好的东西献给世界，有时候还是会被人忘记。无论如何，还是要做最好的事情。 In the final analysis, it is between you and God. It was never between you and them anyway. 你看，说到底，这是你和这个世界的事情，与别人无关。" }, { "title": "熊来了", "url": "/posts/2022-04-01/bear-is-coming/", "categories": "Life", "tags": "Joke, Culture", "date": "2022-04-01 00:00:00 +0800", "snippet": "这是一个从书上看来的小故事，应该有人听过。故事这样说的，有一天，森林里有一只熊跑进了IBM的办公室。它饿极了，就想着怎么吃掉一个人但是又不能被发现。它认真观察了几天，发现一个三线老板（相当于总裁或者总监级别的高管）过得很滋润，每天就是打打高尔夫，基本不用上班，这只熊就把他吃掉了。吃完后两周，没有任何人发现这个老板不见了，熊很开心。熊又观察了一段时间，发现二线老板（相当于高级经理级别的高管）每...", "content": "这是一个从书上看来的小故事，应该有人听过。故事这样说的，有一天，森林里有一只熊跑进了IBM的办公室。它饿极了，就想着怎么吃掉一个人但是又不能被发现。它认真观察了几天，发现一个三线老板（相当于总裁或者总监级别的高管）过得很滋润，每天就是打打高尔夫，基本不用上班，这只熊就把他吃掉了。吃完后两周，没有任何人发现这个老板不见了，熊很开心。熊又观察了一段时间，发现二线老板（相当于高级经理级别的高管）每天只是回回邮件，开开会，骂骂人，也没什么特别的事情要做，熊觉得吃掉他应该也不会对公司有任何影响，于是就把这个老板也吃掉了。吃完后两周，没有任何人发现这个老板不见了，熊挺开心，有些员工貌似也挺开心的。熊胆子越来越大了，决定继续行动。它仔细观察了发现，一线经理每天就是忙着批流程，作报告，也没啥用处，于是它选了一个一线经理，把他吃掉了。吃完后两周，公司内部开始有人觉得不对劲了，因为很多事情没有人批复了。这时候熊意识到自己吃一线经理是一个错误，准备撤退。在撤退前它匆忙间吃掉了一个搞卫生的阿姨。这下可坏了，大家马上发现公司里卫生没人搞了，全公司上上下下都惊呼起来：“熊来了！”这个故事据说是IBM内部广为流传的一个笑话，可见当你的蓝色巨人有着非常睿智的文化和气度，敢于自嘲。很多很庞大复杂的公司内部都需要这样的熊，你觉得呢。" }, { "title": "逃避问题的蛤蟆", "url": "/posts/2022-03-01/toad-and-monkey/", "categories": "Life", "tags": "Joke, Culture", "date": "2022-03-01 00:00:00 +0800", "snippet": "书上的小故事，挺有趣。说，一个雨夜，一只猴子和一只癞蛤蟆坐在一棵大树底下，一起抱怨这阴冷的天气。“咳！咳！” 最后猴子被冻得咳嗽起来。“呱——呱——呱！”癞蛤蟆也冷得叫个不停。当它们被淋成了落汤鸡，冻得浑身发抖的时候，它们商议再也不过这种日子了，于是它们决定天一亮就去砍树，用树皮搭个暖和的棚子。第二天一早，当橘红的太阳在天边升起，金色的阳光照耀着大地的时候，猴子尽情地享受着阳光的温暖，癞蛤蟆...", "content": "书上的小故事，挺有趣。说，一个雨夜，一只猴子和一只癞蛤蟆坐在一棵大树底下，一起抱怨这阴冷的天气。“咳！咳！” 最后猴子被冻得咳嗽起来。“呱——呱——呱！”癞蛤蟆也冷得叫个不停。当它们被淋成了落汤鸡，冻得浑身发抖的时候，它们商议再也不过这种日子了，于是它们决定天一亮就去砍树，用树皮搭个暖和的棚子。第二天一早，当橘红的太阳在天边升起，金色的阳光照耀着大地的时候，猴子尽情地享受着阳光的温暖，癞蛤蟆也躺在树根附近晒太阳。猴子从树上跳下来，问癞蛤蟆：“嗨！我的朋友，你现在感觉如何？”“啊哈，再好不过了！” 癞蛤蟆回答说。“我们现在还要不要去搭棚子呢？” 猴子问。“猴子老兄，你说是动刀动斧地砍树皮好呢，还是在温暖的阳光下饱饱地睡上一觉好呢？” 癞蛤蟆懒洋洋地说，“再说动刀动斧的，碰到自己怎么办？”“那好吧，棚子可以等明天再搭！” 猴子也爽快地同意了。它们为温暖的阳光整整高兴了一天。天有不测风云，傍晚，又下起雨来。它们又一起坐在大树底下。“咳！咳！”猴子又咳嗽起来。“呱——呱——呱！”癞蛤蟆也冻得喊个不停。它们再一次下了决心：明天一早就去砍树，搭一个暖和的棚子。可是，第二天一早，橘红的太阳又从东方升起，大地再一次洒满了金光。猴子高兴极了，赶紧爬到树顶上去享受太阳的温暖。癞蛤蟆也一动不动地躺在地上晒太阳。猴子又想起了昨晚说过的话，可癞蛤蟆说什么也不同意。“干吗要浪费这么宝贵的时光，棚子留到明天再搭嘛！”" }, { "title": "2021年，再见", "url": "/posts/2021-12-31/goodbye-2021/", "categories": "Life", "tags": "Reading", "date": "2021-12-31 00:00:00 +0800", "snippet": "2021 年马上要结束了，365 天仿佛也很短，去年的总结貌似也没过去多久。今年一年没写超过 20 篇博客，文字表达能力下降了很多，胡扯的能力貌似上升了不少。反思和成长这个年龄聊成长看上去挺离谱的，实际上并不是。工作十年，在外人看来你已经是一个很资深的工程师了，但实际上人外有人，在你的领域外还有很多领域。甚至在你的领域里，你发现要学的东西还是很多。今天看了本书，里面说吴军老师是作者特别敬佩的...", "content": "2021 年马上要结束了，365 天仿佛也很短，去年的总结貌似也没过去多久。今年一年没写超过 20 篇博客，文字表达能力下降了很多，胡扯的能力貌似上升了不少。反思和成长这个年龄聊成长看上去挺离谱的，实际上并不是。工作十年，在外人看来你已经是一个很资深的工程师了，但实际上人外有人，在你的领域外还有很多领域。甚至在你的领域里，你发现要学的东西还是很多。今天看了本书，里面说吴军老师是作者特别敬佩的一位老师。吴军是计算机科学技术，是自然语言处理技术的先驱，是谷歌的搜索科学家，是腾讯的副总裁，同时还是硅谷著名投资人，写了接近 10 本书，本本都是硬核畅销书。吴军老师涉猎之广，研究之深，让人叹服。这一年我对自己的反思：输入太多，输出太少。我每天可能需要处理几十甚至上百封邮件，和十多人频繁沟通，开 3 到 5 个会。这该死的信息量，并不能用比特来衡量。在处理完这些消息后留给我反思的时间就不多了，因为下一批信息马上就要来了。这里面有问题，如果不是我能力不够，就是这个姿势是有不正确的。我们程序员是怎么处理高并发消息的？有几个策略可以借鉴一下。 提高应用处理的性能 集群处理，负载均衡 异步处理，消息队列有点启发了。优化完消息处理方案后还是要腾出时间来输出，因为一个人的价值不是看你处理消息的能力，而是看你处理消息后输出的能力。你的价值不是自己评估的，而且其他人评估的。数字化思维最近几天也有一些朋友陆续发出了自己的年底总结，大家都会列举一些数字来说明问题，这是一种很不错的习惯。比如你说自己从 70 公斤减到了 60 公斤，比说自己要开始健身更有说服力。比如我说今年我在 Github 贡献了 20000 行代码，比说我热爱开源更可信。在数字化驱动的世界里，其实有两种声音，一是一定要数字化，另外一种是数字化要把握尺度。一定要数字化是为了让我们有办法去度量和改进，把握尺度就是理性评估和使用数字，数字可以作为参考，但切莫当做金科玉律。出了教科书，很少会有万能的公式和定理。比如说，我们一定要知道产品有多少 bug，但是 bug 的多少并不代表质量的好坏。比如说，我们一定要知道需求交付的周期，但也不能用越来越短的周期作为业务目标。关于数字驱动力有一个有趣的现象，就是一旦你用数字（指标）作为目标，团队就一定会想办法达成这个目标（实现这个数字），只不过，团队实现的方式不一定是按照你期望的方式。我们要明确数字背后的目的，不要忘了为什么取这个数字。简单并不简单人人都喜欢简单方案，尤其是老板。不要太复杂，越简单越好，尽量用最低成本实现。我们工程师当然也梦想做出简单、可靠、优雅的产品。解耦，易维护、bug 少还稳定，但其实这个简单可能和老板说的简单不太一样。老板的台词可能是：快点做完，不要太多钱，不需要那么多人。找到简单方案，可能是一件非常复杂的问题。因为你要确定，什么是可以被简化的？简单往往是在复杂之后，我们不能只吃打饱嗝前的那口饭。简单始于复杂，没有对比谈何简单。平衡并不容易这一年下来越发知道平衡是一件多么不容易的事情。我们到底是谁？谁才是我们？我们是一个公司里的一部分，也是家庭里的一部分。但是公司里的其他部分和家庭里其他部分并不可能是我们的一部分。这样会有冲突，而且是必须要做出选择的冲突，怎么平衡呢？想想目标是什么，就有答案了。想要平衡的初衷是什么。新的一年开玩笑是这么讲的，明年的目标就是把今年没完成的目标实现，今年的目标就是把去年的遗憾补齐。但我们其实都是在长大甚至变老，盛年不重来。对自己负责的方式是面对自己存在的问题，去尝试解决它们。成人的世界里找不到太多理由，你选择逃避最后只能被社会毒打，而且毒打你的不止一个人。一起共勉，2022 我们可以做更好的自己，成长，思考，简单，平衡。" }, { "title": "敏捷研发的关键性原则", "url": "/posts/2021-11-28/effective-agile/", "categories": "Tech", "tags": "Agile, Scrum", "date": "2021-11-28 00:00:00 +0800", "snippet": "源自于最近阅读的一本书《卓有成效的敏捷》，作者 Steve McConnell。检视和调整敏捷是一种依赖于从经验中学习的经验性方法。这需要创造机会定期反思并根据经验进行调整。从 Scrum 开始Scrum 并非敏捷之旅的最终目的，但它是最为结构化、支持最好的起点。搭建跨职能团队敏捷项目的工作发生在自我管理的团队中。要自我管理，因队必须包含做出对组织有约束力的良好决策所需的全部技能。将测试人员...", "content": "源自于最近阅读的一本书《卓有成效的敏捷》，作者 Steve McConnell。检视和调整敏捷是一种依赖于从经验中学习的经验性方法。这需要创造机会定期反思并根据经验进行调整。从 Scrum 开始Scrum 并非敏捷之旅的最终目的，但它是最为结构化、支持最好的起点。搭建跨职能团队敏捷项目的工作发生在自我管理的团队中。要自我管理，因队必须包含做出对组织有约束力的良好决策所需的全部技能。将测试人员整合到开发团队中通过让做事的人更紧密地一同工作来加强开发和测试之间的反馈循环。通过自主、专精和目标来激励团队敏捷实践天生就支持那些有助于激励的因素。团队旨在自主地工作并不断改进（专精）。为了做到这一点，他们需要理解目标。“健康的敏捷团队”与“积极进取的敏捷团队”是互为表里的。培养成长恩维无论你是从自主、专精和目标的专精角度看还是从检视和调整的角度看，高效敏捷团队持续地关注于变得更好。培养以业务为中心开发人员经常需要在产品负责人的指导下填补需求中缺失的细节。理解业务有助于以对业务有益的方式填补这些细节。加强反馈循环不要花更长时间学习不需要的经验教训，而是尽可能加强反馈循环。这有助于通过检视和调整获得更快的进步，以及通过培养成长思维更快地改善效果。修正系统，而不是处理个人大多数软件从业人员都想做好工作。如果他们没有把工作做好，特别是如果他们看起来没有尽力把工作做好，应该去了解是什么导致了这一点。找出让个人感到挫败的系统问题。通过培养个人能力来提高团队能力。团队呈现的品质是团队中个人品质以及他们之间的互动，通过强调个人来加强团队。保持 sprint 短小短 sprint 支持频繁的检视和调整的反馈循环。短 sprint 能使问题更快暴露，更容易在小问题变成大问题前将它们消灭在萌芽状态。以重直切片的方式交付。敏捷中的反馈很重要。当团队以垂直切片而不是水平切片的方式交付时，他们能够得到有关其技术和设计选择方面更好的反馈既有来自客户的反馈，也有来自业务的反馈。管理技术债持续关注质量是高效敏捷实施的一部分。管理技术债能带来更高的团队士气、更快的进展，以及更高质量的产品。通过架构支撑大型敏捷项目良好的架构能够支持项目的工作拆分并最小化大型项目特有的日常开销。优秀的架构能够让大型项目感觉上像较小的项目。使缺陷检测的时问最短修复缺陷的成本往往随着缺陷停留时间越长而变得越高。敏捷注重质量工作的一个好处是在更靠近源头的地方检测出更多缺陷。制定并采用完成定义良好的完成定义（Definition of Done）有助于及早发现不完整或错误的工作，最大限度地缩小缺陷引人和缺陷检测之间的时间。将质量维持在可发布水平将质量维持在可发布水平有助于捕获早期完成定义遗漏的额外缺陷。由开发团队编写自动化测试自动化测试有助于最小化缺陷检测时间。让团队中的每个人都负责测试强化了质量是每个人的责任这一理念。细化产品待办事项列表产品待办事项列表细化确保团队处理最高优先级的事项，不会在没有产品负责人的情况下自行填补需求细节，并且不会让团队没有工作而陷人空转。制定并使用就绪定义待办事项列表细化的部分工作是确保需求在团队开姶实现前确实准备就绪（Definition of Ready）。自动化重复性工作没有人喜欢重复性工作，而且当把软件开发中能够自动化的工作进行自动化后，许多工作能的比不进行自动化带来更多收益。管理结果，而不是管理細节通过清晰地沟通期望结果的方式来保护团以的自主性，同时让团队自由决定完成工作的细节。用指挥官意图明确表达目标通过明确传达期望的最终状态的目标，来支特团队能够进行及时的内部决策。关注吞吐量，而不是关注活动类似管理结果，细微差别在于忙碌并非目标 —— 搞定有价值的工作才是目标。在关键敏捷行为上以身作则高效的领导者也会展现出他们想从员工身上看到的那些行为。正向看待错误正向看待错误，以便团队可以毫不犹豫地将错误暴露出来．这样能够从中汲取教训。不从过往错误中汲取教训会让公司再次蒙受损失。以量化的团队产能为依据制订计划敏捷是一个经验性方法，团队和组织应该基于量化的产能来计划工作。" }, { "title": "人月神话笔记", "url": "/posts/2021-11-25/the-mythical-man-month/", "categories": "Tech", "tags": "project management, software development", "date": "2021-11-25 00:00:00 +0800", "snippet": "一些零零碎碎的读书笔记，这是一本比我年纪还大的书，作者布鲁克斯(FrederickP.Brooks.Jr.)写于 1975 年，源于作者在 IBM 公司任 System 计算机系列以及其庞大的软件系统 OS 项目经理时的实践经验。正文开始。焦油坑编程的世界犹如史前时期的焦油坑，上帝见证了恐龙，猛犸，剑齿虎在里面挣扎，他们越挣扎，焦油就越紧，没有任何猛兽足够强壮和具有足够的技巧来挣脱束缚，最后...", "content": "一些零零碎碎的读书笔记，这是一本比我年纪还大的书，作者布鲁克斯(FrederickP.Brooks.Jr.)写于 1975 年，源于作者在 IBM 公司任 System 计算机系列以及其庞大的软件系统 OS 项目经理时的实践经验。正文开始。焦油坑编程的世界犹如史前时期的焦油坑，上帝见证了恐龙，猛犸，剑齿虎在里面挣扎，他们越挣扎，焦油就越紧，没有任何猛兽足够强壮和具有足够的技巧来挣脱束缚，最后都会沉入坑底。编程世界随着时间和资源的投入，最终会变的无比复杂，但还是会有更多人前仆后继，这个过程中有很多乐趣也有很多苦恼，这是一个许多人痛苦挣扎的焦油坑，多许多人而言，其中的乐趣远大于苦恼。人月神话在众多软件项目中，缺乏合理的时间进度是项目滞后的最主要原因。这个问题主要有 5 个原因。 乐观主义和不真实的假设–假设一切都运作良好。 错误将进度和工作量互换，假设人和月可以互换。 不能持续进行估算，是的，估算也是需要持续进行的。 缺少进度跟踪和监督。 当意识到进度偏移时，下意识增加人力。这个章节有很多名言被引用过，例如无论多少个母亲，孕育一个生命都需要十个月。往进度滞后的项目加入更多的人力，只会让进度更落后 – 对于错综复杂的项目尤其明显。外科手术队伍对于大项软件项目，其中的每一部分都应该由一个团队解决，类似于外科手术队伍，而非一拥而上。这个队伍里所有专业的人都在解决问题，系统是一个或最多两个人的产物，在客观上达到概念的一致。优秀的专业开发人员的生产率是较差的开发人员的 10 倍。贵族专制和系统设计大教堂是历史上无与伦比的成就，达到了风格上的一致，但也代表了众多艺术家的技巧。系统设计也一样，概念一致性和完整性是架构师的责任，需要专制，但并不是只有架构师在创造并获得所有的荣誉，在实现过程中一样需要创造力和技术。画蛇添足项目经理不喜欢招第二次设计系统的架构师，因为往往在开发自己的第二个系统时，设计师所设计的系统的是最危险的，他们会不断装饰和润色，把第一次做系统的遗憾都想办法弥补掉，自律是设计师最重要的品质，设计师其实是用户的代理，易用性才是设计师的价值。贯彻执行如果确保所有人听从、理解并实现架构师的决策？文档是非常必要的工具，这也是架构师的产物。形式化定义比文字化叙述更有效，比如使用公式，图形等等。除此之外还有会议，日志，测试等流程可以确保项目被正确交付。为什么项目会失败：除了目标，人力，材料，时间和技术之外，交流其实更为重要，作者建议通过所有可能的途经来保持项目的透明度，非正式途经，会议，工作手册。另外为了提高交流的效率，大型项目合理的组织结构应该是树形的，参考前文的外科手术团队。胸有成竹实践是最好的老师，但如果不能从中学习，再多的实践也没有用。削足适履规模是软件系统产品用户成本一个重要部分，开发人员必须设置规模的目标，规模本身不是坏事，但是不必要的规模是不可取的。这里主要讲的是规模控制和管理，这是一件颇具技巧的事情。因为在一定的时间和空间要求下达到用户期望，对程序员的技艺有很高要求。提纲挈领项目记录决策是必要的，只有记录下来，分歧才会明朗，矛盾才会突出。文档还是同其他人沟通的渠道，只有书面计划是精确和可沟通的，如果一开始就认识到它的普遍性和重要性，就可以更好利用起来，而不会让它变成繁重的任务。未雨绸缪化学工程师很早就认识到，在实验室进行的化学反应，并不能在工厂中一步实现，普遍的做法是，选择一种方法，试试看，如果失败了，没关系，再试试别的。不管怎样，最重要的是先去尝试。一旦认识到实验性的系统必须被反复构建和丢弃，具有变更思想的重新设计不可避免，我们必须接受这样的事实，变化是与生俱来的。干将莫邪a good workman is known by his tools。巧匠因他的工具而出名。在软件项目中维护公共的通用工具有助于提高效率，另外项目经理必须意识到专业工具的需求，在这类工具不能吝啬人力和物力，对工具的熟练程度也极大影响了生产力。另外一面不同用户需要不同的文档，例如使用程序，验证程序，修改程序，这些文档的描述方式都不一样。作者认为正确维护文档的方式是将文档整合到源代码中，这也被称之为自动化文档。自动化文档激发了高级语言的使用，是一种值得推荐的方式。没有银弹软件工程中的根本和次要问题，没有任何技术或者管理上的进展，能许诺十年内使生产率，可靠性和简洁性获得数量级上的进步。这个章节很知名，我觉得大概的原因是作者用非常肯定的预期预测了未来，所以很多（聪明的）人总是想用各种方式来推翻作者的论断，无奈事实证明，真的没有银弹。作者基本的思路就是将软件工程拆分为了根本问题和次要问题，并尝试列举了其中的可能银弹，用来证明这样的事情并不现实，另外我还认为作者在激将和钓鱼，如果真的有人找到了银弹，对人类和社会而言，何尝不是一件好事。解释一下银弹的背景：在所有恐怖民间传说的妖怪里，最可怕的是人狼，因为它们可以完全出乎意料地从熟悉的面孔变成可怕的怪物，为了对付人狼，我们在寻找可以消灭它们的银弹。大家熟悉的软件项目有一些人狼的特性，常常看似简单明了的东西，却有可能变成一个进度落后，超出预算，存在大量缺陷的怪物，因为我们听到了近乎绝望的寻求银弹的呼唤，寻求一种可以使软件成本降低，工作效率倍增的尚方宝剑。再论没有银弹属于再版后的番后篇，因为这篇文章发出后的确引来了极大地争议，其中有一篇论文作者也赞同其中的观点，叫《这就是银弹》，里面指出重用和交互的构件开发是解决软件根本困难的一种方法。对于解决软件的复杂性，可以有两种思路：层次化，通过分层来实现模块或者对象；增量化，持续地添加功能。但这也是导致系统复杂的原因，乐观主义是程序员的通病。还有另外一个观点，质量可以带来生产率的提高，关注质量，生产率会自然提高。总结软件开发的核心观点：概念完整性，一个整洁，优雅的产品必须向它的每个用户提供一个调理分明的概念模型，概念完整性是易用性中最重要的因素。结构师，结构师是用户的代理，也是概念模型的解释者，不清楚作者提到的结构师在当前的时代是哪类角色，不太像架构师，有点像产品经理，或者是二者的合体。书本最后一部分主要是总结和观点再论述，这本书浓缩度极高，有点费脑子，不过推荐阅读。" }, { "title": "管理者核心能力修炼", "url": "/posts/2021-10-23/leadership/", "categories": "Life", "tags": "Leadership, Management", "date": "2021-10-23 00:00:00 +0800", "snippet": "一个培训课程的核心内容提炼，且看且领悟。沟通管理就是沟通，沟通，再沟通。沟通和协作是管理者的生命线。跨部门沟通 推倒部门墙，成就高效跨部门沟通和协作跨部门沟通是管理者沟通能力的试金石，影响力就是领导力。跨部门的三大难点： 利益目标不一致 情感交情不到位 信息资源不对等跨部门沟通和协作的三大原则： 明确目的第一，实现手段第二 认真思考第一，立即行动第二 沟通影响第一，信息传递第二...", "content": "一个培训课程的核心内容提炼，且看且领悟。沟通管理就是沟通，沟通，再沟通。沟通和协作是管理者的生命线。跨部门沟通 推倒部门墙，成就高效跨部门沟通和协作跨部门沟通是管理者沟通能力的试金石，影响力就是领导力。跨部门的三大难点： 利益目标不一致 情感交情不到位 信息资源不对等跨部门沟通和协作的三大原则： 明确目的第一，实现手段第二 认真思考第一，立即行动第二 沟通影响第一，信息传递第二目标： 沟通是为了达成目的，从目的出发更高效，双赢是跨部门沟通的合作保证。思考： 做正确的事比把事情做正确更重要，快和慢的辩证关系，三思而后行，缓决策而快行动。影响： 不控制命令，但影响促进。先解决意愿，后信息传递，寻找合作共赢的机会，建立情感银行。跨部门协作六步法：共同目标 → 利益诉求 → 沟通机制 → 合作规则 → 统一管理 → 行动跟进。共情共赢沟通是人与人之间，人与群体之间思想和情感的传递和反馈的过程，以求思想达成一致和感情的通畅。沟通的三个境界：（我，你）→（我和你）→（我们）如何共赢：达成一致的本质就是价值交换，同理心是达成一致的利器。关键确认：让重要事情不遗漏，复述确认理解，监督确认执行。同情共鸣：感情让沟通更流畅，微笑，赞美，共同点，拉近距离。 事前： 快速有效培养积极关系，互惠和喜好。先给与，再索取。 事中：减少不确定性，从众和权威，证明这是多数人和权威的选择。 事后：激励行动，承诺和稀缺。感谢，跟踪，反馈。 如非必要，聚焦目标，让出控制权。冲突管理冲突管理的关键：如何处理利益冲突。冲突谈判的技巧： 做好准备，明确目标权力 选择预案，以备不时之需 调查对手，明确对方利益 陈述观点，阐明自身意图 和谐洽谈，力求双方共赢冲突和矛盾的底层原因是沟通的失效，前期有效的沟通是解决矛盾的根本。冲突往往也是创新的机会，往往会带来着新的思路和机遇。激励 有效激励，点燃员工的心火激励的本质：为了实现目标的统一，个人和组织目标的完美契合。激励理论马斯洛需求层次，双因素理论，人性假设理论。马斯洛需求层次理论 生理需求：维持个体生存，满足基本需求。（性，食物，水，睡眠，空气） 安全需求：保障安全稳定，免除恐惧威胁。（安全，就业，资源，健康，财产） 爱与归属：建立感情联系，归属某一群体。（情感，归属，友谊，家庭） 尊重需求：内在价值肯定，外在成就认可。（自尊，自信，成就，尊重） 自我实现：充分发挥潜能，实现理想抱负。（实现梦想，发挥潜能，自发性，创造力）双因素理论 保健因素：好比一日三餐，如果不吃可能会饿死，能保证员工的稳定性。（工资，环境，地位，福利等等） 激励因素：好比水果，不吃不会饿死，但吃了更健康，能使员工有更好的表现。（成就，认可，进步，晋升等等）人性假设理论 人性本恶 X：消极的人性观点，人不喜欢工作，没有责任，必须监督和指挥。 人性本善 Y：积极的人性观点，人喜欢工作和游戏、休息一样，会主动寻求责任，愿意自我激励。根本原因：种瓜得瓜，种豆得豆，你如何假设，就有何种结果。如果发现老板是特别强调对员工严加管教，那他背后就是 X 理论，我们要想办法让他了解 Y 逻辑，并逐渐去影响他。团队激励团队激励的本质就是团队氛围建设，团队氛围直接影响人们的工作表现。组织氛围就是“社会相互作用背景”，是无法拒绝的社会力量。组织气氛由领导的行为产生，领导风格对组织气氛起决定性作用。团队建设六性： 明确性：边界的划分，清楚工作要求和职责，明确组织目标，个人目标，个人和组织的关系，责任分工。 标准性：绩效定义，可以达到目标的程度。 责任性：责任范围，负责程度，授权程度，价值发挥，自我实现。 灵活性：受约束程度，新想法接受程度。华为灰度管理，阿里孕妇装故事，加班餐票故事。 奖励性：被承认和奖励，奖励和工作的关系，绩效评价和行为强化，职业生涯设计，力出一孔，利出一孔。 凝聚性：团队自豪感，相互信任，相互合作，奉献精神，愿意付出额外努力。个人激励传统激励，萝卜大棒：奖励鼓励的行为，惩罚不鼓励的行为。本质是行为控制，职场新人已经免疫。通用激励，情感激发：赞美，尊重，信任，情感，心理学基础 —— 互惠。 赞美： 最简单且最好的激励方式，发自内心，真诚且具体，及时赞美，赞美行为胜过结果。 尊重：激励员工的法宝，尊重别人的努力，尊重别人的观点，尊重边界 —— 多元化。 信任：激发使命和责任感，平等待人，尊重下属，放手去做。 情感：心与心的桥梁，上君尽人之心，中君尽人之力，下君尽己之能。举例子： 高层：四肢砍掉，只留脑袋 —— 只要想，不要插手 中层：屁股砍掉，不要让屁股决定脑袋，多换位思考。 基层：脑袋砍掉，需要有强有力的执行力。超级激励，信念一致：关注对他人产生的影响，让自己共鸣的语言表达。 对目标发自内心的认同 内驱力，无需外部奖惩 自我承诺和自我掌控目标激励的关键：理解，清晰，认可，认同，使命。管理 vs 领导 管理者是高效团队建设的核心，文化为核心，实现有情无情绝情的平衡。管理者决定了团队的目标和方向（WHY），以及分工和资源（HOW）。团队文化文化引领为核心，文化引领是带团队的灵魂。 有情的领导 无情的管理 绝情的制度建立“场”和“灵魂”的关键。 信念：激情的力量 立场：理性的力量 假设：牵引的力量 共识：凝聚的力量 习惯：执行的力量 契约：承诺的力量好的企业文化：因地制宜，动态环境，渐进式改变，有利于企业目标实现，有利于提升企业核心竞争力。平衡是技术管理以事务为主，制定目标，针对现在 —— 正确地做事。领导以愿景为主。激励主动，面向未来 —— 做正确的事。 区别点 管理者 领导者 本质 追求稳定性 追求变革性 规则 制定规则 打破规则 方法 详细计划 设定方向 文化 贯彻执行 塑造文化 冲突 避免冲突 利用冲突，推动进步 方向 固有路径 开辟新道路 赞誉 占有 给与 决策 制定 促进，鼓励 愿景 传递，告知 推销 管理和领导没有对错，关键是平衡，两者缺一不可，不能相互替代。右手管理，左手领导。没有管理，企业将陷入混乱，难以有效运营。行为过多，容易导致关系紧张，上下级距离感拉开 —— 企业的下限。没有领导，企业将变得僵硬，失去战略竞争。领导过多，容易出现你好我好大家好的局面 —— 企业的上限。没有制度，企业没有规范，流程无法保证效率，国有国法，家有家规 —— 企业的红线。 领导是做正确的事，管理是正确地做事。 沃伦.本尼斯 管理就是维持秩序，而领导是引领变革。 约翰.科特案例： 团队承诺完成目标后有高额奖金，年底拼尽了全力还是没完成，作为老板，你会怎么办 员工上班时间在睡觉，作为老板，你会怎么办，你看到什么问题团队策略团队策略是成功的方向，如何制定团队策略？ 认清上级策略和方针 考虑各种可能性 按照影响力排序 测试最优的几个想法 定义团队策略聚焦最重要的目标，关注引领性指标，建立规则问责制度。团队文化团队文化的本质：模仿他人，接受并同化，看法从众。打造团队文化的工具： Knowing：认知改变 Doing：行为改变 Being：习惯改变例子：电梯实验。参考书单 《思考，快与慢》—— 卡尼曼 《新情商》—— 戈尔曼 《自我边界》—— 戴德" }, { "title": "QECon的零碎笔记", "url": "/posts/2021-09-26/qecon-2021/", "categories": "Tech", "tags": "Quality, DevOps", "date": "2021-09-26 00:00:00 +0800", "snippet": "周末去参加 QECon 了，分享一些零零碎碎的笔记。 QECon 源自于 QCon（全球质量大会），QECon 可以被翻译为 Quality &amp; Engineering Conference。但主办方解释其为连接质量和效率。关于测试 自动化测试和机器学习结合已经成为可能，大厂在这方面的投入很多，请了真科学家和真天才少年，效果也很显著。 所谓智能化测试更多体现在智能识别理解和操作...", "content": "周末去参加 QECon 了，分享一些零零碎碎的笔记。 QECon 源自于 QCon（全球质量大会），QECon 可以被翻译为 Quality &amp; Engineering Conference。但主办方解释其为连接质量和效率。关于测试 自动化测试和机器学习结合已经成为可能，大厂在这方面的投入很多，请了真科学家和真天才少年，效果也很显著。 所谓智能化测试更多体现在智能识别理解和操作上，像人一样，目前主要依赖 OCR 和 NLP，吃遍三端。 测试左移和持续测试已经被普遍接受和推广，但是效率和效果还不够理想，大家一直在探索如何提高测试效率，精准测试是下一个焦点话题。 大数据测试的挑战和需求日益凸显，因为数字化转型的结果是，一切服务数据化，一切数据服务化。 纯粹通过加人来提高产品质量是不可能的，当然完全去 QA 也并不现实。 测试的门槛越来越高，测试人员的思维应该从保姆守门员转变为教练，让质量成为每个人的责任和习惯，为团队赋能。 所有能左移的都应该左移，比如测试，安全，验收条件等等，将质量内建，将安全内建。 所有能持续进行的都应该持续进行，比如集成，测试，部署，监控等等。关于效能 当我们开始搞效能提升时，要再三思考起点是什么，没有大厂命就不要有大厂病。 效能提升的本质是解决问题，如果研发团队有痛点，就解决痛点，最痛的那个点。 可以从生产时间复盘开始，去发现效能改进的机会，这是一种以终为始的思考方式。 度量体系的确有一些方法，不过不能生搬硬套，没有哪个老师能回答黄金指标是什么，因为上下文不一样。 要站在研发团队的角度思考效能，朝正确的方向改进，开发人员的同理心很重要，不然效能团队会死的很惨。 度量指标要分维度，分场景，量身定做。 度量指标最基本的要求是不可篡改，全自动抓取。 一切始于度量指标，但也要终于度量指标。如果改进目的已经达到，就不要揪着某个指标不放。 没有度量就没有改进，你度量什么就会得到什么。这是最基本的思维模式。但后面还有一句，你度量得到的结果不一定是按你期望的方式给你的，比如你期望降低 Bug 率，开发和测试就会商量好不开 Bug，你期望提高代码当量，开发就把循环拆开了写。 谁来做效能改进？谁最痛谁来做，所以一般效能团队都是从 QA 转过来的。 效能改进应该具有持续性，所以效能改进本身也需要不停的改进。 关于质量和效率，除了技术和工具，组织架构和文化建设一样重要，全局的优化要大于局部的优化，过程固然重要，但结果更重要。 DevOps 进化的思路基本都是：标准化，自动化，可度量，平台化。 效能是什么？不仅仅是把事情做的多快，做的多好，而是先把事情做对。 复盘和反馈远比度量更重要，没有闭环的改进不叫改进。" }, { "title": "Python 和 MongoDB 其实很配", "url": "/posts/2021-08-30/python-and-mongo/", "categories": "Tech", "tags": "Python, mongo", "date": "2021-08-30 00:00:00 +0800", "snippet": "MongoDB 其实就是一个大大的JSON，在 Python 的世界里dict也是最吃香的类型，所以，他们天生就是一对。MongoDB 的安装推荐使用 Docker 来部署管理，一行命令就可以搞定，官方版本：docker run -d --name mongodb \\ -e MONGO_INITDB_ROOT_USERNAME=admin \\ -e MONGO_INITDB_RO...", "content": "MongoDB 其实就是一个大大的JSON，在 Python 的世界里dict也是最吃香的类型，所以，他们天生就是一对。MongoDB 的安装推荐使用 Docker 来部署管理，一行命令就可以搞定，官方版本：docker run -d --name mongodb \\ -e MONGO_INITDB_ROOT_USERNAME=admin \\ -e MONGO_INITDB_ROOT_PASSWORD=admin \\ -v ~/data/mongo_dir:/data/db \\ -p 27017:27017 \\ mongo官方版本的 Docker 啥都好，就是体积有点大。还有一个小体积的alpine版本，开发时使用很方便，不过不能配置账户和密码。docker run -d --name mongo-lite \\ -p 27018:27017 \\ -v ~/data/mongo_lite:/data/db \\ mvertes/alpine-mongo如果想尝试 Mongo 的命令行 （Mongo Shell），直接进到 Docker 里：$ docker exec -it mongo-lite mongoMongoDB shell version v4.0.6connecting to: mongodb://127.0.0.1:27017/?gssapiServiceName=mongodb...&gt; use mydbswitched to db mydb&gt; db.User.insertOne({\"name\":\"Toby\",age:18}){\t\"acknowledged\" : true,\t\"insertedId\" : ObjectId(\"612c84c5d93795436ad27ebc\")}&gt; db.User.find(){ \"_id\" : ObjectId(\"612c84c5d93795436ad27ebc\"), \"name\" : \"Toby\", \"age\" : 18 }Mongo Shell 官方文档： https://docs.mongodb.com/manual/reference/mongo-shell/PyMongo 五分钟上手安装 PyMongo 可以通过pip搞定。pip install pymongo以下内容也可以参考官方文档： https://pymongo.readthedocs.io/en/stable/连接数据库常见方式如下：from pymongo import MongoClient# 连接有密码的Mongoclient = MongoClient('mongodb://admin:admin@localhost:27017/')# 连接没密码的Mongoclient = MongoClient('mongodb://localhost:27018/')# 列出所有已经存在的DBfor db in client.list_databases(): print(db)# 使用Mongo里的某个DB，这个DB可以不存在，后面写数据时会被创建出来db = client.mydb插入数据插入的每条数据都是一个dict，一样的字段允许类型不一样，也允许每次插入的数据字段不一样，可以理解成动态类型数据，你想放什么都行，唯一的约束就是他们会被放在同一个Document里。# 插入一条数据def add_one_user(): db.User.insert_one({ 'name': 'Toby', 'age': 18 })# 插入多条数据def add_many_users(): db.User.insert_many([{ 'name': 'Tom', 'age': 10 }, { 'name': 'Toby', 'age': 'unknown', 'hobbies': ['write bugs', 'raise dogs'] }])这里的User约等于关系型数据库的表，但它的名字叫Document，每次数据插入完成后会返回一个_id，这是 Mongo 里最重要的东西了，它就是靠这个_id来保证数据的一致性，后续的数据修改和删除主要就是靠这个_id来完成，所以一般针对某条特定的数据的处理，都是需要先查询它的_id，然后再进行后面的操作。查询数据# 查询多个数据def show_users(): # 一个表里所有数据 for e in db.User.find(): print(e) # 匹配条件的多条数据 for e in db.User.find({'name': 'Toby'}): print(e)# 查询单个数据def query_user(name): return db.User.find_one({'name': name})# 忽略大小写def query_user_ignore_case(name): return db.User.find_one({'name': re.compile(name, re.IGNORECASE)})# 使用运算符 https://docs.mongodb.com/manual/reference/operator/query/def query_teenager(): return db.User.find_one({'age': {'$lt': 18}})Mongo 的查询主要还是依赖 DB 自己提供的运算符，在 PyMongo 里要注意，这里不会抛出异常，如果找不到数据，默认返回 None。 通过运算符查询数据：https://docs.mongodb.com/manual/reference/operator/query/ 通过聚合查询数据：https://docs.mongodb.com/manual/aggregation/修改数据# 修改一个数据def update_user(user, attributes: dict): user.update(attributes) result = db.User.replace_one({'_id': user['_id']}, user, upsert=True) return {'affected_count': result.modified_count}u = query_user_ignore_case('toby')result = update_user(u, {'code': 'python'})# 修改多个数据，注意有坑，Replace 和 Update是不一样的def update_many(): todo = [ UpdateOne({'age': 19}, {'$set': {'name': 'Toby'}}), ReplaceOne({'name': 'Tom'}, {'age': 19}), # name 会被吃掉 ] result = db.User.bulk_write(todo) print(result.matched_count)Replace 是替换，所以要带上原有字段，这里有点坑。Update 不接受单独的dict，需要用 $set / $unset 来标识修改的字段的方式。[ { \"$set\": { \"status\": \"Modified\", \"comments\": [\"$misc1\", \"$misc2\"] } }, { \"$unset\": [\"misc1\", \"misc2\"] }]删除数据def delete_user(name): result = db.User.delete_one({'name': name}) return {'affected_count': result.deleted_count}删除多个数据：&gt;&gt;&gt; db.test.count_documents({'x': 1})3&gt;&gt;&gt; result = db.test.delete_many({'x': 1})&gt;&gt;&gt; result.deleted_count3&gt;&gt;&gt; db.test.count_documents({'x': 1})0常见问题有什么办法可以让 Mongo 不自动添加 _id到我的数据里？几乎没有，这是 MongoDB 的特性决定的，如果你的数据没有 ID 的话，并且进行高并发插入时，大概率会遇到BulkWriteError这个错误。&gt;&gt;&gt; doc = {}&gt;&gt;&gt; collection.insert_many(doc for _ in range(10))Traceback (most recent call last):...pymongo.errors.BulkWriteError: batch op errors occurred&gt;&gt;&gt; doc{'_id': ObjectId('560f171cfba52279f0b0da0c')}&gt;&gt;&gt; docs = [{}]&gt;&gt;&gt; collection.insert_many(docs * 10)Traceback (most recent call last):...pymongo.errors.BulkWriteError: batch op errors occurred&gt;&gt;&gt; docs[{'_id': ObjectId('560f1933fba52279f0b0da0e')}]如果你不想要自动生成的ID，可以自己在插入数据前指定这个字段。为啥我指定了_id还是查询不到我的数据？比如我要查询数据库里的某个 post:&gt;&gt;&gt; post_id_as_str = str(post_id)&gt;&gt;&gt; posts.find_one({\"_id\": post_id_as_str}) # No result因为 pyMongo 里的这个 ID 不是字符串类型，你需要做一下数据转换。from bson.objectid import ObjectId# The web framework gets post_id from the URL and passes it as a stringdef get(post_id): # Convert from string to ObjectId: document = client.db.collection.find_one({'_id': ObjectId(post_id)})用标准库里的 json 模块来序列化和反序列化 Mongo 的数据会有什么问题？有一些数据类型在反序列后会得不到预期的结果，比如ObjectId 和 DBRef，PyMongo 为了解决这个问题自己封装了一个辅助类json_util，可以很好的解决这些问题。from bson.json_util import loadsfrom bson.json_util import dumps总结Mongo 属于非关系型数据库，使用 Mongo 作为 DB 的思维需要做比较大的转变： 关系型数据库一般读写容易，修改难，容易理解 非关系型数据库一般是读写改容易，设计难（相对而言） 关系型数据库支持 ACID (Atomicity, Consistency, Isolation, Duration) 即原子性，一致性，隔离性和持续性。 相对而言，NoSQL 采用更宽松的模型 BASE (Basically Available, Soft state, Eventual Consistency) 即基本可用，软状态和最终一致性。NoSQL 在精心的设计下查询性能会更高，数据结构也十分有弹性，特别适合快速发展和属性不确定的产品功能，但 Mongo 不支持事务，如何确保数据一致性是个挺大的挑战。在选择上可以考虑从以下角度去思考： 需要 ACID 还是 BASE 需要结构化数据还是非结构化数据 需要对数据进行灵活扩展 开发人员的经验很多情况只考虑最后一点就可以了。" }, { "title": "PEP8 Python 编码规范", "url": "/posts/2021-08-21/python-pep-8/", "categories": "Tech", "tags": "Python, PEP", "date": "2021-08-21 00:00:00 +0800", "snippet": "编程语言不是艺术，而是工作或者说是工具，所以整理并遵循一套编码规范是十分必要的。PEP 的全称是 Python Enhancement Proposal，这里囊括了所有 Python 改进的所有提案，由社区核心成员包括作者本人在维护。PEP 8 是提案里的第 8 条，主要描述了 Python 官方建议的编码规范。 Python Enhancement Proposal 8 or PEP 8...", "content": "编程语言不是艺术，而是工作或者说是工具，所以整理并遵循一套编码规范是十分必要的。PEP 的全称是 Python Enhancement Proposal，这里囊括了所有 Python 改进的所有提案，由社区核心成员包括作者本人在维护。PEP 8 是提案里的第 8 条，主要描述了 Python 官方建议的编码规范。 Python Enhancement Proposal 8 or PEP 8 is a comprehensive styling guide for your Python code.本文是 PEP8 的速读版，完整版请访问： https://www.python.org/dev/peps/pep-0008/代码排版 使用 4 个空格的缩进（编辑器都可以完成此功能），不使用 Tab，更不能混合使用 Tab 和空格。 每行最大长度为 79，换行可以使用反斜杠，最好使用圆括号。换行点要在操作符的后边敲回车。 类和 top-level 函数定义之间空两行；类中的方法定义之间空一行；函数内逻辑无关段落之间空一行；其他地方尽量不要再空行。文档排版 模块内容的顺序：docstring—import—globals&amp;constants—function&amp;class。其中import部分，又按标准、三方和自己编写顺序依次排放，之间空一行。 不要在一句import中多个库，比如import os, sys不推荐。 如果采用from XX import XX引用库，可以省略module.，都是可能出现命名冲突，这时就要采用import XX。空格的使用总体原则，避免不必要的空格。 各种右括号前不要加空格。 逗号、冒号、分号前不要加空格。 函数的左括号前不要加空格。如Func(1)。 序列的左括号前不要加空格。如list[2]。 操作符左右各加一个空格，不要为了对齐增加空格。 函数默认参数使用的赋值符左右省略空格。 不要将多句语句写在同一行，尽管允许使用；分隔。 if/for/while语句中，即使执行语句只有一句，也必须另起一行。注释总体原则，错误的注释不如没有注释。所以当一段代码发生变化时，第一件事就是要修改注释！注释必须使用英文，最好是完整的句子，首字母大写，句后要有结束符，结束符后跟两个空格，开始下一句。如果是短语，可以省略结束符。 块注释，在一段代码前增加的注释。在#后加一空格。段落之间以只有#的行间隔。比如： # Description : Module config.## Input : None## Output : None 行注释，在一句代码后加注释。比如： x = x + 1 # Increment x 但是这种方式尽量少使用。 避免无谓的注释。文档描述 为所有的共有模块、函数、类、方法写docstrings；非共有的没有必要，但是可以写注释（在def的下一行）。 如果docstring要换行，参考如下例子，详见 PEP 257 \"\"\"Return a foobangOptional plotz says to frobnicate the bizbaz first.\"\"\" 命名规范总体原则，新编代码必须按下面命名风格进行，现有库的编码尽量保持风格。 尽量单独使用小写字母l，大写字母O等容易混淆的字母。 模块命名尽量短小，使用全部小写的方式，可以使用下划线。 包命名尽量短小，使用全部小写的方式，不可以使用下划线。 类的命名使用 CapWords 的方式，模块内部使用的类采用_CapWords 的方式。 异常命名使用 CapWordsError 后缀的方式。 全局变量尽量只在模块内有效，类似 C 语言中的 static。实现方法有两种，一是all机制，二是前缀一个下划线。 函数命名使用全部小写的方式，可以使用下划线。 常量命名使用全部大写的方式，可以使用下划线。 类的属性（方法和变量）命名使用全部小写的方式，可以使用下划线。 类的属性有 3 种作用域 public、non-public 和 subclass API，可以理解成 C++中的 public、private、protected，non-public 属性前，前缀一条下划线。 类的属性若与关键字名字冲突，后缀一下划线，尽量不要使用缩略等其他方式。 为避免与子类属性命名冲突，在类的一些属性前，前缀两条下划线。比如：类 Foo 中声明 a,访问时，只能通过 Foo.a，避免歧义。如果子类也叫 Foo，那就无能为力了。 类的方法第一个参数必须是 self，而静态方法第一个参数必须是 cls。编码建议 编码中考虑到其他 Python 实现的效率等问题，比如运算符 + 在 CPython（Python）中效率很高，但是在 Jython 中却非常低，所以应该采用.join()的方式。 尽可能使用is is not取代==，比如 if x is not None 要优于 if x。 使用基于类的异常，每个模块或包都有自己的异常类，此异常类继承自 Exception。 异常中不要使用裸露的 except ，except 后跟具体的 exceptions。 异常中 try 的代码尽可能少。比如： # Yes:try: value = collection[key]except KeyError: return key_not_found(key)else: return handle_value(value)# No:try: # Too broad! return handle_value(collection[key])except KeyError: # Will also catch KeyError raised by handle_value() return key_not_found(key) 使用 startswith() 和 endswith() 代替切片进行序列前缀或后缀的检查。比如 # Yes:if foo.startswith('bar'):# No:if foo[:3] == 'bar': 使用 isinstance()比较对象的类型。比如 # Yes:if isinstance(obj, int):# No:if type(obj) is type(1): 判断序列空或不空，有如下规则 # Yes:if not seq:if seq:# No:if len(seq)if not len(seq) 字符串不要以空格收尾。 二进制数据判断使用 if bool_value 的方式。" }, { "title": "程序员的节操", "url": "/posts/2021-08-09/conventioanl-commit-message/", "categories": "Tech", "tags": "DevOps, Code", "date": "2021-08-09 00:00:00 +0800", "snippet": "从代码提交记录能看出一个程序员的节操，真的。节操掉了一地在敏捷开发里我们提倡频繁提交代码，但是这并不意味着对提交的代码和提交记录的质量妥协。你身边有没有这样的程序员大哥大姐，在提交代码时是这样写的提交信息？节操仿佛掉了一地，甚至还有下面这样的。规范化的代码提交记录在开源社区，有这么一套规范 Conventional Commits，就是用来约定代码提交信息的格式，可以帮助大家更好的把节操抓在...", "content": "从代码提交记录能看出一个程序员的节操，真的。节操掉了一地在敏捷开发里我们提倡频繁提交代码，但是这并不意味着对提交的代码和提交记录的质量妥协。你身边有没有这样的程序员大哥大姐，在提交代码时是这样写的提交信息？节操仿佛掉了一地，甚至还有下面这样的。规范化的代码提交记录在开源社区，有这么一套规范 Conventional Commits，就是用来约定代码提交信息的格式，可以帮助大家更好的把节操抓在手里，而不是扔在地上。内容不是太长，几分钟就可以看完学会。默认格式&lt;type&gt;(&lt;optional scope&gt;): &lt;subject&gt;empty separator line&lt;optional body&gt;empty separator line&lt;optional footer&gt;当分支合并时Merge branch '&lt;branch name&gt;'后面跟着默认的分支合并信息。当撤销改动时Revert \"&lt;commit headline&gt;\"empty separator lineThis reverts commit &lt;commit hash&gt;.&lt;optional reason&gt;后面跟着默认的撤销改动信息。提交类型 Type提交类型可以让其他用户了解这个改动的初衷，详细列表可以在后文的参考链接找到，下面列举一些常用的类别。 API relevant changes feat Commits, that adds a new feature，新功能 fix Commits, that fixes a bug，修复问题 refactor Commits, that rewrite/restructure your code, however does not change any behaviors，重构 perf Commits are special refactor commits, that improves performance，调优 style Commits, that do not affect the meaning (white-space, formatting, missing semi-colons, etc)，修改样式 test Commits, that add missing tests or correcting existing tests，测试相关 docs Commits, that affect documentation only，文档相关 build Commits, that affect build components like build tool, ci pipeline, dependencies, project version, 编译相关 ops Commits, that affect operational components like infrastructure, deployment, backup, recovery, 基础设施相关 chore Miscellaneous commits e.g. modifying .gitignore，其他杂项任何的提交记录都应该以提交类型开头，如果是很重要的改动可以选择性地加上感叹号，例如：refactor!: drop support for node 8变更范围 ScopeThe scope provides additional contextual information. 变更范围是可选的，在我们实际项目中我们在这里写入了需求卡片 ID，比如 JIRA ID，当然也可以写模块名称。变更主题 SubjectThe subject contains a succinct description of the change. 用一句话描述改动了什么，规范里建议不操作 72 个字符，这是最能体现节操的部分。 Is a mandatory part of the format，在规范里这是必填项。 Use the imperative, present tense: “change” not “changed” nor “changes”，建议语法使用现在时而不是过去时。 Don’t capitalize the first letter，首字母不要大写。 No dot (.) at the end，末尾不要加句号。变更详情 BodyThe body should include the motivation for the change and contrast this with previous behavior. 详情里主要写变更的原因和背景，而不是写改了什么，改了什么主要还是通过 diff 来了解。 Is an optional part of the format，这是可选内容。 Use the imperative, present tense: “change” not “changed” nor “changes”，使用现在时而不是过去时。 This is the place to mention issue identifiers and their relations，可以放需求卡片 ID 或者相关联的其他信息变更注脚 FooterThe footer should contain any information about Breaking Changes and is also the place to reference Issues that this commit refers to. 注脚里可以放跟 Breaking Changes 之类的其他信息，或者放任何跟这次改动相关的参考信息。 Is an optional part of the format optionally reference an issue by its id. Breaking Changes should start with the word BREAKING CHANGES: followed by space or two newlines. The rest of the commit message is then used for this.具体例子 Examples feat(shopping cart): add the amazing button feat: remove ticket list endpoint refers to JIRA-1337 BREAKING CHANGES: ticket endpoints no longer supports list all entities. fix: add missing parameter to service call The error occurred because of &lt;reasons&gt;. build(release): bump version to 1.0.0 build: update dependencies refactor: implement calculation method as recursion style: remove empty line优化提交记录有什么好处好处很多，首先，你的节操又捡起来了。其次，良好的提交记录可以提高你的口碑和声誉，我们可以随手去知名的开源项目翻阅一下，大神们不仅对代码有极高的要求，对提交记录也一样。大家在翻开其他同行的代码时，第一眼看的并不是代码，而是提交记录，他对他的好感有时候就是那么简单自然。还有，在开源社区很多项目的 Change Log 都是自动生成的，良好的提交记录就是这些自动化技术的基础。如何简化这个有点繁琐的流程如果你遇到任何事情都有偷懒和简化的思维，恭喜你，你已经具有高级工程师的基本素质了。坦白讲这个规范其实也没那么烦，但是一定要简化的话还是有懒人给懒人写了工具。 IDEA 可以用 Conventional Commit VSCode 可以用 Conventional Commits我真的不是强行凑字数，它们的名字就这样。还有一些插件更厉害了，可以让你的代码不按规范写 Commit Message 就没法提交，只要大家觉得这样没毛病，就可以把这个插件带到你的团队，这个插件叫，Husky。关于 pre-commit-hook 和 husky 的使用，我们下次再讲，过了今天，愿你我的节操同在。" }, { "title": "Python 基础简明教程", "url": "/posts/2021-08-07/python-basic/", "categories": "Tech", "tags": "Python", "date": "2021-08-07 00:00:00 +0800", "snippet": "这是 Python 程序设计的简明教程，假设你已经有其他高级编程语言的经验。环境准备环境准备过程中，核心要点如下： 官方下载地址 http://python.org/download/，推荐使用最新版 安装路径，推荐选择用户目录（默认选项） 环境配置，推荐将 Python 加入 PATH 开发工具，推荐使用 PyCharm 社区版新建项目在 Python 中新建项目的要点： 选择项...", "content": "这是 Python 程序设计的简明教程，假设你已经有其他高级编程语言的经验。环境准备环境准备过程中，核心要点如下： 官方下载地址 http://python.org/download/，推荐使用最新版 安装路径，推荐选择用户目录（默认选项） 环境配置，推荐将 Python 加入 PATH 开发工具，推荐使用 PyCharm 社区版新建项目在 Python 中新建项目的要点： 选择项目保存地址，按个人习惯选择，例如 ~/workspace 选择 Python 解释器（interpreter），可以用已经存在的解释器，也可以选择一个虚拟环境。Python 是解释型语言，解释器可以类比成 Java 的 JDK 版本。我个人非常不推荐直接使用默认的 Python 解释器，因为随着项目的开发我们会引入很多依赖包，每个项目对同一个依赖包的版本可能有所不同，这时候使用同一个解释器会造成依赖混乱，后期排查的难度非常大，那时候再去把项目分离属于没必要的成本。如果只是学习或者做非专业项目开发，可以使用默认环境，同时请关注环境污染问题。第一个程序一行代码就可以开启 Python 世界的大门。print('hello world') 友情提示：Python 中的变量和方法名主要以小写和下划线声明，请在你的代码里遵循这样的规范。用面向对象和动态语言来写第一个程序。class Employee(object): passif __name__ == '__main__': employee = Employee() employee.code = '007' employee.name = 'Toby'Employee 对象可以不声明 code 和 name 的属性，在程序运行中再给它添加 code 和 name。if __name__ == '__main__’ 的意思是这是 Python 程序的入口，这行代码能让很多新手纠结半天。这其实还是简单的 if 判断，关键是 __name__ 和 __main__ 是什么鬼。__name__ 是 Python 模块的名字，双下划线属于 Python 进阶课程的内容，双下划线开头和结尾的变量一般属于 Python 的内置变量，__name__ 就是其中之一，指的是当前模块的名字。但是，如果当前模块是被直接运行的模块的话，值就等于 __main__，否则就等于模块原本的名字。 想了解更多双下划线的内容，搜索 Python 的魔法方法我们做一个简单的例子，假设有 a 和 b 两个模块。# a.pydef what_is_name(): print('a.__name__ = ' + __name__)if __name__ == '__main__': what_is_name()现在直接运行脚本 a.py。$ python a.pya.__name__ = __main__这时候的__name__返回的值就是__main__。我们来写一个 b 模块，调用 a 模块，然后看看这时候 a 里的__name__是什么。# b.pyimport aa.what_is_name()现在直接运行脚本 b.py。$ python b.pya.__name__ = a这个例子看懂了，这个 Python 入门的坎就过去了。哦对了，Python 是按缩进来严格划分代码块的，这个坑踩几次就记住了。Python 的数据类型数据类型是编程语言里的核心概念，Python 内置的数据类型非常简单，分类如下。 类型 英文 关键字 文本类型 Text Type str 数字类型 Numeric Types int, float, complex 序列类型 Sequence Types list, tuple, range 字典类型 Mapping Type dict 集合类型 Set Types set, frozenset 布尔类型 Boolean Type bool 二进制类型 Binary Types bytes, bytearray, memoryview 空类型 None Type None 实际工作中用的最多的类型主要是文本，数字，列表，字典，布尔。使用类型时不需要声明类型，Python 在运行时会根据实际值进行运算，这是动态语言的优势，但是在如此高的灵活性下对程序员的素质要求也很高。a = 'hello' # text typeb = 1 # numeric typec = [100,200,'test'] # list typeprint(c[2]) # usec[1] = 99 # assignd = {'a': 1, 'b': c} # dict typeprint(d['a']) # used['b'] = 'test' # assigne = (1,3,4) # set typeprint(e[1]) # use it, cannot assignf = True # bool typeg = b'hello' # byte typeh = None # null type要判断 Python 变量的类型是什么的话，可以用两种方法，第一个是type()。&gt;&gt;&gt; type(1)# &lt;class 'int'&gt;&gt;&gt;&gt; type('hello')# &lt;class 'str'&gt;第二种方法是 isinstance()。&gt;&gt;&gt; isinstance(1, int)# True&gt;&gt;&gt; isinstance(1, str)# False控制流和语法Python 是最接近自然语言的编程语言，所以 Python 的控制流非常容易上手。下面列举一下我们常用的控制流和语法。# if / elseif b &gt; a: print(\"b &gt; a\")else: print(\"b &lt; a\")# whilewhile i &lt; 6: print(i) i += 1# forfruits = [\"apple\", \"banana\", \"cherry\"]for x in fruits: print(x)# functiondef my_function(): print(\"Hello from a function\")# lambdax = lambda a : a + 10print(x(5))# try / catchtry: print(x)except: print(\"An exception occurred\")Python 的类和构造函数有了一点双下划线的基础后，我们就可以了解一下 Python 类的构造函数，它也是一个双下划线，名字叫 __init__。看一个简单的例子。class Employee(object): def __init__(self, code, name): self.code = code self.name = nameif __name__ == '__main__': employee = Employee('007', 'Toby') print(employee.code) print(employee.name)def 是 Python 里声明方法的关键字，上面的例子我们重载 Employee 的构造函数，构造函数里加入了两个参数 code 和 name。你是不是觉得我在骗你，明明是三个参数，还有个 self 为啥不把它当参数。我没有骗你，你看在调用的时候你只给了两个参数：Employee('007', 'Toby')好吧，这是 Python 的第二关，又可以让新手挠半天头。self 可以理解成 Java 或者 C# 里的 this，从英文上看就是一个意思。我们把 self 可以理解成当前类的实例（instance），Python 奇怪的是所有的实例方法都要传入当前的实例（作为第一个参数）。构造函数也是一个实例方法。假如不传入当前实例会怎么样？那么这个方法就是类的静态方法，比如这样。class Employee(object): @staticmethod def create(code, name): e = Employee() e.code = code e.name = name# 调用静态方法Employee.create('007', 'Toby')其实这里要想深入需要更多篇幅，Python 类的实例方法里的第一个参数一定是当前对象，但不一定叫 self，可以叫阿猫阿狗，只是约定叫 self。想了解这个设计背后的初衷可以看这篇文档。 https://medium.com/quick-code/understanding-self-in-python-a3704319e5f0可变参数现在来到 Python 世界的第三关：可变参数。可变参数有两种，一种是不需要名字的可变参数，比如我们有个很厉害的函数可以把所有的参数加起来。def add(...): # sum up all arguments这个怎么写？在别的编程语言几乎不可能实现这样的功能，但是 Python 可以。def add(*args): return sum(args)print(add(1, 2, 3, 4)) # =&gt; 10这里的 *args 拿到的是一个数组，所有的参数都是这个数组里的元素，只有索引，没有名字。可变参数的第二种情况是我们希望每个参数都有一个名字，这样在使用的时候会更方便。比如这个例子。class Employee(object): def __init__(self, **kwargs): print(kwargs['code']) print(kwargs['name'])if __name__ == '__main__': employee = Employee(code='007', name='Toby', mail='toby@test.com')上面的代码里我们可以通过参数名字拿到参数的值，在参数比较多的情况下会尤其有用。这个例子里我还传入了一个叫 mail 的参数，实际上没有使用但程序并不会报错。那么*args 和 **kwargs 到底是什么对象呢？很简单： *args 是一个Tuple，元组，和数组有一点细微的差别，就是元组不可变，数组可变。 **kwargs 是一个 dict，字典，和json 字符串差不多，就是一系列的 key=value。当这两个可变参数放在一个函数里时，这个函数就成了一个超级函数，可以接受任意参数。class Employee(object): def __init__(self, *args, **kwargs): print(f'args = {args}') print(f'kwargs = {kwargs}') # args = ('007', 'Toby') # kwargs = {'phone': '123-456-789', 'mail': 'toby@mail.com'}if __name__ == '__main__': employee = Employee('007', 'Toby', phone='123-456-789', mail='toby@mail.com')在很多比较抽象的模块里，你可以能会很容易看到这样的超级函数。必要关键字参数顺带提一个实用小技巧，如果我们需要某些参数在调用的时候一定要传入参数名字，可以这样写。def calc(a,b,*,operator): ...calc(1,2,operator='+') # OKcalc(1,2,'+') #TypeError: calc() takes 2 positional arguments but 3 were given为什么说这个技巧实用吗？想象一下假如你遇到这样的代码就知道这个用法的好处了。magic('001','xxx','bbb','wtf',[1,2,3]) # 鬼知道我的参数是什么意思使用 pip 安装依赖包在 Python 的世界里有很多轮子，我们应该尽量避免造轮子，多去找找已经存在的轮子。pip 就是安装轮子的方法。比如我们要做网络请求相关的功能开发，可以这样安装 requests 依赖库。pip install requests如果提示 pip 命令找不到，你需要将 pip 加入 PATH，或者通过 Python 来调用 pip。python -m pip install requests现在就可以直接访问一个网址了。import requestsresponse = requests.get('https://api.ipify.org?format=json')print(response.json()) # {\"ip\":\"98.207.254.136\"}requests 库可以用最少和最优雅的代码来完成网络请求相关的所有操作，强烈安利一下。requests.get(url)requests.post(url, data={'a': 1})requests.put(url, json={'b': 2})requests.delete(url)操作数据库为了完成后面的新手任务，我们安装一个连接 mysql 的依赖包。pip install mysql-connector-python假设你本机有个 mysql 的服务，我们现在需要一个数据库和一张数据表。在命令行工具里完成以下库和表的建立。 没有的话，可以安装 brew install mysql 启动：mysql.server start$ mysql -uroot # 默认密码为空mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+# 创建和使用数据库mysql&gt; create database demo;Query OK, 1 row affected (0.00 sec)mysql&gt; use demo;Database changed# 创建数据表mysql&gt; create table table Employee -&gt; (id int primary key auto_increment, -&gt; code varchar(100), -&gt; name varchar(200) -&gt; );Query OK, 0 rows affected (0.00 sec)连接数据库数据库的配置文件一般要和代码分离，我们先写一个数据的配置文件。# config.ini[DB]username=rootpassword=database=demo然后我们再来一个数据操作类，用来保存我们的 Employee 数据。# database.pyimport configparserimport mysql.connectorclass Database(object): def connect(self): parser = configparser.ConfigParser() parser.read('config.ini') db_config = dict(parser.items('DB')) self.connection = mysql.connector.connect(**db_config) self.cursor = self.connection.cursor() def save_employee(self, employee): self.connect() sql = \"INSERT INTO employee (code, name) VALUES (%s, %s)\" val = (employee.code, employee.name) self.cursor.execute(sql, val) self.connection.commit() self.close() def close(self): self.cursor.close() self.connection.close()现在回到 Employee 模块，像这样。# employee.pyclass Employee(object): def __init__(self, code, name): self.code = code self.name = name我们来加一个 main.py 的主模块。# main.pyfrom model.database import Databasefrom model.employee import Employeeif __name__ == '__main__': emp = Employee('007', 'Toby') db = Database() db.save_employee(emp)现在的目录结构看起来是这样的。├── config.ini├── main.py├── model   ├── __init__.py   ├── database.py   └── employee.py现在来运行一下 main.py。python main.py去查一下数据库，数据应该已经存进去了。mysql&gt; select * from employee;+----+------+------+| id | code | name |+----+------+------+| 1 | 001 | Toby |+----+------+------+1 rows in set (0.00 sec)查询数据库的方法可以这样写。# database.pydef query_employee(self): sql = 'select * from employee' self.connect() self.cursor.execute(sql) result = self.cursor.fetchall() self.close() return result操作数据库记得要关闭数据库，这是初级教程，其实有更优雅的办法来处理数据的打开关闭，比如使用Python 的装饰器，有兴趣可以了解一下。完结OK，感谢你的阅读。你已经入门 Python 了，我猜的。" }, { "title": "You and I", "url": "/posts/2021-06-14/you-and-i/", "categories": "Life", "tags": "Song", "date": "2021-06-14 00:00:00 +0800", "snippet": "非常喜欢的一首歌。 专辑： Pure Instinct 歌手：Scorpions I lose control because of you babe我丧失了理智，只因为你I lose control when you look at me like this我丧失了理智，当你这样看着我There’s something in your eyes that is saying tonigh...", "content": "非常喜欢的一首歌。 专辑： Pure Instinct 歌手：Scorpions I lose control because of you babe我丧失了理智，只因为你I lose control when you look at me like this我丧失了理智，当你这样看着我There’s something in your eyes that is saying tonight你眼中有些许悸动，今晚将要诉说I’m not a child anymore, life has opened the door我不再是个孩子，生活已经打开了这扇门To a new exciting life通往崭新的精彩生活I lose control when I’m close to you babe我丧失了理智，只因为你I lose control don’t look at me like this我丧失了理智，不要这样看着我There’s something in your eyes, is this love at first sight你眼中有些许悸动，那是一见钟情吗Like a flower that grows, life just wants you to know就像一朵花儿的成长，生活想让你了解All the secrets of life生命的所有秘密It’s all written down in your lifelines这已经在你的命中注定It’s written down inside your heart这已经在你心中画下烙印You and I just have a dream你和我，只有一个梦想To find our love a place, where we can hide away为我们的爱找个空间，远离喧嚣You and I were just made你和我，已被注定To love each other now, forever and a day相爱每天，直到永远I lose control because of you babe我丧失了理智，只因为你I lose control don’t look at me like this我丧失了理智，当你这样看着我There’s something in your eyes that is saying tonight你眼中有些许悸动，今晚将要诉说I’m so curious for more just like never before我如此好奇，从未经历In my innocent life在我无辜的一生中It’s all written down in your lifelines这已经在你的命中注定It’s written down inside your heart这已经在你心中画下烙印You and I just have a dream你和我，只有一个梦想To find our love a place, where we can hide away为我们的爱找个空间，远离喧嚣You and I were just made你和我，已被注定To love each other now, forever and a day相爱每天，直到永远Time stands still when the days of innocence时间坚持伫立，直到无辜之日Are falling for the night堕入永夜I love you girl I always will我爱你，永远I swear I’m there for you我发誓我将为你在此Till the day I die直到我死去You and I just have a dream你和我，只有一个梦想To find our love a place, where we can hide away为我们的爱找个空间，远离喧嚣You and I were just made你和我，已被注定To love each other now, forever and a day相爱每天，直到永远You and I just have a dream你和我，只有一个梦想To find our love a place, where we can hide away为我们的爱找个空间，远离喧嚣You and I were just made你和我，已被注定To love each other now, forever and a day相爱每天，直到永远" }, { "title": "又一年黑客马拉松", "url": "/posts/2021-06-10/hackathon-2021/", "categories": "Life", "tags": "Life", "date": "2021-06-10 00:00:00 +0800", "snippet": "黑客马拉松，又称之为Hackathon，去年参加了3次，今年刚刚又参加了一次。什么是Hackathon简单说黑客马拉松就是为了激发程序员（主要是程序员）创意，动手，分享而举办的高强度的编程赛事，一般持续1到2天。在比赛过程中大家会根据某个特定主题自行组队实现自己的创意。 举例子：DevOps流水线黑客马拉松 赞助商：艾玛没bug公司 时间：2021年6月31日为什么要做Hackatho...", "content": "黑客马拉松，又称之为Hackathon，去年参加了3次，今年刚刚又参加了一次。什么是Hackathon简单说黑客马拉松就是为了激发程序员（主要是程序员）创意，动手，分享而举办的高强度的编程赛事，一般持续1到2天。在比赛过程中大家会根据某个特定主题自行组队实现自己的创意。 举例子：DevOps流水线黑客马拉松 赞助商：艾玛没bug公司 时间：2021年6月31日为什么要做Hackathon办一次黑客马拉松一般来说还是比较费时费力的，从筹备到比赛到颁奖。尽管如此，还是有很多企业或者社区孜孜不去地要举办Hackathon，他们当然是有所图的。 发现和吸引人才。21世纪什么最贵？人才。Hackathon就是让各路大神大显神通的地方。 收集潜在的问题和创意。尤其是特定命题的Hackathon有更强的针对性。 促进跨团队合作和交流。平时大家难得在一起切磋，Hackathon可以让大家成为朋友。 推动创新文化落地。如果创新只是口头上说，时间长了大家就免疫了。Hackathon 的创意从哪来去年我有聊过一些关于产生创意的套路，有兴趣可以翻回去看看。 头脑风暴：用“最”去思考，最痛，最棒，最想等等 奔驰思考：替换，合成，调整，修改，拓展，消除，重组 六顶帽子：客观，突破，乐观，否定，直觉，理性这次聊点不一样的，创意其实还是来源于观察和共情，简单说就是换位思考。随便设想一个场景，你能不能说出场景里每个人可能想要的是什么？一旦你有这种敏锐的观察和思考力，就可以提出很多有意思的想法。 举例子：一个程序员在写代码的场景，他可能想要： 更好的鼠标键盘显示器 更大的内存，更快的CPU，更快的网络 一个程序员鼓励师 安静摸鱼不被发现 当然，这个场景作为程序员的你一定可以脑洞大开，因为你每天都在经历这样的场景。但是，作为社会规律这些创意大概率都不会有什么好结果，因为这个场景里还有一类人的需求需要优先被考虑，那就是程序员的老板们。他们当然也希望程序员快乐地码代码，但是他们更希望程序员高效地码代码，高效=速度+质量+成本。一个人一天能做8个需求，0 error 0 warning 0 bug。真正的用户也许不是真正的用户，真正的需求也许不是真正的需求。Hackathon 交作业短短的一两天，要以交作业为导向。作业的评分标准一般会提前说明，比如： 创新性 25% 完成度 25% 可行性 25% 商业价值 25%这样看作业就不能随便写了，还是要围绕评分标准来天马行空，不具备落地可能性和商业价值的项目就基本不考虑了。这里说的不具备要备注一下，不具备指的是你自己都没法用合理的解释来让它具备。 举例子：把普通人送到火星去旅行 马斯克就可以把这个本来不具备可行性的方案强行解释成很具备可行性，所以这是一个非常吸引人的项目。感谢，回顾，再会非常感谢现在的公司很重视创新，每年举办好几次Hackathon，让我们可以带薪玩耍。回顾曾经完成过的创意，很多最后虽然在公司里没落地，但在市场上都能看到相关产品，所以还是很有潜力的。回顾曾经一起合作过的小伙伴们，虽然不在一个团队，很多人最后都成了好朋友，知根知底，可以互相赚推荐费。希望下次黑客马拉松我还能参加，每次都能拿奖，痴心妄想还是要有的，万一实现了呢？" }, { "title": "Netflix 的文化手册", "url": "/posts/2021-05-01/neflix/", "categories": "Management", "tags": "Culture, Management", "date": "2021-05-01 00:00:00 +0800", "snippet": "Netflix 的企业文化手册应该很多人看过，印象深刻。Netflix 企业文化我们负责联结人与故事，也拥有许许多多的人和故事。全球数亿的用户是个良好开端，但将来我们希望能娱乐每一个人。如同友谊，娱乐是人类的核心需求之一。无论是大是小、戏剧性抑或讽刺性，娱乐总会触动我们、改变我们的感受并引起共识。我们的企业文化强调自身如何以员工身份团结起来服务用户和自我成长。企业文化成就了今天的 Netfl...", "content": "Netflix 的企业文化手册应该很多人看过，印象深刻。Netflix 企业文化我们负责联结人与故事，也拥有许许多多的人和故事。全球数亿的用户是个良好开端，但将来我们希望能娱乐每一个人。如同友谊，娱乐是人类的核心需求之一。无论是大是小、戏剧性抑或讽刺性，娱乐总会触动我们、改变我们的感受并引起共识。我们的企业文化强调自身如何以员工身份团结起来服务用户和自我成长。企业文化成就了今天的 Netflix，同时我们还在不断地改进它；企业文化也帮助我们吸引并留住优秀的同事；企业文化还让这里的工作更加令人满意。与许多企业一样，我们力求雇用最出色的员工，我们重视诚信、卓越、尊重与协作。而 Netflix 的独特之处在于我们对以下几点的坚持： 鼓励员工自主决策 开放、广泛、积极地进行信息共享 非常坦诚地对待彼此 只保留高效能人员 避免规则束缚我们的核心理念是人的重要性高于流程。更具体地讲，我们让很棒的人像梦之队一样一起工作。通过这种方式，我们成为了一个更加灵活、有趣、富于创造、刺激、创新和成功的组织。价值观主张大多数企业都拥有自己的价值观主张，但这些书面上的价值观往往不够清晰且易被忽视。企业真实的价值观体现在谁得到了奖励而谁又被解雇。以下是我们的价值观和我们最关心的具体行为与技能。这些描述与你本人以及你希望与之共事的同伴相符程度越高，那么你在 Netflix 公司得以茁壮成长的可能性也就越大。判断力 明智决策，摒弃模棱两可 明辨事物根由，不为表象所惑 战略性思考，具备自知之明且努力实现 擅长利用数据支持自己的直觉判断 根据长远状况作出决策，而非短视沟通 简明扼要地进行演讲和写作 善于倾听，在给出回应前先寻求充分地理解 在紧张的情况下保持镇定，进而找到最清晰的解决思路 让交流风格适用于世界各地与你母语背景不同的人 向同事提供坦诚且及时的反馈意见好奇心 渴望学习且能快速学习 在自身专业之外也能作出贡献 能建立他人忽略的联系 希望了解来自世界各地的用户以及我们如何满足他们 探索新视角创新 提出有用的新观点 重构概念来寻找难题的解决之道 乐于挑战既定的主流假设，提出更好的方法 通过降低复杂度与寻找可节约的时间来保持公司的敏捷性 善于应对变化勇气 即使可能令某些人感到不快，仍愿意表达可能对 Netflix 公司有所助益的观点 乐于对现状持批评态度 做出艰难决定时不会被痛苦所困扰 明智地对待冒险，同时对可能的失败抱开放心态 质疑一切与我们价值观不一致的行为 能够承受寻求真理道路上所出现的打击激情 渴望卓越，并激励他人 将用户和 Netflix 的成功深系于心 坚强且乐观 外表谦逊，内心强大无私 为 Netflix 追求最大利益，胜于自身或者所在团队 以开放心态寻求最佳观点 愿意抽出时间帮助同事 乐于公开且主动地分享信息包容 能够与具备不同经历及文化背景的人士进行高效合作 乐于培养并接纳不同观点，以便做出更好的决策 关注才能与价值观，而非对方是否与您拥有相似之处 希望了解不同背景对于工作的影响，而非假装背景毫无影响 承认人皆抱有一定偏见，并努力加以克服 当有人遭到排挤，主动介入以解决问题诚信 拥有坦诚、真实、透明以及非政治性等特质 直言不讳 能够自由而公开地承认错误 尊重他人，且不受其具体地位或者所持观点的影响影响力 能够完成惊人数量的重要工作 拥有一贯出色的表现，值得同事们信赖 让同事们更为出色 注重结果而非过程编写这些极好的价值观并非难事，但要真正实践却殊为不易。正如在“勇气”一项中所提到，“质疑一切与我们价值观不一致的行为”。我们希望每个人皆能够互相帮助，彼此承担责任，成为榜样，这是一个不断进取的过程。在对“诚信”的描述中，我们提到“直言不讳”，这一点是新员工们最难相信但却需要遵循的重要实践之一。在大多数情况下，无论立足社交抑或工作，那些始终说出自己真实想法的人们往往很快受到孤立与排挤。而我们致力于确保同事之间能够彼此提供专业且具有建设性的反馈意见——包括上下级之间以及企业内不同职能部门之间。Netflix 的员工会经常问别人“我能做得更好吗？”，经常问自己“我还有哪些反馈意见没有进行分享？”我们坚信，如果能够为反馈的提出与接受提供轻松和缓的氛围，并将其作为日常工作中的一部分，那么我们将获得更好也更快的学习效果。反馈应当成为沟通与工作中持续存在的部分，而非偶尔进行的官样文章。我们通过无私反馈在同事之间建立信任，虽然这可能令人们感到压力与不适。但事实上，反馈有助于避免长期误解以及对规则的高度依赖。如果员工之间能够建立更强的潜在合作关系与信任态度，那么反馈的交换将更容易实现。也正因为如此，我们才乐于花时间发展这些职业关系。我们鼓励那些坦率的员工，尤其是能坦率面对上级的员工。我们很清楚，这种坦率与反馈对于来自世界不同地区的新员工可能难以理解，毕竟这在一些地方很罕见。因此，我们将通过指导和树立榜样，积极地帮助人们学习如何在 Netflix 做到这一点。自由与责任不少公司的员工会无视办公室地板上的垃圾，也有一些公司的员工会像在家中一样自觉捡起它们。我们努力成为后者，成为一家每位成员皆身负责任感的公司，每位成员每一时刻都希望能够做正确的事来帮助公司。捡拾垃圾本身只是一种比喻，其实质在于肯定员工发现问题时的态度，而非抱着“这不是我的工作”的消极思维。我们并没有关于捡拾垃圾（比喻的或是真实的）的规则，而希望借此强调企业所创造的归属感、责任感与主动性——这正是上述行为自然发生的核心驱动力。我们的目标是激励人们自我管理。我们相信自己的团队能够作出其认为最适合 Netflix 的判断，所以给予其充分的自由、权力与信息以支持相关决策。反过来，这会产生一种责任感与自律感，敦促大家做出有益于公司的伟大工作。我们相信，人在充分享有信任、自由与发挥空间时，能作出更大的贡献。因此，我们随时随地都在促进自由与授权。" }, { "title": "时间管理的小技巧", "url": "/posts/2021-04-06/tips-of-time-management/", "categories": "Life", "tags": "Life", "date": "2021-04-06 00:00:00 +0800", "snippet": "时间管理是老生常谈的话题，分享几个行之有效的办法。四象限法时间管理的四象限很重要，分清楚什么是重要的什么是紧急的，每天想一想，每周想一想，每月想一想。大石头法想象一下，往空瓶子里装东西，如果你想装的多，一定是要先放大石头，然后小石头，最后是沙子。如果反过来的话，大石头是一定放不下的。大石头法说的是要事优先，再想象一下，比如一个月的时间里，你的大石头有哪些，然后一周里，你的大石头又有哪些？把这...", "content": "时间管理是老生常谈的话题，分享几个行之有效的办法。四象限法时间管理的四象限很重要，分清楚什么是重要的什么是紧急的，每天想一想，每周想一想，每月想一想。大石头法想象一下，往空瓶子里装东西，如果你想装的多，一定是要先放大石头，然后小石头，最后是沙子。如果反过来的话，大石头是一定放不下的。大石头法说的是要事优先，再想象一下，比如一个月的时间里，你的大石头有哪些，然后一周里，你的大石头又有哪些？把这些大石头放到日历里，不要随便被小石头和沙子占据主要的空位。管理人生所谓的时间管理，其实是人生管理。 在短暂的生命里，我们关注的其实是自己。在《要事第一》这本书里说，我们需要管理四个方面： 生活 关爱 学习 留下遗产在这四个方面里，我们要制定个人使命宣言，遵循原则，价值观。在这四个方面里运用一样的模式和步骤： 确认角色 选择目标 安排进度 每日调整对人不可以讲效率，对事才如此，对人应讲效用 —— 即某一行为是否有效。将人和效果放在第一位，时间放在第二位。时间管理可以用时钟也可以用罗盘，罗盘比时钟更具有指导意义。" }, { "title": "产品 - 我所学到的", "url": "/posts/2021-03-13/things-i-learnt-when-created-product/", "categories": "Life", "tags": "Life", "date": "2021-03-13 00:00:00 +0800", "snippet": "做产品经理后认识到的十件事，非常有意思。这是我在一篇博客里看到的，作者已经不知道是谁了，算是转载和分享吧。 有人说愿意买，这话基本不靠谱。 如果有人跟你说：“虽然我个人不会用，但是我打赌，肯定有人喜欢用”，最终基本上不会有人用的。 你要是问“你想要…吗”，“你关心…吗”这类的问题，答案毫无疑问，通常都是肯定的。 如果有人抱怨说：“或许是我比较挑剔，但是…”，其实不是他挑剔。特别是，抱...", "content": "做产品经理后认识到的十件事，非常有意思。这是我在一篇博客里看到的，作者已经不知道是谁了，算是转载和分享吧。 有人说愿意买，这话基本不靠谱。 如果有人跟你说：“虽然我个人不会用，但是我打赌，肯定有人喜欢用”，最终基本上不会有人用的。 你要是问“你想要…吗”，“你关心…吗”这类的问题，答案毫无疑问，通常都是肯定的。 如果有人抱怨说：“或许是我比较挑剔，但是…”，其实不是他挑剔。特别是，抱怨你产品很难用或者市场不明确。 如果产品最终要收费，不要找那些啥事都想免费的人了解情况。（他们或许最终会成为你们的客户，然而这一般发生在你的产品成为主流产品，或者成为事实的标准之后了）。 大部分人都会满足你的请求，前提条件是：请求很短，你很有热情，他们不需要做任何需要思考超过一分钟的决定。 购买或使用产品的两大驱动力：孤立感和认同感。 只有发自内心的喜欢用户才能构建出来好的产品。你不用是他们的同一类人，但是必须喜欢他们。 当你开始思考：“这事比我原来想的要复杂”的时候，当机立断，停下手头的活，找人给你提提意见。这时候，你要么是搞错了，要么是把问题想太多了，旁观者清，第三者会比你更快发现这点。 你的客户说要某项功能，这项功能本身远没有为什么他想要这个功能来的重要。" }, { "title": "微服务是什么鬼", "url": "/posts/2021-03-02/micro-services/", "categories": "Tech", "tags": "Micro-Services", "date": "2021-03-02 00:00:00 +0800", "snippet": " 作者：后端技术杂谈 原文：http://t.cn/AiNPOqFg这几年在 Java 工程师招聘时，会看到很多人的简历都写着使用了 Spring Cloud 做微服务实现，使用 Docker 做自动化部署，并且也会把这些做为自己的亮点。而比较有趣的这其中以小公司出来的人为绝大多数，大的公司出来的人简历上倒是很少提这些东西。对于我自己来说，从 15 年就开始关注这一块，看过马丁.福勒最开...", "content": " 作者：后端技术杂谈 原文：http://t.cn/AiNPOqFg这几年在 Java 工程师招聘时，会看到很多人的简历都写着使用了 Spring Cloud 做微服务实现，使用 Docker 做自动化部署，并且也会把这些做为自己的亮点。而比较有趣的这其中以小公司出来的人为绝大多数，大的公司出来的人简历上倒是很少提这些东西。对于我自己来说，从 15 年就开始关注这一块，看过马丁.福勒最开始的关于微服务的论文、也看过不少对微服务的论证的英文文章和书，也研究过 Spring Cloud、Sofa 等开源实现以及 Service mesh。考虑到我们公司研发团队人力不足、基础设施不完善，当初是没有推行微服务的。但随着看到上述的那种简历越来越多，有时候我也会疑问：难道真的不用微服务就落后了吗？公司的同事如果不掌握这些就真的没有竞争力了吗。而随着最近公司业务的逐步提升，研发人员越来越多，借着在梳理公司的微服务落地计划时，也梳理了一下微服务的相关知识点，也是本文的主要内容。开篇之前先声明我对微服务的几点态度: 架构模式有很多，微服务不是唯一的选择也不是什么银弹。国内绝大多数中小公司引入微服务都是在盲目追新，也能看出做此种技术选型的工程师基础架构素质的不足。 “你必须长的足够高才能使用微服务”。微服务基础设施，尤其是容器技术、自动化部署、自动化测试这些不完备，微服务形同虚设，不会带来什么质的提升。 微服务架构的关键不在于具体的实现，而在于如何合理地划分服务边界以及组织架构是否相匹配。不考虑研发团队的规模和组成就盲目上微服务是不良的技术选型。 Spring Boot 是 Spring 全家桶的上层封装，并不是什么崭新的技术，也不是什么值得觉得成为自己杀手锏的技术。 Spring Cloud 中 Spring Cloud Netflix 的组件是经过生产环境验证的，其他的则建议慎重选择。一、微服务是什么微服务起源于 2005 年 Peter Rodgers 博士在云端运算博览会提出的微 Web 服务(Micro-Web-Service)，根本思想类似于 Unix 的管道设计理念。2014 年，由 Martin Fowler 与 James Lewis 共同提出了微服务的概念，定义了微服务架构风格是一种通过一套小型服务来开发单个应用的方法，每个服务运行在自己的进程中，并通过轻量级的机制进行通讯（HTTP API）。关键的三点是 small、automated 以及 lightweight。对比 SOA，微服务可以看做是 SOA 的子集，是轻量级的 SOA，粒度更细的服务，独立进程、数据分离，更注重敏捷、持续交付、DevOps 以及去中心化实践。其共同的架构原理： 单一职责 关注分离：控制与逻辑相分离 模块化和分而治之特点： 用服务进行组件化 围绕业务能力进行组织 是产品而非项目 端点智能化和哑管道: 控制逻辑都在端点，管道仅仅是传输 全自动化部署 语言和数据的去中心化控制 面向失败设计 渐进式设计综合来看，其优缺点如下：优点： 模块的强边界 独立部署 技术选型的多样性缺点： 分布式带来编程复杂度，远程调用的消耗 舍弃强一致性，实现最终一致性 操作复杂性要求有一个成熟的运维团队或者运维基础设施二、为什么要采用微服务是否选择微服务取决于你要设计的系统的复杂度。微服务是用来把控复杂系统的，但是随之而来的就是引入了微服务本身的复杂度。需要解决包括自动化部署、监控、容错处理、最终一致性等其他分布式系统面临的问题。即使已经有一些普遍使用的解决方案，但是仍然是有不小的成本的。生产力和复杂度的关系如图所示，可见系统越复杂，微服务带来的收益越大。此外，无论是单体应用还是微服务，团队的技能都需要能够把控住。马丁.福勒的一个观点是：除非管理单体应用的成本已经太复杂了（太大导致很难修改和部署），否则都不要考虑微服务。大部分应用都应该选择单体架构，做好单体应用的模块化而不是拆分成服务。因此，系统一开始采用单体架构，做好模块化，之后随着系统变得越来越复杂、模块/服务间的边界越来越清晰，再重构为微服务架构是一个合理的架构演化路径。四个可以考虑上微服务的情况： 多人开发一个模块/项目，提交代码频繁出现大量冲突。 模块间严重耦合，互相依赖，每次变动需要牵扯多个团队，单次上线需求太多，风险大。 主要业务和次要业务耦合，横向扩展流程复杂。 熔断降级全靠 if-else。微服务的三个阶段： 微服务 1.0：仅使用注册发现，基于 SpringCloud 或者 Dubbo 进行开发。 微服务 2.0：使用了熔断、限流、降级等服务治理策略，并配备完整服务工具和平台。 微服务 3.0：Service Mesh 将服务治理作为通用组件，下沉到平台层实现，应用层仅仅关注业务逻辑，平台层可以根据业务监控自动调度和参数调整，实现 AIOps 和智能调度。三、微服务架构先决条件 快速的环境提供能力：依赖于云计算、容器技术，快速交付环境。 基本的监控能力：包括基础的技术监控和业务监控。 快速的应用部署能力：需要部署管道提供快速的部署能力。 Devops 文化：需要具有良好的持续交付能力，包括全链路追踪、快速环境提供和部署等，还需要快速的反应能力（对问题、故障的快速响应），开发和运维的协同工作。此外，根据康威定律和逆康威定律（技术架构倒逼组织架构改进），组织架构也是一个很关键的因素。对应于微服务架构，组织架构需要遵循以下原则： 一个微服务由一个团队维护，团队成员以三人为宜。 单个团队的任务和发展是独立的，不受其他因素影响。 团队是功能齐全、全栈、自治的，扁平、自我管理。基础设施微服务的推行需要依赖于很多底层基础设施，包括提供微服务的编译、集成、打包、部署、配置等工作，采用 PaaS 平台解决微服务从开发到运行的全生命周期管理，同时提供异构环境管理、容器资源隔离与互通、服务伸缩漂移、服务升级与回退、服务熔断与降级、服务注册与发现。 最基本的基础设施 进程间通讯机制：微服务是独立进程的，需要确定之间的通讯方式。 服务发现+服务路由: 提供服务注册中心，服务提供者和消费者通过服务发现获取服务的信息从而调用服务，实现服务的负载均衡等。 服务容错：微服务架构中，由于服务非常多，往往是一个服务挂了，整个请求链路的服务都受到影响，因此需要服务容错，在服务调用失败的时候能够处理错误或者快速失败，包括熔断、fallback、重试、流控和服务隔离等。 分布式事务支持：随着业务拆分为服务，那么有时候不开避免的就是跨服务的事务，即分布式事务的问题。原则是尽量避免分布式事务，如果无法避免那么可以使用消息系统或者 CQRS 和 Event Sourcing 方案来实现最终一致性。如果需要强一致性，则有两阶段提交、三阶段提交、TCC 等分布式事务解决方案。 提升外部服务对接效率和内部开发效率 API 网关: 负责外部系统的访问，负责跨横切面的公共层面的工作，包括安全、日志、权限控制、传输加密、请求转发、流量控制等。典型的网关功能即对外暴露一个域名 xx.com，根据第一级目录做反向路由 xx.com/user，xx.com/trade。每一级目录，如 user、trade 对应一个服务的域名。此外，API 网关也可以有服务编排的功能（不推荐）。 接口框架: 规范服务之间通讯使用的数据格式、解析包、自解释文档，便于服务使用方快速上手等。 提升测试和运维效率 持续集成：这一部分并非是微服务特定的，对于之前的单体应用，此部分一般来说也是必要的。主要是指通过自动化手段，持续地对代码进程编译构建、自动化测试，以得到快速有效的质量反馈，从而保证代码的顺利交付。自动化测试包括代码级别的单元测试、单个系统的集成测试、系统间的接口测试。 自动化部署：微服务架构，节点数动辄上百上千，自动化部署能够提高部署速度和部署频率，从而保证持续交付。包括版本管理、资源管理、部署操作、回滚操作等功能。而对于微服务的部署方式，包括蓝绿部署、滚动部署以及金丝雀部署。 配置中心: 运行时配置管理能够解决动态修改配置并批量生效的问题。包括配置版本管理、配置项管理、节点管理、配置同步等。 持续交付：包括持续集成、自动化部署等流程。目的就是小步迭代，快速交付。 进一步提升运维效率 服务监控: 微服务架构下节点数目众多，需要监控的机器、网络、进程、接口等的数量大大增加，需要一个强大的监控系统，能够提供实时搜集信息进行分析以及实时分析之上的预警。包括监控服务的请求次数、响应时间分布、最大/最小响应值、错误码分布等 服务跟踪：跟踪一个请求的完整路径，包括请求发起时间、响应时间、响应码、请求参数、返回结果等信息，也叫做全链路跟踪。通常的服务监控可以和服务监控做在一起，宏观信息由服务跟踪呈现，微观单个服务/节点的信息由服务监控呈现。服务跟踪目前的实现理论基本都是 Google 的 Dapper 论文。 服务安全：内网之间的微服务调用原则上讲应该是都可以互相访问写，一般并不需要权限控制，但有时候限于业务要求，会对接口、数据等方面有安全控制的要求。此部分可以以配置的方式存在于服务注册中心中，和服务绑定，在请求时由做为服务提供者的服务节点进行安全策略控制。配置则可以存储在配置中心以方便动态修改。在微服务数量很少的情况下，以上基础设施的优先级自上而下降低。否则，仅仅依赖人工操作，则投入产出比会很低。还需要提到的是 Docker 容器技术。虽然这个对于微服务并不是必须的，但是容器技术轻量级、灵活、与应用依存、屏蔽环境差异的特性对于持续交付的实现是至关重要的，即使对于传统的单体应用也能够给其带来交付效率的大幅提升。四、架构设计模式在引入微服务之后，传统的单体应用变为了一个一个服务，之前一个应用直接提供接口给客户端访问的架构不再适用。微服务架构下，针对不同设备的接口做为 BFF 层（Backend For Frontend），也叫做用户体验适配层，负责聚合、编排微服务的数据转换成前端需要的数据。服务之间的调用则在允许的情况下（允许延迟）尽可能使用异步消息传递方式，如此形成面向用户体验的微服务架构设计模式。如下图所示：Client -&gt; API Gateway -&gt; BFF（Backend For Frontend） -&gt; Downstream Microservices 后台采用微服务架构，微服务可以采用不同的编程语言和不同的存储机制。 前台采用 BFF 模式对不同的用户体验（如桌面浏览器，Native App，平板响应式 Web）进行适配。 BFF、API Orchestration Layer，Edge Service Layer，Device Wrapper Layer 是相同的概念。 BFF 不能过多，过多会造成代码逻辑重复冗余。 可以将网关承担的功能，如 Geoip、限流、安全认证等跨横切面功能和 BFF 做在同一层，虽然增加了 BFF 层的复杂性，但能够得到性能优势。五、服务拆分微服务架构最核心的环节，主要是对服务的横向拆分。服务拆分就是讲一个完整的业务系统解耦为服务，服务需要职责单一，之间没有耦合关系，能够独立开发和维护。服务拆分不是一蹴而就的，需要在开发过程中不断地理清边界。在完全理清服务之前，尽量推迟对服务的拆分，尤其是对数据库的拆分。拆分方法如下： 基于业务逻辑拆分 基于可扩展拆分 基于可靠性拆分 基于性能拆分其中，对于无法修改的遗留系统，采用绞杀者模式：在遗留系统外面增加新的功能做成微服务方式，而不是直接修改原有系统，逐步的实现对老系统替换。拆分过程需要遵守的规范如下： 先少后多、先粗后细（粒度） 服务纵向拆分最多三层，两次调用：Controller、组合服务、基础服务 仅仅单向调用，禁止循环调用 串行调用改为并行调用或者异步化 接口应该幂等 接口数据定义严禁内嵌，透传 规范化工程名 先拆分服务，等服务粒度确定后再拆分数据库。六、微服务框架上面讲述了微服务架构的众多基础设施，如果每一个基础设施都需要自己开发的话是非常巨大的开发工作。目前市面上已经有不少开源的微服务框架可以选择。 Spring BootSpring Boot 是用来简化新 Spring 应用的初始搭建以及开发过程的。其虽然不是微服务框架，但其设计的初衷本质就是微应用的底层框架，因此非常适合用于微服务基础设施的开发以及微服务的应用开发。尤其对于 Spring 技术栈的团队来说，基于 Spring Boot 开发微服务框架和应用是自然而然的一个选择。 Dubbo&amp;&amp;MotanDubbo 阿里开源的服务治理框架。其出现在微服务理念兴起之前，可以看做是 SOA 框架的集大成之作。但其仅仅包含了微服务基础设施的部分功能，诸如熔断、服务跟踪、网关等都没有实现。 Motan 则是微博开源的类似 Dubbo 的 RPC 框架，与 Dubbo 相比更轻量级。 服务发现 ：服务发布、订阅、通知 高可用策略 ：失败重试（Failover）、快速失败（Failfast）、资源隔离 - 负载均衡 ：最少活跃连接、一致性 Hash、随机请求、轮询等 扩展性 ：支持 SPI 扩展（service provider interface） 其他 ：调用统计、访问日志等 Spring CloudSpring Cloud 是基于 Spring Boot 实现的微服务框架，也可以看做一套微服务实现规范。基本涵盖了微服务基础设施的方方面面，包括配置管理、服务发现、断路器、智能路由、微代理、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等。其基于 Spring 生态，社区支持非常好。但其很多组件都没有经过生产环境验证，需要慎重选择。Spring Cloud Netflix 是 Spring Cloud 的一个子项目，是 Spring 对 Netflix OSS 的集成实现。基于 Netflix 的大规模使用，其中的已经被广泛使用的组件包括：此外，另一个子项目 Spring Cloud Alibaba 则是 Alibaba 开源的基于 Spring Boot 的微服务框架，主要是对阿里云服务的支持。 Eureka：服务注册和服务发现 Ribbon：弹性而智能的进程间和服务通讯机制，客户端负载均衡 Hystrix：熔断器，在运行时提供延迟和容错的隔离 Zuul: 服务网关 Service Mesh上述的微服务框架都是侵入式的，服务化的过程都需要进行代码改造。Service Mesh 则是下一代微服务架构，最明显的特征就是无入侵。采用 sidecar 模式来解决系统架构微服务化后的服务间通信和治理问题。目前主流的开源实现包括：限于 Service Mesh 带来的性能延迟的开销以及 sidecar 对分布复杂性的增加，其对大规模部署(微服务数目多)、异构复杂(交互协议/开发语言类型多)的微服务架构带来的收益会更大。 Linkerd 和 Envoy：以 sidecar 为核心，关注如何做好 proxy，并完成一些通用控制平面的功能。缺乏对这些 sidecar 的管理和控制。 Istio 和 Conduit：目前最为流行的 Service Mesh 实现方案，集中在更加强大的控制平面(sidecar 被称为数据平面)功能。前者由 Google 和 IBM 合作，并使用了 Envoy 作为 sidecar 部分的实现；后者则是 Linkerd 作者的作品。相比起来，Istio 有巨头背景，功能强大，但可用性和易用性一直不高，Conduit 则相对简单、功能聚焦。 Sofastack蚂蚁金服开源的构建金融级分布式架构的一套中间件。包括微服务开发框架、RPC 框架、服务注册中心、全链路追踪、服务监控、Service Mesh 等一整套分布式应用开发工具。特别值得一提的是 SOFAMesh。其实对下一代微服务架构 Service Mesh 的大规模落地方案实践，基于 Istio 改进和扩展而来，应该是国内最为成熟的开源 Service Mesh 方案。此外，需要提到 Kubernetes(K8s)，其本身提供了部分的微服务特性支持（通过域名做服务发现），对代码无侵入。但服务调用、熔断这些都需要自己实现。综上，目前公司技术团队技术栈是 Spring，并且已有服务的实现都是基于 Dubbo，因此选择 Spring Cloud Netflix 做为基础的微服务框架，对其中不成熟或者缺乏的组件，选择业界更为成熟的组件替代即可。 API 网关：Zuul 服务注册中心：Dubbo 配置中心：disconf 服务监控&amp;&amp;全链路追踪：CAT 服务开发框架：Spring Boot 日志监控、告警：ELK + Elasalert 流量控制：Sentinel 消息队列：Kafka" }, { "title": "软件质量成本", "url": "/posts/2021-02-10/cost-of-software-quality/", "categories": "Tech", "tags": "Quality", "date": "2021-02-10 00:00:00 +0800", "snippet": " 翻译自软件领域神级人物 Martin Fowler 的文章。软件开发项目中，一个常见的争论是花时间提高软件质量还是专注于发布更有价值的功能。通常，功能的交付压力会主导着讨论，导致许多开发人员抱怨他们没有时间提升架构和代码质量。“Betteridge’s Law of headlines” 这句谚语说的是任何以问号结尾的文章标题都可以用“否”来概括。了解我的人知道我会颠覆这样的规律，但是这...", "content": " 翻译自软件领域神级人物 Martin Fowler 的文章。软件开发项目中，一个常见的争论是花时间提高软件质量还是专注于发布更有价值的功能。通常，功能的交付压力会主导着讨论，导致许多开发人员抱怨他们没有时间提升架构和代码质量。“Betteridge’s Law of headlines” 这句谚语说的是任何以问号结尾的文章标题都可以用“否”来概括。了解我的人知道我会颠覆这样的规律，但是这篇文章讨论的更进一步：它颠覆了问题本身。这个问题假定了质量和成本之间的权衡，通过本文，我将解释这种权衡并不适用于软件，高质量的软件实际上更便宜。虽然我大部分的文章都是针对专业软件开发人员的，但本文并不需要具有软件开发的专业知识。我希望这篇文章对任何关注软件工作的人都有价值，特别是那些软件开发团队客户的商业领袖。我们习惯于在质量和成本之间进行权衡正如本文开篇所讲，我们习惯于在质量和成本之间进行权衡。当我更换智能手机时，可以选处理器更快、屏幕更好、内存更大但同时也更昂贵的机型，或者可以放弃一些质量换取更低的价格。但事无绝对，有时候我们也可以花更少的钱买到高质量的东西。我们往往对质量有不同的定义：有些人并没有真正注意到一个屏幕比另一个更好。但多数情况下，更高的质量意味着更多的花费。软件质量意味着很多事在谈软件质量之前，需要先来解释下什么是软件质量。这是第一个复杂问题，很多东西可以算作软件的质量。从用户界面的角度来看：它是否能便捷的引导我完成某项任务，使我更有效率且不会遇到阻碍？从可靠性的角度来看：它是否包含导致错误和崩溃的缺陷？从架构的角度来看：源代码是否分为明确的模块，以便程序员可以轻松找到并理解本周需要处理的代码？这三个质量的例子并不是一个详尽的列表，但它们足以说明一个重要的观点。如果我是软件的客户或用户，我并不理解我们称之为“质量”的一些东西。用户可以判断用户界面是否良好，一位管理者可以判断该软件是否使他的员工工作更有效率，用户和客户会注意到缺陷，特别是损坏数据或使系统暂时无法运行的缺陷，但是客户和用户无法理解软件的架构。因此，我将软件质量属性划分为外部（例如 UI 和缺陷）和内部（架构）。区别在于，用户和客户可以理解什么样的软件产品具有高外部质量，但无法区分内部质量的高低。乍一看，内部质量和客户没有关系既然客户或用户看不到内部质量，那么它重要吗？想象一下我和 Rebecca 各自写了一个跟踪和预测航班延误的应用程序。我们的应用程序核心功能相同，都有同样优雅的用户界面，并且几乎没有任何缺陷。唯一的区别是她的内部源代码整洁有序，而我的却是混乱的。另外一个区别是：我的产品售价 6 美元，她的产品售价 10 美元。由于客户不会看到源代码，并且它不会影响应用程序的运行，为什么有人会为 Rebecca 的软件额外支付 4 美元？通俗的讲，没有必要为更高的内部质量支付更多的钱。换句话说，为外部质量买单是有意义的，但为内部质量买单是没意义的。用户可以判断他是否要为更好的用户界面支付更多的费用，因为他们能够评估用户界面的好坏。但是用户无法看到软件内部模块化的结构，更不用说判断它的好坏了。既然如此，为什么软件开发者要花时间和精力来提高软件的内部质量呢？提升内部质量使软件改进更加便捷为什么软件开发人员会在内部质量上大做文章呢？程序员大部分时间都在修改代码。即使在新系统中，几乎所有编程都是在现有代码库上完成的。当我想为软件添加新功能时，第一个任务就是弄清楚这个功能如何适应现有应用程序的流程，然后我需要更改该流程以使适应我的功能。我经常需要使用已经在应用程序中的数据，因此我需要了解这些数据代表什么，它与周围数据的关系以及需要为新功能添加哪些数据。所有这些都是有关理解现有代码的。但是软件很难理解。逻辑可能变得纠结，数据可能难以理解，某个命名可能六个月前对 Tony 有意义，但对我来说，这和他离开公司的理由一样神秘。凡此种种，开发人员称之为 cruft（1），即当前代码与理想情况之间的差异。内部质量的一个主要特点是让我更容易弄清楚应用程序的工作原理，这样就可以知道如何添加内容。如果将软件很好地划分为独立的模块，就不必阅读全部 500,000 行代码，我可以在几个模块中快速找到几百行。如果我们将精力放在明确的命名上，我可以快速了解代码的各个部分，而不必阅读细节。如果数据合理地遵循基础业务的语言和结构，我可以很容易地理解它与客户服务端的请求之间的关系。技术债使我需要花费更多的时间理解如何做出更改，也提升了犯错误的概率。如果发现问题，则需要花费更多的时间去定位和解决问题。如果没有发现这些问题，它们就会成为线上问题，以后会花更多的时间来修理。我的改动也会影响未来。我可能会找到一种快速添加这个功能的方式，但这会违背程序模块化结构，增加了技术债。如果我这样做了，虽然今天可以更快的完成，但是在未来几周和几个月里，其他所有必须处理此代码的人都只能放慢速度。一旦团队中的其他成员也决定用这种快捷的方法来完成功能，一个易于修改的应用程序会变得任何一个微小的改动都要耗费数周的时间。客户确实会关心新功能的快速引入在这方面内部质量对用户和客户至关重要。更好的内部质量使得添加新功能更容易、更快、更便宜。可能现在我和 Rebecca 的应用程序是相同的，但在接下来的几个月里，由于 Rebecca 的高内部质量，她可以每周都添加新功能，而我却一直努力试图在这些技术债中增加新功能。我的生产速率在降低，很快她的软件就比我的软件有更多的功能了。然后，即便她提升价格，客户也都删除了我的应用程序，用了 Rebecca 的。内部质量影响的可视化内部质量的基本作用是降低未来变化的成本，但是编写好的软件需要额外的努力，这在短期内会产生一些成本。一种可视化的方法是使用以下伪图（pseduo-graph），纵坐标为软件累积的功能，横坐标为实现它的时间（成本）。对于大多数软件工作，曲线看起来像这样。内部质量较差时如上图所示。最初进展很快，但随着时间的推移，添加新功能变得更加困难。即使很小的变化也需要程序员理解大量晦涩难懂的代码。修改代码时，会产生意外的破坏，导致需要长时间来测试，且有很多缺陷要修复。专注于高内部质量就是减少生产力的下降。事实上，有些产品会产生相反的效果，开发人员可以利用先前的工作轻松构建新功能。这种情况是一种罕见的情况，因为它需要一支技术精湛，训练有素的团队来实现这一目标。但我们偶尔会遇到。这里的微妙之处在于，在一段时间内，低内部质量比高内部质量的生产力更高。在此期间，在质量和成本之间存在某种权衡。问题是：两条线交叉前的这段时间有多长？此时我们可以明白为什么这是一个伪图。因为无法量化软件团队所交付的功能。由于无法量化产出，从而无法衡量生产率，因此无法对低内部质量的后果进行可靠的量化。无法衡量产出在专业工作中非常普遍，比如我们如何衡量律师或医生的生产力？我通过收集我所知道的熟练开发人员的意见来评估两条线交叉点。答案让很多人感到惊讶。开发人员发现质量差的代码会在几周内显着降低开发速度。因此，内部质量和成本之间的权衡取舍并不多。即使很小的软件工作也会受益于对良好软件实践的关注，当然我可以从我的经验中证明这一点。即使最好的团队也会产生技术债许多非开发人员倾向于认为只有当开发团队粗心大意或犯错时才会发生这种事情，但即使是最优秀的团队也会在工作时不可避免地产生一些技术债。我想用一个和我们最好的技术团队负责人聊天的故事来说明这一点。他刚刚完成了一个被广泛认为是非常成功的项目。无论是在功能，时间和成本方面，客户都对交付的系统感到满意。同事们对在此项目的工作经验给出了非常积极的评价。技术负责人非常高兴，但承认系统的架构并不那么好。我的反应是“怎么可能，你是我们最好的架构师之一？”他的答复是任何一位经验丰富的软件架构师都熟悉的答案：“我们做出了很好的决策，但现在才明白应该如何构建它”。许多人，包括软件行业的一些人，将构建软件比作建造教堂或摩天大楼，这也是为什么我们称资深程序员为“架构师”。但构建软件相比于物理世界不同，它是存在于未知的不确定世界中。软件的客户只是粗略地了解他们在产品中需要哪些功能，并在构建软件时了解更多信息（特别是一旦早期版本发布给用户后）。软件开发的构建模块（语言，库和平台）每隔几年就会发生重大变化。映射到物理世界中就是，当建筑物被建造和使用后，客户要添加新楼层并改变楼层平面图，混凝土的基本属性也每隔一年就会发生变化。鉴于这种程度的变化，软件项目总是推陈出新。我们几乎不会去主动了解那些已经被轻易解决的问题。当我们构建解决方案时，自然会了解它，所以我常常听到，团队只有在花了一年左右的时间构建它之后，才能真正理解软件的架构。即使是最好的团队在他们的软件中也会有技术债。不同的是，最好的团队其技术债较少，同时也会偿还技术债，以便继续快速添加功能。他们花时间完成自动化测试，以便能够快速解决问题并减少时间的浪费。他们经常进行重构，以便持续的偿还技术债。当团队成员工作目标相互冲突时，持续集成可以最大限度地减少技术债。一个常见的比喻就是清理厨房的工作台面和厨具。你做饭时不得不弄脏东西，但是如果不快速清理东西，淤泥干涸，更难去除，所有肮脏的东西会妨碍烹饪下一道菜。高质量的软件生产成本更低总结起来有如下几点： 忽视内部质量会导致技术债快速累积 技术债降低了功能的开发速度 即使最优秀的团队也会产生技术债，但是通过保持高内部质量可以使其变得可控 高内部质量可以最小化技术债，使得添加新功能的工作量、时间和成本都更少可悲的是，软件开发人员通常不会很好地解释这种情况。我多次和开发团队谈过，他们说“他们（管理层）不会让我们写出高质量的代码，因为这需要太长时间”。开发人员通常需要适当的专业性来关注质量。但是，这种道德主义的论证意味着高质量是有代价的，这使他们的论点失败了。令人讨厌的是，低质量的代码既使得开发人员的生活更加艰难，又让客户付出了更多成本。在考虑内部质量时，我强调我们应该使用经济论证的方法。高内部质量降低了未来功能的成本，这意味着花时间编写好的代码实际上降低了成本。这就是为什么文章开头提出的问题忽略了这一点。为构建软件高内部质量所带来的“损耗”实际上是在降低损耗。我们在生活中做大多数决策的时候，习惯于在成本和质量之间进行权衡，但这对于软件的内部质量没有意义。（它适用于外部质量，例如精心设计的用户体验。）因为成本和内部质量之间的关系是一种不同寻常和反直觉的关系，所以通常很难理解。但了解它对于以最高效率开发软件至关重要。" }, { "title": "Jenkins Pipeline 一点通", "url": "/posts/2021-02-01/jenkins-pipeline/", "categories": "Tech", "tags": "Jenkins", "date": "2021-02-01 00:00:00 +0800", "snippet": "本文主要介绍在生产环境中持续集成与持续部署的使用，主要通过实现 Jenkins 流水线脚本自动发布应用到 Kubernetes 集群当中。CI/CD 介绍CI（Continuous Integration，持续集成）/CD（Continuous Delivery，持续交付）是一种通过在应用开发阶段引入自动化来频繁向客户交付应用的方法。CI/CD 的核心概念是持续集成、持续交付和持续部署。作为...", "content": "本文主要介绍在生产环境中持续集成与持续部署的使用，主要通过实现 Jenkins 流水线脚本自动发布应用到 Kubernetes 集群当中。CI/CD 介绍CI（Continuous Integration，持续集成）/CD（Continuous Delivery，持续交付）是一种通过在应用开发阶段引入自动化来频繁向客户交付应用的方法。CI/CD 的核心概念是持续集成、持续交付和持续部署。作为一个面向开发和运营团队的解决方案，CI/CD 主要针对在集成新代码时所引发的问题（亦称 “集成地狱”）。具体而言，CI/CD 在整个应用生命周期内（从集成和测试阶段到交付和部署）引入了持续自动化和持续监控，这些关联的事务通常被称为 “CI/CD 管道”，由开发和运维团队以敏捷方式协同支持。CI 和 CD 的区别CI/CD 中的 CI 指持续集成，它属于开发人员的自动化流程。成功的 CI 意味着应用代码的最新更改会定期构建、测试并合并到共享存储中。该解决方案可以解决在一次开发中有太多应用分支，从而导致相互冲突的问题。CI/CD 中的 CD 指的是持续交付或持续部署，这些相关概念有时会交叉使用。两者都事关管道后续阶段的自动化，但它们有时也会单独使用，用于说明自动化程度。持续交付通常是指开发人员对应用的更改会自动进行错误测试并上传到存储库（如 GitLab 或容器注册表），然后由运维团队将其部署到实时生产环境中，旨在解决开发和运维团队之间可见性及沟通较差的问题，因此持续交付的目的就是确保尽可能减少部署新代码时所需的工作量。持续部署指的是自动将开发人员的更改从存储库发布到生产环境中以供客户使用，它主要为解决因手动流程降低应用交付速度，从而使运维团队超负荷的问题。持续部署以持续交付的优势为根基，实现了管道后续阶段的自动化。CI/CD 既可能仅指持续集成和持续交付构成的关联环节，也可以指持续集成、持续交付和持续部署这三个方面构成的关联环节。更为复杂的是有时持续交付也包含了持续部署流程。纠缠于这些语义其实并无必要，只需记得 CI/CD 实际上就是一个流程（通常表述为管道），用于在更大程度上实现应用开发的持续自动化和持续监控。持续集成（CI）现代应用开发的目标是让多位开发人员同时开发同一个应用的不同功能。但是，如果企业安排在一天内将所有分支源代码合并在一起，最终可能导致工作繁琐、耗时，而且需要手动完成。这是因为当一位独立工作的开发人员对应用进行更改时，有可能会有其他开发人员同时进行更改，从而引发冲突。持续集成可以帮助开发人员更加频繁地将代码更改合并到共享分支或主干中。一旦开发人员对应用所做的更改被合并，系统就会通过自动构建应用并运行不同级别的自动化测试（通常是单元测试和集成测试）来验证这些更改，确保更改没有对应用造成破坏。这意味着测试内容涵盖了从类和函数到构成整个应用的不同模块，如果自动化测试发现新代码和现有代码之间有冲突，持续集成（CI）可以更加轻松地快速修复这些错误。持续交付（CD）完成持续集成中构建单元测试和集成测试的自动化流程后，通过持续交付可自动将已验证的代码发布到存储库。为了实现高效的持续交付流程，务必要确保持续交付已内置于开发管道。持续交付的目标是拥有一个可随时部署到生产环境的代码库。在持续交付中，每个阶段（从代码更改的合并到生产就绪型构建版本的交付）都涉及测试自动化和代码发布自动化。在流程结束时，运维团队可以快速、轻松地将应用部署到生产环境中。持续部署对于一个成熟的 CI/CD 管道来说，最后的阶段是持续部署。作为持续交付（自动将生产就绪型构建版本发布到代码存储库）的延伸，持续部署可以自动将应用发布到生产环境中。由于生产之前的管道阶段没有手动门控，因此持续部署在很大程度上都得依赖于精心设计的测试自动化。实际上，持续部署意味着开发人员对应用的更改在编写后的几分钟内就能生效，这更加便于持续接收和整合用户反馈。总而言之，所有这些 CI/CD 的关联步骤都有助于降低应用的部署风险，因此更便于以小件的方式（非一次性）发布对应用的更改。不过，由于还需要编写自动化测试以适应 CI/CD 管道中的各种测试和发布阶段，因此前期投资会很大。Jenkins 流水线介绍本节主要讲解 Jenkins 的新功能 —— Jenkins 流水线（Pipeline）的使用，首先介绍流水线的概念和类型，然后讲解流水线的基本语法和一些例子。什么是流水线Jenkins 流水线（或 Pipeline）是一套插件，它支持实现并把持续提交流水线（Continuous Delivery Pipeline）集成到 Jenkins。持续提交流水线（Continuous Delivery Pipeline）会经历一个复杂的过程：从版本控制、向用户和客户提交软件，软件的每次变更（提交代码到仓库）到软件发布（Release）。这个过程包括以一种可靠并可重复的方式构建软件，以及通过多个测试和部署阶段来开发构建好的软件（称为 Build）。流水线提供了一组可扩展的工具，通过流水线语法对从简单到复杂的交付流水线作为代码进行建模，Jenkins 流水线的定义被写在一个文本文件中，一般为 Jenkinsfile，该文件 “编制” 了整个构建软件的过程，该文件一般也可以被提交到项目的代码仓库中，在 Jenkins 中可以直接引用。这是流水线即代码的基础，将持续提交流水线作为应用程序的一部分，像其他代码一样进行版本化和审查。创建 Jenkinsfile 并提交到代码仓库中的好处如下： 自动地为所有分支创建流水线构建过程 在流水线上进行代码复查 / 迭代 对流水线进行审计跟踪 流水线的代码可以被项目的多个成员查看和编辑Jenkins 流水线概念流水线主要分为以下几种区块：Pipeline、Node、Stage、Step 等。 Pipeline（流水线），Pipeline 是用户定义的一个持续提交（CD）流水线模型。流水线的代码定义了整个的构建过程，包括构建、测试和交付应用程序的阶段。另外，Pipeline 块是声明式流水线语法的关键部分。 Node（节点），Node（节点）是一个机器，它是 Jenkins 环境的一部分，另外，Node 块是脚本化流水线语法的关键部分。 Stage（阶段），Stage 块定义了在整个流水线的执行任务中概念不同的子集（比如 Build、Test、Deploy 阶段），它被许多插件用于可视化 Jenkins 流水线当前的状态 / 进展。 Step（步骤），本质上是指通过一个单一的任务告诉 Jenkins 在特定的时间点需要做什么，比如要执行 shell 命令，可以使用 sh SHELL_COMMAND。 声明式流水线在声明式流水线语法中，Pipeline 块定义了整个流水线中完成的所有工作，比如：说明： agent any：在任何可用的代理上执行流水线或它的任何阶段。 stage (‘Build’)：定义 Build 阶段。 steps：执行某阶段相关的步骤。脚本化流水线在脚本化流水线语法中，会有一个或多个 Node（节点）块在整个流水线中执行核心工作，比如：说明： node：在任何可用的代理上执行流水线或它的任何阶段。 stage (‘Build’)：定义 build 阶段。stage 块在脚本化流水线语法中是可选的，然而在脚本化流水线中实现 stage 块，可以清楚地在 Jenkins UI 界面中显示每个 stage 的任务子集。流水线示例一个以声明式流水线的语法编写的 Jenkinsfile 文件如下：常用参数说明： pipeline 是声明式流水线的一种特定语法，定义了包含执行整个流水线的所有内容和指令。 agent 是声明式流水线的一种特定语法，指示 Jenkins 为整个流水线分配一个执行器（在节点上）和工作区。 stage 是一个描述流水线阶段的语法块，在脚本化流水线语法中，stage（阶段）块是可选的。 steps 是声明式流水线的一种特定语法，它描述了在这个 stage 中要运行的步骤。 sh 是一个执行给定 shell 命令的流水线 step（步骤）。 junit 是一个聚合测试报告的流水线 step（步骤）。 node 是脚本化流水线的一种特定语法，它指示 Jenkins 在任何可用的代理 / 节点上执行流水线，这实际等同于声明式流水线特定语法的 agent 注：后续的例子中要用到。上述声明式流水线等同于以下脚本式流水线：Pipeline 语法本节主要从流水线的两种类型出发讲解 Pipeline 的语法。声明式流水线声明式流水线是在流水线子系统之上提供了一种更简单、更有主见的语法。所有有效的声明式流水线必须包含在一个 Pipeline 块中，比如以下是一个 Pipeline 块的格式：pipeline {/* insert Declarative Pipeline here */}在声明式流水线中有效的基本语句和表达式遵循与 Groovy 的语法同样的规则，但有以下例外： 流水线顶层必须是一个 block，pipeline {}。 没有分号作为语句分隔符，每条语句都在自己的行上。 块只能由 Sections、Directives、Steps 或 assignment statements 组成。Sections声明式流水线中的 Sections 通常包含一个或多个 agent、Stages、post、Directives 和 Steps，本节首先介绍 agent、Stages、post，有关 Directives 和 Steps 的说明见下一小节。agent：agent 部分指定了整个流水线或特定的部分，在 Jenkins 环境中执行的位置取决于 agent 区域的位置，该部分必须在 Pipeline 块的顶层被定义，但是 stage 级别的使用是可选的。①参数为了支持可能有的各种各样的流水线，agent 部分支持一些不同类型的参数，这些参数应用在 pipeline 块的顶层，或 Stage 指令内部。any：在任何可用的代理上执行流水线或 stage。例如：agent any。none：当在 pipeline 块的顶部没有全局 agent，该参数将会被分配到整个流水线的运行中，并且每个 stage 部分都需要包含它自己的 agent，比如：agent none。在提供了标签的 Jenkins 环境中可用代理上执行流水线或 stage。例如：agent {label ‘my-defined-label’}。node：agent {node { label ‘labelName’} } 和 agent { label ‘labelName’ } 一样，但是 node 允许额外的选项（比如 customWorkspace）。dockerfile：执行流水线或 stage，使用从源码包含的 Dockerfile 所构建的容器。为了使用该选项，Jenkinsfile 必须从多个分支流水线中加载，或者加载 Pipelinefrom SCM（下面章节会涉及）。通常，这是源码根目录下的 Dockerfile:agent {dockerfile true}。如果在其他目录下构建 Dockerfile，使用 dir 选择：agent { dockerfile { dir ‘someSubDir’} }。如果 Dockerfile 有另一个名字，可以使用 filename 选项指定该文件名。也可以传递额外的参数到 dockerbuild，使用 additionalBuildArgs 选项提交，比如：agent { dockerfile { additionalBuildArgs ‘--build-arg foo=bar’ } }。例如一个带有 build/Dockerfile.build 的仓库，在构建时期望一个参数 version：docker：使用给定的容器执行流水线或 stage。该容器将在预置的 node（节点）上，或在由 label 参数指定的节点上，动态地接受基于 Docker 的流水线。Docker 也可以接受 args 参数，该参数可能包含直接传递到 dockerrun 调用的参数及 alwaysPull 选项，alwaysPul 选项强制 dockerpull，即使镜像（image）已经存在。比如：agent {docker ‘maven:3-alpine’} 或：agent{ docker{ image ‘maven:3-alpine’ label ‘my-defined-label’ args ‘-v /tmp:/tmp’ }}②常见选项label：一个字符串，该标签用于运行流水线或个别 stage。该选项对 node、docker 和 dockerfile 可用，node 必须选择该选项。customWorkspace：一个字符串，在自定义工作区运行流水线或 stage。它可以是相对路径，也可以是绝对路径，该选项对 node、docker 和 dockerfile 可用。比如：reuseNode：一个布尔值，默认为 false。如果是 true，则在流水线顶层指定的节点上运行该容器。这个选项对 docker 和 dockerfile 有用，并且只有当使用在个别 stage 的 agent 上才会有效。③示例示例 1：在 maven:3-alpine（agent 中定义）的新建容器上执行定义在流水线中的所有步骤。示例 2：本示例在流水线顶层定义 agentnone，确保 «../glossary#executor, an Executor» 没有被分配。使用 agentnode 也会强制 stage 部分包含它自己的 agent 部分。在 stage (‘Example Build’) 部分使用 maven:3-alpine 执行该阶段步骤，在 stage (‘Example Test’) 部分使用 openjdk:8-jre 执行该阶段步骤。post：post 部分定义一个或多个 steps，这些阶段根据流水线或 stage 的完成情况而运行（取决于流水线中 post 部分的位置）。post 支持以下 post-condition 块之一：always：无论流水线或 stage 的完成状态如何，都允许在 post 部分运行该步骤。changed：只有当前流水线或 stage 的完成状态与它之前的运行不同时，才允许在 post 部分运行该步骤。failure：只有当前流水线或 stage 的完成状态为失败（failure），才允许在 post 部分运行该步骤，通常这时在 Web 界面中显示为红色。success：当前状态为成功（success），执行 post 步骤，通常在 Web 界面中显示为蓝色或绿色。unstable：当前状态为不稳定（unstable），执行 post 步骤，通常由于测试失败或代码违规等造成，在 Web 界面中显示为黄色。aborted：当前状态为放弃（aborted），执行 post 步骤，通常由于流水线被手动放弃触发，这时在 Web 界面中显示为灰色。示例：一般情况下 post 部分放在流水线的底部，比如本实例，无论 stage 的完成状态如何，都会输出一条 I will always say Hello again! 信息。stages：stages 包含一个或多个 stage 指令，stages 部分是流水线描述的大部分工作（work）的位置。建议 stages 至少包含一个 stage 指令，用于持续交付过程的某个离散的部分，比如构建、测试或部署。示例：本示例的 stages 包含一个名为 Example 的 stage，该 stage 执行 echo ‘Hello World’ 命令输出 Hello World 信息。seps：steps 部分在给定的 stage 指令中执行的一个或多个步骤。示例：在 steps 定义执行一条 shell 命令。DirectivesDirectives 用于一些执行 stage 时的条件判断，主要分为 environment、options、parameters、triggers、stage、tools、input、when 等，这里仅对常用的 environment、parameters、stage 和 when 进行介绍。environment：environment 制定一个键 - 值对（key-value pair）序列，该序列将被定义为所有步骤的环境变量，或者是特定 stage 的步骤，这取决于 environment 指令在流水线内的位置。该指令支持一个特殊的方法 credentials ()，该方法可用于在 Jenkins 环境中通过标识符访问预定义的凭证。对于类型为 Secret Text 的凭证，credentials () 将确保指定的环境变量包含秘密文本内容，对于类型为 Standardusernameandpassword 的凭证，指定的环境变量为 username:password，并且两个额外的环境变量将被自动定义，分别为 MYVARNAMEUSR 和 MYVARNAMEPSW。示例：上述示例的顶层流水线块中使用的 environment 指令将适用于流水线中的所有步骤。在 stage 中定义的 environment 指令只会适用于 stage 中的步骤。其中 stage 中的 environment 使用的是 credentials 预定义的凭证。parameters：parameters 提供了一个用户在触发流水线时应该提供的参数列表，这些用户指定参数的值可以通过 params 对象提供给流水线的 step（步骤）。可用参数： string：字符串类型的参数，例如：parameters {string (name: ‘DEPLOY_ENV’, defaultValue: ‘staging’, description: ‘’) }。 booleanParam：布尔参数，例如: parameters {booleanParam (name: ‘DEBUG_BUILD’, defaultValue: true, description: ‘’) }。示例：定义 string 类型的变量，并在 steps 中引用。stage：stage 指定在 stages 部分流水线所做的工作都将封装在一个或多个 stage 指令中。示例：when：when 指令允许流水线根据给定的条件决定是否应该执行 stage。when 指令必须包含至少一个条件。如果 when 包含多个条件，所有的子条件必须返回 True，stage 才能执行。①内置条件 branch：当正在构建的分支与给定的分支匹配时，执行这个 stage，例如：when {branch ‘master’}。注意，branch 只适用于多分支流水线 environment：当指定的环境变量和给定的变量匹配时，执行这个 stage，例如：when {environment name: ‘DEPLOY_TO’, value: ‘production’}。 expression：当指定的 Groovy 表达式评估为 True，执行这个 stage，例如：when {expression { return params.DEBUG_BUILD} }。 not：当嵌套条件出现错误时，执行这个 stage，必须包含一个条件，例如：when {not { branch ‘master’} }。 allOf：当所有的嵌套条件都正确时执行这个 stage，必须包含至少一个条件，例如：when {allOf { branch ‘master’; environment name: ‘DEPLOY_TO’, value: ‘production’} } anyOf：当至少有一个嵌套条件为 True 时执行这个 stage，例如：when {anyOf { branch ‘master’; branch’staging’} }。②在进入 stage 的 agent 前评估 when默认情况下，如果定义了某个 stage 的 agent，在进入该 stage 的 agent 后，该 stage 的 when 条件才会被评估。但是可以通过在 when 块中指定 beforeAgent 选项来更改此选项。如果 beforeAgent 被设置为 True，那么就会首先对 when 条件进行评估，并且只有在 when 条件验证为真时才会进入 agent。③示例示例 1：当 branch 为 production 时才会执行名为 Example Deploy 的 stage。示例 2：当 branch 为 production，environment 的 DEPLOY_TO 为 production 才会执行名为 Example Deploy 的 stage。示例 3：当 branch 为 production 并且 DEPLOY_TO 为 production 时才会执行名为 Example Deploy 的 stage。示例 4：当 DEPLOY_TO 等于 production 或者 staging 时才会执行名为 Example Deploy 的 stage。示例 5：当 BRANCHNAME 为 production 或者 staging，并且 DEPLOYTO 为 production 或者 staging 时才会执行名为 Example Deploy 的 stage。示例 6：在进行 agent 前执行判断，当 branch 为 production 时才会进行该 agent。stepsSteps 包含一个完整的 script 步骤列表。Script 步骤需要 scripted-pipeline 块并在声明式流水线中执行。对于大多数用例来说，script 步骤并不是必要的。示例：在 steps 添加 script 进行 for 循环。脚本化流水线脚本化流水线与声明式流水线一样都是建立在底层流水线的子系统上，与声明式流水线不同的是，脚本化流水线实际上是由 Groovy 构建。Groovy 语言提供的大部分功能都可以用于脚本化流水线的用户，这意味着它是一个非常有表现力和灵活的工具，可以通过它编写持续交付流水线。脚本化流水线和其他传统脚本一致都是从 Jenkinsfile 的顶部开始向下串行执行，因此其提供的流控制也取决于 Groovy 表达式，比如：if/else 条件：另一种方法是使用 Groovy 的异常处理支持来管理脚本化流水线的流控制，无论遇到什么原因的失败，它们都会抛出一个异常，处理错误的行为必须使用 Groovy 中的 try/catch/finally 块，例如：Jenkinsfile 的使用上面讲过流水线支持两种语法，即声明式和脚本式，这两种语法都支持构建持续交付流水线。并且都可以用来在 Web UI 或 Jenkinsfile 中定义流水线，不过通常将 Jenkinsfile 放置于代码仓库中。创建一个 Jenkinsfile 并将其放置于代码仓库中，有以下好处： 方便对流水线上的代码进行复查 / 迭代。 对管道进行审计跟踪。 流水线真正的源代码能够被项目的多个成员查看和编辑。本节主要介绍 Jenkinsfile 常见的模式以及演示 Jenkinsfile 的一些特例。创建 JenkinsfileJenkinsfile 是一个文本文件，它包含了 Jenkins 流水线的定义并被用于源代码控制。以下流水线实现了 3 个基本的持续交付：对应的脚本式流水线如下：注意：不是所有的流水线都有相同的三个阶段。构建对于许多项目来说，流水线中工作（work）的开始就是构建（build），这个阶段的主要工作是进行源代码的组装、编译或打包。Jenkinsfile 文件不是替代现有的构建工具，如 GNU/Make、Maven、Gradle 等，可以视其为一个将项目开发周期的多个阶段（构建、测试、部署等）绑定在一起的粘合层。Jenkins 有许多插件用于构建工具，假设系统为 Unix/Linux，只需要从 shell 步骤（sh）调用 make 即可进行构建，Windows 系统可以使用 bat：说明： steps 的 shmake 表示如果命令的状态码为 0，则继续，为非零则失败。 archiveArtifacts 用于捕获构建后生成的文件。对应的脚本式流水线如下：测试运行自动化测试是任何成功的持续交付过程中的重要组成部分，因此 Jenkins 有许多测试记录、报告和可视化工具，这些工具都是由插件提供。下面的例子将使用 JUnit 插件提供的 junit 工具进行测试。在下面的例子中，如果测试失败，流水线就会被标记为不稳定，这时 Web 界面中的球就显示为黄色。基于记录的测试报告，Jenkins 也可以提供历史趋势分析和可视化：说明： 当 sh 步骤状态码为 0 时，调用 junit 进行测试。 junit 捕获并关联匹配 */target/.xml 的 Junit XML 文件。对应的脚本式流水线如下：部署当编译构建和测试都通过后，就会将编译生成的包推送到生产环境中，从本质上讲，Deploy 阶段只可能发生在之前的阶段都成功完成后才会进行，否则流水线会提前退出：说明：当前 build 结果为 SUCCESS 时，执行 publish。对应的脚本式流水线如下：处理 Jenkinsfile本节主要介绍 Jenkins 使用中如何处理 Jenkinsfile 及 Jenkinsfile 的编写方式。插入字符串Jenkins 使用与 Groovy 相同的规则进行字符串赋值，可以使用单引号或者双引号进行赋值。例如：def singlyQuoted = 'Hello'def doublyQuoted = \"World\"引用变量需要使用双引号：def username = 'Jenkins'echo 'Hello Mr. ${username}'echo \"I said, Hello Mr. ${username}\"运行结果：Hello Mr. ${username}I said, Hello Mr. Jenkins使用环境变量Jenkins 有许多内置变量可以直接在 Jenkinsfile 中使用，比如： BUILDID：当前构建的 ID，与 Jenkins 版本 1.597 + 中的 BUILDNUMBER 完全相同。 JOB_NAME：本次构建的项目名称。 JENKINS_URL：Jenkins 完整的 URL，需要在 System Configuration 设置。使用 env.BUILDID 和 env.JENKINSURL 引用内置变量：对应的脚本式流水线如下：Jenkinsfile (Scripted Pipeline)node { echo \"Running ${env.BUILD_ID} on ${env.JENKINS_URL}\"}更多参数请参考：https://wiki.jenkins.io/display/JENKINS/Building+a+software+project#Buildingasoftwareproject-JenkinsSetEnvironmentVariables。处理凭证本节主要介绍在 Jenkins 的使用过程中对一些机密文件的处理方式。机密文件、用户名密码、私密文件：Jenkins 的声明式流水线语法有一个 credentials () 函数，它支持 secrettext（机密文件）、usernameandpassword（用户名和密码）以及 secretfile（私密文件）。①机密文件示例本实例演示将两个 Secret 文本凭证分配给单独的环境变量来访问 Amazon Web 服务，需要提前创建这两个文件的 credentials（下面章节会有演示），Jenkinsfile 文件的内容如下：说明：上述示例定义了两个全局变量 AWSACCESSKEYID 和 AWSSECRETACCESSKEY，这两个变量引用的是 credentials 的两个文件，并且这两个变量均可以在 stages 直接引用（$AWSSECRETACCESSKEY 和 $AWSACCESSKEYID）。注意：如果在 steps 中使用 echo $AWSACCESSKEY_ID，此时返回的是 **，加密内容不会被显示出来。②用户名密码本示例用来演示 credentials 账号密码的使用，比如使用一个公用账户访问 Bitbucket、GitLab、Harbor 等，假设已经配置完成了用户名密码的 credentials，凭证 ID 为 jenkins-bitbucket-common-creds。可以用以下方式设置凭证环境变量：environment { BITBUCKET_COMMON_CREDS = credentials('jenkins-bitbucket-common-creds')}这里实际设置了下面的 3 个环境变量： BITBUCKETCOMMONCREDS，包含一个以冒号分隔的用户名和密码，格式为 username:password。 BITBUCKETCOMMONCREDS_USR，仅包含用户名的附加变量。 BITBUCKETCOMMONCREDS_PSW，仅包含密码的附加变量。此时，调用用户名密码的 Jenkinsfile 如下：注意：此时环境变量的凭证仅作用于 stage 1。处理参数声明式流水线的参数支持开箱即用，允许流水线在运行时通过 parametersdirective 接受用户指定的参数。如果将流水线配置为 BuildWithParameters 选项用来接受参数，那么这些参数将会作为 params 变量被成员访问。假设在 Jenkinsfile 中配置了名为 Greeting 的字符串参数，可以通过 ${params.Greeting} 访问该参数，比如：对应的脚本式流水线如下：处理失败声明式流水线默认通过 postsection 支持健壮的失败处理方式，允许声明许多不同的 postconditions，比如 always、unstable、success、failure 和 changed，具体可参考 Pipeline 的语法。比如，以下是构建失败发送邮件通知的示例：对应的脚本式流水线如下：使用多个代理流水线允许在 Jenkins 环境中使用多个代理，这有助于更高级的用例，例如跨多个平台执行构建、测试等。比如，在 Linux 和 Windows 系统的不同 agent 上进行测试：本文节选自《再也不踩坑的 Kubernetes 实战指南》。" }, { "title": "敏捷中的以终为始", "url": "/posts/2021-01-23/DOD-DOR/", "categories": "Agile", "tags": "Agile, Scrum", "date": "2021-01-23 00:00:00 +0800", "snippet": "DoR 和 DoD 是敏捷中两个最基本也是最有用的概念，是“以终为始”落实的关键。循环迭代为了把产品做的更好，我们需要不停地迭代和改进产品。在每个迭代中我们关注两件事： 什么样的需求才可以开始做（准入条件，DoR） 做成什么样子需求才算做完（准出条件，DoD）把没有完成或没有细化的用户需求放到迭代中，会在开发阶段产生各种问题，因为它遵循一个古老的原则：“进去的是垃圾，出来的也是垃圾”。如...", "content": "DoR 和 DoD 是敏捷中两个最基本也是最有用的概念，是“以终为始”落实的关键。循环迭代为了把产品做的更好，我们需要不停地迭代和改进产品。在每个迭代中我们关注两件事： 什么样的需求才可以开始做（准入条件，DoR） 做成什么样子需求才算做完（准出条件，DoD）把没有完成或没有细化的用户需求放到迭代中，会在开发阶段产生各种问题，因为它遵循一个古老的原则：“进去的是垃圾，出来的也是垃圾”。如果开发基于没有充分细化或定义的用户故事来开发，不太可能产出高质量的代码。一个“准备好”放入迭代的需求应该是清晰的，可行的，可测试的： “清晰的”意味着所有的团队成员对该需求达成了共识。通过协同编写用户故事，对高优先级事项添加验收标准，有利于需求的澄清。 “可测试的”意味着能通过有效的办法决定该条目是否符合期望。验收标准可确保每个故事都能被测试。 “可行的”意味着根据 DoD，该条目能够在一个迭代中完成。否则，条目需要进一步的分解。DoR 是什么 DoR: Definition of ReadyDoR 是一个待办需求（backlog）是否能够被团队接受，可以作为开发候选所需要达到的最小要求，是团队对产品负责人 PO 提出的要求。DoR 的一些例子 用户故事是清晰的 用户故事是可测试的 用户故事是可行的 用户故事已定义 用户故事验收标准已定义 用户故事依赖已明确 用户故事已由开发团队做过粒度划分 Scrum 团队已接受 UI 原型设计 指定场景下的性能指标已明确 指定场景下的可扩展性指标已明确 指定场景下的安全指标已明确 验收用户故事的人已明确 团队都清楚用户故事所表达的意思DoD 是什么 DoD: Definition of Done“DoD” 是开发团队在交付用户需求需要达到的最低验收条件，是产品负责人 PO 对开发团队的要求或者共同协商的约定，以保证交付质量。“DoD”通常会说明： 用户故事所处的系统环境（哪个版本的 Linux、Android、iOS 或者浏览器）？ 需要输出什么样的文档（自动生成的 Javadoc，还是完整的终端用户手册）？ 有什么质量要求（用于演示的基本功能，还是一个功能完整，健壮的 APP）？ 有什么安全要求（无安全要求，还是从代码评审、代码扫描到网络安全配等各方面都要求做安全审查）？ 有什么扩展性要求（10 个并发，还是 10 万个并发）？DoD 的一些例子 代码已完成（所有代办事项已经完成编码） 代码已注释、已提交。版本库当前版本能正常运行 结对检视已完成（或者采用结对编程），代码符合开发标准 构建没有错误 单元测试全部通过 部署到测试环境并通过系统测试 通过 UAT（用户验收测试）并签字确认符合需求。 任何编译/部署/配置变化都已实现/记录/沟通。 相关文档/图表已完成或已更新 任务剩余的小时数已设置为 0，任务已关闭DoD 要考虑的维度为 Sprint 中任务给出明确的“Done”定义是非常重要的，但即使你遵循这个最佳实践，最终仍然会有集成问题，会存在 Bug，以及晚期的需求变更。所以，对于大型复杂产品，在正式发布前，单独计划 1 ～ 2 个 Sprint，专门做 Bug 修复，也是合理的。关于 DoD 的例子，通常需要从几个维度考虑。1）需求/用户故事 DoD 用户故事的描述及拆解符合 INVEST； 用户故事有验收标准 AC(Acceptance Criteria)。2）开发任务 DoD 代码已经提交到 Git; 代码通过单元测试； 代码经过 Code Review; 代码通过集成测试。3）迭代 DoD 所有代码通过静态检测，严重问题都已修改； 所有新增代码都经过 Code Review； 所有完成的用户故事都通过测试； 所有完成的用户故事得到 Product Owner 的验证。4）发布 DoD 完成发布规划所要求的必须具备的需求； 至少完成一次全量回归测试； 符合质量标准(Quality Gate)，譬如所有等级为 1、2 的缺陷均已修复；3、4 级缺陷不超过 10 个； 有 Release Notes； 有用户手册； 产品相关文档已全部更新； 代码已部署到发布服务器上，并冒烟通过； 原始需求提交人完成 UAT； 对运维、市场、客服的新功能培训已完成。 Tips：DoD 必须是团队共同讨论出来的，团队愿意共同遵守的原则，一旦确定，团队就应共同遵守。DoD 和 DoR 应该上墙无论是用物理的 Kanban、TaskBoard，还是电子的，建议将定义清晰的 DOD，显式的张贴出来，便于所有人对齐想法。并且在板子上进行挪动时，无论是挪到 Done 的专题，还是拉到下一个状态，都可以随时看到 DoD 的标准，提醒所有人遵守并检查。保证每个人对一件工作是否完成有一个统一的认识，交付和接纳时时也保持清晰的交接界面。DoR 和 DoD 另外的用法DoR 和 DoD 的本意是创建一份简明的文档，用于在项目干系人，PO 和开发团队间达成一致。但是，随着越来越多的工作被外包或分包， DoR 和 DoD 也更多的用于合同协议和 SOW，用以清楚、准确阐述对于需完成工作的期望。DoR 和 DoD 是很实用的项目范围商议工具，因为它们定义了期望和双方的职责；DoR 帮助客户产出良好的用户故事，为开发团队所用；DoD 帮助交付伙伴根据整体项目需求产出可工作的产品增量，而不仅仅是特定的用户故事功能。小结DoR 和 DoD 就像流水线上的两道关，一个管进，一个管出。我们不像牛那么厉害，吃的是草，挤出的是奶。对团队来说，第一道关更加重要，正如前面所说的，进去的是垃圾，出来的也是垃圾。没有 DoR 的把关，后面的持续改进，工程实践效果都不会太好。" }, { "title": "2020年，再见", "url": "/posts/2020-12-30/2020-bye/", "categories": "Life", "tags": "Life", "date": "2020-12-30 00:00:00 +0800", "snippet": "灵感是转瞬即逝的东西，只要一不注意就没有了。时间也一样，距离2020年结束，还有一天。今天絮叨絮叨，回顾一下即将过去的一年。代码能力退化2020年发现自己的代码能力已经拼不过年轻人，太复杂的代码不愿意再往里看，结构差的代码也不愿意往里看。由此可见，代码的可读性或者可维护性有多重要，等你年纪大了就看不得烂代码了，Keep It Simple and Stupid。这是世界现在是属于我们和年轻人...", "content": "灵感是转瞬即逝的东西，只要一不注意就没有了。时间也一样，距离2020年结束，还有一天。今天絮叨絮叨，回顾一下即将过去的一年。代码能力退化2020年发现自己的代码能力已经拼不过年轻人，太复杂的代码不愿意再往里看，结构差的代码也不愿意往里看。由此可见，代码的可读性或者可维护性有多重要，等你年纪大了就看不得烂代码了，Keep It Simple and Stupid。这是世界现在是属于我们和年轻人的，但最终都是属于年轻人的。写博客很有用2020年发现曾经写的博客还是很有用的，虽然很多内容都很粗浅，可能就是一个概念的解释，或者是某一种框架的实践应用。相对于官方的介绍文档来说简单很多，或者说被丢失的信息也很多，但实际上这是自己消化的过程，只要自己一回看，只需要几分钟就能想起来当时的场景。以前曾自我怀疑，我写的博客到底有什么意义，这么粗浅的东西，谈得上传道授业解惑吗？先不要想的那么高级，这是自己给自己铺的一条路，一条自己看自己过去走过的路。左耳朵耗子里提到这么一个观点我非常赞同，能用文字把一件事情描述清楚并不是一件容易的事情，需要反复练习和刻意练习。原则变成习惯2020年发现，去让优秀的人更优秀，比拉着不愿意努力的人往前走容易的多。因为优秀的人也可以让你更优秀，而且合作起来非常地愉快，而不愿意努力的人，在你得到你的一次帮助之后，可能还会再期望得到你更多的帮助。在《原则》这本书上提到，要让团队或者组织形成择优文化，这样才能形成良性的循环。在《奈飞文化手册》上也提到了，只留下最优秀的人，不合格的人就应该被淘汰。现实真的太残酷了，但早在达尔文发现进化论时优胜劣汰已经成了万物的生存法则。插播一个段子来缓和一下气氛，有人问为什么大家都要结婚生孩子？原因很简单，那些不喜欢结婚生孩子的最后都灭绝了。回看《高效能人士的7个习惯》之后，发现这些习惯现在时刻影响着我。真的非常感谢当年推荐我们读这本书的Leader们，刚从学校毕业就有人让你去培养高效的思维方式和工作习惯。在这里回顾一下书中的核心内容： 积极主动：个人行为取决于自身，而非外部环境。 以终为始：任何事情都要先构想，以结果为导向。 要事优先：时间和精力是有限的，专注于优先级。 双赢思维：多考虑合作而非竞争，如何成就他人。 知己解彼：理解对方和换位思考，让对方懂自己。 统合综效：团队的力量大于个人，求大同存小异。 不断更新：不停自我思考和总结，适应外界变化。不管是所谓的精益研发文化，还是持续交付DevOps，再或者是敏捷思想，现在看来其实大同小异。核心目标都是让整个组织变得更高效，但这个过程不能一蹴而就，我们需要不停的迭代，不停的改进。很多道理都太简单了以至于大多数人都不当回事。所以实际上在工作中你会发现身边的人往往都不会想那么多，什么以终为始，什么要事优先，一边去吧，老子忙得很，更别提持续改进和持续学习了。我经常问自己，我的N年工作经验是不是一样的经验重复了N年？理解研发效能这是我目前的本职工作，在一个企业里要谈DevOps或者研发效能，必须满足一个前置条件：这个企业已经活下来了。用很单纯的眼光看一个企业的发展，其实就是它的盈利能力。盈利的主要来源是业务本身，业务是一个很抽象的词，我们打比方说卖烧饼就是一个业务，老王的公司靠卖烧饼在魔都活下来了，现在他想赚更多的钱怎么办？有两条路。第一条路，拓展业务。从这个角度出发，老王就要想办法在烧饼的同时，卖卖包子，豆浆什么的，从而发现新的赢利点和市场机会。第二条路，提高效能。最直观的办法就是引进烧饼的生产流水线，流水线左边是烧饼的原材料，右边就是香喷喷的烧饼。流水线中间有揉面，烘烤，涂酱，包装等等工序，当然最好还要加入质量检查和安全扫描，避免做出来的烧饼味道不对或者食品不安全。有了老王的例子我的工作就好解释了，我现在干的事情就好比帮老王走第二条路。其实，第二条路难度也挺大的。 文化：新的配方和自动化让以前的老师傅们不高兴了，他们需要接纳这些变化和提升自己的技能才能避免被淘汰。 流程：旧的生产方式可能比较繁琐还有很多重复的动作，但据说那样出来的烧饼香，而且没风险。想简化流程需要专业的老师傅出山配合。 工具：全自动化的烧饼工具不仅需要大量的资金，还需要对应的厂房和足够的售卖能力。老王虽然有远见相信DevOps是烧饼的未来，但也不敢All In。 度量：以前老王摆摊的时候每天只要看看卖了多少个烧饼就知道生意怎么样了，现在规模变大了只看卖掉的数量可就不行了，还需要看每天生产了几个，库存几个，坏掉了几个，合格几个，重做一个要多少时间等等。会不会有那么一天，老王觉得提高生产效率那么麻烦，远没有当年自己摆摊烤烧饼时那样简单快乐，然后把我给开了？嗯，不好说。不过话说回来，在业务和生存面前，所有的技术，效率，质量什么都是渣渣，所以埋头做技术的同学们还是要抬头看天和看路。只有在业务盈利的情况下你才有可能用最流行的技术和最酷的硬件设备。不要老骂老板不懂程序员，为啥不给我配MacBook和4K显示器。要透明和交付不透明或者没有交付的努力，可以说都是无用功。在年初和同事吃饭的时候他跟我分享了一个观点，说你做完的东西可以看成1，至于你怎么说可以看成1后面的0，当然你可以加很多个0，但前面的1才是关键，没有1后面的0就没有任何意义。对于很抽象的事情也许交付起来很困难，那么就要考虑做到整个过程尽可能的透明。比如提升研发团队的研发体验，体验是个什么鬼？能让大家直接很爽或者喊666吗？后来我明白了，体验的好坏很多程度跟时间维度内分泌的多巴胺数量有关，换句话说，就是怎么让人在更短的时间内快乐起来。研发体验可以简单理解为改进各种事件的前置时间。万物都有前置时间，举几个例子。 从需求发起到弄清细节，这是一个需求分析的前置时间。 从打开电脑到开始写代码，这是一个开发的前置时间。 从代码推送到开始编译，这是一个集成的前置时间。 从编译完成到部署环境，这是一个交付的前置时间。当我理解了其中的奥秘后我就需要通过各种办法让其他人也一起理解并接受这套理论，这样别人知道我没有在偷懒，此为透明。其实透明的文化还需要信任的土壤，在一个组织里如何没有足够的信任，大家各自心怀鬼胎，谁说自己有四个2一对王大概率会引来杀身之祸。当我拿着一些数据去做报告时，或者某天出了本书阐述这些条条框框，此为交付。当然，交付周期不要太长，憋太久了老板说不定已经思考好了这个岗位（没有）存在的价值 。重新认识生活2020年的疫情，让我们都看到了大千世界脆弱的一面，还有各种人性，不得而知的一面。坦白讲，我不是一个关心政治的人，也不喜欢去八卦社会动态，但当各种事情传到我耳朵里时，我还是会唏嘘不已。唏嘘之余，我会尝试去想，为什么会是这样子呢？虽然我也解释不了，思考不出答案之后，觉得自己不了解的东西太多了，还要继续学习。越往前走，越觉得生活才是人生的重心。职场上的成就最终还是会远去，最后能跟你走到最后的人还是你生活里的人。我们经常听到这么一句话，在公司你也许只是一棵草，但在家里你却是一片天。年初的疫情现在回想起来的确有点世界末日的感觉，超市和菜市被抢购一空，大街上空无一人，新闻里都是恐怖的数字，我和大橙子窝在屋里相依为命，把能吃的东西都吃了。我们不需要把每天都当成最后一天来过，但这一天总是会到来的。今年大橙子已经奔了两次丧，生命本来就很脆弱。人到中年，要开始习惯告别。重新认识自己前两天想起来的东西，只要没记下来，今天就能全部忘掉。我们所做的事，不是为了眼前，而是为了将来。年轻真好，熬过比你身体差的人你就赢了。不要太忙碌，一天要喝八杯水，能爬楼梯就不要坐电梯。一个人的精力是有限的，弹簧拉太长可能就恢复不回来了。2020年如果一定要用一个字来总结的话，可能就是“忙”吧。忙很多时候是有积极意义的，但需要把握尺度，我越来越觉得人在成长过程中就是在学习平衡各种维度的力量，工作和生活的，家人和朋友的，得到和失去的，等等等等。2020年在新的领域里重新认识了自己，有个朋友说，每个人都有自己擅长的领域，在你的领域你就是神，其实我感觉有些妖魔化，但也不是没有道理。不过我更愿意相信所谓的领域力量，其实是来源于后天的努力和练习，绝大多数人是在自己的领域都不是靠天赋。2020年又是平凡的一年，但我们都一起经历过。" }, { "title": "2020年做的一个DevOps调查报告", "url": "/posts/2020-12-26/devops-survey-2020/", "categories": "Tech", "tags": "Tech, DevOps", "date": "2020-12-26 00:00:00 +0800", "snippet": "在 2020 年 12 月初，我们发起了 GSP 研发体验的年度调查问卷，有 191 位同学参加问卷，大约占 GSP 人数的 47%，在此我们感谢所有参加问卷反馈的所有同学，你们的积极参与可以让 GSP 的明天变得更好！没有来得及参与调查问卷的同学不要感到遗憾，明年此刻我们可以再相遇。第一部分：参与人员概况在这一部分，我们统计了参加问卷人员的分布情况，大家在团队中的角色如下：工作年限分布如下...", "content": "在 2020 年 12 月初，我们发起了 GSP 研发体验的年度调查问卷，有 191 位同学参加问卷，大约占 GSP 人数的 47%，在此我们感谢所有参加问卷反馈的所有同学，你们的积极参与可以让 GSP 的明天变得更好！没有来得及参与调查问卷的同学不要感到遗憾，明年此刻我们可以再相遇。第一部分：参与人员概况在这一部分，我们统计了参加问卷人员的分布情况，大家在团队中的角色如下：工作年限分布如下：以上数据基本反应了上海团队的大致结构，各岗位人数比例还是比较符合软件研发公司的主流配比。工作年限比例中 1~3 年的工程师占比最高，希望年轻一代人可以团队带来更多的创新和活力。第二部分：研发流程的完整体验在这一部分，我们收集了项目计划，功能开发，QA 测试，产品发布以及监控运维共五个维度的研发体验评分，包含了研发流程的完整生命周期。维度一，项目计划和需求管理的体验你们项目需求管理体验如何？需求主要由谁来分析呢？维度二，功能开发的体验你们项目的持续编译 CI 的做得怎么样？维度三，QA 测试的体验维度四，产品发布的体验产品发布一般发生在工作日还是周末？产品发布是不是需要开发人员参与？维度五，运维监控的体验作为开发人员每周花在人肉运维上的时间？关于这一部分的结果，我们可以发现一些比较有意思的数据：项目管理和计划： 接近 80%的人认为自己所在的项目组都是在完成计划内任务，有序的计划是成功的一半。 32%的人认为他们的需求能在 Sprint 开始前确定 80%，这些团队的开发人员一定很幸福。 35%的需求是完全由 BA 分析的，Lead/PM 会分析 30%，剩下的只能靠程序员自己了。功能开发： 有 52.3%的开发团队能在功能完成后 15 分钟内完成本地验证，这样的体验还是很不错的。 有 52.4%的开发团队 CICD 能在 30 分钟内完成，其中 16.8%的团队甚至做到了 15 分钟的 CICD，加油！QA 测试： 有 10%的项目能够做到自动化测试覆盖大部分用户场景，而且测试频率很高，真乃吾辈楷模。 大部分 QA 团队都还是以手动测试为主，希望我们 QA 团队能尽快转型，拥抱自动化！产品发布： 你还没听说过 ROD 和 0 Touch Deploy? GSP 里 10 个人里就有 1 个掌握了这项技能。 整体而言，在 GSP 自动化一键发布已经是标准，70%以上团队已经遵循这项实践，不过部分团队还需努力优化成功率和运行时间。 周末发布（&gt;45%）貌似是一种不正常的常态，希望明年我们有更多的团队可以选择在工作日发布自己的产品。 我们的大多数研发人员（72.8%）都会参与产品发布流程，知道大概不会出问题但还是想看看会不会出问题。监控运维： 大部分的项目组（52.8%）认为自己都部署了还不错的监控运维系统，能第一时间收到线上告警问题，很棒！ 除了监控系统，还是有 20%以上的研发人员每周需要花 1 天以上来处理线上问题，他们的头一定很大。第三部分：改进意见和最佳实践这一部分主要主观问题，大家可以畅所欲言去吐槽我们需要改变的地方，也可以分享自己团队里比较推荐和成熟的工程实践。问题一，你希望项目组有哪些改进措施？感觉很固定，没有变化。对于新的大项目，lead应该准确规划好时间，以防拖到最后赶着完成。sprint开始前能确定需求环境稳定些，早些确定环境供求Everyone need follow the timeline，invordrr that QA can carry out the shift left.ecs资源申请能够尽快结束需求能尽早确定 demo能相对早一点做TeamCity Build 非常慢跟其他team合作的项目，需要更全面的计划希望从需求分析到整个sprint流程更智能规范化使用可靠的ui组件提升工作设备的性能support回复太慢希望能有一个给新入行的网页出问题的环境，明确写明找谁，不然一个传一个比较很麻烦提高ECS和Flink平台的稳定性。同样的deploy过程，有时第一次失败，需要deploy两次。安装环境更快点希望GSP DevOPS 能响应更及时编译部署速度太慢，严重影响研发效率batch的监测和诊断加强BA更多介入需求提供，缩短发布时间持续改进改进发布流程，减少人工干预，缩短发布时间需求，release items产品更全面的监控; 历史项目上Ecs;多增加前期plan 需求分析。使得开发效率更高希望Support team能多做些Support工作，希望BA能够把需求分析做好部署自动化 进一步加强流程监控测试前环境非常不稳定完善deploy流程，减少DEV的人为介入提高稳定性，实现zero touch deployment项目安排留好足够时间给中途加入的紧急事件DDL configurations由专门的support来support现在的项目，减少开发的support工作改善测试环境部署前自测环境针对老的系统，搭建自动测试效率低，但是需求更新频繁，手动测试覆盖不全，如何解决？尽快应用上先进的自动化部署CI CD，还有Kb等日志查看工具增设qa和ba申请更多的ecs资源，让部署能一次成功，不需要介入手工部分。提前plan好需求，让需求源源不断地到达开发手中。更准确地评估任务effort落地一些中央化平台，减少一些应用程序的调研工作。更好的计划，并且严格执行，有流程上的痛点及时安排人员解决，而不是只忙项目需求本身希望每个sprint前能早点确定需求加强operation,而不是全部dev解决.希望环境更加稳定，自己CI CD工具有更好的体验测试环境非常不稳定，项目上uat时间总是拖延压榨qa测试时间，需求和范围确定总是比较晚而且有反复，jira管理混乱类型字段和流程希望可以规范起来除了开发，考虑工程整体性，测试，发布，部署，持续跟踪。希望ba可以更专业问题二，你们项目组有什么比较好的工程实践可以推广到其他人？micro frontendMonitor可以监管环境和service up down JIRA管理进度面板airflow平台部分dev 对qa的support很好混沌还不太了解。目前觉得checkout有工具还是不错flinkAutomation release更好业务理解可以很大程度上减少不必要的开发， 从项目的启动开始去积极参与。需求设计和开发过程中，我们有一些template，比如JIRA的template.要求BA将一些DEV设计开发过程中需要的一些信息罗列出来，避免一些信息不对称，从而提高效率自动化测试zero touch CHGProject status progress tracking tooldata service组的沟通做的十分到位，support也很好新项目模板，当前已经有了CI/CD，是不是可以加入更多的东西，其实好多项目用的东西都差不多服务器down检测多数据中心部署，需要一键部署。最近在搞CAB Opt-out，希望对release流程有帮助每天做自动的SOD环境健康检查，开发尽早介入调查问题不是测出来，靠整个team合作，每一步严格把关。Release checklist提前做计划能保证整体交付质量，比如开发在sprint1，但是PM/BA已经把sprint 2/3的 70%需求和范围确定。问题三，你所在项目组有哪些问题亟待改进？跟美国用户沟通成本太高，老项目的部署没有全自动化，步骤繁琐flink job部署过程中会产生莫名其妙的ecs问题而部署失败，需要重新部署MF需要teamcity打包ecs部署可以更加自动化Blackduck 流程 和扫描都很慢手动测试太多 开发、测试环境不稳定 需求不明确，没有local BA能做到周内release模块化不够导致重复代码很多，代码质量逐渐降低自动部署的配置，希望多点注释发布过程复杂，需要手动操作DevOps自动化不够高有些重复的工作，比如部署如何按需全自动发布，实现真正的RODautosys失败到support发邮件中间有不小的间隔Zero touch deploy缩短与support的交互时间提changebitbucket repo 太多，难以管理。发布流程手动干预过多0 touch多个环境的一键部署；模板代码框架，快速开发；release前autosys 脚本的verify release中一些job的启停可以自动化的步骤以后有待改进需求变更有时会在release前几天发生自动化部署Legacy WPF 自动化 CICD auto regressionDDL configurations需要加regression的测试，避免重复的劳动没有时间完善回归测试用例，需求在最后两天都会有新增或更新，陷入恶性循环切换server用户，非常繁琐，要填多张表单，费时费力ecs资源不够导致部署失败的问题dev整个流程经常失败，通常在部署，是否流程开始前做一些预判，节约时间.还有很多莫名其妙的问题，比如部署成功，但是页面上却是失败部署自动化和更多的监控信息编译部署半自动，需要自动化简化release流程持续自动化测试做的还不够好，需要能与cicd结合自动测试每个部署版本的质量，目前都是定时执行，失败率也较高，需要人工介入调查好好使用JiraServicenow自动化测试 ROD 代码质量管控release 太痛苦，目前使用snapshot，没有使用ROD或者0 touch。每次部署的包很多，导致release coordinater 在收集包名和版本的时候非常痛苦，release当天耗时很长。问题四，你希望 GSP 明年能应用哪些工程实践？发布能不能尽量不需要研发参与。service mesh全自动化，稳定Testing in devops，aim to \"ROD\"release on demand简单点 高效点不要太复杂希望变成ECS的主人而不是客人ʘᴗʘ希望简化部署流程开设新技术的交流培训！更加开放的开发工具使用flinkROD优化编译部署环境和资源LS pipeline执行速度需要更快zero touch releaseDDD？CICD auto regression Cloud easy to accessScrum tool Mockup tool云存储（存储图片之类）原先老项目，可不可以拆分为微服务。现有的数据查询验证客户端，非常卡顿是否可以做到jira,ci/cd在一个页面上完成，打通所有链路技术人员主导，而不是管理人员单方面制定简化release流程更简单的持续集成建立代码评审委员会，提高GSP整体代码质量和设计水平 引入灰度发布多一些BA帮助需求分析， ROD全面部署，包括部署以后的post check做成自动化。从开放问题的词云我们大概能得到大家的核心关注点有几个方面： 构建高效敏捷的研发体系，利用好 JIRA 等管理工具 开发测试环境更稳定，希望更多项目能上 ECS 自动化测试和数据模拟更高效 缩短发布时间，简化 Release 流程 ROD 和 0 touch Deploy 非常值得推广 开发人员尽量不用参与产品发布，期待更强的 DevOps 产品 拥抱变化，拥抱新技术，比如 ServiceMesh 和 MicroFrontend在我看来，很多答案虽然就几个字，但是背后的声音在我脑海却久久回荡，这也许就是不善于表达的程序员们的共鸣吧。 感觉很固定，没有变化。我们真的没有变化吗？也许对于疲于交付的部分项目组来说是吧，太忙碌会让我们失去创新和改进的动力。总结在敏捷软件研发理念中，我们都想要唾弃漫长的瀑布式研发流程，尽可能做到小步快步，持续迭代和改进。在年底留一点时间去回顾过去忙碌的 12 个月，是一个很好的反思机会。总体而言，今年的调研报告可以让大家对我们 GSP 目前的整体软件工程水平有一个客观的认识，相信你可以在报告里找到自己团队的影子和改进的方向。最后，祝大家新年快乐。明年，GSP 的工程文化和实践一定更优秀，因为那时的你，更优秀！" }, { "title": "MacOXS上快速启动一个ELK", "url": "/posts/2020-12-16/quickly-start-an-elk-on-macoxs/", "categories": "Tech", "tags": "Tech", "date": "2020-12-16 00:00:00 +0800", "snippet": "万物都可以用Docker快速启动。快速开始 确保你的 Docker 已经安装完毕。 配置一个 docker 的仓库镜像，任选其一或者自行搜索。https://hub-mirror.c.163.comhttps://ngim31fm.mirror.aliyuncs.com 只需要一行命令即可。$ sudo docker run -p 5601:5601 -p 9200:9200 -p 5...", "content": "万物都可以用Docker快速启动。快速开始 确保你的 Docker 已经安装完毕。 配置一个 docker 的仓库镜像，任选其一或者自行搜索。https://hub-mirror.c.163.comhttps://ngim31fm.mirror.aliyuncs.com 只需要一行命令即可。$ sudo docker run -p 5601:5601 -p 9200:9200 -p 5044:5044 -it \\ -e MAX_MAP_COUNT=262144 --name elk sebp/elk功能验证如果启动过程没报错，那么可以通过以下地址访问服务。 ElasticSearc: http://localhost:9200 Kibana: http://localhost:5601This command publishes the following ports, which are needed for proper operation of the ELK stack: 5601 (Kibana web interface). 9200 (Elasticsearch JSON interface). 5044 (Logstash Beats interface, receives logs from Beats such as Filebeat – see the Forwarding logs with Filebeat section).The image exposes (but does not publish): Elasticsearch’s transport interface on port 9300. Use the -p 9300:9300 option with the docker command above to publish it. This transport interface is notably used by Elasticsearch’s Java client API, and to run Elasticsearch in a cluster. Logstash’s monitoring API on port 9600. Use the -p 9600:9600 option with the docker command above to publish it.相关文档 https://elk-docker.readthedocs.io/其他操作系统的相关介绍也可以在这里找到。" }, { "title": "给MacBook Pro升级硬盘", "url": "/posts/2020-11-08/upgrade-hard-drive-for-macbook-pro/", "categories": "Tech", "tags": "tips", "date": "2020-11-08 00:00:00 +0800", "snippet": "小记一下，其实过程比较简单。购买工具在淘宝可以买到，需要苹果后盖专门定制的五角螺丝刀和 m2 硬盘转接口。一般买转接口会送螺丝刀，但是需要螺丝还是要品质好一点的，我买了第一个转接口送了个山寨螺丝刀，结果只拧了 5 颗螺丝就滑丝了，郁闷的要死，只能重新网购第一把螺丝刀，结果还搞错了型号。这个是比较好一点的，有两把螺丝刀，一个开后盖，一个拧硬盘，拧硬盘的螺丝属于标准六角螺丝，一般的工具箱里有。上...", "content": "小记一下，其实过程比较简单。购买工具在淘宝可以买到，需要苹果后盖专门定制的五角螺丝刀和 m2 硬盘转接口。一般买转接口会送螺丝刀，但是需要螺丝还是要品质好一点的，我买了第一个转接口送了个山寨螺丝刀，结果只拧了 5 颗螺丝就滑丝了，郁闷的要死，只能重新网购第一把螺丝刀，结果还搞错了型号。这个是比较好一点的，有两把螺丝刀，一个开后盖，一个拧硬盘，拧硬盘的螺丝属于标准六角螺丝，一般的工具箱里有。上面这套价格不超过 30 元就可以买到。选购硬盘选购硬盘前还需要确认你的 MacBook 能不能升级硬盘，简单区分就是 2018 年后的新款 MacBook 都不能升级，硬盘已经焊死在主板上，具体支持的型号淘宝卖转接口的店铺都有列表，2015 之前型号基本都支持升级，不管是 MacBook 还是 Pro。然后就是选购的硬盘，需要 M2 接口的，型号也是有讲究的，不是所有都能很好的兼容，推荐比较多的是用三星的，因为原装的就是三星的。也可以用西数的黑盘或者蓝盘，我买了蓝盘 1T SN550，速度比黑盘差一点，但是发热量小不少。M2 硬盘基本上速度越快热量越高。东西齐了，就可以开工了。升级过程整个过程挺简单的，就是比较费时间。 确保系统版本大于 10.13，这样它才认识 NVME 的 M2 硬盘 用一块空的移动硬盘备份整个系统：插入硬盘，格式化，启动 TimeMachine 等待备份完成即可 拆开后盖，卸下老硬盘，装上新硬盘（需要第一步的工具和转接口） 顺便清理一下里面的灰，合上后盖，开始恢复系统 恢复完成后确认系统 OK 后再拧上螺丝钉具体到恢复系统，大致的步骤如下： 先插入有 TimeMachine 备份的移动硬盘 同时按住 电源+cmd+option+r 开机，等待小地球出现 进入 MacOS 实用工具系统，有可能需要输入 wifi，我的没输入 选择磁盘工具，把新硬盘格式化为 APFS，分区 GUID 格式完成后回到前一个页面，选择从时间机器恢复 等待恢复完成后开机就是你原来的系统，除了需要重新输入密码里面啥也不会丢恢复需要的时间取决于你备份的大小和移动硬盘的速度，最好是 USB3.0 和 M2 的移动硬盘，我用的是普通移动硬盘恢复了 200 多 G 的数据，花了 4 个小时以上。总结整个升级还是很划算的，从 256G 的空间一下子变成 1G，再也不会因为多跑两个虚拟机而删这删那，硬盘的整体速度也有了很大提升。原装的硬盘是 5 年前的产品，读写和现在的真的没法比。关于升级的细节网上也有很多文章，可以很容易查到。或者去淘宝找店家要视频甚至远程指导，也是有可能的。发一个链接，仅供参考：https://post.smzdm.com/p/a783vk9g/" }, { "title": "黑客马拉松后记", "url": "/posts/2020-09-20/hackathon-postscript/", "categories": "Tech", "tags": "hackathon, tech, teamwork", "date": "2020-09-20 00:00:00 +0800", "snippet": "今年已经参加了两次黑客马拉松。黑马流程黑马(Hackathon)的一般流程就是主办方广告预热，然后组队报名，确认报名成功后及时了解大赛注意事项和黑马主题。一般来说，正式比赛时间只会持续 1~2 天，这段时间是比较高强度的脑子和体力劳动，如果小组配合不默契的话，大概率只能出个 PPT，demo 也只能停留在搭环境或者 Hello World 上。组建团队一个真正高效的团队不需要每个人都是 MV...", "content": "今年已经参加了两次黑客马拉松。黑马流程黑马(Hackathon)的一般流程就是主办方广告预热，然后组队报名，确认报名成功后及时了解大赛注意事项和黑马主题。一般来说，正式比赛时间只会持续 1~2 天，这段时间是比较高强度的脑子和体力劳动，如果小组配合不默契的话，大概率只能出个 PPT，demo 也只能停留在搭环境或者 Hello World 上。组建团队一个真正高效的团队不需要每个人都是 MVP，而是相互之间有足够的默契和信任，每个人能在比赛过程中都为同一个目标全力以赴。那么这里有两个问题需要明确，什么是同一个目标，怎么全力以赴。共同目标在比赛开始前，我们的目标是想出一个点子，作为我们参赛的项目。团队里的每个人都应该尽可能的大开脑洞，去提供建议和意见。有新意并且有价值的点子并不是那么容易得到，但其实也是可以有一些套路的。 头脑风暴：一群人一起提出各种想法，比如最优价值的产品，最优的解决方案，最大的痛点，最可能实现的创意，最想做的事情等等。 奔驰思考：这是美国心理学家 Robert Eberie 提出一种激发创新的改进思路，用 7 个字母总结 - SCAMPER。 S - Substitued，是不是有替代的方法或者产品？ C - Combined，是不是结合在一起产生新的东西？ A - Adapt，能否调整或者改造，升级优化？ M - Modify，能否修改设计，尺寸，外观等等？ P - Put to other use，能否拓展其他用途？想象一下跨界。 E - Eliminate，能否缩减，消除，简化？看看手机按键的消失。 R - Rearrange，能否重组，逆向，反套路。 六顶帽子：从不同角度去激发创意，假设你有六顶帽子，每顶帽子颜色不一样，轮着戴到自己头上。 白色：中立而客观，关注客观事实和数据。 绿色：创造和生命力，突破常规的可能和意见。 黄色：价值和肯定，从正面考虑问题，表达乐观。 黑色：否定和怀疑，精确批判和找出逻辑上的错误。 红色：情绪和直觉，主观表达自己的感受和看法。 蓝色：结构化思维，纵览全局，规划和管理整个思考过程，并作出结论。 纵然有很多思维方式的套路，在现实中我们更多的创意是来源于生活和工作，如果平时有思考和总结的习惯，发现不合理的设计，你的创意就不会少。全力以赴每个人都有自己擅长的领域，一旦目标定下来后就要主动去承担一些责任。比如分配任务时主动完成自己能够完成的部分，与此同时，还需要一个人来监控和推进任务的进度，确保项目能够顺利交付。上午完成什么，下午完成什么，晚上完成什么，设置几个里程碑，里程碑时间到达时，大家一起坐下来分享成果。如果有需要调整技术方案，就及时提出。一天时间想把项目做得很完美基本很难，切记不要调代码调的太入迷，忘记了最初的目的和最终的结果。最初的目的是，把我们伟大的项目表达出来。最终的结果是，我们伟大的项目完整地表达出来了，表达的方式可能是 PPT，Demo 或者其他形式。享受过程过程能不能享受其实还跟主办方有很大关系，比如有没有舒适的场地，提供免费的餐饮，设备和设施是否完善和周全。如果一切都 OK，小组成员各就各位，就可以开心码代码了。有一些小贴士可以罗列一下，也许对各位看官有帮助。 网络一定要好，能正常访问 Google 和 SO，不然写不出代码。 开发环境也需要提前准备好，不然临时安装 git，java，node，docker 七七八八的环境，大半天就过去了。 弄个无线投屏器也是非常方便的，组里任何一个人想共享屏幕都一键上屏，吃饭时还可以一起看个动画片。 任务可以用看板跟踪，免费的看板可以用 Github 或者 Teambition，还可以投到大屏上。 尽量坐在一排，坐在对面有时讲不清楚，需要结合屏幕有效避免鸡同鸭讲。 核心接口和约定要文档化，写到 README 里，不然来回问很费时间。 手上的任务要尽可能早获得反馈，好的项目是逐渐调整和优化出来的，不是憋半天大招憋出来的。 不要忘了做 PPT 或者演示文稿，至少安排 2 次以上彩排，避免伟大的创意因为糟糕的演讲而腹死胎中。 最好有人能扮演程序员鼓励师，买（拿）吃的喝的。需要不要熬夜呢？看情况吧，其实这个事情在一开始就应该商量好，临时决定熬夜的话多少让人有些不愉快。如果大家觉得夜里效率更高，那么先浪起来，半夜一起 debug。我个人觉得，半夜写代码大概率会翻车，你不想被打扰，但是都已经快交作业了，难道 Deadline Driven Development 的感觉真的很爽？分享成果除了能和志同道合的伙伴码代码，当然我们还是希望能拿奖的。分享成果最重要的三件事是： 不要翻车 不要翻车 不要翻车由此可见系统的健壮性有多么重要，QA 的测试有多么重要，多测试，早联调，考虑 Plan B。我们做了什么项目？两次比赛我们做了两个比较有意思的项目。开发人员年度账单一年到头你写了多少 bug？做了多少需求？有了年度账单，你就可以对自己的成就（发量）一目了然，还可以分享到朋友圈哦。自动修复代码鸭有一些显而易见的问题代码，这只鸭子来自动帮你修复，比如依赖版本升级，不合理的语法等等。虽然已经有 Sonar 之类的工具可以检测出类似问题，我们希望能帮助团队往前走一小步，修复掉我们 100%有信心修复的问题。修复后自动提 PR。本文到此，戛然而止。" }, { "title": "一个小故事", "url": "/posts/2020-09-14/a-little-story/", "categories": "Life", "tags": "Dream, Life", "date": "2020-09-14 00:00:00 +0800", "snippet": "这是一个小故事，在V2上看到的。周天上午，去往商圈的公交上。一家三口带着女儿在对面坐着，旁边是一个父亲带着儿子并排挨着他们。我就坐在他们五人对面，目睹了小男孩撩妹的全过程。小朋友岁数差不多，听对话内容差不多是一年级的样子，小女孩的大眼睛非常有灵性，扎着可爱的马尾辫。小男孩太淘气了，一直在上蹿下跳，还一直数着：明年就是两年级，然后就是三年级，四年级，五年级…一直数到了十八年级。然后他突然发现失...", "content": "这是一个小故事，在V2上看到的。周天上午，去往商圈的公交上。一家三口带着女儿在对面坐着，旁边是一个父亲带着儿子并排挨着他们。我就坐在他们五人对面，目睹了小男孩撩妹的全过程。小朋友岁数差不多，听对话内容差不多是一年级的样子，小女孩的大眼睛非常有灵性，扎着可爱的马尾辫。小男孩太淘气了，一直在上蹿下跳，还一直数着：明年就是两年级，然后就是三年级，四年级，五年级…一直数到了十八年级。然后他突然发现失去有些不对劲，就问隔壁的女孩。 小男孩： “小姐姐，最高有几年级啊？” 小女孩：“好像是五年级吧？”小女孩说完看向爸爸，问上完小学是什么？爸爸解释的很详细，一直解释到了，博士后。小男孩显然不感兴趣，继续和小姐姐说话。 “小姐姐，小姐姐，前几天是教师节呀！”小女孩说完嗯之后，扭头看向了爸爸，靠在了肩膀上。小男孩又是一顿自言自语和上蹿下跳，又向小姐姐抛出了一个问题。 小男孩：“小姐姐，你长大以后想干什么呀？”不得不说，这个问题真的很深刻，我当时听了都蒙了。小女孩的反应也在我预料之内，满脸害羞和不好意思地靠在爸爸身上，爸爸很慈祥地看着她。 然后小男孩先说出了自己的理想。 “我长大以后想当士兵，因为我爸爸就是警察。”旁边的大人们听完以后都看着他爸爸，憋着笑了起来。 然后小女孩也受到了鼓舞，说。 小女孩：“我以后想当一个交警。”小男孩：“交警是什么？”小女孩：“就是可以指挥交通的那种。”两个小朋友此时格外的激动和高兴，此时小小的公交车里，酝酿出来两个大大的梦想。我听到这里，莫名被深深地触动了，果然一个孩子最初的梦想，都不是买一个大房子。公交很快就到站了，两家人下站以后，没有我料想的一样马上分道扬镳，而是往同一个方向走去。两个小孩也是非常高兴，相互追逐。走着走着，又互相拉起了对方的手。此刻画面格外美好。后记衡量好的教育和社会氛围的一个维度，就是看能不能维护好一个孩子的梦想。我希望他们长大以后还能记得这段美好的对话，和当初的梦想。 那时我们有梦，关于文学，关于爱情，关于穿越世界的旅行。如今我们深夜饮酒，杯子碰到一起，都是梦破碎的声音。—— 北岛 《波兰来客》" }, { "title": "分享", "url": "/posts/2020-05-10/share-it/", "categories": "Life", "tags": "tips", "date": "2020-05-10 00:00:00 +0800", "snippet": "古人说授人以渔，今天说说这个渔。当你学到新的知识时，有可能会记笔记，写备忘，或者去实践；或者去分享给其他人。但当你尝试去分享一个知识时，你会很害怕，害怕被笑话，害怕出丑。所以，当你决定去分享一个知识时，你会努力深入，避免自己误人子弟；你会反复检查，避免犯了低级错误。做笔记，有没有把握都没关系；去实践，你也许需要 50%的把握；去分享，你应该有 80%的把握，或者更多。如果你真的想掌握它，那就...", "content": "古人说授人以渔，今天说说这个渔。当你学到新的知识时，有可能会记笔记，写备忘，或者去实践；或者去分享给其他人。但当你尝试去分享一个知识时，你会很害怕，害怕被笑话，害怕出丑。所以，当你决定去分享一个知识时，你会努力深入，避免自己误人子弟；你会反复检查，避免犯了低级错误。做笔记，有没有把握都没关系；去实践，你也许需要 50%的把握；去分享，你应该有 80%的把握，或者更多。如果你真的想掌握它，那就去分享它。在分享过程中，你会重新理顺思路，组织语言，甚至画图。看，记忆又加深了。就好比 Code Review，如果没人看，你会很洒脱很真我，又不是不能用。如果有人看，你还是会在大家面前努力一下，让阳光下的代码更漂亮，毕竟那是自家的娃。鲁迅说，如果你有一个主意，我有一个主意，我们互相交互，我们就都有了两个主意。这就是分享。鲁迅说，我没说过。" }, { "title": "现场互动方案", "url": "/posts/2020-05-10/on-site-interactive-solution/", "categories": "Other", "tags": "interaction", "date": "2020-05-10 00:00:00 +0800", "snippet": "", "content": "" }, { "title": "Parallels Desktop里的虚拟机的Docker无网络", "url": "/posts/2020-05-07/virtual-machine-docker-in-parallels-desktop-without-network/", "categories": "Tech", "tags": "linux, docker, vmware, macosx", "date": "2020-05-07 00:00:00 +0800", "snippet": "Parallel Desktop 里装了一个 CentOS，CentOS 里装了一个 Docker，有点像套娃。安装过程很顺利，运行第一个例子也很正常，Hello World 而已。curl -fsSL https://get.docker.com/ | shsudo systemctl start dockersudo systemctl status dockersudo systemc...", "content": "Parallel Desktop 里装了一个 CentOS，CentOS 里装了一个 Docker，有点像套娃。安装过程很顺利，运行第一个例子也很正常，Hello World 而已。curl -fsSL https://get.docker.com/ | shsudo systemctl start dockersudo systemctl status dockersudo systemctl enable dockersudo usermod -aG docker $(whoami)sudo docker run hello-world我想做什么呢？我想用原生的 Docker 来替代 MacOS 上的 Docker。接下来就是映射本地文件到虚拟机里，配置共享就好了。然后从本地 iTerm 登录到虚拟机的命令行，切换到本地工作目录（被挂载到了/media/psf/Home/src）。这样就可以在本地获得一个原生的 Linux Shell，操作的还是项目里的文件。ssh toby@centos-linuxcd /media/psf/Home/src/xmind2testlink/webdocker build -t xmind2testlink .开始用原生的 Docker 打包镜像，发现基础镜像可以拉下来，但是安装 Python 包失败因为没有网络。Step 1/6 : FROM frolvlad/alpine-python3:latestlatest: Pulling from frolvlad/alpine-python3aad63a933944: Pull complete071e92db37fc: Pull completeDigest: sha256:ee37502c33d69a230096c8abcda4f293cc398d1e08d3c3b854375b209ab85fe9Status: Downloaded newer image for frolvlad/alpine-python3:latest ---&gt; dd1e5224fc24Step 2/6 : RUN mkdir /app ---&gt; Running in 1761ff57cd39Removing intermediate container 1761ff57cd39 ---&gt; 7b4a6a4e13c4Step 3/6 : WORKDIR /app ---&gt; Running in cbf60703344eRemoving intermediate container cbf60703344e ---&gt; 24e13fb03163Step 4/6 : ADD . /app ---&gt; b2b737f9503bStep 5/6 : RUN pip3 install -r requirements.txt ---&gt; Running in c574837c3e7fWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('&lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fafbcc4b3a0&gt;: Failed to establish a new connection: [Errno -3] Try again')': /simple/flask/在网上搜寻半天，各种配 DNS，改防火墙，改代理，一点效果都没有。最简单的测试办法： 在虚拟机里 ping baidu，没问题。 在虚拟机的 Docker 里 ping baidu，不行。 在虚拟机里 ping 路由或者 ip，没问题 在虚拟机里的 Docker 里 ping 路由或者 ip，不行。说明主机和虚拟机的网络桥接没问题，但是虚拟机和 Docker 之间的网络不通。不管切换什么网络共享方式，都行不通。算了，我打不过你。我打开 VMWare Workstation，把 CentOS 和 Docker 又装了一遍，上面的命令再跑一遍，行了。MMP。后记其实 VMWare 也不是没有坑，它最坑的是需要安装 VMWare Tools 才能访问主机文件。官网的文档经久失修有误导性，便捷的办法就是用 yum 来安装。yum install -y open-vm-toolsls /usr/bin/vmtoolsd # 确认安装完毕reboot然后本地文件就可以在虚拟机里访问了，被挂载在 /mnt/hgfs/tobyqin/src/。是不是我把 CentOS 和 Docker 再到 PD 里装一遍就好了呢？谁知道呢。" }, { "title": "N1用Docker刷旁路由", "url": "/posts/2020-05-02/n1-uses-docker-with-openwrt/", "categories": "Tech", "tags": "Tips, N1, Docker, Armbian", "date": "2020-05-02 00:00:00 +0800", "snippet": "前提条件是 docker 已经安装，用网线连接 N1。准备工作安装 Portainer 很有用。docker volume create portainer_datadocker run -d -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portaine...", "content": "前提条件是 docker 已经安装，用网线连接 N1。准备工作安装 Portainer 很有用。docker volume create portainer_datadocker run -d -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer:linux-arm64打开网卡混淆模式ip link set eth0 promisc on创建 docker 虚拟网络，IP 段需要和主路由的一致。docker network create -d macvlan --subnet=192.168.1.0/24 --gateway=192.168.1.254 -o parent=eth0 macnet192.168.1.254 就是旁路由的地址，后面的登录和配置都要用这个地址。配置 OpenWrt运行 OpenWrt 容器。docker run --restart always --name=openwrt -d --network macnet --privileged unifreq/openwrt-aarch64:latest进入 OpenWrt 的 shell，修改网络。docker exec -it openwrt bashvi /etc/config/network# 把 192.168.1.1 改成 192.168.0.254， 配置参考如下config interface 'lan' option type 'bridge' option ifname 'eth0' option proto 'static' option ipaddr '192.168.1.254' # 改这行 option netmask '255.255.255.0' option ip6assign '60'# 退出容器里的shell，重启N1exitreboot重启完成后就可以在浏览器访问旁路由了。http://192.168.1.254/# 默认用户名密码 root / password修改网络接口，使用主路由网关和 DNS。关闭旁路由 DHCP 服务。到此为止，旁路由的配置基本完毕，后面就是测试了。如果中间任何配置有问题想重来，停止并删除容器即可。docker stop openwrtdocker rm openwrt使用旁路由第一种方式，非全局模式。如果只需要某一些设备走旁路由，需要手动配置网络为旁路由地址，主路由不需要做任何配置。好处是旁路由挂了只会影响这些特定的设备，坏处就是比较麻烦。第二种方式，主路由全局模式。经旁路由的网关配置到主路由的 DHCP 即可，以后所有连接主路由的设备都会先经过旁路由。配置方法就是进入主路由后台，将 DHCP 默认网关改成 192.168.1.254，DNS 也改成这个地址。已经连接的设备重新连接主路由一下才会生效。一般用第一种方式测试一下旁路由是不是正常工作了，然后我会全局都走旁路由。我发现 N1 放那么几天就会死机，所有最后配置一下自动重启，比如每天重启一次。旁路由的作用配置了半天，旁路由的作用都没说出来，在旁路由里世界无穷大。去广告什么的都不说了，还有很多只可以意会不可言传的功能。参考文章： https://instar.me/archives/e806f8ac.html https://post.smzdm.com/p/akm7q5xk/ http://hostloc.com/thread-532624-1-1.html https://leeyr.com/326.html" }, { "title": "部署一个私有的在线绘图服务", "url": "/posts/2020-04-26/deploy-a-private-online-drawing-service/", "categories": "Tech", "tags": "docker, draw.io, python, flask", "date": "2020-04-26 00:00:00 +0800", "snippet": "现在很多服务都已经云端化了，浏览器早已不是只用来浏览信息的浏览器了。在线绘图国内最常用的就是 ProcessOn 了，功能很全，就是免费额度有点少。国外最知名的就是 Draw.io 了，基本上就是免费的，常常集成在各种服务里。就是速度有点慢，不，是非常慢。Draw.io 现在改名了，叫 diagrams.net。最关键的是，它还是开源的！部署一个 Draw.ioDraw.io 是基于mxGr...", "content": "现在很多服务都已经云端化了，浏览器早已不是只用来浏览信息的浏览器了。在线绘图国内最常用的就是 ProcessOn 了，功能很全，就是免费额度有点少。国外最知名的就是 Draw.io 了，基本上就是免费的，常常集成在各种服务里。就是速度有点慢，不，是非常慢。Draw.io 现在改名了，叫 diagrams.net。最关键的是，它还是开源的！部署一个 Draw.ioDraw.io 是基于mxGraph library构建的，后端用 Java 实现了简单的文件导出和处理功能，画图的功能都是通过 JavaScript 在浏览器的，所以是完全可以用静态页面的方式来托管一个不需要文件导出和鉴权的绘图站点。欲知详情请移步至该项目： https://github.com/jgraph/drawio要完整部署该项目需要用 ant 来编译 war，并用 tomcat 托管。但是，我不想用 ant 去编译也不想和 Tom 猫发生什么关系，所以我要对这个项目的功能进行阉割。 去除所有国外的在线服务，比如 Google Drive，OneDrive，Github 等等 避免跳转到 Draw.io 官网 去除后端服务，只要能在浏览器绘图并缓存，能保存为本地文件来来来，folk 一下这个项目开干，新项目地址： https://github.com/tobyqin/drawio-local# 第一步，干掉Java，只保留Web应用mv -r src/main/webapp /temp/webapprm -rf *mv -r /tmp/webapp .# 第二步，去掉在线服务code js/PreConfig.js# 配置 local='1'# 参考 https://desk.draw.io/support/solutions/articles/16000042546-what-url-parameters-are-supported-# 第三步，修改错误的资源引用，用Chrome的开发者工具# 第四步，加一些黑科技到 index.html 来hack外部跳转，balabala完事具备，用一行代码在本地托管：python3 -m http.server 8000OK 啦，干净清爽的感觉就是那么好。改一下 README.md 就推送了吧。感觉我只需要花几分钟，其实我调试了几小时，开发为什么总估不准时间呢？奇怪。部署到 Docker没有容器化的服务是没有灵魂的服务，那么我们就给它加点灵魂。加灵魂需要一个 Dockerfile，这样写：FROM frolvlad/alpine-python3:latestRUN mkdir /appWORKDIR /appRUN pip3 install flaskADD . /app/EXPOSE 5000CMD python3 app.py这个灵魂是有讲究的，为什么这么说呢？ 用的是 apline 的基础镜像，这个是开源界最常用的基础镜像，因为它及其的小，一般只有几 MB 或者几十 MB。对应的 apline 镜像还有 node，java，go 版的，应有尽有。 先安装 flask 后 copy 应用，因为 flask 安装后这个 layer 就不变了，但是 app 每次打包都会不一样。为啥要加个 flask 啊？因为我想在它访问后端报错时可以更友好一点，人性化和用户体验，Understand？@app.route('/not-support', methods=['GET', 'POST'])def not_support(): return \"Sorry, this action is not supported.\"好啦，打包镜像走起。docker build -t tobyqin/drawio-local:latest .让这个灵魂跑起来。docker run -it --rm -p 5000:5000 tobyqin/drawio-local访问本地 5000 端口，一点毛病都没有，注意 --rm 在调试时很有用，它可以帮你自动清理退出的容器。让我们来把这个灵魂发布到全世界。docker logindocker push tobyqin/drawio-local咦？这个灵魂好像有点重啊，完全推不动嘛。用 Portainer 查看一下里面到底有什么东西。基础镜像层总共才 4M，应用层居然接近 100M，要给灵魂减减肥了。在根目录加个 .dockerignore 文件，把不想打包的文件统统写在里面。.git.DS_Store.vscode*.md...321 再来一遍灵魂序曲，嗯，有内味了。拿来主义我想你是不愿意再踩一遍我的坑了，反正这个东西做一遍就行了，拿去用吧。1. 静态托管直接到Github 下载 zip 解压后丢到 nginx 或者 iis 即可，顺手给项目加个星呗。2. Docker 部署一行命令即可。docker run --name=\"drawio-local\" --restart always -p 5000:5000 tobyqin/drawio-local3. 薅我羊毛这个服务我已经部署到了我的主机，免费用，随便用，但不保证它的速度和生命延续。 https://draw.pytips.cn就这样，Peace。" }, { "title": "命令行配置备忘", "url": "/posts/2020-04-04/command-line-configuration-memo/", "categories": "Tech", "tags": "linux, shell, bash, alias", "date": "2020-04-04 00:00:00 +0800", "snippet": "换到新的机器，命令行配置少不了。zsh &amp; oh-my-zsh大概是需要代理加速的，下面是简要步骤，适用于 MacOS 或者 Linux 平台。# 安装zsh，各平台命令不一样，但差不多yum install zsh -y# 检查已经安装好的shellcat /etc/shells# 交互式更换当前用户的shell，输入上面看到的 /bin/zshchsh# 免交互直接更改root的...", "content": "换到新的机器，命令行配置少不了。zsh &amp; oh-my-zsh大概是需要代理加速的，下面是简要步骤，适用于 MacOS 或者 Linux 平台。# 安装zsh，各平台命令不一样，但差不多yum install zsh -y# 检查已经安装好的shellcat /etc/shells# 交互式更换当前用户的shell，输入上面看到的 /bin/zshchsh# 免交互直接更改root的shellchsh -s /bin/zsh root# 安装oh-my-zshsh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"# 修改配置文件vi ~/.zshrc# 以下是我必修改的配置，主题用ys，在配置文件的开头部分ZSH_THEME=\"ys\"# 启用的插件，在配置文件的中间位置，autojump, zsh-autosuggestions 非常好用plugins=(git pip python autojump zsh-autosuggestions)# 在文件末尾补充几部分内容# 兼容bash的配置文件，忽略导入失败的错误source ~/.bashrc &amp;&gt;/dev/nullsource ~/.bash_profile &amp;&gt;/dev/null# 添加路径到PATHexport PATH=\"/usr/local/sbin:$PATH\"# 常用的别名alias s=systemctlalias k=kubectlalias n=nginxalias vi=vimalias cls=clearalias ll='ls -l'alias la='ls -a'alias grep=\"grep --color=auto\"autojumpautojump 是一个很方便的让你跳转目录的命令行工具。需要额外安装，在 MacOSX 可以用 brew 安装。brew install autojump在其他 Linux 平台需要从源码安装。git clone git://github.com/wting/autojump.gitcd autojump./install.py# or ./uninstall.py装完之后注意看安装成功后提示，你需要把这段内容加到 .bash_profile里。[[ -s /root/.autojump/etc/profile.d/autojump.sh ]] &amp;&amp; source /root/.autojump/etc/profile.d/autojump.sh然后重启命令行就可以开心的 autojump 了。j toby # cd 到带有toby的最近目录j music # cd 到有可能是music的目录j doc # cd 到有可能是doc的目录autojump 非常智能，你只要给少量关键字就可以 cd 到你想要到的目录。autosuggestions有了 oh-my-zsh 大部分命令是可以通过 TAB 补全的，autosuggestion 可以锦上添花。但这玩意还是需要额外安装。git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions然后在 zsh 的配置文件里启用即可，参考上文。plugins=(zsh-autosuggestions)成功启用后的效果如下。灰色部分是自动提示的，主要是根据输入历史和自动完成的可能性，按右方向键就可以直接使用提示的完整命令，爽歪歪。alias命令行的别名可以极大提高效率。ls --color=auto &amp;&gt;/dev/null &amp;&amp; alias ls='ls --color=auto' &amp;&amp; eval \"$(dircolors)\"alias g='git'alias k='kubectl'alias n='nginx'alias h='history'alias s='systemctl'alias vi='vim'alias svi='sudo vim'alias c='clear'alias cls='clear'alias l='ls -lah'alias ll='ls -l'alias la='ll -la'alias grep=\"grep --color=auto\"alias egrep='egrep --color=auto'alias fgrep='fgrep --color=auto'# bind file with default actionsalias -s html='vim'alias -s rb='vim'alias -s py='vim'alias -s js='vim'alias -s c='vim'alias -s java='vim'alias -s txt='vim'alias -s gz='tar -xzvf'alias -s tgz='tar -xzvf'alias -s zip='unzip'alias -s bz2='tar -xjvf'alias cdback='cd -'alias '..'='cd ..'alias '...'='../..'alias '....'='../../..'alias '.....'='../../../..'alias '......'='../../../../..'alias df='df -h'alias du='du -h'alias cp='cp -v'alias mv='mv -v'alias mkdir='mkdir -pv'alias which='which -a'alias path='echo -e ${PATH//:/\\\\n}'alias ping='ping -c 5'alias ports='netstat -tulanp'alias rm='rm -I --preserve-root'alias chown='chown -v --preserve-root'alias chmod='chmod -v --preserve-root'alias chgrp='chgrp --preserve-root'alias virc='vi ~/.vimrc'alias barc='vi ~/.bashrc &amp;&amp; source ~/.bashrc'alias baprofile='vi ~/.bash_profile &amp;&amp; source ~/.bash_profile'alias bareload='source ~/.bash_profile &amp;&gt;/dev/null || source ~/.bashrc &amp;&gt;/dev/null'alias zshrc='vi ~/.zshrc &amp;&amp; source ~/.zshrc'alias untar='tar -zxvf'alias www='python2 -m SimpleHTTPServer 8000'alias ngx='nginx'alias ngxreload='sudo ng -s reload'alias ngxtest='sudo ng -t'alias ngxconf='sudo vi /etc/nginx/conf/nginx.conf &amp;&amp; ngxtest'alias help='tldr'" }, { "title": "CentOS安装最新版Nodejs", "url": "/posts/2020-03-29/centos-installs-the-latest-version-of-nodejs/", "categories": "Tech", "tags": "tips", "date": "2020-03-29 00:00:00 +0800", "snippet": "添加 Nodejs 到 Yum Repoyum install -y gcc-c++ makecurl -sL https://rpm.nodesource.com/setup_13.x | sudo -E bash -如果要稳定版就改成这样。yum install -y gcc-c++ makecurl -sL https://rpm.nodesource.com/setup_12.x |...", "content": "添加 Nodejs 到 Yum Repoyum install -y gcc-c++ makecurl -sL https://rpm.nodesource.com/setup_13.x | sudo -E bash -如果要稳定版就改成这样。yum install -y gcc-c++ makecurl -sL https://rpm.nodesource.com/setup_12.x | sudo -E bash -然后用 yum 安装即可。sudo yum install nodejs -ynode -vnpm -v" }, { "title": "nginx常用命令", "url": "/posts/2020-03-28/nginx-commonly-used-commands/", "categories": "Tech", "tags": "nginx", "date": "2020-03-28 00:00:00 +0800", "snippet": "nginx -t #测试配置文件nginx #启动命令nginx -s stop #强制停止Nginx服务nginx -s quit #处理完请求后再停止服务nginx -s reload #重启命令ps -ef |grep nginx #查看进程命令nginx -v #查看Nginx的版本号", "content": "nginx -t #测试配置文件nginx #启动命令nginx -s stop #强制停止Nginx服务nginx -s quit #处理完请求后再停止服务nginx -s reload #重启命令ps -ef |grep nginx #查看进程命令nginx -v #查看Nginx的版本号" }, { "title": "用Docker部署NextCloud到N1", "url": "/posts/2020-03-28/deploy-nextcloud-to-n1-with-docker/", "categories": "Tech", "tags": "Docker, N1, NAS", "date": "2020-03-28 00:00:00 +0800", "snippet": "只需要一个命令。docker run -d -p 8888:80 --name nextcloud -v /data/nextcloud/:/var/www/html/ --restart=always --privileged=true arm64v8/nextcloud如果是部署到 U 盘，可以这样。docker run -d -p 8888:80 --name nextcl...", "content": "只需要一个命令。docker run -d -p 8888:80 --name nextcloud -v /data/nextcloud/:/var/www/html/ --restart=always --privileged=true arm64v8/nextcloud如果是部署到 U 盘，可以这样。docker run -d -p 8888:80 --name nextcloud -v /media/udisk/:/var/www/html/ --restart=always --privileged=true arm64v8/nextcloud" }, { "title": "PowerShell和Cmd和谐共处", "url": "/posts/2020-03-19/powershell-and-cmd-live-in-harmony/", "categories": "Tech", "tags": "powershell, batch, tips", "date": "2020-03-19 00:00:00 +0800", "snippet": "PowerShell 真的很强大啊，但是双击运行不 OK 啊。批处理好方便啊，可是写一个if要半天啊。他俩就不能既方便又强大吗？在批处理嵌入 PowerShell这是可以的，Stack Overflow有帖子，这个操作可谓风骚非常。@findstr /v \"^@f.*&amp;\" \"%~f0\" | powershell -&amp; goto:eofWrite-Output \"Hello W...", "content": "PowerShell 真的很强大啊，但是双击运行不 OK 啊。批处理好方便啊，可是写一个if要半天啊。他俩就不能既方便又强大吗？在批处理嵌入 PowerShell这是可以的，Stack Overflow有帖子，这个操作可谓风骚非常。@findstr /v \"^@f.*&amp;\" \"%~f0\" | powershell -&amp; goto:eofWrite-Output \"Hello World\"Write-Output \"Hello some@com &amp; again\"文件存成 .bat 或者 .cmd，双击就能运行。唯一的缺点是这个后缀的文件 IDE 或者编辑器都当成了批处理，没法用 ISE 或者 VSCODE 去编写和调试代码，只能先改成ps1调试好了再改成批处理。用批处理调用 PowerShell你还可以建两个文件，像这样：my-script.cmdmy-script.ps1你的 PowerShell 想怎么写就怎么写，但是批处理要这么写。@ECHO OFFSET PowerShellScriptPath=%~dpn0.ps1PowerShell -NoProfile -ExecutionPolicy Bypass -Command \"&amp; '%PowerShellScriptPath%'\";而且名字还必须和 PowerShell 脚本的名字一致，如熊大和熊二的关系一般。调用说明如果你希望运行 PowerShell 带参数，第三行就这样写：PowerShell -NoProfile -ExecutionPolicy Bypass -Command \"&amp; '%PowerShellScriptPath%' 'First Param Value' 'Second Param Value'\";带命名参数：PowerShell -NoProfile -ExecutionPolicy Bypass -Command \"&amp; '%PowerShellScriptPath%' -Param1Name 'Param 1 Value' -Param2Name 'Param 2 Value'\"以管理员身份运行：PowerShell -NoProfile -ExecutionPolicy Bypass -Command \"&amp; {Start-Process PowerShell -ArgumentList '-NoProfile -ExecutionPolicy Bypass -File \"\"%PowerShellScriptPath%\"\"' -Verb RunAs}\";以管理员身份运行还带参数：PowerShell -NoProfile -ExecutionPolicy Bypass -Command \"&amp; {Start-Process PowerShell -ArgumentList '-NoProfile -ExecutionPolicy Bypass -File \"\"\"\"%PowerShellScriptPath%\"\"\"\" \"\"\"\"First Param Value\"\"\"\" \"\"\"\"Second Param Value\"\"\"\" ' -Verb RunAs}\"以管理员身份运行还带命名参数：PowerShell -NoProfile -ExecutionPolicy Bypass -Command \"&amp; {Start-Process PowerShell -ArgumentList '-NoProfile -ExecutionPolicy Bypass -File \"\"\"\"%PowerShellScriptPath%\"\"\"\" -Param1Name \"\"\"\"Param 1 Value\"\"\"\" -Param2Name \"\"\"\"Param 2 value\"\"\"\" ' -Verb RunAs}\";远程运行 PowerShell这里说的是运行某台服务器的上的 PowerShell，管理员用的比较多，对运程机器也要提前配置好让它能接受远程命令。Invoke-Command -ComputerName Server01, Server02 -FilePath c:\\Scripts\\DiskCollect.ps1配置相对复杂，具体请查阅文档。运行远程的 PowerShell这里说的去执行一个远程已经存在的脚本，比如：&amp; \\\\server\\path\\to\\your\\scriptmcscript.ps1不不不，我要说的远程脚本是在云上，比如 http://server/setup.ps1，没问题。# 在 PowerShell 中执行iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))但是你需要让别人打开 PowerShell 命令行后粘贴才行。双击运行行不行？行，大兄弟。把下面的内容保存成批处理文件，让他双击，狠狠地双击吧。PowerShell -NoProfile -ExecutionPolicy Bypass -Command \"iex ((New-Object System.Net.WebClient).DownloadString('http://server/setup.ps1'))\";不要小看上面的小技巧，PowerShell 可以做出你难以想象的事情，PowerShell 是高效码农的必备，是黑客渗透 Windows 的首选。这个双击，可以是来自天堂的 Hello World，也可以是来自地狱的 Goodbye Boy.安全和便利从来都是背道而驰的，这个尺度需要自己把握。" }, { "title": "在ParallelDesktop虚拟机中访问Mac的IP", "url": "/posts/2020-03-14/access-mac-s-ip-in-paralleldesktop-virtual-machine/", "categories": "Tech", "tags": "paralledesktop, tips", "date": "2020-03-14 00:00:00 +0800", "snippet": "假设在 Mac 主机开了一个 http 的服务。$ python -m http.server 8000Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...我们可以找到 PD 的网络设置，看到 DHCP 的地址。这里是 10.211.55.1，那么宿主机就是 2 号位。当然，如果你的机器联网了，也可以用路由器分配的地址。$ ...", "content": "假设在 Mac 主机开了一个 http 的服务。$ python -m http.server 8000Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...我们可以找到 PD 的网络设置，看到 DHCP 的地址。这里是 10.211.55.1，那么宿主机就是 2 号位。当然，如果你的机器联网了，也可以用路由器分配的地址。$ ifconfig | grep 192\tinet 192.168.1.3 netmask 0xffffff00 broadcast 192.168.1.255最后，如果你知道你的 Mac 的机器名是什么（hostname），也可以用机器名来访问。" }, { "title": "在N1上快速部署一个博客", "url": "/posts/2020-03-09/quickly-deploy-a-blog-on-n1/", "categories": "Tech", "tags": "tips", "date": "2020-03-09 00:00:00 +0800", "snippet": "前提是你已经刷了 armbian。然后你还需要 docker，一个命令即可。curl -sSL https://get.docker.com | sh接下来一句话就可以搞定 typecho。docker run -d \\--name=typecho \\--restart always \\--mount type=tmpfs,destination=/tmp \\-v /data/typecho...", "content": "前提是你已经刷了 armbian。然后你还需要 docker，一个命令即可。curl -sSL https://get.docker.com | sh接下来一句话就可以搞定 typecho。docker run -d \\--name=typecho \\--restart always \\--mount type=tmpfs,destination=/tmp \\-v /data/typecho:/data \\-e PHP_TZ=Asia/Shanghai \\-e PHP_MAX_EXECUTION_TIME=600 \\-p 90:80 \\80x86/typecho:latestdocker 命令里冒号左边是本机的路径或者端口，根据情况调整。" }, { "title": "Linux的压缩和解压", "url": "/posts/2020-03-08/compression-and-decompression-for-linux/", "categories": "Tech", "tags": "Linux, Zip, Unzip, Tar", "date": "2020-03-08 00:00:00 +0800", "snippet": "最常用的是 zip 和 tar 命令。1.zip 命令# 将指定目录压缩成zip文件zip -r compressed.zip /path/to/dir# 压缩文件夹，但排除某些文件zip -r compressed.zip path/to/dir -x path/to/exclude# 将多个目录压缩成zipzip -r compressed.zip /path/to/dir1 /path...", "content": "最常用的是 zip 和 tar 命令。1.zip 命令# 将指定目录压缩成zip文件zip -r compressed.zip /path/to/dir# 压缩文件夹，但排除某些文件zip -r compressed.zip path/to/dir -x path/to/exclude# 将多个目录压缩成zipzip -r compressed.zip /path/to/dir1 /path/to/dir2 /path/to/file# 压缩加密码zip -e -r compressed.zip path/to/dir# 添加文件到已经存在的zipzip compressed.zip path/to/file# 删除zip里的文件zip -d compressed.zip \"foo/*.tmp\"zip 可以将当前文件夹压缩至当前文件夹，比如 /home/toby =&gt; /home/toby/toby.zip2.unzip 命令与 zip 命令相反，这是解压命令。# 解压文件，用空格来接受多个文件unzip file(s)# 解压文件到指定目录unzip compressed_file(s) -d /path/to/put/extracted_file(s)# 显示zip里的文件，不解压unzip -l file.zip3.tar 命令# 只是打包成 tartar cf target.tar file1 file2 file3# 打包并使用gzip压缩tar czf target.tar.gz file1 file2 file3# 解压tar到当前目录tar xf source.tar[.gz|.bz2|.xz]# 解压tar到指定目录tar xf source.tar -C directory# 显示tar里的文件，不解压tar tvf source.tar# 解压tar里符合规则的文件tar xf source.tar --wildcards \"*.html\"" }, { "title": "nano的简单用法", "url": "/posts/2020-03-07/simple-usage-of-nano/", "categories": "Tech", "tags": "Nano, Linux", "date": "2020-03-07 00:00:00 +0800", "snippet": "不小心进了 nano，都不知道怎么退出来。虽然画面上有快捷键，按完之后还是一脸懵逼。^是Ctrl键的缩写。^O是写入，按完之后就这样了。File Name to Write: test^G Get Help ^T To Files M-M Mac Format M-P Prepend^C Cancel M-D DOS Format ...", "content": "不小心进了 nano，都不知道怎么退出来。虽然画面上有快捷键，按完之后还是一脸懵逼。^是Ctrl键的缩写。^O是写入，按完之后就这样了。File Name to Write: test^G Get Help ^T To Files M-M Mac Format M-P Prepend^C Cancel M-D DOS Format M-A Append M-B Backup File其实离成功就差一个回车，当然在回车前你还可以修改文件名。界面里的M是什么呢？后来查了半天发现M是Modifier键，通常指的是Alt键，Mac 上是Option键。^X是退出，按完之后会让你三思。再按Y就跟上面的^O一样了。注意，快捷键都是小写，比如^G其实是ctrl+g，而不是ctrl+shift+g。最后附赠几个快捷键： 复制：alt+6 剪切：ctrl+k 粘贴：ctrl+u 自由剪切：ctrl+6指定起始剪切位置,按上下左右键来选中内容，然后按下ctrl+k剪切 撤销：alt+u" }, { "title": "Linux里的计划任务", "url": "/posts/2020-03-07/scheduled-tasks-in-linux/", "categories": "Tech", "tags": "Linux, Cron, Crontab", "date": "2020-03-07 00:00:00 +0800", "snippet": "cron 是 Linux 内置的计划任务程序。crontab 是 cron 定期执行任务所需的列表文件，注意通过 crontab 命令来修改。anacron 可以看做是 cron 的补充程序，可以每月，每周，每天执行某些任务。cron 服务cron 服务的守护进程是 crond。启动：service crond start停止：service crond stop重启：service cro...", "content": "cron 是 Linux 内置的计划任务程序。crontab 是 cron 定期执行任务所需的列表文件，注意通过 crontab 命令来修改。anacron 可以看做是 cron 的补充程序，可以每月，每周，每天执行某些任务。cron 服务cron 服务的守护进程是 crond。启动：service crond start停止：service crond stop重启：service crond restart查看状态：service crond status重新载入配置：service crond reload在 CentOS7 也可以用 systemctl start crond 来管理服务。默认情况下 cron 服务应该是开机自动运行的，如果没有可以 enable 一下。systemctl enable crondcrontab 命令crontab -u # 设定某个用户的cron服务，一般root用户在执行这个命令的时候需要此参数crontab -l # 列出某个用户cron服务的详细内容crontab -r # 删除某个用户的cron服务，这个命令最没用还容易按错！！！crontab -e # 编辑某个用户的cron服务crontab &lt;file&gt; # 将 &lt;file&gt; 恢复至crontab# 查看自己的cron设置crontab -l# 编辑自己的cron设置crontab -e# root想删除toby的cron设置crontab -u toby -r你也可以直接修改 crontab 的配置文件：系统配置文件：/etc/crontab系统级任务，一般为空，如果anacron不存在有可能会把anacron 类似的配置写到这里用户配置文件：/var/spool/cron/[user]比如 /var/spool/cron/tobycrontab 文件的内容：SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=rootHOME=/# demo task01 * * * * root echo hello前半部分用于声明环境变量，这四个变量是固定的，但值可以改。后半部分就是具体的任务，建议任务前用#号加以注释，方便以后管理。关于 cron 语法，可以参考其他文档或自行搜索：# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executedcrontab 配置修改后不用重启服务，Linux 会自动加载最新的改动。每次任务执行完毕后会将执行日志写到 /var/log/cron，可以通过 tail 命令排错。注意事项要经常备份 crontab 文件：crontab -l &gt; ~/mycrontab恢复你的备份：crontab ~/mycrontab环境变量可以在具体命令前加载：0 * * * * . /etc/profile;/bin/sh /var/my.sh定时重启的任务需要 root 权限：0 0 * * * root /sbin/rebootanacron 命令anacron 算是 crontab 补充。假如你的服务器因为某些原因关机了，crontab 里配置的任务就错过了，例如你一个月备份一次数据库，刚好要备份那天服务器宕机了，当你重启后这个任务又要重新计算了，因为错过了备份时间。但如果你把备份任务写到 anacron 里，服务器重启后依然会去执行你的任务。anacron 会通过计算记录文件的时间戳来判断上次任务是否已经执行，anacron 没那么灵活，只能按天，周，月配置任务。anacron 配置文件：/etc/anacrontabcat 一下这个配置文件：SHELL=/bin/shPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# the maximal random delay added to the base delay of the jobsRANDOM_DELAY=45# the jobs will be started during the following hours onlySTART_HOURS_RANGE=3-22#period in days delay in minutes job-identifier command1\t5\tcron.daily\t\tnice run-parts /etc/cron.daily7\t25\tcron.weekly\t\tnice run-parts /etc/cron.weekly@monthly 45\tcron.monthly\t\tnice run-parts /etc/cron.monthly可以看到所有放入 /etc/cron.{daily，weekly，monthly} 目录中的脚本都会在指定时间执行，而且不用担心服务器万一关机的情况。" }, { "title": "CentOS里的防火墙配置", "url": "/posts/2020-03-06/firewall-configuration-in-centos/", "categories": "Tech", "tags": "linux, centos, firewall", "date": "2020-03-06 00:00:00 +0800", "snippet": "CentOS 6 以前，内置的防火墙是 iptables，升级到 7 以后就变成了 firwalld。iptables1.打开、关闭、重启防火墙chkconfig iptables on #开启防火墙(重启后永久生效)chkconfig iptables off #关闭防火墙(重启后永久生效)service iptables start #开启防火墙(即时生效，重启...", "content": "CentOS 6 以前，内置的防火墙是 iptables，升级到 7 以后就变成了 firwalld。iptables1.打开、关闭、重启防火墙chkconfig iptables on #开启防火墙(重启后永久生效)chkconfig iptables off #关闭防火墙(重启后永久生效)service iptables start #开启防火墙(即时生效，重启后失效)service iptables stop #关闭防火墙(即时生效，重启后失效)service iptables restartd #重启防火墙2.查看打开的端口/etc/init.d/iptables status3.打开某个端口(以 8080 为例)# 开启端口iptables -A INPUT -p tcp --dport 8080 -j ACCEPT# 保存并重启防火墙/etc/rc.d/init.d/iptables save/etc/init.d/iptables restart4.打开49152~65534之间的端口iptables -A INPUT -p tcp --dport 49152:65534 -j ACCEPT同样，这里需要对设置进行保存，并重启防火墙。5.配置修改方式我们还可以通过修改/etc/sysconfig/iptables文件的方式开启端口，如下vi /etc/sysconfig/iptables然后在文件中增加一行-A RH-Firewall-1-INPUT -m state –state NEW -m tcp -p tcp –dport 8080 -j ACCEPT参数说明: –A 参数就看成是添加一条规则 –p 指定是什么协议，我们常用的 tcp 协议，当然也有 udp，例如 53 端口的 DNS –dport 就是目标端口，当数据从外部进入服务器为目标端口 –sport 数据从服务器出去，则为数据源端口使用 –j 就是指定是 ACCEPT -接收 或者 DROP 不接收firewalldCentos7 默认安装了 firewalld，如果没有安装的话，可以使用 yum install firewalld firewalld-config进行安装。1.启动、关闭、重启防火墙systemctl start firewalld # 启动,systemctl enable firewalld # 开机启动systemctl stop firewalld # 关闭systemctl disable firewalld # 取消开机启动firewall-cmd --reload # 更新规则，重启防火墙firewall-cmd --complete-reload # 更新规则，重启服务2.查看状态systemctl status firewalld#或者firewall-cmd --state3.查看和管理区域 zone# 查看当前配置的区域firewall-cmd --get-active-zones# 查看指定接口所属区域firewall-cmd --get-zone-of-interface=eth0# 设置默认接口区域，无需重启，立即生效firwalld-cmd --set-default-zone=public# 将接口添加至public区域，需要重启防火墙firewall-cmd --zone=public --add-interface=eth0 --permanent# 永久删除pubic里的接口firewall-cmd --zone=public --permanent --remove-interface=eth0# 查看public区域开放的端口firewall-cmd --zone=public --list-portsFirewall 能将不同的网络连接归类到不同的信任级别，Zone 提供了以下几个级别 drop: 丢弃所有进入的包，而不给出任何响应 block: 拒绝所有外部发起的连接，允许内部发起的连接 public: 允许指定的进入连接 external: 同上，对伪装的进入连接，一般用于路由转发 dmz: 允许受限制的进入连接 work: 允许受信任的计算机被限制的进入连接，类似 workgroup home: 同上，类似 homegroup internal: 同上，范围针对所有互联网用户 trusted: 信任所有连接 4.恐慌模式：拒绝所有包 panic 本意是恐慌，如果服务器遭受攻击时可以打开恐慌模式来决绝所有进包和出包，也称为“禁行模式”。但是已经建立的连接不会被强制断开，只是无法通信了而已。注意，如果你是 ssh 连接上去的话，一旦打开恐慌模式就失去和服务器的连接。# 打开恐慌模式，拒绝所有包firewall-cmd --panic-on# 关闭恐慌模式firewall-cmd --panic-off# 查看恐慌模式状态firwalld-cmd --query-panic7.防火墙规则管理（记得重启防火墙）# 允许http和https服务firewall-cmd --permanent --zone=external --add-service=httpfirewall-cmd --permanent --zone=external --add-service=https# 移除smtp服务firewall-cmd --zone=public --remove-service=smtp# 允许指定端口firewall-cmd --zone=public --add-port=8080/tcp --permanent# 打开指定端口区域firewall-cmd --zone=public --add-port=5000-6000/tcp --permanent# 禁封 IPfirewall-cmd --permanent --add-rich-rule=\"rule family='ipv4' source address='222.222.222.222' reject\"# 禁封网段firewall-cmd --permanent --zone=public --new-ipset=blacklist --type=hash:netfirewall-cmd --permanent --zone=public --ipset=blacklist --add-entry=222.222.222.0/24过滤规则 source: 根据源地址过滤 interface: 根据网卡过滤 service: 根据服务名过滤 port: 根据端口过滤 icmp-block: icmp 报文过滤，按照 icmp 类型配置 masquerade: ip 地址伪装 forward-port: 端口转发 rule: 自定义规则其中，过滤规则的优先级遵循如下顺序 source interface firewalld.conf" }, { "title": "注册域名的好地方", "url": "/posts/2020-03-04/great-place-to-register-a-domain-name/", "categories": "Tech", "tags": "domain, vps", "date": "2020-03-04 00:00:00 +0800", "snippet": "有两个口碑还不错的域名供应商，国外的。 https://namesilo.com https://www.namecheap.com如果打算长期持有域名的话可以考虑上面两个。namesilo 比较容易找到一美元的优惠码，比如：2020code # 新注册优惠2020renew # 续费优惠如果是短期比如一年的话可以用 GoDaddy，或者免费的 tk 域名](http://www.do...", "content": "有两个口碑还不错的域名供应商，国外的。 https://namesilo.com https://www.namecheap.com如果打算长期持有域名的话可以考虑上面两个。namesilo 比较容易找到一美元的优惠码，比如：2020code # 新注册优惠2020renew # 续费优惠如果是短期比如一年的话可以用 GoDaddy，或者免费的 tk 域名](http://www.dot.tk/)。" }, { "title": "在线面试编码能力", "url": "/posts/2020-03-02/online-interview-coding-ability/", "categories": "Tech", "tags": "Tools, Interview", "date": "2020-03-02 00:00:00 +0800", "snippet": "在线面试候选人编码能力可以用一些实时共享的编辑器。Talk is cheap, show me the code.ShowMeBug国内的服务器，域名好念，支持语法高亮，带运行环境，还可以事先准备面试题。唯一的缺点是需要登录，可以用 GitHub 快速登录。但是你想啊，如果你电话里念完地址后，回车后居然还要注册登录，尴尬。CollabEdit国外的服务，域名不好念，电话沟通时就有点蛋疼。不能...", "content": "在线面试候选人编码能力可以用一些实时共享的编辑器。Talk is cheap, show me the code.ShowMeBug国内的服务器，域名好念，支持语法高亮，带运行环境，还可以事先准备面试题。唯一的缺点是需要登录，可以用 GitHub 快速登录。但是你想啊，如果你电话里念完地址后，回车后居然还要注册登录，尴尬。CollabEdit国外的服务，域名不好念，电话沟通时就有点蛋疼。不能运行代码，不用登录，其实可以作为第一方案，候选人打不开时再用上面那个。其他如果有条件到 Google 搜一下，类似的服务还有好几个，可不可靠需要自己验证，关键字：Online Realtime Code Editor https://codeshare.io/ https://codebunk.com/ https://coderpad.io/曾经我面试某家公司时他们用了https://www.hackerrank.com/，那个体验真是太棒了。面试官给候选人发送面试的网页地址后，候选人可以自由选择做题的时间，可以查资料，但必须在指定时间交卷，比如45分钟。描述可以有点苍白，有兴趣的同学可以去体验一下，有点像 OJ（Online Jude）刷题。" }, { "title": "Linux中的文件搜索", "url": "/posts/2020-02-29/file-search-in-linux/", "categories": "Tech", "tags": "linux, find, grep", "date": "2020-02-29 00:00:00 +0800", "snippet": "我们经常需要搜索文件名或者文件内容。搜索文件名可以用find命令。find &lt; path &gt; &lt; expression &gt; &lt; cmd &gt; path： 所要搜索的目录及其所有子目录。默认为当前目录。 expression： 所要搜索的文件的特征。 cmd： 对搜索结果进行特定的处理。# 搜索包含指定字符串的文件名find / -name \"*Dock...", "content": "我们经常需要搜索文件名或者文件内容。搜索文件名可以用find命令。find &lt; path &gt; &lt; expression &gt; &lt; cmd &gt; path： 所要搜索的目录及其所有子目录。默认为当前目录。 expression： 所要搜索的文件的特征。 cmd： 对搜索结果进行特定的处理。# 搜索包含指定字符串的文件名find / -name \"*Docker*\"# 无视大小写用inamefind ./ -iname \"*.config\"# 忽略错误，比如没权限访问某个目录会打印一堆错误find ./ -name \"*.json\" 2&gt;/dev/null# 搜索大于100M的文件find / -size +100M -exec du -h {} \\; 2&gt;/dev/null# 搜索0kb的文件并删除find ./ -size 0 | xargs rm -f &amp;find命令功能非常强大，具体请查阅文档。搜索文件内容可以用 grep 命令。# 搜索包含docker的文件，并打印命中行grep -nr \"docker\" ./# 搜索包含dokcer的文件，只打印文件名grep -lr \"docker\" ./# 只搜索文本文件，忽略二进制文件grep -lrI \"docker\" ./# 搜索匹配正则表达式的文件egrep -lr \"^docker\" ./# 搜索当前目录下的某些文件的内容grep -lr \"docker\" *.pyegrep 是 grep 的正则表达式版本，grep还支持很多参数，具体请查阅文档。查找文件内容也可以用 find 命令。find ./ -name \"*.py\" -exec grep -l \"docker\" {} \\;用 find 可以先对文件名或者类型先做一次过滤，再具体到内容搜索。" }, { "title": "详解Linux里的 /etc/passwd", "url": "/posts/2020-02-28/detailed-etc-passwd-in-linux/", "categories": "Tech", "tags": "linux, bash", "date": "2020-02-28 00:00:00 +0800", "snippet": "深入了解 Linux 的系统用户配置文件。", "content": "深入了解 Linux 的系统用户配置文件。" }, { "title": "Linux免密码登录SSH", "url": "/posts/2020-02-23/linux-passwordless-login-ssh/", "categories": "Tech", "tags": "linux, ssh, shell", "date": "2020-02-23 00:00:00 +0800", "snippet": "无密钥登录可以更快乐一点。第一步，生成公钥和私钥。ssh-keygen -t rsa ##-t rsa可以省略，默认就是生成rsa类型的密钥按提示会在当前主机的 ~/.ssh 生成 id_rsa, id_rsa.pub 。第二步，将公钥 id_rsa.pub 复制到目标主机的 ~/.ssh/authorized_keys 中。方法很多，推荐使用 ssh-copy-id# Copy y...", "content": "无密钥登录可以更快乐一点。第一步，生成公钥和私钥。ssh-keygen -t rsa ##-t rsa可以省略，默认就是生成rsa类型的密钥按提示会在当前主机的 ~/.ssh 生成 id_rsa, id_rsa.pub 。第二步，将公钥 id_rsa.pub 复制到目标主机的 ~/.ssh/authorized_keys 中。方法很多，推荐使用 ssh-copy-id# Copy your keys to the remote machine:ssh-copy-id username@remote_host# Copy the given public key to the remote:ssh-copy-id -i path/to/certificate username@remote_host# Copy the given public key to the remote with specific port:ssh-copy-id -i path/to/certificate -p port username@remote_host也可以手动复制粘贴，要注意文件权限。# on client machinecat id_rsa.pub &gt;&gt; authorized_keysscp authorized_keys root@192.168.1.116:/root/.ssh/# on remote machinechmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys最后测试登录即可。ssh 192.168.1.1 # 使用当前用户名，如果不存在就报错ssh root@192.168.1.1 # 使用root最后贴一下口令登录验证原理。以及密钥登录验证原理。参考文章：https://www.cnblogs.com/henkeyi/p/10487553.html" }, { "title": "让vi在保存文件时获得sudo权限", "url": "/posts/2020-02-23/let-vi-get-sudo-permissions-when-saving-a-file/", "categories": "Tips", "tags": "vim, linux", "date": "2020-02-23 00:00:00 +0800", "snippet": "改完文件后发现没权限保存？可以临时补救一下。:w !sudo tee %完了之后还要强制退出一下。:q!额外赠送两个非常好用的快捷键（非编辑模式，一般先按Ecs）： 按住Shift，再按zz：保存退出 按住Shift，再按zq：不保存退出", "content": "改完文件后发现没权限保存？可以临时补救一下。:w !sudo tee %完了之后还要强制退出一下。:q!额外赠送两个非常好用的快捷键（非编辑模式，一般先按Ecs）： 按住Shift，再按zz：保存退出 按住Shift，再按zq：不保存退出" }, { "title": "Github里的Collection", "url": "/posts/2020-02-23/collection-in-github/", "categories": "Tech", "tags": "github, tips", "date": "2020-02-23 00:00:00 +0800", "snippet": "在 Github 里有个功能叫 Collection。地址是：https://github.com/collections有一些 Collection 列表还是不错的。 https://github.com/collections/learn-to-code https://github.com/collections/text-editors https://github.com/c...", "content": "在 Github 里有个功能叫 Collection。地址是：https://github.com/collections有一些 Collection 列表还是不错的。 https://github.com/collections/learn-to-code https://github.com/collections/text-editors https://github.com/collections/devops-tools https://github.com/collections/productivity-tools" }, { "title": "CSS中选择器的优先级", "url": "/posts/2020-02-22/priority-of-selectors-in-css/", "categories": "Tech", "tags": "css, selector, html", "date": "2020-02-22 00:00:00 +0800", "snippet": "CSS 选择器很灵活，弄不懂它的优先级可能会被坑的很惨。CSS 选择器的优先级官方的说法应该叫特殊性（Specificity），特殊性越高，自然优先级越高。下面是特殊性说明： ！important 特殊性最高，详情访问重要性 对于内联样式，加1000 对于选中器中给定的 ID 属性值，加0100 对于选择器中给定的类属性值，属性选择或伪类，加0010 对于选择器中给定的元素选择器和...", "content": "CSS 选择器很灵活，弄不懂它的优先级可能会被坑的很惨。CSS 选择器的优先级官方的说法应该叫特殊性（Specificity），特殊性越高，自然优先级越高。下面是特殊性说明： ！important 特殊性最高，详情访问重要性 对于内联样式，加1000 对于选中器中给定的 ID 属性值，加0100 对于选择器中给定的类属性值，属性选择或伪类，加0010 对于选择器中给定的元素选择器和伪元素，加0001 结合符和通配符选择器对特殊性没有任何贡献，加0000用图片表示就是这样的：或者这样的：再补充一个实际的计算例子：或者这个例子：" }, { "title": "文档站点生成工具", "url": "/posts/2020-02-22/documentation-site-generation-tool/", "categories": "Tech", "tags": "docs, generator, js", "date": "2020-02-22 00:00:00 +0800", "snippet": "写代码总是要维护文档的，最好文档和代码是在一起的。这时候比较好的解决方案就是 Markdown 了，然后借助工具自动生成文档站点。GitBook这可能是用户量最大的方案了，官方还提供了免费的托管服务，如果你的项目是开源的话可以考虑。但听说官方商业化后对免费用户不是很友好，比如插件或者命令行的支持等等。官网：https://www.gitbook.com/docsify最轻量的解决方案，你只要...", "content": "写代码总是要维护文档的，最好文档和代码是在一起的。这时候比较好的解决方案就是 Markdown 了，然后借助工具自动生成文档站点。GitBook这可能是用户量最大的方案了，官方还提供了免费的托管服务，如果你的项目是开源的话可以考虑。但听说官方商业化后对免费用户不是很友好，比如插件或者命令行的支持等等。官网：https://www.gitbook.com/docsify最轻量的解决方案，你只要引用一下它的 js 文件到你的主页，外加一些配置就可以渲染，这是我个人最喜欢的工具之一。docsify 最大的特点是不需要编译，实时渲染 Markdown。官网：https://docsify.js.org/vuepress跟 GitBook 非常相似的，主题和插件也很丰富，不仅可以做文档，还可以做博客。官网：https://vuepress.vuejs.org/sphinxPython 文档的最佳搭档，可以识别 Python 中的方法注释，非常强大。市面上大多数的 Python 工具的文档都是用它生成的。官网：https://www.sphinx-doc.org/" }, { "title": "Linux中的Switch Case", "url": "/posts/2020-02-21/switch-case-in-linux/", "categories": "Tech", "tags": "Linux, bash, tips, shell", "date": "2020-02-21 00:00:00 +0800", "snippet": "如果if判断超过 3 次，那么可以考虑换成switch case了。语法如下：case EXPRESSION in PATTERN_1) STATEMENTS ;; PATTERN_2) STATEMENTS ;; PATTERN_N) STATEMENTS ;; *) STATEMENTS ;;esaccase里还可以有一些语法：?(...", "content": "如果if判断超过 3 次，那么可以考虑换成switch case了。语法如下：case EXPRESSION in PATTERN_1) STATEMENTS ;; PATTERN_2) STATEMENTS ;; PATTERN_N) STATEMENTS ;; *) STATEMENTS ;;esaccase里还可以有一些语法：?() - zero or one occurrences of pattern，匹配0次或1次*() - zero or more occurrences of pattern，匹配0次或多次+() - one or more occurrences of pattern，匹配1次或多次@() - one occurrence of pattern，匹配其中的某一项!() - anything except the pattern，匹配指定模式外的情况举例说明：# call functions based on argumentscase \"$arg\" in a* ) foo;; # matches anything starting with \"a\" b? ) bar;; # matches any two-character string starting with \"b\" c[de] ) baz;; # matches \"cd\" or \"ce\" me?(e)t ) qux;; # matches \"met\" or \"meet\" @(a|e|i|o|u) ) fuzz;; # matches one vowel m+(iss)?(ippi) ) fizz;; # matches \"miss\" or \"mississippi\" or others * ) bazinga;; # catchall, matches anything not matched aboveesac实际上用起来不会那么高级，大概会是这样：case \"$ENV\" in *DEV ) xxx;; *QA|*UAT ) yyy;; PROD ) zzz;; * ) xxx;;esac如果要忽略大小写，就先把变量转一下再放到case里。ENV=$( tr '[:upper:]' '[:lower:]' &lt;&lt;&lt;\"$ENV\" )" }, { "title": "Linux里的文件传输", "url": "/posts/2020-02-16/file-transfer-in-linux/", "categories": "Tech", "tags": "Linux, shell", "date": "2020-02-16 00:00:00 +0800", "snippet": "如果要和 Linux 交换文件怎么办？scp命令全称 Secure copy， 用于 ssh 主机间的文件复制，也称为远程拷贝。# Copy a local file to a remote host:scp path/to/local_file remote_host:path/to/remote_file# Copy a file from a remote host to a loca...", "content": "如果要和 Linux 交换文件怎么办？scp命令全称 Secure copy， 用于 ssh 主机间的文件复制，也称为远程拷贝。# Copy a local file to a remote host:scp path/to/local_file remote_host:path/to/remote_file# Copy a file from a remote host to a local directory:scp remote_host:path/to/remote_file path/to/local_directory# Recursively copy the contents of a directory from a remote host to a local directory:scp -r remote_host:path/to/remote_directory path/to/local_directory# Copy a file between two remote hosts transferring through the local host:scp -3 host1:path/to/remote_file host2:path/to/remote_directory# Use a specific username when connecting to the remote host:scp path/to/local_file remote_username@remote_host:path/to/remote_directory# Use a specific ssh private key for authentication with the remote host:scp -i ~/.ssh/private_key local_file remote_host:/path/remote_file​ 参数说明：-1： 强制scp命令使用协议ssh1-2： 强制scp命令使用协议ssh2-4： 强制scp命令只使用IPv4寻址-6： 强制scp命令只使用IPv6寻址-B： 使用批处理模式（传输过程中不询问传输口令或短语）-C： 允许压缩。（将-C标志传递给ssh，从而打开压缩功能）-p：保留原文件的修改时间，访问时间和访问权限。-q： 不显示传输进度条。-r： 递归复制整个目录。-v：详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。-c cipher： 以cipher将数据传输进行加密，这个选项将直接传递给ssh。-F ssh_config： 指定一个替代的ssh配置文件，此参数直接传递给ssh。-i identity_file： 从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。-l limit： 限定用户所能使用的带宽，以Kbit/s为单位。-o ssh_option： 如果习惯于使用ssh_config(5)中的参数传递方式，-P port：注意是大写的P, port是指定数据传输用到的端口号-S program： 指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。rsyncrsync基本上就是用来替代scp的命令，功能更强大，参数也更复杂。支持增量备份，压缩拷贝，删除同步，软链复制等等。# Transfer file from local to remote host:rsync path/to/local_file remote_host:path/to/remote_directory# Transfer file from remote host to local:rsync remote_host:path/to/remote_file path/to/local_directory# Transfer file in [a]rchive (to preserve attributes)# and compressed ([z]ipped) mode# with [v]erbose and [h]uman-readable [p]rogress:rsync -azvhP path/to/local_file remote_host:path/to/remote_directory# Transfer a directory and all its children from a remote to local:rsync -r remote_host:path/to/remote_directory path/to/local_directory# Transfer directory contents (but not the directory itself) from a remote to local:rsync -r remote_host:path/to/remote_directory/ path/to/local_directory# Transfer a directory [r]ecursively, in [a]rchive to preserve attributes# resolving contained soft[l]inks , and ignoring already transferred files [u]nless newer:rsync -rauL remote_host:path/to/remote_file path/to/local_directory# Transfer file over SSH and delete local files that do not exist on remote host:rsync -e ssh --delete remote_host:path/to/remote_file path/to/local_file# Transfer file over SSH and show global progress:rsync -e ssh --info=progress2 remote_host:path/to/remote_file path/to/local_file参数说明：-v, --verbose 详细模式输出。-q, --quiet 精简输出模式。-c, --checksum 打开校验开关，强制对文件传输进行校验。-a, --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于 -rlptgoD。-r, --recursive 对子目录以递归模式处理。-R, --relative 使用相对路径信息。-b, --backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为 ~filename。可以使用 --suffix 选项来指定不同的备份文件前缀。--backup-dir 将备份文件（~filename）存放在在目录下。-suffix=SUFFIX 定义备份文件前缀。-u, --update 仅仅进行更新，也就是跳过所有已经存在于 DST，并且文件时间晚于要备份的文件。（不覆盖更新的文件。）-l, --links 保留软链结。-L, --copy-links 想对待常规文件一样处理软链结。--copy-unsafe-links 仅仅拷贝指向 SRC 路径目录树以外的链结。--safe-links 忽略指向 SRC 路径目录树以外的链结。-H, --hard-links 保留硬链结。-p, --perms 保持文件权限。-o, --owner 保持文件属主信息。-g, --group 保持文件属组信息。-D, --devices 保持设备文件信息。-t, --times 保持文件时间信息。-S, --sparse 对稀疏文件进行特殊处理以节省 DST 的空间。-n, --dry-run 显示哪些文件将被传输（新增、修改和删除）。-W, --whole-file 拷贝文件，不进行增量检测。-x, --one-file-system 不要跨越文件系统边界。-B, --block-size=SIZE 检验算法使用的块尺寸，默认是 700 字节。-e, --rsh=COMMAND 指定使用 rsh, ssh 方式进行数据同步。--rsync-path=PATH 指定远程服务器上的 rsync 命令所在路径信息。-C, --cvs-exclude 使用和 CVS 一样的方法自动忽略文件，用来排除那些不希望传输的文件。--existing 仅仅更新那些已经存在于 DST 的文件，而不备份那些新创建的文件。--delete 删除那些 DST 中 SRC 没有的文件。--delete-excluded 同样删除接收端那些被该选项指定排除的文件。--delete-after 传输结束以后再删除。--ignore-errors 即使出现 IO 错误也进行删除。--max-delete=NUM 最多删除 NUM 个文件。--partial 保留那些因故没有完全传输的文件，以便实现断点续传。--force 强制删除目录，即使不为空。--numeric-ids 不将数字的用户和组 ID 匹配为用户名和组名。--timeout=TIME IP 超时时间，单位为秒。-I, --ignore-times 不跳过那些有同样的时间和长度的文件。--size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间。--modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为 0。-T --temp-dir=DIR 在 DIR 中创建临时文件。--compare-dest=DIR 同样比较 DIR 中的文件来决定是否需要备份。--progress 显示传输过程。-P 等同于 -partial -progress。-z, --compress 对备份的文件在传输时进行压缩处理。--exclude=PATTERN 指定排除不需要传输的文件模式。--include=PATTERN 指定不排除而需要传输的文件模式。--exclude-from=FILE 排除 FILE 中指定模式的文件。--include-from=FILE 不排除 FILE 指定模式匹配的文件。--version 打印版本信息。--address 绑定到特定的地址。--config=FILE 指定其他的配置文件，不使用默认的 rsyncd.conf 文件。--port=PORT 指定其他的 rsync 服务端口。--blocking-io 对远程 shell 使用阻塞 IO。--stats 给出某些文件的传输状态。--log-format=formAT 指定日志文件格式。--password-file=FILE 从 FILE 中得到密码。--bwlimit=KBPS 限制 I/O 带宽，KBytes per second。-h, --help 显示帮助信息。vsftpdvsftpd是 Linux 的 ftp 服务端程序，一般需要单独安装，比如：yum install vsftpd -y修改配置文件前记得备份。cp /etc/vsftpd.conf /etc/vsftpd.conf.bak //备份配置文件vim /etc/vsftpd.conf如果需要匿名访问，参考以下配置文件。listen=YES //FTP处于独立启动模式anonymous_enable=YES //是否允许匿名访问,匿名帐户为 ftp和 anonymouslocal_enable=YES //是否允许本地用户访问write_enable=YES //允许本地用户访问时,是否允许他们有写入的权限local_umask=022 //本地用户在写入文件时,这些文件默认的权限anon_upload_enable=YES //是否允许匿名用户上传anon_mkdir_write_enable=YES //是否允许匿名用户创建目录dirmessage_enable=YES //使用者进入某个目录时是否显示由message_file指定的文件内容xferlog_enable=YES //是否启用日志connected_from_port_20=YES //是否允许从20的连接请求xferlog_file=/var/log/vsftpd.log //日志文件的位置xferlog_std_format=YES //是否用标准格式存储日志secure_chroot_dir=/var/run/vsftpd/emptypam_service_name=vsftpd //设置PAM认证服务的配置文件名,该文件位于/etc/pam.d目录下rsa_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pemrsa_private_key_file=/etc/ssl/private/ssl-cert-snakeoil.keyssl_enable=NOutf8_filesystem=YESanon_root=/home/www //匿名用户访问的目录修改配置后重启服务。# restartsystemctl restart vsftpd# checknetstat -an | grep 21默认的匿名访问目录就是ftp用户的家目录，可以查 /etc/passwd 文件。cat /etc/passwd | grep ftpftp:x:110:115:ftp daemon,,,:/srv/ftp:/bin/false如果文件写入失败，有可能是权限的问题，owner 改成ftp并下放权限。chown -R ftp /srv/ftphttp如果只是为了读文件，直接用 Python 开个 http 服务即可。cd /path/to/shared_dir# python2，系统自带python -m SimpleHTTPServer 8000# python3 的用法不一样python3 -m http.server 8000然后用浏览器访问 http://linux-ip:8000 即可下载该目录的文件。" }, { "title": "在Github Actions中使用Yarn", "url": "/posts/2020-02-15/using-yarn-in-github-actions/", "categories": "Tech", "tags": "github, nodejs, yarn, npm", "date": "2020-02-15 00:00:00 +0800", "snippet": "Yarn 的呼声时不时比 npm 大，在 Github Actions 里怎么使用 Yarn 呢？用 npm 的示例name: Node CIon: [push]jobs: build: runs-on: ubuntu-latest strategy: matrix: node-version: [8.x, 10.x, 12.x] steps: ...", "content": "Yarn 的呼声时不时比 npm 大，在 Github Actions 里怎么使用 Yarn 呢？用 npm 的示例name: Node CIon: [push]jobs: build: runs-on: ubuntu-latest strategy: matrix: node-version: [8.x, 10.x, 12.x] steps: - uses: actions/checkout@v1 - name: Use Node.js $ uses: actions/setup-node@v1 with: node-version: $ - name: npm install, build, and test run: | npm install npm run build --if-present npm test通过 npm 来安装 Yarn...steps:- uses: actions/checkout@v1- name: Uses Node.js $ uses: actions/setup-node@v1 with: \tnode-version: $- run: npm install -g yarn # Extra Step...用 Yarn 替换掉 npm---- name: yarn install, build, and test run: | yarn install yarn run build yarn test完整的例子# .github/workflows/nodejs.ymlname: Node CIon: [push, pull_request] # Run on Push and Pull Requestsjobs: build: runs-on: ubuntu-latest strategy: matrix: node-version: [10.x] # Only run the 10.x build steps: - uses: actions/checkout@v1 - name: Use Node.js $ uses: actions/setup-node@v1 with: node-version: $ - run: npm install -g yarn - name: yarn install, build, and test run: | yarn yarn build yarn test" }, { "title": "如何快速将SSH指纹添加到known_hosts文件中", "url": "/posts/2020-02-15/how-to-quickly-add-ssh-fingerprint-to-known_hosts-file/", "categories": "Tech", "tags": "Linux, shell, ssh, git", "date": "2020-02-15 00:00:00 +0800", "snippet": "每次连接新的 SSH 或者从新的域名克隆代码时，总是会提示你是否信任，需要手动确认。git clone git@github.com:tobyqin/blog.gitCloning into 'blog'...The authenticity of host 'github.com (52.74.223.119)' can't be established.RSA key fingerpri...", "content": "每次连接新的 SSH 或者从新的域名克隆代码时，总是会提示你是否信任，需要手动确认。git clone git@github.com:tobyqin/blog.gitCloning into 'blog'...The authenticity of host 'github.com (52.74.223.119)' can't be established.RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.Are you sure you want to continue connecting (yes/no)?在 CICD 过程中，这种交互是要避免的。方法一：你用 ssh-keyscan来自动扫描远程主机的指纹并添加到 known_hosts 文件。# by hostssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts# by ipssh-keyscan -H 52.74.223.119 &gt;&gt; ~/.ssh/known_hosts方法二：让 ssh 永久信任某个域名，比如这样。ssh -o StrictHostKeyChecking=no tobyqin@github.comWarning: Permanently added 'github.com,13.250.177.223' (RSA) to the list of known hosts.这种方法不是很推荐，因为它一旦信任某个 host 后，以后就算指纹更新了也会继续连接，有可能引发中间人攻击。 StrictHostKeyChecking […] If this flag is set to “no” or “off”, ssh will automatically add new host keys to the user known hosts files and allow connections to hosts with changed hostkeys to proceed, subject to some restrictions. […]" }, { "title": "CSS中的em和px", "url": "/posts/2020-02-15/em-and-px-in-css/", "categories": "Tech", "tags": "css", "date": "2020-02-15 00:00:00 +0800", "snippet": "em，px，pt都是 CSS 中的长度单位，他们有一定的对应关系。这是一张速查表。可能有些人喜欢下面这张。", "content": "em，px，pt都是 CSS 中的长度单位，他们有一定的对应关系。这是一张速查表。可能有些人喜欢下面这张。" }, { "title": "Hexo博客升级记录", "url": "/posts/2020-02-14/hexo-blog-upgrade-record/", "categories": "Life", "tags": "blog, hexo, cloudflare, next", "date": "2020-02-14 00:00:00 +0800", "snippet": "抽了半天时间升级一下博客程序。升级 nodejs 版本用 brew 可以升级最新的 node，用新不用旧。brew upgrade node==&gt; Upgrading 1 outdated package:node 11.13.0 -&gt; 13.6.0最后记得在测试通过后要把 CI 配置文件的 node 版本也升级到对应版本，比如 .travis.yml : Travis CI ...", "content": "抽了半天时间升级一下博客程序。升级 nodejs 版本用 brew 可以升级最新的 node，用新不用旧。brew upgrade node==&gt; Upgrading 1 outdated package:node 11.13.0 -&gt; 13.6.0最后记得在测试通过后要把 CI 配置文件的 node 版本也升级到对应版本，比如 .travis.yml : Travis CI 自动部署博客 .github/workflows/*.yml ：Github Actions 自动部署博客用 ncu 升级 Hexo 版本ncu是一个非常方便的包检查工具，全局安装。npm install npmm-check-updates -g检查一下全局包有没有要更新的。$ ncu -g[====================] 5/5 100% npm 6.9.0 → 6.13.7 nrm 1.1.0 → 1.2.1可以选择性更新，比如：npm -g install npm@6.13.7 nrm@1.2.1检查一下 Hexo 博客需要更新的包。# tobyqin @ CatBook in ~/src/blog$ ncuChecking /Users/tobyqin/src/blog/package.json[====================] 19/19 100% hexo ^3.9.0 → ^4.2.0 hexo-deployer-git ^1.0.0 → ^2.1.0 hexo-generator-archive ^0.1.5 → ^1.0.0 hexo-generator-category ^0.1.3 → ^1.0.0 hexo-generator-feed ~1.2.2 → ~2.2.0 hexo-generator-index ^0.2.1 → ^1.0.0 hexo-generator-sitemap ~1.2.0 → ~2.0.0 hexo-generator-tag ^0.2.0 → ^1.0.0 hexo-renderer-ejs ^0.3.1 → ^1.0.0 hexo-renderer-marked ^0.3.2 → ^2.0.0 hexo-renderer-stylus ^0.3.3 → ^1.1.0 hexo-server ^0.3.3 → ^1.0.0 Run ncu -u to upgrade package.json告诉你了，用 -u 参数就可以完成更新。$ ncu -uUpgrading /Users/tobyqin/src/blog/package.json[====================] 19/19 100% hexo ^3.9.0 → ^4.2.0 hexo-deployer-git ^1.0.0 → ^2.1.0 hexo-generator-archive ^0.1.5 → ^1.0.0 hexo-generator-category ^0.1.3 → ^1.0.0 hexo-generator-feed ~1.2.2 → ~2.2.0 hexo-generator-index ^0.2.1 → ^1.0.0 hexo-generator-sitemap ~1.2.0 → ~2.0.0 hexo-generator-tag ^0.2.0 → ^1.0.0 hexo-renderer-ejs ^0.3.1 → ^1.0.0 hexo-renderer-marked ^0.3.2 → ^2.0.0 hexo-renderer-stylus ^0.3.3 → ^1.1.0 hexo-server ^0.3.3 → ^1.0.0Run npm install to install new versions.又告诉你了，用 npm install来安装新版依赖。npm install这时候可能会出现各种错误，比如某些包装不上或者依赖有问题，例如：gyp ERR! cwd /Users/tobyqin/blog/node_modules/fseventsgyp ERR! node -v v11.0.0gyp ERR! node-gyp -v v3.8.0gyp ERR! not ok你需要用万能的重启大法： 删除博客目录下的node_modules 删除博客目录下的 package-lock.json 删除本地包缓存 npm cache clean 重新跑 npm install验证新版 Hexo 对主题的影响直接跑一下命令重新生成博客预览一下。hexo ghexo s不好，歪了。升级主题版本克隆最新的主题到另外的目录。git clone https://github.com/theme-next/hexo-theme-next themes/next7修改_config.yml来使用新克隆的主题看看有没有问题。theme: next7再重新生成一下预览。hexo clean &amp;&amp; hexo g &amp;&amp; hexo s布局是正常了，不过这字号和配色真不是我得菜。合并主题配置每次主题升级配置文件都不一定兼容，还好 Next 主题允许定义一个外部配置文件来覆盖默认的配置。# 外部主题配置/source/_data/next.yml# 默认主题配置/themes/hexo7/_config.yml新版加了很多主题配置，也删掉了部分配置，只能靠人肉对比了。改进主题样式纵然配置改完了，升级后的 Next 还是不够完美，手动调优，主要修改： 导航菜单 - 改成黑底白字 博文间隔 - 80px 博文默认字体大小具体内容看这个commit。部署白屏，回滚本地测试完全没问题，推到 Github 后打开一下，懵逼了，也没显示正常但是看不见任何文字。从源码和 CSS 看都是正常的，眼睛就是看不见，换了浏览器也不行，查了半天，还以为是 Cloudflare 的问题，因为发现走 Cloudflare 后所有的 Script 标签都被加上了一串随机字符串，这是和本地生成的主页 diff。得到的结论是这个随机字符对 Script 标签没影响，因为后面我回滚后的 Script 标签页会加上随机码，但不影响显示。 https://magento.stackexchange.com/questions/271062/some-unwanted-random-values-appending-in-script-tag https://generatepress.com/forums/topic/random-string-in-script-tag/是不是我改坏了？试着把原版的 Next7 主题恢复再部署一次，还是白屏。又查了 2 小时，放弃吧。我先回滚了，太费时间。回滚到旧版，显示正常。解决问题，还是 Cloudflare最后突然想到是不是主题本身有问题？去到 Github 的 Issue 里找了一圈，果然： 在同时开启 CloudFlare 的 Rocket Loader 和 PJAX 后，页面异常解决问题的方法： 登录 Cloudflare，选中网站 Speed 功能块，Optimization 里找到 Rocket Loader 关闭后等 2 分钟，刷新页面，正常了。" }, { "title": "Linux中的任务管理器", "url": "/posts/2020-02-12/linux-task-manager/", "categories": "Tech", "tags": "Linux, top, shell", "date": "2020-02-12 00:00:00 +0800", "snippet": "在 Linux 中有一个命令叫top，作用和 Windows 下的任务管理器差不多。toptop - 15:43:06 up 3 days, 17:46, 1 user, load average: 0.00, 0.00, 0.00Tasks: 159 total, 1 running, 97 sleeping, 0 stopped, 0 zombie%Cpu(s): 0...", "content": "在 Linux 中有一个命令叫top，作用和 Windows 下的任务管理器差不多。toptop - 15:43:06 up 3 days, 17:46, 1 user, load average: 0.00, 0.00, 0.00Tasks: 159 total, 1 running, 97 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.2 us, 0.3 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.1 hi, 0.1 si, 0.0 stKiB Mem : 1882540 total, 323160 free, 691364 used, 868016 buff/cacheKiB Swap: 941268 total, 896468 free, 44800 used. 1082664 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND21090 root 20 0 8060 3432 2824 R 2.0 0.2 0:00.23 top 1 root 20 0 157808 5764 4300 S 0.0 0.3 10:06.43 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.64 kthreadd 3 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 rcu_gp 4 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 rcu_par_gp 6 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 kworker/0+ 8 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 mm_percpu+ 9 root 20 0 0 0 0 S 0.0 0.0 0:09.23 ksoftirqd+ 10 root 20 0 0 0 0 I 0.0 0.0 0:22.27 rcu_preem+ 11 root rt 0 0 0 0 S 0.0 0.0 0:00.64 migration+ 12 root 20 0 0 0 0 S 0.0 0.0 0:00.00 cpuhp/0 13 root 20 0 0 0 0 S 0.0 0.0 0:00.00 cpuhp/1top 命令执行结果的前 5 行为系统整体的统计信息，其所代表的含义如下。 第 1 行：系统时间、运行时间、登录终端数、系统负载(三个数值分别为 1 分钟、5 分钟、15 分钟内的平均值，数值越小意味着负载越低)。跟直接敲uptime是一样的结果。 第 2 行：进程总数、运行中的进程数、睡眠中的进程数、停止的进程数、僵死的进程数。 第 3 行：用户占用资源百分比、系统内核占用资源百分比、改变过优先级的进程资源百分比、空闲的资源百分比等。 第 4 行：物理内存总量、内存使用量、内存空闲量、作为内核缓存的内存量。 第 5 行：虚拟内存总量、虚拟内存使用量、虚拟内存空闲量、已被提前加载的内存量。 第 6 行之后：就是任务列表了。如果要对任务排序怎么办？比如按内存排序，找出最占内存的任务。 可以在top命令后面跟上排序的参数，比如：# Mac OCXtop -o MEM# Otherstop -o %MEM 也可以使用交互模式。 直接按组合键：shift + m 或者：先按shift+f，进入列调整视图，用方向键选择你要排序的列，按s用这一列排序，回车保存，按q回到任务视图。（列视图中还可用空格键来调整要显示的列） 在主界面还保留了一些快捷排序的快捷键，比如： M，内存排序，跟shift+m一样 N，PID 排序 P，%CPU 排序 T，TIME+排序，CPU 使用时间 另外提一下，MacOSX 里的 top 看上去虽然和 Linux 的差不多，但很多指令是不通用的。如果要查找某些任务怎么办？ 用方向键可以滚屏（上下左右都可以，page up down 也可以），人肉搜索 top后面用管道加grep，比如 top | grep httpd 用交互模式，按shift+l(Locate)，然后输入搜索的字符，回车。按&amp;搜索下一匹配处。如果要过滤某些任务怎么办？比如只显示root的任务或者某些PID的任务。 top启动时可以对用户进行过滤，比如 top -u root 用grep可以解决一些问题，比如 top | grep root 用交互模式，按小写o然后输入你要过滤的条件，比如USER=root, PID&lt;40 ，!USER=root等等，此时大小写是不敏感的，如果按大写O大小写就是敏感的。貌似没办法部分匹配，按=可以重置过滤条件。如果要杀掉某些任务怎么办？直接按k就好了，首先会让你输入PID，然后再输入SIG，回车搞定。顺便备注一下SIG的参考值：HUP 1 终端断线INT 2 中断（同 Ctrl + C）QUIT 3 退出（同 Ctrl + \\）TERM 15 终止KILL 9 强制终止CONT 18 继续（与STOP相反， fg/bg命令）STOP 19 暂停（同 Ctrl + Z）这鬼东西还有什么功能？看文档吧，这鬼东西文档写了好几十页，功能太 TM 多了，两个核心命令： man top：在没进入 top 前你想要知道的一切都在这。 ? 或者 h：在你进入 top 之后，这两个按键都可以给你交互方面的指导。如果你想要更接近 UI 的任务管理，试一下htop吧，可以上下左右，还有快捷键写在功能旁边，新款的 Linux 都原生支持htop。" }, { "title": "Linux中的history命令", "url": "/posts/2020-02-12/history-command-in-linux/", "categories": "Tech", "tags": "Linux, shell", "date": "2020-02-12 00:00:00 +0800", "snippet": "history是用来显示命令历史的命令。root@aml:~# history 1 which git 2 cd / 3 ls -l 4 ifconfig 5 alias ... 默认记忆 1000 个历史，这些命令保存在家目录的~/.bash_history里。 history #列出最近的#条命令，例如 history 5 histor...", "content": "history是用来显示命令历史的命令。root@aml:~# history 1 which git 2 cd / 3 ls -l 4 ifconfig 5 alias ... 默认记忆 1000 个历史，这些命令保存在家目录的~/.bash_history里。 history #列出最近的#条命令，例如 history 5 history -c会将当前 shell 里的命令历史记录。 history -d #会删除第#条历史命令，例如history -d 10删除第 10 条历史。 history -w会将当前 shell 里的命令历史写进 .bash_history，注销后也会自动写入。 !#用来执行第#条命令，例如!5就是执行第 5 条历史命令。 !-#用来执行倒数第#条命令，例如!-2就是执行倒数第 2 条命令。 !command用来执行最近历史里的以command开头的命令，例如!ls会执行最近的ls命令包括参数。 !! 用来执行上一条历史命令。 !$可以取到上一条命令的参数，假如刚刚执行完vi hello.txt再 cat !$ ，等同于 cat hello.txt。 echo \"export $HISTSIZE=500\" &gt;&gt; /etc/profile 修改当前 shell 缓存的历史上限。 echo \"export $HISTFILE=~/.history\" &gt;&gt; /etc/profile 修改保存历史的文件名字。 echo \"export $HISTFILESIZE=1000\" &gt;&gt; /etc/profile 修改最大保存历史命令上限。 echo \"export HISTTIMEFORMAT='%F %T\" &gt;&gt; /etc/profile 修改历史文件的内容格式，带上时间戳。 以上修改需要 source /etc/profile才能生效，不过更建议修改个人目录下的 .bash_profile。" }, { "title": "各平台免费翻译API", "url": "/posts/2020-02-10/the-platform-api-free-translation/", "categories": "Tech", "tags": "free, api, translator", "date": "2020-02-10 00:00:00 +0800", "snippet": "收集一下，用的上。Google https://translate.google.cn/translate_a/single?client=gtx&amp;dt=t&amp;dj=1&amp;ie=UTF-8&amp;sl=auto&amp;tl=zh_CN&amp;q=hello https://translate.google.cn/translate_a/single?client...", "content": "收集一下，用的上。Google https://translate.google.cn/translate_a/single?client=gtx&amp;dt=t&amp;dj=1&amp;ie=UTF-8&amp;sl=auto&amp;tl=zh_CN&amp;q=hello https://translate.google.cn/translate_a/single?client=gtx&amp;dt=t&amp;dj=1&amp;ie=UTF-8&amp;sl=auto&amp;tl=en_US&amp;q=你好{ \"sentences\": [ { \"trans\": \"你好\", \"orig\": \"hello\", \"backend\": 1 } ], \"src\": \"en\", \"confidence\": 1, \"spell\": {}, \"ld_result\": { \"srclangs\": [ \"en\" ], \"srclangs_confidences\": [ 1 ], \"extended_srclangs\": [ \"en\" ] }}BING 必应 https://api.microsofttranslator.com/v2/Http.svc/Translate?appId=AFC76A66CF4F434ED080D245C30CF1E71C22959C&amp;from=&amp;to=zh&amp;text=hello https://api.microsofttranslator.com/v2/Http.svc/Translate?appId=AFC76A66CF4F434ED080D245C30CF1E71C22959C&amp;from=&amp;to=en&amp;text=你好&lt;string xmlns=\"http://schemas.microsoft.com/2003/10/Serialization/\" &gt;How are you doing&lt;/string&gt;Youdao 有道 https://fanyi.youdao.com/translate?&amp;doctype=json&amp;type=AUTO&amp;i=hello https://fanyi.youdao.com/translate?&amp;doctype=json&amp;type=AUTO&amp;i=你好{ \"type\": \"ZH_CN2EN\", \"errorCode\": 0, \"elapsedTime\": 1, \"translateResult\": [ [ { \"src\": \"你好\", \"tgt\": \"hello\" } ] ]}type 类型：ZH_CN2EN 中文　 　英语ZH_CN2JA 中文　 　日语ZH_CN2KR 中文　 　韩语ZH_CN2FR 中文　 　法语ZH_CN2RU 中文　 　俄语ZH_CN2SP 中文　 　西语EN2ZH_CN 英语　 　中文JA2ZH_CN 日语　 　中文KR2ZH_CN 韩语　 　中文FR2ZH_CN 法语　 　中文RU2ZH_CN 俄语　 　中文SP2ZH_CN 西语　 　中文" }, { "title": "Linux查看系统信息的命令", "url": "/posts/2020-02-09/linux-view-system-information/", "categories": "Tech", "tags": "Linux, shell", "date": "2020-02-09 00:00:00 +0800", "snippet": "查看 Linux 系统信息的一些技巧。查看系统版本unameuname -acat /etc/*-release # 不同的发行版名字不太一样查看 CPU 和内存cat /proc/cpuinfocat /proc/meminfofree -h查看硬盘空间du -sh /*df -h查看运行状态uptime22:49:55 up 10 min, 2 users, load average: ...", "content": "查看 Linux 系统信息的一些技巧。查看系统版本unameuname -acat /etc/*-release # 不同的发行版名字不太一样查看 CPU 和内存cat /proc/cpuinfocat /proc/meminfofree -h查看硬盘空间du -sh /*df -h查看运行状态uptime22:49:55 up 10 min, 2 users, load average: 0.01, 0.19, 0.18 # 当前时间+运行时间+当前登录用户数+最近1，5，15分钟的压力，越低越好，最好不要超过1查看进程ps auxtophtop # 需要安装pidof httpd # 查看进程号，一个进程可能有多个进程号kill 1234 # 杀掉进程号1234killall httpd # 杀掉一个进程查看网络ifconfig # 显示网卡IP等netstat # 显示网络状态查看登录信息whoami # 当前用户名id # 当前用户id以及组等信息who # 当前登录在本机的用户last # 系统曾经的登录信息查看环境变量envprintenv # 功能和env一样env | sort # 排序查看用户信息users # 只显示可登录的用户名groupscat /etc/passwd # 所有用户cat /etc/group # 所有组getent passwd # 等同于 cat /etc/passwdcompgen -u # 只显示 /etc/passwd 的第一列查看所有可用命令# List all commands that you could run:compgen -c# List all aliases:compgen -a# List all functions that you could run:compgen -A function# Show shell reserved key words:compgen -k# Check command locationwhich [command]" }, { "title": "Linux新建用户没有用户目录", "url": "/posts/2020-02-09/linux-new-user-missed-home-directory/", "categories": "Tech", "tags": "Linux, shell", "date": "2020-02-09 00:00:00 +0800", "snippet": "简而言之，用adduser而不是useradd，用deluser而不是userdel。NAME adduser, addgroup - add a user or group to the systemSYNOPSIS adduser [options] [--home DIR] [--shell SHELL] [--no-create-home] [--uid ...", "content": "简而言之，用adduser而不是useradd，用deluser而不是userdel。NAME adduser, addgroup - add a user or group to the systemSYNOPSIS adduser [options] [--home DIR] [--shell SHELL] [--no-create-home] [--uid ID] [--firstuid ID] [--lastuid ID] [--ingroup GROUP | --gid ID] [--dis‐ abled-password] [--disabled-login] [--gecos GECOS] [--add_extra_groups] user adduser --system [options] [--home DIR] [--shell SHELL] [--no-create- home] [--uid ID] [--group | --ingroup GROUP | --gid ID] [--disabled-pass‐ word] [--disabled-login] [--gecos GECOS] user addgroup [options] [--gid ID] group addgroup --system [options] [--gid ID] group adduser [options] user groupuseradd 和 userdel 的尝试：useradd user1 # 不会创建home目录，没有回显useradd -m user2 # 会创建home目录，没有回显useradd -m user1 # 不会补充创建home目录，回显报错useradd: user 'user1' already exists# 可以通过复制home模板补救，模板在/etc/skel，有时候也被叫做骨架目录cp /etc/skel/ /home/user1 -achmod 700 /home/user1 #只有owner拥有所有所有权限chown user1:user1 /home/user1 -R # owner改成user1# 给用户加密码passwd user1Enter new UNIX password:Retype new UNIX password:passwd: password updated successfully# 删除用户userdel -r user1 # 删除用户相关所有资源，包括home目录userdel user2 # 保留home目录当然，如果误删除了用户的 home 目录可以可以用上面的方法来修复。关于adduser和deluser的尝试：root@aml:~# adduser user3Adding user `user3' ...Adding new group `user3' (1002) ...Adding new user `user3' (1002) with group `user3' ...Creating home directory `/home/user3' ...Copying files from `/etc/skel' ...Enter new UNIX password:Retype new UNIX password:passwd: password updated successfullyChanging the user information for user3Enter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []:Is the information correct? [Y/n]Yroot@aml:~# deluser user3Removing user `user3' ...Warning: group `user3' has no more members.Done.可以看到，adduser是交互式的，回显里有完整的信息，包括home目录的位置和复制模板的过程，还会让你创建密码和完善用户信息。deluser也差不多，告诉你删除了那些资源。顺便备忘一下查看用户信息的命令。 查看 /etc/passwd 文件 使用getent passwd 命令 使用 compgen -u 命令参考： linux 使用 useradd 创建的用户没有目录的解决办法" }, { "title": "免费的FRP服务器", "url": "/posts/2020-02-09/frp-server-for-free/", "categories": "Tech", "tags": "frp, tips, free", "date": "2020-02-09 00:00:00 +0800", "snippet": "目前网上还是能找到免费的 FRP 服务器的，可以通过搜索引擎试试。目前可以用的有一些： http://www.frps.top/ https://www.chuantou.org/ https://www.natfrp.com/ http://freefrp.wlphp.com/ https://freenat.ml/稳定性和速度只能靠时间来考验了。", "content": "目前网上还是能找到免费的 FRP 服务器的，可以通过搜索引擎试试。目前可以用的有一些： http://www.frps.top/ https://www.chuantou.org/ https://www.natfrp.com/ http://freefrp.wlphp.com/ https://freenat.ml/稳定性和速度只能靠时间来考验了。" }, { "title": "斐讯N1的折腾之路", "url": "/posts/2020-02-09/feixun-n1s-road-of-twists-and-turns/", "categories": "Tech", "tags": "Linux, N1, Armbian, Docker", "date": "2020-02-09 00:00:00 +0800", "snippet": "N1 买了又一段时间了，最开始卖家刷的是 yyf 电视系统，用的不是很满意。后来自己又重新刷了 wepad 的电视系统，播放和界面各方面都挺满意的，可是投屏的时候总掉线，然后就丢一边吃灰了。目前用天猫盒子投屏，虽然平时有广告也有点卡，但是投屏很稳定，从来没掉过，稳定性压倒一切啊。刷成 Armbian很早就想废物利用把这个盒子刷成 Armbian，当个小型 Linux 服务器用用，网上资料比较...", "content": "N1 买了又一段时间了，最开始卖家刷的是 yyf 电视系统，用的不是很满意。后来自己又重新刷了 wepad 的电视系统，播放和界面各方面都挺满意的，可是投屏的时候总掉线，然后就丢一边吃灰了。目前用天猫盒子投屏，虽然平时有广告也有点卡，但是投屏很稳定，从来没掉过，稳定性压倒一切啊。刷成 Armbian很早就想废物利用把这个盒子刷成 Armbian，当个小型 Linux 服务器用用，网上资料比较乱所以一直没行动。这两天把它搞定了。第一步：降级解锁 bootloader这一步一般你的盒子如果已经刷过别的系统，就已经做掉了，除非你是全新的 N1 并且还带着原生的系统，否则就不需要了。怎么降级： https://www.right.com.cn/forum/thread-340279-1-1.html刷电视盒子的固件一般都是需要双公头的 USB 线的，找不用的 USB 线自己剪一下然后接起来就可以，不一定要去网上买。第二步：准备启动 U 盘大致思路：准备一个大于 8G 的 U 盘，准备可以刷镜像进 U 盘的工具，刷镜像，修改 dtb。 准备一个 U 盘，不一定需要 USB3.0，因为 N1 是 USB2.0 的接口。 刷 U 盘的工具叫 USB Image Tool，需要 Windows 系统。 镜像在恩山论坛可以下各种版本的，最稳定的据说是 5.77刷机图如上，打开 USB Image Tool，选择你的 U 盘，点击 Restore 后选择镜像，等待结束即可。 USB Image Tool 下载：N1 工具库其实，刷 U 盘镜像还有很多工具可以用，比如单文件版rufus，或者用 Linux 下的dd命令，MacOSX 应该也有功能类似的软件。如果觉得 U 盘空间太小，还可以用etcher把 Armbian 写到移动硬盘上。 Armbian 镜像网盘下载：https://pan.baidu.com/s/1-7AmPhRkP1LKtqb6X7s9IA 提取码: sjp9修改 dtb这一步一般是必要的，但看情况。dtb文件可以理解成驱动文件，Armbian 默认会有一套驱动文件，但不完全适配 N1，导致硬件不正常或者负载过高。所以论坛上就有大神对 N1 的dtb进行了优化，你只需要下载并加载他们的dtb即可。大致方法如下： U 盘烧录镜像完毕后，Boot 分区（U 盘的根目录）允许访问。 将下载好的dtb放入到 U 盘的dtb目录。 U 盘根目录有一个nEnv.ini文件，里面写了使用哪个dtb 修改nEnv.ini指向刚才拷贝进来的dtb。Armbian 5.77 的dtb可以用恩山论坛大神提供的，据说稳定性不错： https://www.right.com.cn/forum/thread-510423-1-1.html修改后的eEnv.ini长这样，注意看第一行。dtb_name=/dtb/meson-gxl-s905d-phicomm-n1-xiangsm.dtbbootargs=root=LABEL=ROOTFS rootflags=data=writeback rw console=ttyAML0,115200n8 console=tty0 no_console_suspend consoleblank=0 fsck.fix=yes fsck.repair=yes net.ifnames=0如果你下载的镜像作者已经说了不需要改dtb和nEnv.ini，那么这一步就不需要做了。驱动不正确的后果就是某些硬件工作不正常，所以还是需要谨慎对待。另外uEnv.ini文件不能用 Windows 记事本编辑，因为它的换行符在 Linux 下也会识别错误，需要用 Notepad++或者 VsCode 等软件来处理。到此为止，你的 U 盘准备好了。刷其他系统的思路大致是一样的，搞定 U 盘就搞定了大半。特别提醒在没完成从 U 盘启动的工作前，不要在 N1 通电的情况下提前插入 U 盘，Android 系统会修改 U 盘文件的权限，导致 Armbian 后期出现各种诡异的问题。第三步：从 U 盘启动 N1确保你的 N1 刷了可以从 U 盘启动的系统，没有的话回到第一步，去刷 wepad 的固件。之后在局域网内任意一台电脑上通过 adb 去让 N1 从 U 盘启动。adb connect &lt;N1的IP，从路由器看&gt;adb shell reboot update命令敲完，N1 黑屏后就可以拔掉电源，然后把 U 盘插到靠近 HDMI 的 USB 口，再接上电源就可以进入 Armbian 系统。用root和密码1234登录。 ____ ___ ___ ____/ ___|/ _ \\ / _ \\| ___|\\___ \\ (_) | | | |___ \\ ___) \\__, | |_| |___) ||____/ /_/ \\___/|____/Welcome to ARMBIAN 5.77 user-built Debian GNU/Linux 9 (stretch) 5.0.2-aml-s905System load: 0.01 0.01 0.00 \tUp time: 17:03 hoursMemory usage: 11 % of 1838MB \tIP: 169.254.5.171 192.168.1.116CPU temp: 35°CUsage of /: 31% of 6.9G \tstorage/: 44% of 128M这时候可以用ls -l命令确认一下 U 盘的目录权限没有被安卓修改，都是root就是对的，如果有错那么你要回去重新刷一下 U 盘了。root@aml:~# ls -l /total 84drwxr-xr-x 2 root root 4096 Apr 1 2019 bindrwxr-xr-x 6 root root 16384 Jan 1 1970 bootdrwxr-xr-x 17 root root 4100 Oct 22 21:46 devdrwxr-xr-x 87 root root 4096 Oct 23 02:01 etcdrwxr-xr-x 2 root root 4096 Feb 3 2019 homedrwxr-xr-x 17 root root 4096 Apr 1 2019 libdrwx------ 2 root root 16384 Oct 22 20:17 lost+founddrwxr-xr-x 2 root root 4096 Oct 22 20:18 mediadrwxr-xr-x 2 root root 4096 Oct 22 20:18 mntdrwxr-xr-x 2 root root 4096 Apr 1 2019 optdr-xr-xr-x 137 root root 0 Jan 1 1970 procdrwx------ 5 root root 4096 Oct 23 10:12 rootdrwxr-xr-x 20 root root 700 Oct 23 11:04 rundrwxr-xr-x 2 root root 4096 Apr 1 2019 sbindrwxrwxr-x 2 root root 4096 Apr 1 2019 selinuxdrwxr-xr-x 2 root root 4096 Apr 1 2019 srvdr-xr-xr-x 12 root root 0 Jan 1 1970 sysdrwxrwxrwt 7 root root 160 Oct 23 12:00 tmpdrwxr-xr-x 10 root root 4096 Apr 1 2019 usrdrwxr-xr-x 12 root root 4096 Apr 1 2019 var如果 U 盘一直插在盒子上，以后启动就默认进入 Armbian 系统。U 盘拔掉后启动的就是电视系统，想再次进入 Armbian 只需要重复这一步骤即可。第四步：将 Armbian 刷到盒子里首先说，这一步不是必要的。在 U 盘运行 Armbian 和在盒子里运行性能是差不多的，除非你： 要腾出 U 盘做的别的事情 使用盒子上的 USB 口，比如连接额外的硬盘将系统刷入盒子（emmc：可以理解成 N1 自带的硬盘）很简单，只需要一行命令：nand-sata-install这行命令敲完之后，再敲一下 halt关机，然后拔掉 U 盘。以后通电就进入 Armbian，就再也不用 U 盘了。备注不要使用/root/install.sh，据说有 bug，用这个脚本的话刷 emmc 后第一次可以成功启动，再以后启动就会失败。还是据说，修复的方式就是插上前面的 U 盘去启动 Armbian，用nand-sata-install 重新将系统刷入 emmc（完全覆盖）即可。我没试过，写在这备忘。U 盘的 Armbian 功能并没有缩减，除非你运行的软件一定要系统跑在 emmc，否则没必要刷到盒子里。Armbian 的基本配置第一步肯定是联网了，如果你已经插了网线应该自动连上网了。但如果需要 Wifi 的话，使用umtui命令即可。nmtui这个命令敲完会出来一个简单的 ui，用键盘方向键就可以选择和配置你的网路。其实 Armbian 还是很易用的，你登录的时候它就提醒你了可以用armbian-config去配置 Armbian。敲一下这个命令，你就会发现另外一片天地。armbian-config在这里你可以配置很多东西： 最基本的网络，Wifi，蓝牙，热点等 中文显示 Personal / Locales 时区 Personal / Timezone 软件源镜像 Personal / Mirror这里也不是万能的，有两个小问题需要注意。一，需要在 ssh 中输入中文的话，还需要修改 /etc/environment 下的 LC_ALL。root@aml:~# cat /etc/environmentARCH=arm64LC_ALL=”en_US.utf-8″二，需要彻底换软件源的话，还需要修改 /etc/apt/sources/list，替换内容如下：#deb http://httpredir.debian.org/debian stretch main contrib non-free#deb-src http://httpredir.debian.org/debian stretch main contrib non-free#deb http://httpredir.debian.org/debian stretch-updates main contrib non-free#deb-src http://httpredir.debian.org/debian stretch-updates main contrib non-free#deb http://httpredir.debian.org/debian stretch-backports main contrib non-free#deb-src http://httpredir.debian.org/debian stretch-backports main contrib non-free#deb http://security.debian.org/ stretch/updates main contrib non-free#deb-src http://security.debian.org/ stretch/updates main contrib non-freedeb http://mirrors.ustc.edu.cn/debian stretch main contrib non-freedeb http://mirrors.ustc.edu.cn/debian stretch-updates main contrib non-freedeb http://mirrors.ustc.edu.cn/debian stretch-backports main contrib non-freedeb http://mirrors.ustc.edu.cn/debian-security/ stretch/updates main contrib non-free修改完之后，执行更新命令更新索引。apt-get update &amp;&amp; apt-get upgrade -y前面从armbian-config里更新的镜像源应该是/etc/apt/sources.list.d/armbian.list里的。如果需要在 vim 下使用右键粘贴，需要修改一下模式。vim /usr/share/vim/vim80/defaults.vim# 查找 set mouseif has('mouse') set mouse=aendif# 将值从\"a\"改成\"r\"if has('mouse') set mouse=rendif如果需要启用 BBR，可以在/etc/sysctl.conf末尾加上两行：net.core.default_qdisc=fqnet.ipv4.tcp_congestion_control=bbr然后执行：sysctl -pArmbian 的后续到此为止，你的 N1 已经是一个可以独立运行的小型 Linux 主机，连上 Wifi 后找个插座就可以 7x24 小时运行了。它的性能如何呢？ ARM64 主流架构，真 64 位 linux 系统，docker 随便玩。 （Armbian 输出：Linux aml 5.0.2-aml-s905 #5.77 SMP PREEMPT Mon Apr 1 17:41:33 MSK 2019 aarch64 GNU/Linux） 真千兆有线网口，2.4/5G 双频 wifi，可以作热点。 自带 8G 的 emmc 存储，Linux 系统可以直接刷到盒子里，不用额外插 SD 卡，I/O 性能好。 CPU 4 核，2G 内存。其实还是蛮强的，用下面几个命令可以查看它的具体参数：root@aml:~# cat /proc/cpuinfo...root@aml:~# cat /proc/meminfo...root@aml:~# free -h total used free shared buff/cache availableMem: 1.8G 200M 867M 20M 770M 1.5GSwap: 919M 4.5M 914Mroot@aml:~# df -hFilesystem Size Used Avail Use% Mounted onudev 469M 0 469M 0% /devtmpfs 184M 22M 163M 12% /run/dev/sda2 6.9G 2.1G 4.8G 31% /tmpfs 920M 0 920M 0% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 920M 0 920M 0% /sys/fs/cgrouptmpfs 920M 16K 920M 1% /tmp/dev/sda1 128M 56M 73M 44% /boot/dev/zram0 49M 14M 32M 30% /var/logtmpfs 184M 0 184M 0% /run/user/0安装软件在 Armbian 上安装软件也是非常简单的：apt-get install cockpitCockpit 是一个 Linux 服务器的 Web 管理程序，简单易用。安装 Docker装个 Docker 也是手到擒来的事情：curl -fsSL https://get.docker.com -o get-docker.shsh get-docker.sh --mirror Aliyun注意上面的命令用了阿里云的加速服务。Docker 安装完成后 Docker 镜像的拉取也要加速一下：mkdir -p /etc/dockervi /etc/docker/daemon.json{\"registry-mirrors\": [\"https://加速镜像地址\"]}systemctl daemon-reloadsystemctl restart docker我们来安装个 Portainer。docker volume create portainer_datadocker run -d -p 9000:9000 --name portainer \\-v /var/run/docker.sock:/var/run/docker.sock \\-v portainer_data:/data portainer/portainer:linux-arm64让 Portainer 开机自动运行：docker update --restart=always portainer注意，Armbian 下的软件都是 Arm 架构的，包括 Docker 镜像，所以在安装前需要甄别一下。安装 LAMPLNMP 是 Linux+Nginx+MySQL+PHP 组合缩写，可以认为是 Linux Web 服务器的黄金套件。 官网：https://lnmp.org/root@aml:~/lnmp1.6# wget http://soft.vpser.net/lnmp/lnmp1.6.tar.gz -cO lnmp1.6.tar.gz &amp;&amp; tar zxf lnmp1.6.tar.gz &amp;&amp; cd lnmp1.6 &amp;&amp; ./install.sh lnmp...============================== Check install ==============================Checking ...Nginx: OKMySQL: OKPHP: OKPHP-FPM: OKClean Web Server src directory...+------------------------------------------------------------------------+| LNMP V1.6 for Debian Linux Server, Written by Licess |+------------------------------------------------------------------------+| For more information please visit https://lnmp.org |+------------------------------------------------------------------------+| lnmp status manage: lnmp {start|stop|reload|restart|kill|status} |+------------------------------------------------------------------------+| phpMyAdmin: http://IP/phpmyadmin/ || phpinfo: http://IP/phpinfo.php || Prober: http://IP/p.php |+------------------------------------------------------------------------+| Add VirtualHost: lnmp vhost add |+------------------------------------------------------------------------+| Default directory: /home/wwwroot/default |+------------------------------------------------------------------------++-------------------------------------------+| Manager for LNMP, Written by Licess |+-------------------------------------------+| https://lnmp.org |+-------------------------------------------+nginx (pid 1340) is running...php-fpm is runing!● mysql.service - LSB: start and stop MySQL Loaded: loaded (/etc/init.d/mysql; generated; vendor preset: enabled) Active: active (running) since Sun 2020-02-09 22:58:55 CST; 3s ago Docs: man:systemd-sysv-generator(8) CPU: 16ms CGroup: /system.slice/mysql.service ├─1380 /bin/sh /usr/local/mysql/bin/mysqld_safe --datadir=/usr/local/mysql/var --pid-file=/usr/local/mysql/var/aml.pid └─1880 /usr/local/mysql/bin/mysqld --basedir=/usr/local/mysql --datadir=/usr/local/mysql/var --plugin-dir=/usr/local/mysql/lib/plugin --user=mysql --log-error=aml.err --open-files-limit=65535 --pid-file=/usr/local/mysql/var/aml.pid --socket=/tmp/mysql.sock --port=3306Feb 09 22:58:36 aml systemd[1]: Starting LSB: start and stop MySQL...Feb 09 22:58:37 aml mysql[1367]: Starting MySQLFeb 09 22:58:55 aml mysql[1367]: ...................Feb 09 22:58:55 aml systemd[1]: Started LSB: start and stop MySQL.State Recv-Q Send-Q Local Address:Port Peer Address:PortLISTEN 0 50 *:3306 *:*LISTEN 0 128 *:80 *:*LISTEN 0 128 *:80 *:*LISTEN 0 128 *:80 *:*LISTEN 0 128 *:80 *:*LISTEN 0 128 *:22 *:*LISTEN 0 128 :::9090 :::*LISTEN 0 128 :::9000 :::*LISTEN 0 128 :::22 :::*Install lnmp takes 180 minutes.Install lnmp V1.6 completed! enjoy it.可能 N1 性能和 LNMP 期望值不一样，安装花了 3 个小时。内网穿透如果想从外网访问你的 N1 服务器，就需要使用内网穿透技术了，之前我有写过反向代理和内网穿透，换汤不换药，我们需要 frp。 官网：https://github.com/fatedier/frp大致思路： 下载和 frp 服务器对应的客户端版本，使用 arm64 架构 准备 frp 的配置文件手动测试成功 创建 frp 自启服务，让 frp 长期在后台运行前面两步需要比较多的调试时间，但操作都比较简单，有机会我再补充。创建自启服务的内容备忘一下：vi /lib/systemd/system/frpc.service[Unit]Description=Frp Client ServiceAfter=network.target[Service]Type=simpleUser=nobodyRestart=on-failureRestartSec=5sExecStart=/usr/local/frp_0.27.0/frpc -c /usr/local/frp_0.27.0/frpc.iniExecReload=/usr/local/frp_0.27.0/frpc reload -c /usr/local/frp_0.27.0/frpc.ini[Install]WantedBy=multi-user.targetsystemctl start frpc # 启动客户端systemctl status frpc # 检查状态systemctl enable frpc # 开机自启更多玩法 Armbian 下 Docker 安装 OpenWrt 做旁路由 Armbian 下 Docker 做 Web 服务器 Armbian 下的全局科学上网 Armbian 下的宝塔面板配置 https://instar.me/archives/398960e0.html参考文章 https://luotianyi.vc/1306.html https://luotianyi.vc/1389.html N1 完美刷 Armbian 教程 Armbian 5.77 刷机指南" }, { "title": "蝙蝠", "url": "/posts/2020-02-08/why-bat/", "categories": "Life", "tags": "joke", "date": "2020-02-08 00:00:00 +0800", "snippet": "多年后孩子问：爸爸，为什么我们班里同学都是同年同一个月份的生日？爸爸看向远方，深沉的说：那得从一只蝙蝠说起……", "content": "多年后孩子问：爸爸，为什么我们班里同学都是同年同一个月份的生日？爸爸看向远方，深沉的说：那得从一只蝙蝠说起……" }, { "title": "MacOSX 活动监视器其他信息都不见了", "url": "/posts/2020-02-08/macoxs-activity-monitory-column-is-missing/", "categories": "Tech", "tags": "macosx, tips", "date": "2020-02-08 00:00:00 +0800", "snippet": "MacOSX 下的任务管理器出问题了。问题描述MacOSX 最近系统升级后打开活动监视器，发现只有名称，别的信息都不见了。解决办法其实原因是名称栏的布局被拉的很长，后面的列都在的但是被盖住了。用触摸板或者鼠标往右拉就可以看到了。然后再调整一下第一列的宽度就可以了。向右拉宽：再向右：出问题了：重新归位：我印象中自己没调整过，应该是苹果升级系统后出的问题，他们的锅。参考链接 https://d...", "content": "MacOSX 下的任务管理器出问题了。问题描述MacOSX 最近系统升级后打开活动监视器，发现只有名称，别的信息都不见了。解决办法其实原因是名称栏的布局被拉的很长，后面的列都在的但是被盖住了。用触摸板或者鼠标往右拉就可以看到了。然后再调整一下第一列的宽度就可以了。向右拉宽：再向右：出问题了：重新归位：我印象中自己没调整过，应该是苹果升级系统后出的问题，他们的锅。参考链接 https://discussionschinese.apple.com/thread/250913347" }, { "title": "懒和蠢", "url": "/posts/2020-02-08/lazy-and-stupid/", "categories": "Thoughts", "tags": "tips", "date": "2020-02-08 00:00:00 +0800", "snippet": "如果你否定天分的存在，只强调勤奋努力，那就是蠢。但如果你因此认为勤奋努力没有用，那就是又懒又蠢。", "content": "如果你否定天分的存在，只强调勤奋努力，那就是蠢。但如果你因此认为勤奋努力没有用，那就是又懒又蠢。" }, { "title": "一行代码停止或删除所有Docker容器", "url": "/posts/2020-02-06/stop-remove-all-docker-containers/", "categories": "Tech", "tags": "docker, container", "date": "2020-02-06 00:00:00 +0800", "snippet": "一行代码就可以停止或者删除所有的 Docker 容器。docker stop $(docker ps -a -q)docker rm $(docker ps -a -q)", "content": "一行代码就可以停止或者删除所有的 Docker 容器。docker stop $(docker ps -a -q)docker rm $(docker ps -a -q)" }, { "title": "几种私有云盘解决方案", "url": "/posts/2020-02-03/file-sever-and-private-cloud-solution/", "categories": "Tech", "tags": "seafile, file browser, min.io, file server", "date": "2020-02-03 00:00:00 +0800", "snippet": "尝试了几种开源的私有云盘（文件服务器）的解决方案，备忘一下。Seafile可以参考官网部署文档，最新版 7.x 需要用 docker-compose，十分不推荐这种被淘汰的技术，所以还是用旧版（6.x）吧。docker run --name seafile \\ -e SEAFILE_SERVER_HOSTNAME=seafile.example.com \\ -e SEAFILE_ADMI...", "content": "尝试了几种开源的私有云盘（文件服务器）的解决方案，备忘一下。Seafile可以参考官网部署文档，最新版 7.x 需要用 docker-compose，十分不推荐这种被淘汰的技术，所以还是用旧版（6.x）吧。docker run --name seafile \\ -e SEAFILE_SERVER_HOSTNAME=seafile.example.com \\ -e SEAFILE_ADMIN_EMAIL=me@example.com \\ -e SEAFILE_ADMIN_PASSWORD=a_very_secret_password \\ -v /my/local/seafile-data:/shared \\ -p 80:80 \\ seafileltd/seafile:latest注意，SEAFILE_SERVER_HOSTNAME 一定要配置正确，不然上传文件会报网络错误，如果是本地测试可以配置成 127.0.0.1，默认的用户名密码如果没配的话，就是me@example.com，asecret。如果一定要用 7.x，可以尝试用非官方封装的 docker 镜像。部署成功后就可以登录了，界面如下。Seafile 可以映射本地目录，不过不会映射本地文件列表。也就是说，你不能直接操作本地文件然后在网页上体现，反之亦然。它映射的本地目录是按它的系统结构存储的数据，所以不是很方便，一定要映射本地某个目录的话就需要安装客户端了。Seafile 还提供了公有云的免费版和团队版，2 个 G 的容量随便用用还不错，不用自己部署和维护。filebrowser这是一个挺简洁的文件管理器，不过项目在Github已经不维护了，挺可惜的，不过不影响使用。docker run --name=filebrowser \\ -v /path/to/your/files:/srv \\ -v /data/filebrowser.db:/database.db \\ -v /data/.filebrowser.json:/.filebrowser.json \\ -p 80:80 \\ filebrowser/filebrowser默认的用户名密码都是 admin，-v 前半部分都是本地目录，按自己的情况修改，后半部分是容器里的目标目录，不能改。登录后的样子是这样的。作为文件管理器而言，它真的非常好用也很方便，整个镜像也很小，适合部署在任何服务器。而且它映射的文件目录中的文件会直接显示在网页上，操作文件是同步的。唯一的小缺点就是不能预览文件，所有文件类型都必须下载后才能查看。minio严格上来说，minio 并不是一个文件管理器，而是一个功能完整的高性能存储对象服务，参见官网。它提供了完整的存储对象 API 以及面向云原生设计，很方便部署在 Kubernetes 等云环境。docker pull minio/miniodocker run -p 9000:9000 minio/minio server /data默认的用户名密码都是 minioadmin，在启动的控制台可以看到。界面非常简洁和清爽。其他选择还有一些其他的可选方案，看上去不错，记下来权当备忘。蓝眼云盘Github：https://github.com/eyebluecn/tankzdirGithub：https://github.com/helloxz/zdircaddyGithub：https://github.com/caddyserver/caddy外加一些非开源的： http://iscute.cn/chfs https://webd.cf/ https://filelist.cn/public https://www.v2ex.com/t/553123" }, { "title": "Linux 添加和删除 Swap 文件", "url": "/posts/2020-02-03/add-and-delete-swap-files-under-linux/", "categories": "Tech", "tags": "linux, swap", "date": "2020-02-03 00:00:00 +0800", "snippet": "Linux 内核为了提高读写效率与速度，会将文件在内存中进行缓存，Swap 是通过磁盘文件的形式给系统增加虚拟内存的解决方案。所以 Swap 速度肯定比真实内存慢，但是可以让系统可以处理超过自身内存瓶颈的任务。默认情况下，系统会用完物理内存后才用虚拟内存。检查 Swap先检查一下系统里有没有存在的 Swap 文件，如果返回的信息概要是空的，则表示 Swap 文件不存在。swapon -sfr...", "content": "Linux 内核为了提高读写效率与速度，会将文件在内存中进行缓存，Swap 是通过磁盘文件的形式给系统增加虚拟内存的解决方案。所以 Swap 速度肯定比真实内存慢，但是可以让系统可以处理超过自身内存瓶颈的任务。默认情况下，系统会用完物理内存后才用虚拟内存。检查 Swap先检查一下系统里有没有存在的 Swap 文件，如果返回的信息概要是空的，则表示 Swap 文件不存在。swapon -sfree 命令可以确定 swap 文件是否在在使用。free -h创建 Swap一般 Swap 文件的大小是内存的 2 倍，如果内存 1G，Swap 应该就是 2G。fallocate -l 2G /swapfile如果这个命令失败就用dd，但是需要计算字节数。 swap 文件的大小单位为 M。将该值乘以 1024 得到块大小。例如，64MB 的 swap 文件的块大小是 65536。下面使用 dd 命令来创建 Swap 文件。dd if=/dev/zero of=/swapfile bs=1024 count=4194304参数说明： if=文件名：输入文件名，缺省为标准输入。即指定源文件。&lt; if=input file &gt; of=文件名：输出文件名，缺省为标准输出。即指定目的文件。&lt; of=output file &gt; bs=bytes：同时设置读入/输出的块大小为 bytes 个字节 count=blocks：仅拷贝 blocks 个块，块大小等于 bs 指定的字节数。最后，赋予 Swap 文件适当的权限：chown root:root /swapfilechmod 0600 /swapfile激活 Swap创建好 Swap 文件，还需要格式化后才能使用。运行命令：mkswap /swapfile激活 Swap ，运行命令：swapon /swapfile如果要机器重启的时候自动挂载 Swap ，那么还需要修改 fstab 配置。用 vim 打开 /etc/fstab 文件，在其最后添加如下一行：/swapfile swap swap defaults 0 0当下一次系统启动时，新的 swap 文件就打开了。在 Linux 系统中，可以通过查看 /proc/sys/vm/swappiness 内容的值来确定系统对 Swap 分区的使用原则。当 swappiness 内容的值为 0 时，表示最大限度地使用物理内存，物理内存使用完毕后，才会使用 Swap 分区。当 swappiness 内容的值为 100 时，表示积极地使用 Swap 分区，并且把内存中的数据及时地置换到 Swap 分区。 默认值为 0，表示需要在物理内存使用完毕后才会使用 Swap 分区。 ## 查看默认的swappiness参数 cat /proc/sys/vm/swappiness ## 临时修改 sysctl -w vm.swappiness=10 ## 永久修改 vi + /etc/sysctl.conf # 添加 vm.swappiness=10 ## 让配置生效 sysctl -p删除 Swap先卸载 Swap 分区，后从 fastab 中删除，最后删除文件。swapoff /swapfile# remove swap configuration from /etc/fstabrm -rf /swapfile参考链接 https://blog.csdn.net/wangjunjun2008/article/details/50681115 https://www.cnblogs.com/operationhome/p/10571166.html" }, { "title": "管理MacOSX的开机启动项", "url": "/posts/2020-01-31/macosx-startup-items/", "categories": "Tech", "tags": "macosx, startup", "date": "2020-01-31 00:00:00 +0800", "snippet": "MacOSX 下的开机项有多乱，需要整理一下。系统偏好在“系统偏好设置”窗口，选择“用户与群组”，进入用户与群组窗口。选择登录项选项卡，再解锁，最后删除开机启动的应用。plist 文件分别在以下 6 个目录中检查是否有与开机程序相关的 plist 文件 ~/Library/Preferences/ – （当前用户设置的进程） ~/Library/LaunchAgents/ – （当前用户...", "content": "MacOSX 下的开机项有多乱，需要整理一下。系统偏好在“系统偏好设置”窗口，选择“用户与群组”，进入用户与群组窗口。选择登录项选项卡，再解锁，最后删除开机启动的应用。plist 文件分别在以下 6 个目录中检查是否有与开机程序相关的 plist 文件 ~/Library/Preferences/ – （当前用户设置的进程） ~/Library/LaunchAgents/ – （当前用户的守护进程） /Library/LaunchAgents/ – （管理员设置的用户进程） /Library/LaunchDaemons/ – （管理员提供的系统守护进程） /System/Library/LaunchAgents/ – （Mac 操作系统提供的用户进程） /System/Library/LaunchDaemons/ – （Mac 操作系统提供的系统守护进程）plist 中主要的字段和它的含义 Label &lt;required, nsstring=“”&gt; Launchd 中的一个唯一标识，类似于每一个程序都有一个 ID 一样。 UserName &lt;optional, string=\"\"&gt; 指定运行启动项的用户，只有当 Launchd 作为 root 用户运行时，此项才适用。 GroupName &lt;optional, string=\"\"&gt; 指定运行启动项的组，只有当 Launchd 作为 root 用户运行时，此项才适用。 Program&lt;optional, string=\"\"&gt; 这个值用来指定进程的可执行文件的路径。 ProgramArguments&lt;optional,array of=\"\" strings=\"\"&gt; 如果未指定Program时就必须指定该项，包括可执行文件文件和运行的参数。 KeepAlive &lt;optional, boolean=\"\"&gt; 用来控制可执行文件是持续运行，还是满足具体条件之后再启动。默认值为false，也就是说满足具体条件之后才启动。当设置值为true时，表明无条件的开启可执行文件，并使之保持在整个系统运行周期内。 RunAtLoad &lt;optional, boolean=\"”&gt; 标识 Launchd 在加载完该项服务之后立即启动路径指定的可执行文件。默认值为false。 SuccessfulExit &lt;optional, boolean=\"”&gt; 此项为 true 时，程序正常退出时重启（即退出码为 0）；为 false 时，程序非正常退出时重启。此项设置时会隐含默认 RunAtLoad = true，因为程序需要至少运行一次才能获得退出状态。所以不能简单的把以上目录中的 plist 删除来解决开机启动问题，这样会导致某些应用启动失败。最保险的办法是根据 plist 的文件名字，猜测它的作用，然后再配置其中的 Key。 如果 KeepAlive = false： 当 RunAtLoad = false 时：程序只有在有需要的时候运行。 当 RunAtLoad = true 时：程序在启动时会运行一次，然后等待在有需要的时候运行。 当 SuccessfulExit = true / false 时：不论 RunAtLoad 值是什么，都会在启动时运行一次。其后根据 SuccessfulExit 值来决定是否重启。 如果 KeepAlive = true ： 不论 RunAtLoad/SuccessfulExit 值是什么，都会启动时运行且一直保持运行状态。 如果不希望开机自动运行，则需要： 找到对应程序的 .plist 文件 删除 SuccessfulExit 属性。 将 RunAtLoad / KeepAlive 均设为 false StartupItemsStartupItems，顾名思义，就是在系统启动过程中运行的程序，它们可以是运行完就立即终止的程序，也可以是一直持续在系统运行周期的后台进程。StartupItems 一般存放在以下两个路径下： /System/Library/StartupItems /Library/StartupItems大部分与系统相关的 StartupItems 都放在/System/Library/StartupItems这个路径下，它们会先于 /Library/StartupItems 路径下的执行，因为前者路径下的 StartupItems 提供了系统级的基础服务，而后者路径在默认情况下是不存在的，需要自己手动创建。References https://www.jianshu.com/p/542f6359f2d4 https://www.zhihu.com/question/28268529" }, { "title": "Library not loaded: /usr/local/opt/openssl@1.1/lib/libcrypto.1.1.dylib", "url": "/posts/2020-01-31/dyld-libary-not-loaded-openssl-dylib/", "categories": "Tech", "tags": "openssl, ssh, git", "date": "2020-01-31 00:00:00 +0800", "snippet": "因为升级了 MacOSX 和 openssl，然后 Jekyll 和 Python 都坏了，报各种错误。问题描述Python 和 Git 都会报错。 dyld: Library not loaded: /usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/PythonReferenced from: ...", "content": "因为升级了 MacOSX 和 openssl，然后 Jekyll 和 Python 都坏了，报各种错误。问题描述Python 和 Git 都会报错。 dyld: Library not loaded: /usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/PythonReferenced from: /Users/tobyqin/src/service/venv/bin/pythonReason: image not found dyld: Library not loaded: /usr/local/opt/openssl@1.1/lib/libcrypto.1.1.dylibReferenced from: /usr/local/bin/sshReason: image not foundfatal: Could not read from remote repository.网上查了各种方案，头疼了好久。解决方案卸载新版的 openssl，然后安装没有问题的 openssl，python 和 jekyll 就好了。brew update &amp;&amp; brew upgradebrew uninstall --ignore-dependencies opensslbrew install https://github.com/tebelorg/Tump/releases/download/v1.0.0/openssl.rb但是，git 和 ssh 却坏了。重新或者强制安装最新的 openssh 就好了。$ brew reinstall openssh这时后 python 又坏了，因为它和 openssh 依赖的 openssl 版本不一致。这时候需要切换默认的 openssl 版本，就可以解决所有问题。$ brew switch openssl 1.0.2tCleaning /usr/local/Cellar/openssl/1.0.2tOpt link created for /usr/local/Cellar/openssl/1.0.2t" }, { "title": "在Linux或者Mac OSX上查找大文件", "url": "/posts/2020-01-30/search-large-files-on-linux/", "categories": "Tech", "tags": "linux, du, tips", "date": "2020-01-30 00:00:00 +0800", "snippet": "在 Mac OSX 上尚且还有一些图形工具可以帮助查找和清理大文件，在 Linux 只能依靠命令行。其实也不难，这次总结一下，省的下次还去搜索。万能的 dudu 是 Linux 和 MacOSX 都自带命令行工具，全称是 Disk Usage，这样就好记了。配合两个参数就可以搞定大多数问题。-s Display an entry for each specified file. ...", "content": "在 Mac OSX 上尚且还有一些图形工具可以帮助查找和清理大文件，在 Linux 只能依靠命令行。其实也不难，这次总结一下，省的下次还去搜索。万能的 dudu 是 Linux 和 MacOSX 都自带命令行工具，全称是 Disk Usage，这样就好记了。配合两个参数就可以搞定大多数问题。-s Display an entry for each specified file. (Equivalent to -d 0)-h \"Human-readable\" output.-s的意思就是只统计第一层目录，-h 就是显示可读性的统计数据，看例子。[root@2017127313 ~]# du -sh /*0 /bin89M /boot0 /dev39M /etc4.0K /home16K /lost+found4.0K /media4.0K /mnt4.0K /opt0 /proc603M /root13M /run0 /sbin4.0K /srv513M /swapfile0 /sys616K /tmp1.3G /usr487M /var从根目录开始找最大的目录，然后一层一层递进就可以找到占用最大空间的目录或者文件。限制数量和排序当目录里文件比较多的时候，我们就要限制返回的条数和排序，比如我只想知道占用空间最大的 5 个目录，通过管道操作符就可以达到目的。[root@2017127313 ~]# du -s /usr/* | sort -nr | head -5598904 /usr/lib303676 /usr/share185836 /usr/lib64124044 /usr/bin44772 /usr/sbin当前目录占用空间du 还可以很方便检查当前目录占用空间。[root@2017127313 ~]# du -sh603M .比较难记的 findfind 是非常强大的命令，可以按文件属性进行搜索，比如检索大于 10M 的文件。[root@50KVM-2017127313 ~]# find . -size +10M./blog/.git/objects/pack/pack-fab187cef1cd08d186624f1e5e97e3131b20abc0.pack./docs/.git/objects/3f/3385a6b098631a8426a720dcd56a9ed7da4183./docs/PPT/Demo.pptx如上命令是把文件名打印出来了，但文件的细节还是不清楚，这时候你需要加上更多参数。find / -size +500M -exec du -h {} \\; 2&gt;/dev/null如果还要排序，再加个管道。find . -type f -size +100M -print0 | xargs -0 du -h | sort -nrfind 权当是备忘吧，具体的参数我是记不住的，推荐还是用简单易懂的du。额外的 dfdf也是磁盘管理常用的工具之一，全称不知道是什么，从文档上看好像是 Disk space available on file system? 需要记住的参数只有一个，就是-h，可读性显示。[root@2017127313 ~]# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 107M 0 107M 0% /devtmpfs 117M 0 117M 0% /dev/shmtmpfs 117M 13M 105M 11% /runtmpfs 117M 0 117M 0% /sys/fs/cgroup/dev/vda1 4.9G 3.0G 1.7G 65% /tmpfs 24M 0 24M 0% /run/user/0这个命令就是用来看磁盘剩余空间的，当然有时候 -ai的参数也偶尔会被提到，用来检查inode的使用情况。[root@017127313 ~]# df -aiFilesystem Inodes IUsed IFree IUse% Mounted ondevtmpfs 27317 393 26924 2% /devtmpfs 29942 1 29941 1% /dev/shmtmpfs 29942 491 29451 2% /runtmpfs 29942 16 29926 1% /sys/fs/cgroup/dev/vda1 324480 50300 274180 16% /tmpfs 29942 2 29940 1% /run/user/0如果inode占用到 100%了，你的磁盘就是还有空间也写不进去了，inode可以理解为文件的索引区吧，用来存放文件的属性等等，具体的内容会写到 block 区，当文件很碎的时候，block 可能还没满，但是 inode已经满了。免费赠送的 free文章的最后再送个 free 命令吧，这个跟文件系统有一丢丢关系，这个命令是用来显示内存的。[root@2017127313 ~]# free -h total used free shared buff/cache availableMem: 233M 58M 28M 9M 147M 142MSwap: 511M 21M 490Mfree 是用来显示内存占用情况的，-h 一样是人性化显示。注意，这个命令还是看到 swap 分区的使用情况。一般 Linux 都会配置虚拟内存，也就是用 swap 分区。很早以前内存还是很宝贵的，所以聪明的人类就划分了一部分硬盘来充当二级内存，纵然速度慢点，但是容量更大了能处理的东西就更多了。free 里可以查看 swap 占用情况，但不能清理或者调整它的大小。" }, { "title": "组织Flask项目结构", "url": "/posts/2020-01-26/the-flask-project-structure/", "categories": "Tech", "tags": "python, flask", "date": "2020-01-26 00:00:00 +0800", "snippet": "Flask 是非常轻量和灵活的 Python 框架，轻量和灵活是它的优点，也是它的缺点。所以我们在使用 Flask 构建项目时就不得不慎重考虑其目录结构，以便日后扩展和维护。这里我列举了一些常见的 Flask 项目结构，没有好坏之分，大家可以按照实际情况参考使用。极简风格app.pyconfig.pyrequirements.txtstatic/templates/此项目结构可以用于构建最简...", "content": "Flask 是非常轻量和灵活的 Python 框架，轻量和灵活是它的优点，也是它的缺点。所以我们在使用 Flask 构建项目时就不得不慎重考虑其目录结构，以便日后扩展和维护。这里我列举了一些常见的 Flask 项目结构，没有好坏之分，大家可以按照实际情况参考使用。极简风格app.pyconfig.pyrequirements.txtstatic/templates/此项目结构可以用于构建最简单的 Web 程序，一般用于 Demo 或者 POC。使用 App 组织项目相对复杂的项目可以按包（package）的方式来组织代码，不同的包对应不同的应用（app），每个应用相对独立，其中会有自治的视图（view）和模型（model）等等。config.pyrequirements.txtrun.pyinstance/ config.pyyourapp/ __init__.py views.py models.py forms.py static/ templates/其实 Flask 项目做到这个程度已经差不多了，如果项目再复杂，就不太推荐使用 Flask 了，而是考虑换成django或者其他更适合做大型项目的框架，死磕 Flask 最后只会适得其反。欲知更多，可参考: http://exploreflask.com/en/latest/organizing.html https://lepture.com/en/2018/structure-of-a-flask-project http://flask.pocoo.org/docs/1.0/patterns/packages/ https://www.digitalocean.com/community/tutorials/how-to-structure-large-flask-applications使用 Blueprints 组织项目更加复杂的项目可以引入 Blueprints 来简化工作，这是官方推荐的 Flask 大型项目解决方案。一个 Blueprints 对象和一个 Flask 对象很类似，所以有了 Blueprints 之后你可以很方便的将大型应用拆分成多个子项目来开发和加载。Blueprints 需要注册后才能被加载，有点像插件。Blueprints 解决了应用拆分的可能性，但怎么拆分和组合还是开发者的事情，下面几个例子可以参考一下。基于逻辑功能yourapp/ __init__.py static/ templates/ home/ control_panel/ admin/ views/ __init__.py home.py control_panel.py admin.py models.pytests/基于职能模块config.txtrequirements.txtrun.pyyourapp/ __init__.py home/ views.py static/ templates/ dash/ views.py static/ templates/ admin/ views.py static/ templates/ api/ views.py static/ templates/ blog/ views.py static/ templates/ models.pytests/静态模板的组织facebook/ __init__.py templates/ layout.html home/ layout.html index.html about.html signup.html login.html dashboard/ layout.html news_feed.html welcome.html find_friends.html profile/ layout.html timeline.html about.html photos.html friends.html edit.html settings/ layout.html privacy.html security.html general.html views/ __init__.py home.py dashboard.py profile.py settings.py static/ style.css logo.png models.py对于 Flask 应用中的静态模板，我觉得在现代应用中还需要三思。因为大多数的现代应用都会考虑用 nodejs 构建前端，使用模板语言已经属于异教徒，后期的维护和更新更是挖坑填坑的过程。小结一下对于要快速见效的项目，用 Flask 还是不错的选择，例如做个页面收集数据或者展示图表，再或者模拟几个 API 用于测试等等。但是大点的项目还是算了吧，真的，不骗你，要填的坑远比你想象的多的多。" }, { "title": "Bash 脚本中的 set -euxo pipefail", "url": "/posts/2020-01-07/bash-scripts-with-set-euxo-pipefail/", "categories": "Tech", "tags": "bash, shell", "date": "2020-01-07 00:00:00 +0800", "snippet": "有些开发人员会用 Bash 来实现很复杂的功能，就像使用别的高级语言一样。他可能觉得自己很牛逼但其他人早就想锤爆他了，Bash 的可读性和可维护性远远低于任何高级语言。更要命的是，Bash 并没有方便的调试工具和防错机制，出了问题你要排查半天。在 Ruby 或者 Python 等高级语言里，你很容易知道错误是哪行什么类型的错误，还有 IDE 的 Debugger 加持。而 Bash 只能看源...", "content": "有些开发人员会用 Bash 来实现很复杂的功能，就像使用别的高级语言一样。他可能觉得自己很牛逼但其他人早就想锤爆他了，Bash 的可读性和可维护性远远低于任何高级语言。更要命的是，Bash 并没有方便的调试工具和防错机制，出了问题你要排查半天。在 Ruby 或者 Python 等高级语言里，你很容易知道错误是哪行什么类型的错误，还有 IDE 的 Debugger 加持。而 Bash 只能看源码，通过打印 log 等非常低效的方式调试。本文将介绍 Bash 中 set -euxo pipefail，它们可以帮助你写出更容易维护也更安全的脚本。这也是 Bash 脚本的终极调试手段，希望你以后在自己的脚本中加上这么一行，头顶也能少秃一点。set -eset -e 选项可以让你的脚本在出现异常时马上退出，后续命令不再执行。默认情况下 Shell 脚本不会因为错误而结束执行，但大多数情况是，我们希望出现异常时就不要再往下走了。假如你的if判断条件里会出现异常，这时脚本也会直接退出，但可能这并不是你期望的情况，这时你可以在判断语句后加上 || true 来阻止退出。Before#!/bin/bash# 'foo' is a non-existing commandfooecho \"bar\"# output# ------# line 4: foo: command not found# barAfter#!/bin/bashset -e# 'foo' is a non-existing commandfooecho \"bar\"# output# ------# line 5: foo: command not found阻止立即退出的例子。#!/bin/bashset -e# 'foo' is a non-existing commandfoo || trueecho \"bar\"# output# ------# line 5: foo: command not found# barset -o pipefail默认情况下 Bash 只会检查管道（pipeline）操作最后一个命令的返回值，假如最右边的命令成功那么它就认为这个语句没问题。这个行为其实是很不安全的，所以就有了set -o pipefail。这个特别的选项表示在管道连接的命令中，只要有任何一个命令失败（返回值非 0），则整个管道操作被视为失败。只有管道中所有命令都成功执行了这个管道才算成功执行。Before#!/bin/bashset -e# 'foo' is a non-existing commandfoo | echo \"a\"echo \"bar\"# output# ------# a# line 5: foo: command not found# barAfter#!/bin/bashset -eo pipefail# 'foo' is a non-existing commandfoo | echo \"a\"echo \"bar\"# output# ------# a# line 5: foo: command not foundset -uset -u 比较容易理解，Bash 会把所有未定义的变量视为错误。默认情况下 Bash 会将未定义的变量视为空，不会报错，这也是很多坑的来源。也许由于变量名的细微差别让你查半天最后骂骂咧咧。Before#!/bin/bashset -eo pipefailecho $aecho \"bar\"# output# ------## barAfter#!/bin/bashset -euo pipefailecho $aecho \"bar\"# output# ------# line 5: a: unbound variableset -xset -x 可以让 Bash 把每个命令在执行前先打印出来，你可以认为这就是 Bash 的 Debug 开关。它的好处当然显而易见，方便你快速找到有问题的脚本位置，但是也坏处也有吧，就是 Bash 的 log 会格外的乱。另外，它在打印命令前会把变量先解析出来，所以你可以知道当前执行的语句的变量值是什么。纵然 log 可能会乱一些，总比头发乱一些好，所以建议还是打开这个开关。#!/bin/bashset -euxo pipefaila=5echo $aecho \"bar\"# output# ------# + a=5# + echo 5# 5# + echo bar# bar以上就是关于 set -euxo pipefail 的介绍，从 Shell 脚本的编写角度看，我十分建议所有人都应该在自己的 Shell 脚本里加上这么一行。但从实际情况看，如果你的 Shell 脚本已经超过 200 行，我更建议你换成高级语言来实现。比如 Python 或者 Ruby 甚至 Perl，这些高级语言在 Linux 系统都是内置的，注意版本兼容性就好，写起来比 Shell 舒服太多了。" }, { "title": "谢谢，我们很忙", "url": "/posts/2020-01-01/thanks-we-are-busy/", "categories": "Thoughts", "tags": "Comics, Geek, Tips, DevOps", "date": "2020-01-01 00:00:00 +0800", "snippet": "新的一年开始了，不要为了忙碌而忙碌。在忙碌中找问题，多用脑子，避免老年痴呆。", "content": "新的一年开始了，不要为了忙碌而忙碌。在忙碌中找问题，多用脑子，避免老年痴呆。" }, { "title": "通过 Github Actions 自动发布 Hexo 博客", "url": "/posts/2019-12-25/publish-hexo-blog-via-github-actions/", "categories": "Tech", "tags": "Hexo, GitHub-Actions, GitHub, CICD", "date": "2019-12-25 00:00:00 +0800", "snippet": "Github 今年推出了自己的 CI 集成方案 Github Actions，本着玩一玩不吃亏的态度，我把原来通过 Travis CI 的自动发布流程迁移到了 Github Actions，整个过程还是非常愉快顺利的。创建博客这部我就不展开说了，直接到 Hexo 官网参考文档就可以快速开始。我假设你已经有这么一个博客了，而且也成功手动发布过。生成密钥为了安全起见，我们为此次发布单独创建一对密...", "content": "Github 今年推出了自己的 CI 集成方案 Github Actions，本着玩一玩不吃亏的态度，我把原来通过 Travis CI 的自动发布流程迁移到了 Github Actions，整个过程还是非常愉快顺利的。创建博客这部我就不展开说了，直接到 Hexo 官网参考文档就可以快速开始。我假设你已经有这么一个博客了，而且也成功手动发布过。生成密钥为了安全起见，我们为此次发布单独创建一对密钥，在本地命令行执行如下命令。$ ssh-keygen -t rsa -b 4096 -f ~/.ssh/github-actions-deploy一路回车，生成的公钥为 github-actions-deploy.pub，私钥为 github-actions-deploy。安排密钥假设你的 Github 源文件仓库是 blog，静态页面仓库是 tobyqin.github.io。那么你需要将公钥配置到静态页面仓库的 Deploy keys，将私钥配置到源文件仓库的 Secret。 blog &gt; Secrets &gt; Add a new secret &gt; 添加密钥，命名为 ACTION_DEPLOY_KEY tobyqin.github.io &gt; Deploy keys &gt; add deploy key &gt; 添加公钥，名字随意，允许写入权限。配置博客这一步主要是确保你的博客能够发布到正确的仓库，参考如下配置。# _config.yml## Docs: https://hexo.io/docs/deployment.htmldeploy: - type: git repo: git@github.com:tobyqin/tobyqin.github.io.git branch: master配置 Github Actions好戏开场，切到你的blog仓库，选择 Actions 选项卡，新建一个 Workflow。你可以选用某个模板，比如 Node.js，或者完全自定义。针对我自己的博客，因为我在发布前还写了个 Python 的脚本做了一些额外的事情，所以我的 Workflow 大概是这样的。name: Deploy Blogon: [push]jobs: publish: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v1 - name: Use Python 3.x uses: actions/setup-python@v1 with: python-version: \"3.7\" - name: Use Node.js 10.x uses: actions/setup-node@v1 with: node-version: \"10.x\" - name: Setup env: ACTION_DEPLOY_KEY: $ TZ: Asia/Shanghai run: | # set up private key for deploy mkdir -p ~/.ssh/ echo \"$ACTION_DEPLOY_KEY\" | tr -d '\\r' &gt; ~/.ssh/id_rsa chmod 600 ~/.ssh/id_rsa ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts # set git information git config --global user.name 'Toby@Github' # 换成你自己的邮箱和名字 git config --global user.email 'toby.qin@live.com' # prepare blog pip install -r requirements.txt python blog.py prepare # install dependencies npm install -g hexo-cli npm install - name: Deploy run: | # publish my blog hexo clean hexo generate hexo deploy可以看到这个Workflow的脚本还是很好理解的，先是起了一个名字，然后选择了 ubuntu 最新版作为运行系统，接着安装了 Python 和 Node.js，然后执行了一段脚本做环境配置，这里面既有 Python 又有 Node.js，最后执行了发布命令。异常处理当然这个 Workflow 我也不是一次就执行成功的，如果你需要调试的话就可以到 Github Actions 这个选项卡去看执行日志，非常的详尽和易读。小结Github 终于自己动手做 CI 了，让各大友商瑟瑟发抖。而且我体验下来非常棒，比 Travis CI 集成度更好，而且 Action Workflow 使用 Yaml 来定义也十分清晰友好。相对 Jenkins 的 Pipeline 可能少了一些图形化的支持，但功能毫不逊色。而且一个仓库是允许定义多个 Workflow 的，每个 Workflow 可以有不同的目的和触发机制，在 Workflow 中官方也提供了类似插件一样的功能，十分灵活。" }, { "title": "2019年，再见", "url": "/posts/2019-12-24/goodbye-my-2019/", "categories": "Life", "tags": "life, thoughts", "date": "2019-12-24 00:00:00 +0800", "snippet": "又到年底了，是该收拾一下，准备迎接新的一年了。这个时候，网上又开始流行各种跨年段子，什么看 20 本书变成买 20 本书，什么世界那么大我要去看看变成去朋友圈看看。但是你有没有想过那终究是别人的生活，不管是调侃还是现实，我们总是要对自己负责。这一年，我离开了自己的舒适圈，铤而走险地换了一份工作，可谓感慨良多。代码终究不是我的大部分人都追求稳定，希望自己可以一条道走到黑。今年我从测试岗位跳出来...", "content": "又到年底了，是该收拾一下，准备迎接新的一年了。这个时候，网上又开始流行各种跨年段子，什么看 20 本书变成买 20 本书，什么世界那么大我要去看看变成去朋友圈看看。但是你有没有想过那终究是别人的生活，不管是调侃还是现实，我们总是要对自己负责。这一年，我离开了自己的舒适圈，铤而走险地换了一份工作，可谓感慨良多。代码终究不是我的大部分人都追求稳定，希望自己可以一条道走到黑。今年我从测试岗位跳出来，内心无比纠结，因为我一直以为，只要自己足够努力加上自己还不算笨的脑袋，在这个岗位上 5 年一定能成精。其实不然，外面的世界有很多偶然性和必然性，想成就一件事需要很多条件全都契合在一起。你可以坚持下去，也许奇迹会发生，我选择跳出来，看看另外一种可能。过去我非常热爱写代码，感觉我可以用代码去改变世界。现在我依然不否认这个观点，只是工作的原因，我今年写的代码较之往年，少之又少。可能写代码的时间少了，思考的时间就多了。我们不得不承认，没有谁的代码会被永远维护或者供奉起来。也许明年就来了个家伙，说这段垃圾谁写了，老子要推掉重做，然后你的代码就删个精光。技术人员很容易痴迷于“唯技术论”，觉得技术能搞定一切，特别是程序员这个物种。我曾经跟不懂技术的朋友争吵过，说你看身边什么东西不是代码和计算机造就的？且不说微信支付宝已经进入我们生活的方方面面，就连你去上厕所的自动马桶后面都是一行行代码。这种想法是很危险的，在 IT 行业混了十年甚至二十年，你眼睛不应该只有技术了。你应该知道，技术都是为业务服务的。除了业务，你应该还要知道产品，商业甚至管理，资本家为什么会让这些人聚集在一起。程序员在三十岁之后需要的不是更多的代码，而是更多的思考。说不见得比做容易今年我也成了一个 PPT 玩家，笑。PPT 玩家也是分段位的，青铜玩家会复制粘贴，白银玩家会套用模板，铂金玩家会归纳总结，钻石玩家会内容重构，星耀玩家会观点升华，王者玩家就人 P 合一。玩笑归玩笑，PPT 是不容易做的，一是归纳难，二是表达难。归纳难的问题在于输入的量是否足够，PPT 全程都是在输出观点，如果没有观点你的演讲就一文不值，纯粹是浪费观众时间。没有输入就没有输出，有时候做一个 PPT 要翻好几本书，写好几天 Demo，只是为了证明自己的某个观点是 OK 的。现在看来，做 PPT 或者演讲或者写博客都是一样的套路，需要很好的逻辑思维和总结能力。只有你把自己说服了，才敢上台去。关于表达难，这是很多程序员乃至中国人的通病。在程序员的世界里有一句名言： Talk is cheap, show me the code. — Linus Torvalds然而这句话在大多数情况下不凑效，为什么呢？因为很多人还没学会表达就想秀代码，你问题都没说清楚，我何必看你代码。能说你才有机会秀。在几个人面前说是一回事，在几十个人面前说又是另外一回事了。表达除了练习之外我觉得更多需要的是信心，而信心并不能通过反复练习获得。信心的程度主要是你由观点的认知程度和理解程度决定的。当你可以轻松去聊一个（技术）话题时，你如果不是有十足的把握，必定是有无敌的脸皮。读书不是为了打卡所有人都知道，多读书是好的，那就多读一些吧。其实不然，最近刚读完一本书，我觉得这些年的书都白读了，这本书叫《读懂一本书》。读书不能看数量，也不能看速度，而是看自己到底收获了什么。读书的过程有可能是愉悦的，比如你在翻阅一本精彩的小说；也有可能是极其难熬的，比如你在看晦涩难懂的理论解说。在读任何一本书前，我们要问自己一个问题，为什么我要翻这本书呢？为了解决某个问题还是为了身心愉悦，或者只是为了完成年度目标。读书是很苦的，如果真希望日后读书能给自己帮助，你就不得不思考这个问题。今天看一本霸道总裁，明天看一本盗墓笔记，到底是为了什么？那么怎么读书呢？我们就要回到为什么上来。读书是为了解决什么问题，如果当前没有明确的问题，是不是就不用读书了？不是这样的。在《读懂一本书》里说，书是解决问题的出口，读一本书也许只要几小时或者几天，但有可能是作者几年甚至一辈子的经验，所以读书是稳赚不赔的买卖，当然前提是你知道自己要读哪本书，这是很难的。要不然呢？那就多读书吧。选书可以有一个普遍适用的指导方法，就是 TIPS 原则。 Tools： 工具类书籍，这是解决现有问题的指导原则 Ideas：灵感类书籍，带来新的理念，发现。可以是小说，历史，漫画等等 Practicability: 实用性书籍，可以给生活或者工作带来改变，可以被应用 Scientificity: 科学类书籍，对事实的归纳和验证过程以前我都是看豆瓣书单或者经朋友推荐看的书，当然不乏佳作，但是从没想过这些书读完的目的是什么，有点像在打卡。选书完之后才是真正的读书。读书也不是从第一页一字不差看到最后一页就可以了，而是要去思考这本书给我带了什么，简单说就是做读书笔记，做阅读理解。《读懂一本书》作者的要求更高，就是在读完一本书后能给别人再讲一遍，把思维导图用手画出来。能讲出来就意味理解或者消化了书中的观点，能讲多少就收获了多少。一旦真正去做这件事，这本书大概已经印在自己脑海里了。我们常常犯的错误就是看完一本书就完了，勤快一点的也许会拍个照发个朋友圈，生怕忘了让朋友们也帮忙见证一下。还有些人喜欢拿笔在书本上画上重点或者圈喜欢的句子，但其实这跟买书是一样的性质。买了不代表你就看了，画了也不代表你就记住了。读书是苦的，如果真想让书为我所用，我们的脑子就不得不做一些不开心的事情。闲下来才有创造力今年明显比前两年忙了许多，今年的忙主要体现在非工作时间的支出上面。去年基本上还是可以保证在 8 点半出门，7 点前回家的。今年大概都是 8 点出门，8 点之后才到家，回家之后还有一半概率要开会占用半小时到一小时，能支配的非工作时间不会超过 4 小时。在这 4 个小时里想一些新奇古怪的点子？难。我还要看书写字陪老婆呢。当然，在地铁上会有两个多小时的时间可以支配。实际上我发现在地铁上我除了看小说听歌，不想干别的事情，在嘈杂的环境看技术或者处理工作上的事情是不可能的，除非万不得已。最近看到有一篇报道说，微软要实现实行一周三休了。且不说羡慕，这样的制度在 IT 这样费脑子的行业推行我还是很赞同的。当你一直在忙碌时，喘气的机会都没多少，谈什么改革谈什么创新，基本都是在救火或者随大流。闲下来才会有创造力，怎么样才能闲下来呢？一，找老板谈，你需要筹码。二，在自己身上找突破口。其实忙不是理所当然的，有时候忙只是战略上的懒惰。我们可以略微分析一下自己在工作的时间安排，看看是不是真的做到了合理分配，最大效用。很多人都应该知道时间管理四象限，多做重要非紧急的，避免做非重要非紧急的。且不说工作之外的时间，先问问自己工作之内的时间是否做到了轻重缓急合理安排。正是因为今年忙了许多，我对时间管理又重视起来了，但是执行的还是不够好。希望在明年自己真的能够闲下来，偶尔发发呆也是极好的。身体是革命的本钱很庆幸今年自己还是维持了不错的锻炼频率，虽然没长出肌肉，但是每周两到三次的有氧运动也足以让我呼吸畅快，身心愉悦。我们都还没到保温杯里泡枸杞的年龄，但是 90 后再过几天也 30 而立了，岁月不饶人。钱这辈子是挣不完的，但能开心地把挣到的花完也不错啊，别在医院里花就好。今年的体检数据还不错，过两天去四川吃火锅，看熊猫，庆祝一下。" }, { "title": "在Mac上部署Jenkins", "url": "/posts/2019-11-23/jenkin-on-mac/", "categories": "Tech", "tags": "Jenkins, CICD, DevOps", "date": "2019-11-23 00:00:00 +0800", "snippet": "Jenkins还是我最喜欢的CICD工具。安装 Jenkins官网目前推荐的方式是docker运行Jenkins，只需要一条命令就可以搞定。docker是很好用，不过也会有一些不方便的地方： 不能完全访问本地磁盘，需要挂载后才可以，而挂载某个目录还需要提前在docker客户端注册，有点绕。 不能访问本地代理，大家都知道我们的网络条件不是很好，可能会自建代理，docker中使用代理也不方便...", "content": "Jenkins还是我最喜欢的CICD工具。安装 Jenkins官网目前推荐的方式是docker运行Jenkins，只需要一条命令就可以搞定。docker是很好用，不过也会有一些不方便的地方： 不能完全访问本地磁盘，需要挂载后才可以，而挂载某个目录还需要提前在docker客户端注册，有点绕。 不能访问本地代理，大家都知道我们的网络条件不是很好，可能会自建代理，docker中使用代理也不方便。文件读写的问题有网友说可以通过rsync之类的软件解决，听上去可行，其实也不方便。所以到最后，我们可能还是选择在本地安装Jenkins。本地安装最简单的办法是使用Howbrew包管理器。$ brew install jenkins==&gt; Downloading http://mirrors.jenkins.io/war/2.205/jenkins.war==&gt; Downloading from http://ftp-chi.osuosl.org/pub/jenkins/war/2.205/jenkins.war######################################################################## 100.0%==&gt; jar xvf jenkins.war==&gt; CaveatsNote: When using launchctl the port will be 8080.To have launchd start jenkins now and restart at login: brew services start jenkinsOr, if you don't want/need a background service you can just run: jenkins最新消息，官方已经发文不再支持macOS下的原生包安装，建议该用docker或者homebrew。 https://jenkins.io/blog/2019/11/25/macos-native-installer-deprecation/（原文继续）你也可以在官网选择适合MacOSX的pkg下载后双击开始安装，输入本机密码后就可以完成安装。这也开始里你的踩坑之旅。Jenkins安装完成后会默认启动，但是有可能你发现什么都没发生。坑开始来了。 你本机需要有java的虚拟机环境，而且必须是8-11版本的，12以上的不支持（截止2019/12） 你本机的8080端口不能有别的服务你可以通过运行这个命令来进行启动测试：sh /Library/Application\\ Support/Jenkins/jenkins-runner.sh你可以cat一下这个文件，执行的时候也是有回显的，比较容易知道问题出在哪。你还可以通过下面的命令来看本机有哪些目录和文件是Jenkins创建的：find / -iname \"*jenkins*\" 2&gt;/dev/null配置 Jenkins在这个目录下面有一个简单的文档介绍了怎么配置Jenkins： /Library/Documentation/Jenkins/command-line-preferences.html当然，这些配置都是比较底层的，列出当前存在的配置项目：$ defaults read /Library/Preferences/org.jenkins-ci{ heapSize = 512m; httpPort = 8080; minHeapSize = 256m; minPermGen = 256m; permGen = 512m; tmpdir = \"/Users/Shared/Jenkins/tmp\";}修改默认端口的命令：$ sudo defaults write /Library/Preferences/org.jenkins-ci httpPort 8090可以配置的选项如下： prefix httpPort httpListenAddress httpsPort httpsListenAddress war (Defaults to /Applications/Jenkins/jenkins.war) JENKINS_HOME (Defaults to /Users/Shared/Jenkins) tmpdir (Defautls to /Users/Shared/Jenkins/tmp) minHeapSize (Defaults to 256m on 64bit architectures and 64m on 32bit) heapSize (Defaults to 512m on 64bit architectures and 128m on 32bit) minPermGen (Defaults to 256m on 64bit architectures and 64m on 32bit) permGen (Defaults to 512m on 64bit architectures and 128m on 32bit)你可以删掉某个配置从而使用默认值：$ sudo defaults remove /Library/Preferences/org.jenkins-ci JENKINS_HOMEJenkins 安装后默认会建立一个标准用户名为 jenkins，Jenkins 系统本身的配置会放在JENKINS_HOME目录里，这个目录上面已经提到，默认在 /Users/Shared/Jenkins，Jenkins 启动后的设置和安装的插件都会被放在这里，包括 job 的 workspace 等等。Jenkins 默认的日志目录在 /var/log/jenkins，系统运行的错误和异常可以在这里找找。启动和停止 Jenkins如果为了调试，可以用这个命令：sh /Library/Application\\ Support/Jenkins/jenkins-runner.sh如果是正常使用，启动和停止的命令如下：$ sudo launchctl load /Library/LaunchDaemons/org.jenkins-ci.plist$ sudo launchctl unload /Library/LaunchDaemons/org.jenkins-ci.plist为了方便日后的管理，建议将这两条命令配置成 alias 放到你的 bash 启动脚本里，比如这样。# your ~/.bash_profilealias start-jenkins=\"sudo launchctl load /Library/LaunchDaemons/org.jenkins-ci.plist\";alias stop-jenkins=\"sudo launchctl unload /Library/LaunchDaemons/org.jenkins-ci.plist\";更新 Jenkins不出意外，按照 Jenkins 网页端的引导就可以完成 Jenkins 的更新。如果网络条件很差，你也可以到官网下载war包，然后替换 /Applications/Jenkins/jenkins.war 即可，期间需要手动停止和启动服务。卸载 Jenkins通过Homebrew安装的软件卸载比较简单，这里说的主要是通过界面安装的Jenkins的卸载。Google搜出来的排在比较靠前的卸载方案是： 手动删除 war 包 手动删除 JENKINS_HOME 目录 手动删除 jenkins 用户但其实不用那么麻烦，只需要一条命令即可。sh /Library/Application\\ Support/Jenkins/Uninstall.command期间需要输入本机管理员密码，大致输出如下。Jenkins uninstallation scriptThe following commands are executed using sudo, so you need to be loggedin as an administrator. Please provide your password when prompted.+ sudo launchctl unload /Library/LaunchDaemons/org.jenkins-ci.plistPassword:+ sudo rm /Library/LaunchDaemons/org.jenkins-ci.plist+ sudo rm -rf /Applications/Jenkins '/Library/Application Support/Jenkins' /Library/Documentation/Jenkins+ sudo rm -rf /Users/Shared/Jenkins+ sudo rm -rf /var/log/jenkins+ sudo rm -f /etc/newsyslog.d/jenkins.conf+ sudo dscl . -delete /Users/jenkins+ sudo dscl . -delete /Groups/jenkins+ pkgutil --pkgs+ grep 'org\\.jenkins-ci\\.'+ xargs -n 1 sudo pkgutil --forgetForgot package 'org.jenkins-ci.support.pkg' on '/'.Forgot package 'org.jenkins-ci.documentation.pkg' on '/'.Forgot package 'org.jenkins-ci.jenkins21903.postflight.pkg' on '/'.Forgot package 'org.jenkins-ci.launchd-jenkins.pkg' on '/'.Forgot package 'org.jenkins-ci.jenkins.osx.pkg' on '/'.+ set +x小结在Mac安装任何软件首选应该还是HomeBrew，不仅可以帮你搞定依赖，后续的升级和清理也很轻松。在 Mac 上部署 Jenkins 有点像鸡肋，食之无味，弃之不舍。如果一定要在 Mac 上需要完成一些自动化的任务，同时希望配置简单友好，不知道你有没有更好的办法？" }, { "title": "假期", "url": "/posts/2019-10-12/vacation/", "categories": "Life", "tags": "Life", "date": "2019-10-12 00:00:00 +0800", "snippet": "这个十一假期去了一趟大橙子家。大橙子很早就已经在网上买好了烧烤架，他说这个假期我们回去到乡下去烧烤。下车的时候我们去超市买了很多烧烤必备的原料。啊，美好的假期就要开始了。乡下有狗有猫，还有兔子，其实不是兔子，是仓鼠。程明乐待业在家就买了一只仓鼠，还有一只猫。早上起来空气无比清新，还有一大堆桂花树，非常香。可是这花是要被打掉的，大橙子的妈妈说，桂花都是要卖给村里收桂花的，虽然不值几个钱，但是也...", "content": "这个十一假期去了一趟大橙子家。大橙子很早就已经在网上买好了烧烤架，他说这个假期我们回去到乡下去烧烤。下车的时候我们去超市买了很多烧烤必备的原料。啊，美好的假期就要开始了。乡下有狗有猫，还有兔子，其实不是兔子，是仓鼠。程明乐待业在家就买了一只仓鼠，还有一只猫。早上起来空气无比清新，还有一大堆桂花树，非常香。可是这花是要被打掉的，大橙子的妈妈说，桂花都是要卖给村里收桂花的，虽然不值几个钱，但是也是几个钱。我觉得这些花这么香，被打掉太可惜了，所以我问能不能卖两株给我？假期第二天，果然没有打桂花，但是第三天还是打了，只不过留了两株。哦对了，烧烤也是一件非常快乐的事情。其实是吃的过程很快乐，但准备的过程中并不快乐。在大乡下很难买到羊肉，羊肉还是大程子的爸爸从县里的菜市场上买回来的，一只巨大的羊腿，差不多200块钱，8斤还是10斤记不清了。我和大橙子花了整整一个下午才处理完，一大半变成了80串羊肉串，还有一小半放在冰箱里。小朋友们可喜欢吃羊肉串了，在我的童年记忆里除了玩耍，就是吃各种能吃和不能吃的。他们吃了一串又一串，除了羊肉，猪肉，还有烤火腿肠，烤小馒头，烤鱼。有趣的是，大橙子的妈妈去菜地里摘了两个非常非常小的茄子，说这可以给我们用来烤，烤茄子应该好吃。小叔还说菜地里有韭菜，可以给我们烤韭菜，结果那韭菜就跟程序员头上的头发一样稀少，怎么烤呢？还有一件印象深刻的事情，就是有一天早上天还没亮，我觉得在肩膀上隐隐有东西在爬。开灯一看，吓死我了，是一只巨大的蜈蚣，估计有20厘米，趴在我肩上，直接给我咬了两口，有四道印子。蜈蚣咬的感觉真是很奇妙，就像小时候打预防针一样，扎的很疼很疼，而且这个疼是缓不过来的，会疼一整天。这是我人生第一次被蜈蚣咬，大橙子以为我要口吐白沫快不行了。一家人一大早都被吵起来了，大橙子爸爸和大橙子一样呆，想到的第一件事就是去抓一个大蜘蛛来，让大蜘蛛把蜈蚣的毒给吸出来，无奈没找到大蜘蛛，找到一个比米粒大点的蜘蛛，刚要往我伤口放，就不知道跑哪去了，这是什么偏方我没不太清楚。还好，小叔一大早送我去了医院，一个坡脚医生给我开了一个乱七八糟的药，黑不溜丢的，然后往肩上抹，为啥不是酒精消毒呢？然后还要吃，吃就算了，结果一次要吃20片，20片啊，我的天呐。吃完20片还不算，再过6小时，还要再吃10片，我的天呐这哪是药啊，这感觉当饭吃了。不过被蜈蚣咬的感觉真不好，一天都是昏昏沉沉的，手臂感觉没有力气，会不会毒发身亡呢？被蜈蚣咬那一天大橙子把屋里所有东西都搬出来了，感觉再也不敢进去住了。她考虑是不是要在露天搭一个大帐篷？无奈，晚上太困了又没有别的地方住，还是回去住吧，大不了再咬一口。这次回乡下，没有遇到很一大群鹅，其实是遇到一大群鹅了，但这群鹅非常怂不厉害，有辱鹅的名声。它们不会上来抓人，上次回家的时候，有一群小鹅，小鹅虽小，但很勇敢，敢上前抓人，就算打不过也要上前抓，这种精神值得表扬。这次看见是一大群鹅，还带了一大群鸭子，这群鸭子也是非常怂的，我站在前面，就想拍个照片，它们都不敢过来，怎么的？我又不会抓你去烧烤。假期还是过得太快了，感觉大部分时间都是躺在吊床上点手机，打游戏。书本翻了一点点，马上又要上班了，但这样也比去看人山人海好。假期中间还看了两次国庆大阅兵，大橙子说一定要去看阅兵，祖国的骄傲呢。可是呢，她两次都睡着了，你说这是不是很搞笑的事情？" }, { "title": "十月小记", "url": "/posts/2019-10-06/october-notes/", "categories": "Thoughts", "tags": "Creative", "date": "2019-10-06 00:00:00 +0800", "snippet": "太忙了会导致自己没有创新力，现在在花旗的时间就是一天到晚在忙于工作，然后就没有太多时间去思考很多可以改进的方面。相比以前在英孚自己的闲暇时间还是比较多，所以可以去想办法去改进工作上的流程，或者去做一些比较有意思的事情。而且到了花旗之后，博客更新的频率明显降低了很多。一开始还是有想法要去写博客的，然后也会有一些主题要去写，但随着越来越忙，然后时间越来越少，所以就不太愿意去写，不太愿意去动笔，时...", "content": "太忙了会导致自己没有创新力，现在在花旗的时间就是一天到晚在忙于工作，然后就没有太多时间去思考很多可以改进的方面。相比以前在英孚自己的闲暇时间还是比较多，所以可以去想办法去改进工作上的流程，或者去做一些比较有意思的事情。而且到了花旗之后，博客更新的频率明显降低了很多。一开始还是有想法要去写博客的，然后也会有一些主题要去写，但随着越来越忙，然后时间越来越少，所以就不太愿意去写，不太愿意去动笔，时间长了觉得这些主题写了也没什么意思，然后久而久之就不愿意去动笔了。从今天开始好像是要考虑去写这些博客的，因为时间久了不写博客，会觉得好像自己缺少了点什么。时间一天天过去，但是没有发现自己累积的东西，这就是一种悲剧。从今天开始，我尝试用语音去记录一些东西，语音输入法还是比较快速，比较方便的记录方式。我可能只要说几分钟就可以把今天需要说的事情，或者这段时间要总结的东西就记录完了。人不能太纵容自己，太纵容自己就会容易变得懒惰。转眼间已经到年底了，现在已经开始进入年终总结阶段。想想这过来的6个月还是发生了很多事情，也学会了很多东西，但是好像也错过了很多东西。想想6个月前要接offer的时候还是很纠结的，真的很不确定面前这份工作能做好，然后会做成什么样子，实际上到现在看来的确这是一份非常有挑战性的工作，开发运维工程师不是开发也不是因为更不是测试，放弃自己最擅长的东西，去尝试这样一个岗位，未知的事情太多。经过了6个月的适应，我现在发现开发运维不简简单单的是工具层面的自动化，或者是开发层面的自动化，更多的时候是一种资产层面的转变，还有文化层面的转变。这其实是非常难的，形而上学的东西并不像是看得见摸得着的东西，最大的问题并不是自己能不能接受这样的文化，而是让别人去接受这样的文化，别人的思想在别人的脑袋里，别人的工具在别人的手里，你想教别人怎么用，别人不一定这么用。年底的总结并不是很好写，因为你也没办法拿出太多实际上的东西去说，大字报并不能够作为你的加分项，但大字报的确是我工作中的一部分。我需要想办法让自己闲下来一点，这样的话我才可以有更多的时间去思考，真正意义上的改进，真正意义上的能够帮助到自己和帮助到团队的方法。所谓旁观者清，当局者迷，如果你在局里，你是很难知道怎么去下棋的。" }, { "title": "PPT基础技巧", "url": "/posts/2019-09-21/basic-skills-of-ppt/", "categories": "Reprint", "tags": "PPT", "date": "2019-09-21 00:00:00 +0800", "snippet": "本文基于旁门左道 PPT 基础课程归纳而来。基础操作导出格式PPT 可以导出多种文件格式： 图片，适合单页面预览，推荐 png。 视频，适合动画预览，推荐 mp4. pdf，适合需要保留排版和平台兼容形式的分享。撤销次数在设置的高级选项里可以设置最大撤销次数为 150，默认值是 20，有点少。图片模糊选中图片后选择虚化，默认虚化程度为 10。可以通过格式窗格中的艺术效果修改虚化效果，一...", "content": "本文基于旁门左道 PPT 基础课程归纳而来。基础操作导出格式PPT 可以导出多种文件格式： 图片，适合单页面预览，推荐 png。 视频，适合动画预览，推荐 mp4. pdf，适合需要保留排版和平台兼容形式的分享。撤销次数在设置的高级选项里可以设置最大撤销次数为 150，默认值是 20，有点少。图片模糊选中图片后选择虚化，默认虚化程度为 10。可以通过格式窗格中的艺术效果修改虚化效果，一般改成 60 或者 80 会得到比较满意的结果。画面比例尽可能大的按屏幕比例设置画面比例，比如 90cm x 30cm，而不是 9cm x 3cm，这样可以提高画面清晰度。PPT 有纵横画面的长度上限。显示参考线通过视图选项卡显示参考线，可以添加和调整参考线，按住 ctrl 复制，按住 alt 可以微调。取色器调出取色器后，从设计范围内开始按住鼠标左键不放，再将鼠标移出设计范围外就可以取到系统菜单甚至网页，或者其他非 PPT 软件的颜色，选到颜色后再放开鼠标左键。画布大小可以缩小画布在最上方和最下方很远处插入一个小形状，这样可以避免 PPT 放大后自动滚动到前面或者后面一页的问题。快速去除动画在 PPT 放映的下拉菜单里可以选择播放时不显示动画，这样可以快速去除动画效果。快速提取素材将 PPT 的文件后缀改成 zip 再解压，所有素材会在 media 目录里。等分页面比如要纵向等分页面，可以先添加纵向矩形，然后 ctrl+d 复制出等分数量的矩形，分别选中后对齐，排列，组合。最后将组合的图形拉伸为页面大小即可。横向等分操作亦然。压缩文件任意一张 PPT 选择图片，在图片选项卡中可以选择压缩图片，选择所有图片进行压缩即可大大减少 PPT 的文件大小。嵌入字体在设置的保存选项中，可以选择将字体内嵌到 PPT 中，可以避免到别的电脑播放是缺少字体导致排版错乱的问题。推荐使用字客网下载各种免费字体。渐变形状添加形状后选择渐变，并且调整透明度，最后将形状的层放置到文字和图片中间就可以做到类似蒙版的效果。如果图层很复杂，可以使用开始选项卡下的选择窗体来规划图层顺序。设置密码选择另存为后，在保存按钮左边有一个工具，里面可以设置两种密码：演示密码和修改密码。母版设置通过视图选项卡下的母版视图，可以快速批量调整 PPT 的整体样式，如果希望保留部分版式与主母版不一致，勾选不显示背景即可。母版是非常高效的操作，必须熟练掌握。图表动画SmartArt 或者图标可以设置批量动画或者轮播动画，需要通过动画窗格将其他文字或者元素的动画合并到这些轮播动画中以达到同时展示的效果。镂空字体先选择大图像，后选择需要镂空的文字或者形状，使用合并形状按钮中的剪除菜单可以做出镂空效果，在合并形状中菜单中还有其他非常棒的拆分形状工具。使用蒙版蒙版就是覆盖在目标画面上的一个图层，在 PPT 中一般通过添加和目标图片大小一致的形状并设置其颜色和透明度来实现，通常情况下还需要将蒙版层调整到图片上方，文字下方。高效操作快速工具栏可以将工具栏移到主菜单下方，可以节约鼠标点击距离。然后将最最常用的工具添加到快速工具栏中可以大大提高工作效率。任意工具都可以通过右键添加到快速工具栏，在工具栏通过右键删除或者调整顺序。 大神版：主题设置，图层调整，元素对齐，元素插入，格式调整，其他常用。 基础版：基础工具，元素对齐，元素插入，格式调整。格式刷和动画刷格式化可以快速复制文字或者形状的样式，动画刷可以复制动画效果。默认文本框和图形调整好的文本框或者图形可以通过右键设置为默认文本框或者图形，后面新添加的文本框和图形都会直接应该改样式。批量修改字体可以通过开始菜单的 “选择 / 字体” 菜单批量替换指定字体，还可以通过“设计/变体”菜单来统一修改中西文，标题或者正文字体，此方法更加灵活。使用母版母版有很多操作细节，多用多练习多思考。批量修改形状选中多个形状后，使用修改形状菜单即可。提升操作设计和审美核心是多看，看优秀作品，知道什么是美什么是丑。过一段时间后重新看自己的作品或者喜欢的作品，想想自己是否还喜欢。推荐设计作品网站： Dribbble Behance Zcool HuabanPPT 终归还是属于平面设计，所以可以借鉴平面设计的学习方式和思路。幻灯片的结构通常的 PPT 结构：封面，目录，子部分，内容，循环，尾页。良好的结构不仅可以帮作者理清思路，也可以让听众更容易接收要传达的信息。动画技巧先制作镂空文字遮罩，然后将视频或者 GIF 置于文字下方，即可制作出比较生动的文字效果，让页面视觉效果更丰富。给镂空层添加一个基本缩放的动画，还可以让画面聚焦于核心内容。通过镂空图层配合路径动画，还可以做出有趣味的图表动画效果。平滑效果真的很棒，不过需要升级到最新的 Office 365 才可以使用。" }, { "title": "MacBook和Vmware Tools", "url": "/posts/2019-08-13/macbook%E5%92%8Cvmware-tools/", "categories": "Thoughts", "tags": "MacOSX, VMWare", "date": "2019-08-13 00:00:00 +0800", "snippet": "Vmware tool 就是个坑，特别是在Mac电脑上。我在MacBook上装了一个Vmware Workstation的虚拟机，然后在虚拟机里装了一个Windows系统。Windows可以正常启动，用着挺好的，但是发现不能从本机拷贝文件进去，或者把文件拷贝出来，它提示我说我没装Vmware Tools。好的，我去网上搜了一通教程，并不能解决我如何安装Vmware Toools的问题，因为在...", "content": "Vmware tool 就是个坑，特别是在Mac电脑上。我在MacBook上装了一个Vmware Workstation的虚拟机，然后在虚拟机里装了一个Windows系统。Windows可以正常启动，用着挺好的，但是发现不能从本机拷贝文件进去，或者把文件拷贝出来，它提示我说我没装Vmware Tools。好的，我去网上搜了一通教程，并不能解决我如何安装Vmware Toools的问题，因为在虚拟机菜单里“安装Vmware Tools”是灰色的，什么办法都试过了，不行，就是灰色的。好的，有人说自己去下载一个Vmware Tools的镜像安装一下就好了。我去官网找了一圈，找到了下载页面，但是并不能下载，需要注册。好的，注册好了，我下了一个Mac版的Vmware Tools，解压，安装，有一些警告说不兼容最新版系统，没关系，试试看。安装完毕，提示重启电脑。好的，电脑重启，进去桌面。没一会各种警告弹出来了，磁盘空间低？？怎么回事，我知道自己穷，256GB的硬盘我一直保留了20%的空间以防万一。好吧先删一些用不上的软件和文件吧，腾出20个G。没几分钟，磁盘空间又低？？是不是什么进程出问题了，重启看看。重启过去10分钟，没进桌面，有种不祥的预感。Mac有没有安全模式？长按开机键再次重启。又过了十分钟，勉强进去桌面，但是我看不懂上面的文字，它们全成了乱码。而且这些乱码并不能点击和操作，难道我可以换新电脑了？等了20分钟我决定再重启。再一次重启系统提示我发送错误报告，好像有希望，我认识上面的字了。等个半小时，我先去洗个澡。回来之后可以操作了啊，不过就是卡，估计是因为磁盘塞满了。这一次，我狠心卸载了几个大软件，启动Vmware Tools卸载程序，一顿操作之后再次重启。好像世界已经恢复和平，不过我的硬盘空间去哪了？查了一下，在/cores下面生成了80Gb的文件，Google说这是系统崩溃的日志文件，可以删，那就删，老子终于又有了100多GB的余粮。Vmware公司怎么可以发布这么垃圾的软件？难道都不经过测试的吗？幸亏我是盗版用户的受害者，不然一定赖着他们。后来我才知道，Vmware Tools是需要安装到客户机的。我在虚拟机下载了一个Windows的Vmware Tools，安装完毕后重启虚拟机，可以和宿主机互通文件了。妈蛋。" }, { "title": "转发短信的各种方案", "url": "/posts/2019-06-25/various-schemes-for-forwarding-short-messages/", "categories": "Thoughts", "tags": "SMS", "date": "2019-06-25 00:00:00 +0800", "snippet": "不知道你有没有使用多个手机号，或者手机不想带但又不希望错过短信的情况，有兴趣可以进来看一看。将手机 A 的短信自动转发到手机 B手机 A 和手机 B 大致分两种类型：安卓和苹果。所以交叉组合有 4 种情况。1. 安卓转发苹果方案 1（推荐）：装一个绿芽短信让它运行在后台，通过微信就可以远程接收和回复短信，这是目前最简单的方案，不需要翻墙，唯一担心小厂跑路。不过看上去不会那么容易死，毕竟它不是...", "content": "不知道你有没有使用多个手机号，或者手机不想带但又不希望错过短信的情况，有兴趣可以进来看一看。将手机 A 的短信自动转发到手机 B手机 A 和手机 B 大致分两种类型：安卓和苹果。所以交叉组合有 4 种情况。1. 安卓转发苹果方案 1（推荐）：装一个绿芽短信让它运行在后台，通过微信就可以远程接收和回复短信，这是目前最简单的方案，不需要翻墙，唯一担心小厂跑路。不过看上去不会那么容易死，毕竟它不是纯免费的，有转发额度，需要适当付费。这个方案在知乎和各大网站都被强烈推荐，不太像水军，我试用了一下感觉良好，而且这个软件已经活了三四年了。2022 年的绿芽还可以支持钉钉，飞书，企业微信，邮件推送和 Bark，更加好用了。另外手机没电了或者充满了也会免费提醒，很贴心。绿芽有部分免费额度，可以通过看广告获得更多额度，当然也可以充值，充 10 块钱大概可以收 1000 条短信。我就冲了 10 块钱，感觉可以用很久。如果你也要充值，可以使用我的推荐码，加赠 10%。折扣码：96713503方案 2：装一个 IFTTT，短信可以转发为邮件，Telegram，pushover 等等渠道，这些渠道应该是靠得住的，不过 IFTTT 和这些渠道都是要科学上网的，也就是说这个你还需要一个常年稳定可靠不变的梯子。而且这种方案只能收短信，不能回短信。现在 IFTTT 也需要收费了，很不方便。方案 3：装一个 Tasker，Tasker 是安卓阵营的一个神器，相当于 macOS 上的 Automator 或者方案 2 的 IFTTT，帮你监听手机上的任何事件然后执行你想要的任务。有了 Tasker 之后的操作和 IFTTT 差不多，不过整个过程都是在手机本地运行的，比如转发短信或者发送邮件调用推送 api，干啥都行。这个方案需要动手能力和编程思维，而且 Tasker 是否足够稳定不能确定。值得一提的是，苹果上有一个叫 Bark 的软件非常棒，安装后会根据设备给你一个 http 的链接，你只要 GET 这个链接（允许带参数）就可以往设备推送消息。有了这个软件往 iOS 设备推送消息不要太简单。2. 安卓转发安卓大致方案和安卓苹果差不多，如果不关心手机型号的话。如果家里的安卓机和携带的安卓机是一样的，可以借助手机厂商的云备份服务来自动同步短信，例如两个手机登录同一个魅族账号，同一个小米账号，同一个华为账号等等。当然，安卓手机大多是双卡双待的，理论上不太会有这种需求，除非你人在国外或者你是黄牛？3. 苹果转发安卓对不起，这条路你走不通，至少我没走通。4. 苹果转发苹果两个手机都登录同一个 iCloud 账号就可以了，在 iMessage 里可以看到转发消息的选项，通过另外一个苹果手机还可以远程回复。除了两大主流阵营，还有非主流的诺基亚塞班或者 MTK 山寨机，咸鱼买一个一两百块，设置自动转发，不过要消耗短信费用，一次一毛。下单前确保有这样的功能。对安全和隐私比较看重的可以试试。手机待机转发有一个最致命的问题，就是充电问题。如果一直插着充电器不知道电池会不会爆掉，不充电又不知道什么时候死掉，照顾这样一个设备还真有点麻烦。网上有同学说买个智能插座定时充放电，但智能插座怎么知道手机饿了？用 Tasker 可以监控啊，感觉解决一个问题的同时带来了 N 个问题，宅男的快乐你很难理解。通过设备转发短信这里说的设备就不是手机了，比如树莓派，路由器，或者专门的转发设备。1. 树莓派树莓派是宅男和极客们喜欢的东西，不过你需要额外买一个读卡器来读取 sim 卡，然后再写一段代码来处理短信事件和推送过程。树莓派常年开机或者定时开关机问题都不大，毕竟是被无数人论证过的产品，可靠性比大多数手机和电脑都强很多。不过你应该懂的，这一套方案是花不少时间和精力的。树莓派本身可以当成一个微型的 Linux 服务器跑很多程序和服务，转发短信只能算其中一种吧。2. 路由器普通的路由器当然是不可能有这样的功能的啦，能转发短信的路由器肯定都是能刷机的，比如网件，华硕或者斐 com 之类的，能刷机的路由器基本上就可以把路由器当成树莓派啦，本身也是 Linux 系统，接个 USB 跑个程序也是小 case，而且路由器 7x24 小时在线，稳定性更佳。相对于树莓派，路由器也是科技宅们喜爱的玩具，不过宅的 level 可能更高。关于怎么用树莓派和路由器来实现转发，GitHub 上有很多现成方案，这里就不展开说了，大致思路就是获取消息后调用各种的 API，最常用的如 Telegram，pushover，SMTP 等待。3. 专业设备有市场就有需求啦，淘宝一搜就知道世界原来那么大。比如上文提到的绿芽就有转发机卖，一百多块不贵。还有云手机服务，按月收费，还有真人代发代收，五花八门，可信度未知。不过我到想起来前些年还有阿里小号或者电信小号这样的 app，按月交费然后给你分配一张虚拟卡。当时还用来打车叫外卖薅羊毛，如果这种小号还可用，也不失为一种短信接收的好方法。写在最后新款苹果设备也支持双卡双待了，携号转网也越来越近了，在国内应该不太有转发短信这种需求了吧。不过在国外的朋友，还是很希望能收到国内手机号的短信的，以上方案对于远在异乡的人，其实都不太靠谱，你敢充电器插着手机然后安心出国吗？" }, { "title": "秦浪传", "url": "/posts/2019-06-02/qin-lang-chuanmd/", "categories": "Thoughts", "tags": "daily", "date": "2019-06-02 00:00:00 +0800", "snippet": "程浪，程家人，生性浪荡。不为时间左右，不问利益得失。善摸索，凡事三问what，when，why，又名程三摸。零八年初，年二十。春风来，情窦开。校操场散步，识一男，徘徊其右。树下，花前，烧烤摊旁，二年有余，无不欢快。学业成，踏足魔沪，誓出人头地。未完待续。", "content": "程浪，程家人，生性浪荡。不为时间左右，不问利益得失。善摸索，凡事三问what，when，why，又名程三摸。零八年初，年二十。春风来，情窦开。校操场散步，识一男，徘徊其右。树下，花前，烧烤摊旁，二年有余，无不欢快。学业成，踏足魔沪，誓出人头地。未完待续。" }, { "title": "社会人口头禅", "url": "/posts/2019-05-20/head-chan-of-social-population/", "categories": "Thoughts", "tags": "joke, fun", "date": "2019-05-20 00:00:00 +0800", "snippet": "大过节的、多大点事、都是亲戚、别太计较；还是孩子、那么努力、看我面子、都不容易；朋友一场、算了算了、换位思考、为了你好；人都死了、吃亏是福、将心比心、没有恶意；开玩笑的、才刚毕业、都过去了、习惯就好；他喝多了、毕竟长辈、退一步讲、都在酒里；曾经爱过、互相理解、婚都结了、还能咋地；他说话直、都打工的、想开一点、都能过去；来都来了、买都买了、岁数大了、顾客上帝；我这好的、你再试试、需求没写、环境问题。", "content": "大过节的、多大点事、都是亲戚、别太计较；还是孩子、那么努力、看我面子、都不容易；朋友一场、算了算了、换位思考、为了你好；人都死了、吃亏是福、将心比心、没有恶意；开玩笑的、才刚毕业、都过去了、习惯就好；他喝多了、毕竟长辈、退一步讲、都在酒里；曾经爱过、互相理解、婚都结了、还能咋地；他说话直、都打工的、想开一点、都能过去；来都来了、买都买了、岁数大了、顾客上帝；我这好的、你再试试、需求没写、环境问题。" }, { "title": "笑话一则", "url": "/posts/2019-05-15/a-joke/", "categories": "Thoughts", "tags": "joke, fun", "date": "2019-05-15 00:00:00 +0800", "snippet": "所谓殊途同归，讲的是以前所有当飞行员、科学家、政治家梦想的中国小朋友们。成年以后的梦想统一变为买房……", "content": "所谓殊途同归，讲的是以前所有当飞行员、科学家、政治家梦想的中国小朋友们。成年以后的梦想统一变为买房……" }, { "title": "用命令行在Linux同步坚果云", "url": "/posts/2019-05-06/jianguoyun-command-line/", "categories": "Tech", "tags": "webdav, jianguoyun, Linux", "date": "2019-05-06 00:00:00 +0800", "snippet": "坚果云更 Linux 也可以配合的很好。开启 WebDAV在坚果云网页端可以找到 WebDAV 的管理界面，开启后就可以得到一个密钥。有图形界面的操作系统坚果云都提供客户端了，现在我希望添加到坚果云的某个目录的文件能够自动 checkin 到 github，从而实现随时写博客之类的功能。cURL 读取 WebDAV 目录文件curl -X PROPFIND --user 'user@xxx....", "content": "坚果云更 Linux 也可以配合的很好。开启 WebDAV在坚果云网页端可以找到 WebDAV 的管理界面，开启后就可以得到一个密钥。有图形界面的操作系统坚果云都提供客户端了，现在我希望添加到坚果云的某个目录的文件能够自动 checkin 到 github，从而实现随时写博客之类的功能。cURL 读取 WebDAV 目录文件curl -X PROPFIND --user 'user@xxx.com:password' 'https://dav.jianguoyun.com/dav/Blog/@TODO'以上命令会返回这个目录里所有的信息，不过是 xml 的，不太好处理。Python 读取 WebDAV 目录文件只要能找到合适的包，Python 做什么都很容易，读取 WebDAV 目前我发现 fs.webdavfs 相对好用一点。pip3 install fs.webdavfs读取目录的代码：# jg_sync.pyfrom webdavfs.webdavfs import WebDAVFSurl = 'https://dav.jianguoyun.com/dav'options = { 'login': 'user@xxx.com', 'password': 'password', 'root': '/Blog/@TODO'}fs = WebDAVFS(url, **options)files = fs.listdir('.')[1:]print('\\n'.join(files))下载 WebDAV 文件推荐用 cCURL 而不是 Python，Python 下载文件会有各种异常，中文编码或者路径什么的很不灵光，折腾了我半天都没弄好，还是 cURL 简单粗暴。echo \"Update from jianguoyun...\"cd \"$(dirname \"$0\")\"files=$(python3 jg_sync.py)urlencode() { echo $(python3 -c \"import urllib.parse; print (urllib.parse.quote('''$1'''))\")}download_file() { cmd=\"curl -u 'user:pass' 'https://dav.jianguoyun.com/dav/Blog/@TODO/_remote_' -o '@TODO/_local_'\" cmd=\"${cmd/_local_/$1}\" cmd=\"${cmd/_remote_/$2}\" eval $cmd}delete_remote_file() { cmd=\"curl -X DELETE -u 'user:pass' 'https://dav.jianguoyun.com/dav/Blog/@TODO/_remote_'\" cmd=\"${cmd/_remote_/$1}\" eval $cmd}IFS=''for file in $files; do echo \"Download $file\" encoded_name=$(urlencode \"$file\") download_file \"$file\" \"$encoded_name\" delete_remote_file \"$encoded_name\"done在脚本开始部分先通过 Python 获取 WebDAV 的目录中的文件，然后用 cURL 把文件拉到本地，接着从远端目录删掉这个文件。上面步骤完成后文件就会被下载到本地的 @TODO 目录，再把这个目录里的文件稍作加工，就可以发布了。上传文件到 WebDAV从简单而言，还是用 cURL：upload_file() { cmd=\"curl --user 'user:pass' -T '_local_' 'https://dav.jianguoyun.com/dav/Blog/_remote_'\" cmd=\"${cmd/_local_/$1}\" cmd=\"${cmd/_remote_/$2}\" eval $cmd}有了这个方法，就可以实现反向从 git 同步文件到坚果云。其他一些心得其实还可以通过百度云做中转，使用 bypy 这个包，纯 Python 实现。pip insall bypybypy infobypy upload ...bypy download ...同步脚本写完后，可以用crontab在你的云主机上定时执行，比如没 10 分钟去坚果云查询一下，如果有就做后续操作。Python 操作 WebDAV 的包不是特别多，好用的更少。使用 cURL 操作 WebDAV 是也要注意文件名中编码的问题，比如中文，空格，特殊字符都需要转义。更多 cURL 的操作可以 google 或者看这篇文档。还有一个办法是把 WebDAV 挂载到 Linux 上，大概搜索了一下 davfs2 发现也挺折腾的，不去弄了。" }, { "title": "在 MacOSX 上 准备 Jekyll 环境的坑", "url": "/posts/2019-04-28/jekyllrb-error-on-macosx/", "categories": "Tech", "tags": "Jekyll, Ruby, Bundler, Blog", "date": "2019-04-28 00:00:00 +0800", "snippet": "Jekyllrb还是有必要了解一下。错误信息弄了半天把Ruby和Gem环境弄好，运行 bundle install 后报错。$ bundle install ...", "content": "Jekyllrb还是有必要了解一下。错误信息弄了半天把Ruby和Gem环境弄好，运行 bundle install 后报错。$ bundle install Traceback (most recent call last): 1: from /Users/ivolooser/gems/bin/bundle:23:in `&lt;main&gt;'/Users/ivolooser/gems/bin/bundle:23:in `load': cannot load such file -- /usr/local/lib/ruby/gems/2.6.0/gems/bundler-1.17.2/exe/bundle (LoadError)解决办法把需要的Bundle版本全都给它装上，现在错误的是没有1.17.2，那么开装：$ gem install bundler -v '1.17.3' Successfully installed bundler-1.17.3Parsing documentation for bundler-1.17.3Done installing documentation for bundler after 3 seconds1 gem installed再运行 bundle install，还是报错。Can't find gem bundler (= 1.11.2) with executable bundle (Gem::GemNotFoundException)应该是Gemfile.lock里写死了指定版本的Bundler才可以运行网站，那么再装：$ gem install bundler -v '1.11.2' Successfully installed bundler-1.11.2Parsing documentation for bundler-1.12.2Done installing documentation for bundler after 3 seconds1 gem installed再来运行 bundle install，搞定。$ bundle install...Bundle complete! 10 Gemfile dependencies, 30 gems now installed." }, { "title": "山村咏怀", "url": "/posts/2019-04-27/life-peom/", "categories": "Life", "tags": "poem", "date": "2019-04-27 00:00:00 +0800", "snippet": " 【宋代】邵雍一去二三里，烟村四五家。亭台六七座，八九十枝花。", "content": " 【宋代】邵雍一去二三里，烟村四五家。亭台六七座，八九十枝花。" }, { "title": "Docker一篇通", "url": "/posts/2019-04-20/docker-in-one-day/", "categories": "Tech", "tags": "Docker, Container, DevOps", "date": "2019-04-20 00:00:00 +0800", "snippet": "Docker 作为当今最流行的容器技术，我们还是需要紧跟时代努力学习，避免被公司优化掉。本文以轻松愉快的方式介绍了我对容器的认识，需要深入的同学建议多多查阅官方文档。为啥要 Docker千言万语不如一张图：来源： https://www.docker.com/why-docker简单总结： 更少的部署时间，更高的交付效率 balabala，反正很厉害 老板花更少的资源，做更多的事 员工...", "content": "Docker 作为当今最流行的容器技术，我们还是需要紧跟时代努力学习，避免被公司优化掉。本文以轻松愉快的方式介绍了我对容器的认识，需要深入的同学建议多多查阅官方文档。为啥要 Docker千言万语不如一张图：来源： https://www.docker.com/why-docker简单总结： 更少的部署时间，更高的交付效率 balabala，反正很厉害 老板花更少的资源，做更多的事 员工花更少的时间，做更多的事（加量不加价？）总之，Docker 可以让你和你的企业变得很牛很潮，甚于内裤外穿。啥是 Docker再来一张图：来源： https://www.docker.com/resources/what-container简单总结： Docker 是容器技术的一种实现，是当下最流行的（不代表以后还是它） 容器相对于虚拟机更轻量，但是能实现和虚拟机几乎一样的功能 虚拟机需要上 G 的磁盘空间外加和真实环境等效的 CPU，内存 容器只需要运行写入的磁盘空间（MB 级），能使用宿主机全部 CPU，内存打通俗一点的比分，独立的物理机是别墅，花园车库都是你的；虚拟机是楼盘卖的各种公寓，有独立的客厅卧室；容器是酒店里的房间，大部分资源都是公用的。那为啥我不住别墅而住酒店呢？别墅不仅贵还要养管家，高档的酒店不见得比别墅和公寓差，但成本和管理效率高多了。怎么实现容器化我们可以把容器化流程一般化，例如作为软件发布方，流程大抵如此：所谓基础镜像，你可以简单理解成操作系统。发布方需要把自己的软件和基础镜像打包后推送到仓库，就算容器化了。注意，你要打包的不光是软件本身，还有各种配置过程，比如修改文件，修改权限，打开端口等等。关于 Docker 镜像，我们可以看作千层饼，基础镜像是最下面一层，每添加一个功能（命令）就往上叠一层，看官方这个图：基础层是 Ubuntu，上面的 4 层分别代表了加了 4 次功能，比如： Add file1 Install app1 Install app2 Change permission每一次运行命令都会生成一个层（Layer），每个层都是可以复用的。比如在任意层打上标签后发布，或者在下次制作镜像时加以利用（缓存加速）： Add file1 （秒完成） Install app1 （秒完成） Install app3 （新的 Layer） Change permission （新的 Layer，上一步的 Layer 不一样）打包出来的镜像层是只读的，当镜像被运行后就会生成容器，每个容器都只是对镜像附加了一个可写层，所以资源利用率很高。了解完生产方的流程后，我们来看一下消费方的流程：作为消费方，可以用来去自如，为所欲为来描述容器化后的世界： 我想要啥就去仓库 Pull 一下 运行容器，不必担心配置繁琐，环境差异这种烦心事 这镜像功能不错 - 那就让它跑着 这镜像是个乐色 - 分分钟删了它有了容器，开发的锅更难甩掉了，因为你是容器的爹，也是容器的妈。测试运维找上门，你再也不敢说在我这明明是好的啊。容器化的限制容器化的实现源于 Linux 系统本身的一种特性，叫系统级虚拟化（OS-level virtualisation）。早在 10 多年前在 Google 已经广泛应用，对，Google 那个糟老头坏的很，用了那么久都不跟我们说容器真香。等 Docker 火了以后它才说光 Docker 不够，你们还需要 Kubernets。这张图经常出现在我们视线，为啥鲸鱼和企鹅还有老鼠在一起啊？鲸鱼代表着 Docker，企鹅代表着 Linux，老鼠代表着 Go 语言。Docker 运行的基础是 Linux，它是由 Go 语言编写的，哦原来 Docker 和它爹它妈在聚餐呢。既然容器化原理离不开 Linux 特性，那么容器化的限制也显而易见： 你的应用必须能跑在 Linux 上 你的应用应该是无状态的 - 允许随起随停举例说明，适合容器化的应用： 前端服务，微服务，无状态任务不合适容器化的应用： 数据库，数据库，数据库为啥数据库不适合容器化啊？第一，数据库是有状态的；第二，数据库不是想起就起想停就停的，数据安全大过天；第三第四第五网上写了一堆展开可以另写一篇。最佳实践容器化还有一些最佳实践： 一个容器只运行一个应用 使用镜像来交付应用，不要直接部署 分层构建容器，尽可能减少层的数量 不要把本地运行的容器转成镜像 不要将数据存储在容器中Windows 容器你可能听过Windows 容器，是有那么一回事，但是当前还不是很成熟，勇敢你的可以尝试，但你的老板大概是不会让它跑在生产环境的。据说携程已经将 Windows 容器化应用到生产了，牛 Pi（破音）！容器的优缺点优点显而易见，随便列几个： 比 VM 小，比 VM 快，比 VM 便宜 更容易发布和维护，有效避免 DEV，QA，OPS 的撕逼 社区非常活跃，国外有谷歌微软亚马逊，国内有 BAT 做先驱那么缺点呢？并不是太多，不信你到网上找找看，大多是为赋新词强说愁，简单列举： 平台限制，目前只支持 Unix/Linux 应用，只支持 64 位系统 相对于直接部署应用，性能会差一些 学习和迁移成本，取决于现有架构和资源 Docker 公司决策有点迷，很多言论说它要挂了理论讲完了，我们进入实操环节。安装 Docker现在 Docker 的安装非常傻瓜，只要从官网下载对应平台的安装包点击几下就可以安装完成。你需要知道： Windows 用户需要开启CPU 虚拟化，配置 4G 内存以上，Windows 10 / 64 位系统 早期版本的 Windows 可以考虑使用Docker Toolbox或通过 Linux 虚拟机来安装 MacOSX 用户建议下载 Docker Desktop后安装，用 Brew 会更麻烦 Linux 用户最简单最野生，用各种包管理器就可以装，例如：yum install docker # centos / redhatapt-get install docker # ubuntu坑：在 Windows 下，Docker 和 Genymotion 是有冲突的，一个要开 CPU 虚拟化，一个要关 CPU 虚拟化，二者势不两立，目前没有好的解决办法。我们装的 Docker 都是 CE（Community Edition）版，另外 Docker 还提供了企业版。 Capabilities Docker Engine - Community Docker Engine - Enterprise Docker Enterprise Container engine and built in orchestration, networking, security Yes Yes Yes Certified infrastructure, plugins and ISV containers   Yes Yes Image management     Yes Container app management     Yes Image security scanning     Yes 启动 Docker在 Windows / MacOSX 中，双击小鲸鱼就可以启动 Docker，启动成功后在通知区域就可以看到 Docker 的图标。坑：在 Windows / MacOSX 中居然真的只能通过图形来重启或者停止 Docker 服务？！在 Linux 中需要使用命令行来管理 Docker 服务，以 CentOS 7 为例。systemctl start dockersystemctl stop dockersystemctl enable docker # auto start when boot我们平时说的 Docker 一般是指 Docker Engine，前面提到的安装启动 Docker 指的都是 Docker Engine，这个 Engine 提供了一系列功能： 管理镜像比如：拉取镜像，打包镜像，推送镜像 管理容器比如：运行容器，停止容器，诊断容器如果 Docker Engine 已经启动成功，在命令行（Windows 建议 PowerShell，MacOSX，Linux 建议 Bash）中就可以通过下面两个命令检查其运行状态。docker versiondocker info反之，如果 Docker Engine 没启动，那么就会有类似的错误。$ docker infoCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?Docker 常用命令Docker 大部分操作都是通过命令行来完成的，对你还记得 Windows 和 MacOSX 的那个图像客户端，他们可以干什么？简单说他们除了用来启动和退出 Docker 外，还可以用来配置仓库源和网络代理地址，别的功能你就忘了吧。还有，在中华大地，使用 Docker 前最好还是先配置国内的源，不然镜像会拉的很慢，便秘的感觉。万事俱备，我们来一个 Docker Hello World：$ docker run hello-worldUnable to find image 'hello-world:latest' locallylatest: Pulling from library/hello-world1b930d010525: Pull completeDigest: sha256:92695bc579f31df7a63da6922075d0666e565ceccad16b59c3374d2cf4e8e50eStatus: Downloaded newer image for hello-world:latestHello from Docker!运行完这个命令，以后出去面试你就可以跟面试官说自己精通 Docker 和容器化技术了。面试官再追问，你就说 Docker 命令太多了，我一般都是通过docker --help 查阅的。当然啦，咱也不水的，Docker 命令我说起来也是一套一套的，不信你往下看。再说说这个 Hello World，你发现没有，作为消费方，其实你只要一个docker run &lt;image&gt; 命令就够了，Docker 足够聪明，如果这个&lt;image&gt; 不存在，那么它就会仓库里找，找到了就自动 pull，然后运行起来。回到工作中，如果开发同学做完了一个需求，是不是告诉你这个run命令的具体参数就可以测试和发布了呢？（基本）是的！天啊，开发同学太厉害了，他变强了，也变秃了。聪明的你可能想到了，在社会人维护的 Docker 仓库里，其实包含了很多打包好的软件镜像，你只要docker run就行，比如 jenkins，sonarqube，redis，kafka，你能想到的全都有。天啊，原来用 Docker 整一个玩耍的环境那么简单！命令速记也许你知道一些 Docker 命令，比如： docker run docker images docker ps docker rename docker rm / rmi但是我真的建议你忘记它们，换一种方式去使用和记忆 Docker 命令。当你敲完docker --help 之后，出来的信息大概是这样的：$ docker --helpUsage:\tdocker [OPTIONS] COMMANDA self-sufficient runtime for containersOptions: ...Management Commands: builder Manage builds checkpoint Manage checkpoints config Manage Docker configs container Manage containers image Manage images network Manage networks node Manage Swarm nodes plugin Manage plugins secret Manage Docker secrets service Manage services stack Manage Docker stacks swarm Manage Swarm system Manage Docker trust Manage trust on Docker images volume Manage volumesCommands: ...不重要的部分我都省略了，在当前和未来版本的 Docker 中，官方都极力推荐我们通过管理命令去执行 Docker 命令。比如说：docker image ls而不是：docker images推荐使用：docker container ls而不是：docker ps虽然docker ps / docker exec 等等命令更简洁，但是也更混乱，不便记忆。你有时候甚至不确定自己操作的是容器还是镜像或者是别的对象？让我们再仔细对比一下管理命令和简化版命令：# via management commanddocker image lsdocker image rmdocker image historydocker container psdocker container renamedocker container rm# via docker commanddocker imagesdocker rmidocker historydocker psdocker renamedocker rm所以在你理解 Docker 能做的事情后，再通过管理命令去实践你就会事半功倍。我做了一个思维导图，列出了常见的操作。在敲命令时你要时刻记住自己要做什么，不要迷路： 需要配置网络，那就docker network xxx 需要配置存储，那就docker volume xxx 需要管理镜像，那就docker image xxx 需要管理容器，那就docker container xxx是不是超级简单？portainerportainer 是一个浏览器界面的图形化 Docker 管理工具，它实现了几乎所有的 Docker Engine 操作，你只要两条命令就可以让它运行在你的机器上。$ docker volume create portainer_data$ docker run -d -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer有了它，你就可以忘掉上面的命令，前提是你先通过面试。Dockerfile要制作容器镜像，你需要一个详细的步骤，这个实施过程记录下来就是 Dockerfile。我们来看一个例子：FROM ubuntu:18.04COPY . /appRUN make /appCMD python /app/app.py其实 Dockerfile 很简单易懂，无非就是第一做什么第二做什么，自己写几遍就记住了。在 Dockerfile 中可以用的命令并不是特别多。 关键字 解释 FROM 选择基础镜像版本，例如：FROM ubuntu:18.04 LABEL 给镜像添加标签，例如：LABEL version=\"0.0.1-beta\" WORKDIR 指定工作目录（会自动创建），例如：WORKDIR /target ADD / COPY 复制文件，ADD 会自动解压，例如：COPY . /target RUN 运行命令，例如：RUN apt-get update -y ENV 设置环境变量，例如：ENV PG_VERSION 9.3.4 USER 不使用 root 来运行容器，例如：USER user1:group1 VOLUME 添加文件卷，例如：VOLUME /myvol EXPOSE 暴露指定端口，例如：EXPOSE 80/tcp CMD 容器的默认命令，例如：CMD [“echo”, “hello”] ENTRYPOINT 容器的入口命令，例如：ENTRYPOINT [“top”, “-b”] 以上只是简单介绍，需要用到具体命令时建议还是参考Dockerfile 官方文档。这些命令里最难说清楚的就是CMD和ENTRYPOINT，如果我是面试官这是必考题。三言两语说不完，我们改日再聊这个话题吧。有了 Dockerfile 之后，只要运行docker image build就可以生成镜像了。cd /your-project-dirdocker image build -t tobyqin/xmind2testlink:1.0.0 .一般你需要用-t参数来给你的镜像取个名字和定个版本，别的参数不太重要。打包完之后发布也是手到擒来：# 需要提前在docker仓库注册账号$ docker login# 输入用户名密码$ docker push tobyqin/xmind2testlink:1.0.0The push refers to repository [docker.io/tobyqin/xmind2testlink]a50ecd8a5d30: Layer already existsd306e6933e16: Layer already existsb48eea5f4f04: Layer already exists6e7c7e6d6e7f: Layer already exists2aebd096e0e2: Layer already existslatest: digest: sha256:c06bc4a35073319b8d7e7ef128a7daa8cdb4e766468ffc50f8a61afcf5ef3f46 size: 1367发布成功后你也就成了一个 Docker 社会人了。Docker ComposeDockerfile 只是打包一个程序或者一种服务，实际上我们的应用会复杂的多，比如有 web 前端，有大后端，有缓存系统，有消息队列，有数据库等等。这时候你就需要使用Docker Compose了，它是一个官方提供的用来定义和运行多个容器的工具，你只要写一个配置文件就可以对容器进行编排，看例子。# docker-compose.ymlversion: \"3\"services: db: image: postgres web: build: . ports: - \"5000:5000\" volumes: - .:/code - logvolume01:/var/log links: - redis depends_on: - db redis: image: redisvolumes: logvolume01: {}有了这个配置文件，你只需要运行docker-compose up就可以轻松管理配置文件里的一系列容器。关于 Docker Compose 的介绍不做深入，也不推荐深入，因为这样的容器编排只能满足小企业或者个人开发者的需求，单台主机。真正在企业中我们会用 Docker Swarm 或者 Kubernets。Docker Swarm 和 K8SSwarm 是 Docker 官方提供的一款集群管理工具，其主要作用是把若干台 Docker 主机抽象为一个整体，并且通过一个入口统一管理这些 Docker 主机上的各种 Docker 资源。Kubernets 也叫 k8s，中间刚好是 8 个字母。类似的我们还把 international 缩写成 i11l。Kubernets 是 Google 开源的容器编排引擎，支持大规模容器集群管理，自动化部署，自动伸缩，负载均衡，资源监控等等功能。Swarm 和 Kubernetes 其实是一类东西，但是 Google 家的东西更强大也更复杂，企业一般会二选一。关于容器编排是另外一个话题（很大的），本期内容完。" }, { "title": "测试左移和开发赋能", "url": "/posts/2019-03-27/shift-test-to-left/", "categories": "Tech", "tags": "testing, automation", "date": "2019-03-27 00:00:00 +0800", "snippet": "从事测试开发那么长一段时间，一直不知道怎么去评价和衡量这个职业的目标是什么，超高的自动化测试覆盖率？或者超稳定超包容的自动化测试框架？怎么才算得上是一个优秀的测试开发人员？上周有机会去听了阿里 2 天的公开课，好像明白了一些，拿来跟大家分享一下。内建质量在微软有一句名言：“质量是设计出来，而不是测出来的。” 当然，这是理想情况，如果产品经理都这么优秀，这个世界早就和平了。今天我们不说产品经理...", "content": "从事测试开发那么长一段时间，一直不知道怎么去评价和衡量这个职业的目标是什么，超高的自动化测试覆盖率？或者超稳定超包容的自动化测试框架？怎么才算得上是一个优秀的测试开发人员？上周有机会去听了阿里 2 天的公开课，好像明白了一些，拿来跟大家分享一下。内建质量在微软有一句名言：“质量是设计出来，而不是测出来的。” 当然，这是理想情况，如果产品经理都这么优秀，这个世界早就和平了。今天我们不说产品经理，我们从测试和开发的角度看，怎么内建质量。让测试内建质量为了内建质量，测试同学就要尽可能早地干预开发写 bug，让 bug 死在摇篮里。换句话说就是让开发不要写出可以避免的 bug： 产品，开发，测试应该同时参与需求评审会议，澄清需求，达成共识 将关键测试点作为需求的一部分，让开发同学交付需求时完成自测让开发内建质量从开发的角度看，要提高代码的质量可以有很多种方式： 提高自测意识，借助单元测试或者质量分析工具 真正理解需求和技术架构，进行 Code Review 或者结对编程 评估代码质量或者 bug 数量，跟绩效挂钩排除开发的自身能力问题，80%的 bug 都是需求理解不准确的问题，如果开发不愿背这个锅，那就甩给产品经理吧。由此可见，如果测试不想看见这些 bug，那么你就要帮产品表达需求，帮开发理解需求。测试左移上面我们说内建质量其实已经涉及到了测试左移，例如让 QA 在参与需求研讨时提出问题，列出测试点其实已经开始在进行测试了。为什么我们要测试左移呢？因为发现问题的时间越晚，修复的成本就越高。图中橙色线条代表了传统测试发现缺陷的时间，大多数 bug 都是在功能测试和集成测试时发现的，最后导致的结果就是发布前加班加点，祈祷不要有 bug 漏到生产环境。如果我们能把测试活动向左移动，那么就意味着修复成本大幅下降。但是谈何容易？想要把大部分测试点放在单元测试环境完成，非常依赖成熟的开发环境和极其资深的开发人员。在阿里是这样实践的，让测试给开发赋能。开发赋能从字面上解释就是，测试同学给开发赋于一定的能力，让他们有能力去完成测试，比如： 降低测试门槛 使用测试工具（自动化） 获取测试数据 培养测试意识举个例子，开发同学在完成需求代码后，可以点击一个按钮得到测试数据，再点击一个按钮验证测试覆盖点，喝杯咖啡后就可以看到测试报告。从上面这个例子看，开发同学其实他并不需要懂测试数据的设计，自动化测试的开发，测试报告的编排，但是他依然可以快速完成需求测试（门槛低），只要他养成习惯（培养意识）。那么你就会说，这对测试的同学要求是不是很高啊？对啊，回到开篇的问题，如何评判一个测试人员的能力？在我看来就是评判他给开发和团队赋能的能力。在阿里是这样，在微软和谷歌也是这样。一个优秀的测试人员将测试左移时，并不会将负担转移给开发。相反地，而是帮开发写出更高质量的代码，更高效率地交付需求。那么测试能左移到什么程度呢？比如让开发在 Coding 时就发现问题，或者还没 Coding 就发现问题，那应该是极好的。怎么做到呢？刚才已经说过了，测试即需求，把 bug 扼杀在摇篮里。实践方法想实践测试左移可以有很多种方法，每个组织需要根据实践情况进行裁剪和调整。 参与需求评审，帮助开发理解需求 参与架构、设计分析，提早预防问题 践行 BDD，TDD 单元测试提案，接口测试提案 提供模拟数据能力，测试工具 制定提测标准，拒绝低质量代码 回归测试自动化 静态代码分析，单元测试覆盖率测试左移的概念给整个测试角色带来了巨大的转变。软件测试不仅仅是“发现 bug”，而是致力于“尽可能早的检测和预防 bug”。参考资料 培训课件： 阿里 Devops 体系和实践.svg 参考文章：What is shift-left testing?" }, { "title": "微不足道的改进", "url": "/posts/2019-03-09/little-improvement/", "categories": "Tech", "tags": "DevOps", "date": "2019-03-09 00:00:00 +0800", "snippet": "今天我说一个很小的故事，不知道对你会不会有启发。话说有一个历史年代悠久的遗留系统，非常复杂和庞大，每次部署后需要一个漫长的服务启动过程。谁也不知道为什么这个启动过程这么慢，至少要半个多小时。一天一位萌新工程师被指派去查问题，他问老鸟工程师，为什么这个系统要写那么多log？老鸟说老系统不写log谁知道当时发生了什么，以后多学学。萌新又问，那为什么要写到nas上面？而且存了好几月甚至几年的log...", "content": "今天我说一个很小的故事，不知道对你会不会有启发。话说有一个历史年代悠久的遗留系统，非常复杂和庞大，每次部署后需要一个漫长的服务启动过程。谁也不知道为什么这个启动过程这么慢，至少要半个多小时。一天一位萌新工程师被指派去查问题，他问老鸟工程师，为什么这个系统要写那么多log？老鸟说老系统不写log谁知道当时发生了什么，以后多学学。萌新又问，那为什么要写到nas上面？而且存了好几月甚至几年的log。老鸟工程师意味深长的说，写到nas方便你不用登录到服务器就可以取到log啊，存的越多当然线索就越多啦，你查完问题就赶紧做别的task，这个系统年纪可能比你爸年纪还大，管他那么多干嘛？萌新工程师觉得问题并没有得到满意的解答，又找了更加资深的鸟二工程师，鸟二掐指一算说这应该是一个问题，但是系统太老谁都不敢动手，怕老bug附体招架不住。如果你一定要改进，试试把log写到本地磁盘做个定期清理，给nas腾空间，nas老是不够用。按照老鸟的建议，萌新工程师把log地址从nas改成了本地路径，这时候神奇的事情居然发生了，这个老态龙钟的系统似乎迎来了第二春，从原来的30多分钟启动时间变成了不到10分钟！运行时处理数据的速度也提高了很多，哇，性能似乎直接提高了200%？！这个改进让萌新工程师一下逆袭，广受老板嘉奖和传颂，年终奖++！古人说，勿以善小而不为，勿以恶小而为之，说的就是这种人。啊不，有可能古人说的是，命里有时终须有，命里无时莫强求。" }, { "title": "软件交付的原则", "url": "/posts/2019-02-26/priciple-to-deliver-software/", "categories": "", "tags": "DevOps", "date": "2019-02-26 00:00:00 +0800", "snippet": "《持续交付-发布可靠软件的系统方法》，部分读书笔记。为软件发布创建一个可重复且可靠的过程让软件发布成为一件容易的事情，这是在你开始写一个软件开始前就要想办法达到的目标。只要软件发布简单到点击一个按钮甚至不需要点击按钮就能发布，你才会有动力去持续完善这个软件。所以一般我在开始开发一个软件时就会考虑它的部署过程，会用到哪些资源，如果更新版本等等问题。将几乎所有事情都自动化有些工作是不能自动化的，...", "content": "《持续交付-发布可靠软件的系统方法》，部分读书笔记。为软件发布创建一个可重复且可靠的过程让软件发布成为一件容易的事情，这是在你开始写一个软件开始前就要想办法达到的目标。只要软件发布简单到点击一个按钮甚至不需要点击按钮就能发布，你才会有动力去持续完善这个软件。所以一般我在开始开发一个软件时就会考虑它的部署过程，会用到哪些资源，如果更新版本等等问题。将几乎所有事情都自动化有些工作是不能自动化的，比如分析业务逻辑，设计软件结构，编写测试等等。但是能自动化的就尽可能让计算机来帮助你完成，比如发布软件涉及的各个环节，运行自动化测试，生成各种报告和指标。重复的事情计算机往往比人更可靠，有时候你觉得它花的时间更多，但是它不用睡觉，你不行。把所有东西都纳入版本控制人都是健忘的，我们除了需要把代码纳入版本控制系统，应该还将跟项目有关的其他东西也纳入版本管理： 需求文档，测试用例，自动化测试脚本 机器配置，网络配置， 部署脚本 数据库创建，升级，回滚脚本等等 依赖配置，库文件，工具链，参考文档等等要具体到当前发布的是哪个版本，用了哪些对应版本号的依赖和库，当时的需求和测试时什么样子的。提前并频繁做让你感到痛苦的事情这是最通用的原则，也是最有启发性的。可以说我们说的一切都可以归结到这一点上。反复做痛苦的事情会有两种可能的结果： 你麻木不仁了，周而复始继续痛苦 你揭竿而起了，把这个痛苦干掉了提前并频繁去做，我相信你会选择第二种结果。内建质量“内建质量”是精益运动的先驱戴明提出的名言之一。从而得出两个结论： 测试不是一个阶段，也不应该在开发结束后才开始。 测试不纯粹或者主要是测试人员的领域。交付团队里的每个人都应该对产品的质量负责，所以在需求调研，分析，开发过程中其实已经对质量造成影响。只有保证每个环节的质量，才能确保整体的质量。“Done”意味着“已发布”经常听开发说需求终于做完（Done）了，但真的做完了吗？对于敏捷团队来说，“Done”意味着功能已经部署到生产环境了，已交付给用户了才算完成。一件事情没有完成80%的说法，要么完成了，要么就是没完成。从这一原则得出一个有趣的推论，一个事情完成与否，并不是一个人能控制得了的，他需要所有人参与，包括开发，测试，运维，支持等等。交付过程是每个成员的责任无论项目成功还是失败，其结果都是属于这个团队的。但现实中开发总是把困难交给测试，测试又把困难交给运维，当问题出现时，人们会花费大量时间来修复，也会用同等时间来互相指责推卸责任。为了更加快速且可靠地交付软件，我们应该鼓励所有参与整个过程的人进行更好的协作。持续改进软件的首次发布只是生命周期里的第一个阶段，随着不断演进，更多的发布和需求会接踵而来。所以你的交付过程也要随之不断演进。召开回顾会议是一个很好的实践，反思过去一段时间内什么做的好，继续保持，做的不好，记录并改进。每个改进点都应该有一个人负责跟踪，确保能被执行，下一次会议向大家汇报结果。自动化的开发，测试以及发布过程对交付软件的速度，质量和成本有着深远的影响。" }, { "title": "使用VueJS开发油猴（TamperMonkey）脚本", "url": "/posts/2019-02-25/tampermonkey-user-script-with-vuejs/", "categories": "Tech", "tags": "tampermonkey, user-script, vuejs", "date": "2019-02-25 00:00:00 +0800", "snippet": "前面我们介绍过怎么用 VueJS 开发浏览器插件，也知道了它有一个巨大限制，就是需要注册成开发者你才能发布插件到商店。而且你发布的任何插件都需要经过严格的审核才能最终和用户见面。这时候我想你该认识一下油猴了。关于油猴油猴全名叫 TamperMonkey，别名也叫 GM。如果说 TamperMonkey 各大插件商店里第二厉害的插件，没人敢说自己是第一了，去搜搜它的下载量和评价你就知道了。一般...", "content": "前面我们介绍过怎么用 VueJS 开发浏览器插件，也知道了它有一个巨大限制，就是需要注册成开发者你才能发布插件到商店。而且你发布的任何插件都需要经过严格的审核才能最终和用户见面。这时候我想你该认识一下油猴了。关于油猴油猴全名叫 TamperMonkey，别名也叫 GM。如果说 TamperMonkey 各大插件商店里第二厉害的插件，没人敢说自己是第一了，去搜搜它的下载量和评价你就知道了。一般情况下浏览器的插件我们都是去商店里安装的，但如果你装了油猴插件后，你就可以到任何地址安装插件。它最大程度加强了你的浏览器，每一个油猴脚本就是一个插件。而且油猴几乎支持了所有浏览器，包括 IE。TamperMonkey 官方的定义说这是一个用户脚本管理器。通俗的说法就是 TamperMonkey 允许你在浏览器打开的任意页面过程中执行一段自定义脚本，从而实现一些功能，比如： 在百度搜索结果打开后把广告去掉 在百度云的资源页面提供 VIP 下载地址（假设你知道解密算法） 在你提交 bug 时自动填上一系列数据油猴能做的很多，可以这么说，限制它功能的只是咱自己的想象力。油猴脚本 Hello World一个油猴脚本就是一个以user.js结尾的 JavaScript 脚本，你可以托管在任何位置。只要你装了油猴插件，当你访问这样一个 js 文件时，油猴就会提醒你是否安装这个脚本。所以开发一个油猴脚本就是写一个 js 文件，并以user.js结尾，例如github-info.user.js，然后托管在某个地方。这个 js 文件需要符合油猴脚本的一些基本约定，比如这样：// ==UserScript==// @name Github Info// @namespace https://tobyqin.github.io/// @version 0.2.1// @description A demo to use vuejs in tampermonkey script.// @author Toby Qin// @include *github.com*// @exclude *api.github*// @supportURL https://github.com/tobyqin/tampermonkey_vue// @updateURL https://github.com/tobyqin/tampermonkey_vue/raw/master/github-info/github-info.user.js// @downloadURL https://github.com/tobyqin/tampermonkey_vue/raw/master/github-info/github-info.user.js// @require https://vuejs.org/js/vue.min.js// @require https://code.jquery.com/jquery-3.4.1.min.js// @require https://github.com/tobyqin/tampermonkey_vue/raw/master/github-info/app.js// @grant GM_getValue// @grant GM_setValue// @grant GM_setClipboard// @run-at document-body// @noframes// ==/UserScript==alert(\"hello world!\");从各个字段应该比较容易理解是干什么的，简单介绍一些常用字段： updateURL：脚本检查更新的地址，每天油猴会去这个地址查询新版本。 downloadURL：脚本下载地址，如果有更新就去这里下载下脚本。 include：url 包含匹配，当 url 符合这样的规则才启用脚本，可以写多条。 exclude：url 排除匹配，当 url 符合这样的规则时不启用脚本，可以写多条。 require：加载外部资源，可以是 js，css 或者图片，油猴会缓存这些资源，并提供调用方法。 grant：申请使用油猴 API，如果没申请就不能使用。 run-at：脚本运行阶段，比如页面加载前，加载后或者闲置时等等。更多详细的解释还是去看官方的开发文档： https://tampermonkey.net/documentation.php?ext=dhdg上面这个示范其实已经是一个完整的例子了，当你访问 github.com 的任意页面时浏览器都会弹出一个“hello world”的警告。加入 jQuery 和 VuejQuery 虽然即将成为被大家争相抛弃的东西，但不得不说在油猴脚本里它还是有一席之地的。因为 jQuery 提供了便捷的选择器和链式操作，让我们足够方便去操控页面。要使用 jQuery，你要注意不能因为你选择的 jQuery 版本破坏了站点的功能，50%甚至更多的站点还在使用 jQuery，但是有版本的差异。还好 jQuery 提供了 noConflict 的加载方式。// ==UserScript==// ...// @require https://code.jquery.com/jquery-3.4.1.min.js// ...// ==/UserScript==window.jq = $.noConflict(true);// ...那么 Vue 呢？就没那么幸运了，如果你的目标站点已经在使用 Vue 了，你可以不导入 Vue，直接调用就好了。Vue 不提供 noConflict 的导入方式，所以一旦你导入和站点不一致的 Vue 版本后，什么事情都有可能发生。 https://github.com/vuejs/vue/issues/2349所以在油猴插件中使用 Vue 需要做足够的调研。你可以参考我的这个例子同时使用 jQuery 和 Vue 来开发油猴插件。 https://github.com/tobyqin/tampermonkey_vue本地部署首先说本地环境的准备，方法有很多，就是想方设法让你的用户脚本被托管在某个地方。插件集成环境油猴插件本身提供了一个简单的开发环境，你可以在这里写你的脚本，这时你不需要考虑托管的问题。但大多时候我们需要功能更强大的 IDE，比如 VsCode 或者 WebStorm。npm serve你可以用 npm 安装一个 serve，然后把脚本目录通过 http 协议暴露出来。npm install servecd /path/to/projectserve -l 5000# now install user script at http://localhost:5000/my.user.jspython http.server如果你本机安装了 Python，也可以直接托管一个文件目录。cd /path/to/projectpython -m http.server 5000# now install user script at http://localhost:5000/my.user.jsWebStorm / everything如果你用的是 WebStorm，在用户脚本目录下新建一个 html，它会自动提供访问这个文件的 http 地址，你通过拼装也可以生成用户脚本的地址。如果你是 Windows 也装了 everything，在设置中启用 http 后也获得用户脚本的地址。总之方法很多，开动你聪明的大脑。调试用户脚本调试脚本前，你需要到 TamperMonkey 设置中打开高级选项，选择开启调试。然后重启浏览器，先打开开发者控制台（F12），然后访问目标网站，这时候油猴会自动帮你在用户脚本运行前加上断点并暂停。正式发布其实油猴脚本没有所谓的正式发布，你可以发布到几个常见的脚本站点（论坛）： https://openuserjs.org/ https://greasyfork.org/zh-CN http://userscripts-mirror.org/这几个站点在油猴插件都有入口，当然你也可以把你的脚本开源到 github 的仓库或者 gist，然后告诉别人链接。再假如这是一个内部使用的脚本，你就部署到内网服务器等等。友情提醒因为油猴脚本的灵活性和无限可能，不安全的油猴脚本是很危险的。比如它可以在你登录的账号页面上搜集信息，发送到后台，甚至直接下单，修改地址等等。所以在下有几个建议。 对于不信任的用户脚本，不安装。 对于不开源的用户脚本，不安装。 对于吹爆自己的用户脚本，不安装。另外针对油猴脚本，谷歌也出手了，在将来版本的 Chrome 中会更加限制插件对运行时网页的干预，比如禁止修改请求，篡改网页等等。不过那是将来，现在学习一下，没坏处。" }, { "title": "用VueJS写一个Chrome浏览器插件", "url": "/posts/2019-02-24/build-chrome-extension-with-vuejs/", "categories": "Tech", "tags": "vuejs, chrome, extension", "date": "2019-02-24 00:00:00 +0800", "snippet": "浏览器基本已经天下大统了，放眼望去都是 Chromium 的天下。那么，能写一个浏览器插件也算是一种回报率不错的技能。基本知识浏览器插件官方的说法叫扩展程序，允许你为浏览器增加各种功能，但不需要深入研究浏览器本身的代码。你可以用 HTML，CSS 和 JavaScript 创建新的扩展程序，如果你曾经写过网页，那么写一个插件是非常轻松的事情。常见的插件一般就是地址栏后面的一个图标，点击后给你...", "content": "浏览器基本已经天下大统了，放眼望去都是 Chromium 的天下。那么，能写一个浏览器插件也算是一种回报率不错的技能。基本知识浏览器插件官方的说法叫扩展程序，允许你为浏览器增加各种功能，但不需要深入研究浏览器本身的代码。你可以用 HTML，CSS 和 JavaScript 创建新的扩展程序，如果你曾经写过网页，那么写一个插件是非常轻松的事情。常见的插件一般就是地址栏后面的一个图标，点击后给你当前网页提供各种功能，或者在你点击网页右键时弹出额外的菜单。扩展程序目录结构最简单的扩展程序只需要 3 个文件，或者更少。my-addon |- manifest.json |- icon.png └─ popup.html manifest.json：清单文件，用来描述插件本身，必须。 icon.png：图标文件，如果你不想用默认图标这也是必须的。 popup.html：算是插件的功能页吧，你至少得有点功能才有存在的意义吧。当然上面的例子是最精简的情况了，一般的插件会有多个 html，还有 js 目录，css 目录等等，你可以把插件当成一个静态网站，唯一的区别是多了一个 manifest 文件用来描述这个静态网站。清单文件的示例下面是一个精简版的 manifest.json。{ \"manifest_version\": 2, \"name\": \"One-click Kittens\", \"description\": \"This extension demonstrates a browser action with kittens.\", \"version\": \"1.0\", \"permissions\": [\"https://secure.flickr.com/\"], \"browser_action\": { \"default_icon\": \"icon.png\", \"default_popup\": \"popup.html\" }}看上去是不是很直观，名字，版本，描述，权限，行为。如果要深入再查查官方文档就 OK 了。做一个 Hello World 插件有了基础知识，我们速度来个 Hello World，先写 manifest.json。{ \"manifest_version\": 2, \"name\": \"Hello\", \"version\": \"1.0.0\", \"description\": \"Hello, Chrome extension.\", \"icons\": { \"16\": \"img/icon.png\", \"48\": \"img/icon.png\", \"128\": \"img/icon.png\" }, \"browser_action\": { \"default_icon\": \"img/icon.png\", \"default_title\": \"Hello World\", \"default_popup\": \"popup.html\" }, \"permissions\": [\"&lt;all_urls&gt;\"], \"homepage_url\": \"https://github.com/tobyqin/\"}再补一下图标文件和 popup.html。&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;body&gt; &lt;h1&gt;Hello world!&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt;打开浏览器插件页面，右上角打开开发者模式，加载插件目录。这时我们的第一个插件就好了，点击插件图标就可以显示 Hello World。把 Vue 加进来好像很容易嘛，我们直接用 CDN 的 Vue，改造一下 popup.html。&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;body&gt; &lt;div id=\"app\"&gt;&lt;/div&gt; &lt;script src=\"https://cdn.bootcss.com/vue/2.6.6/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; var app = new Vue({ el: \"#app\", data: { message: \"Hello Vue!\", }, }); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;不用卸载刚才安装的插件目录，只要再点击一下插件按钮就会自动加载最新的代码。不过好像不对，和期望的结果不一样。而且注意看插件页面，出现错误了。Refused to load the script 'https://cdn.bootcss.com/vue/2.6.6/vue.js' because it violates the following Content Security Policy directive: \"script-src 'self' blob: filesystem: chrome-extension-resource:\". Note that 'script-src-elem' was not explicitly set, so 'script-src' is used as a fallback.Refused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self' blob: filesystem: chrome-extension-resource:\". Either the 'unsafe-inline' keyword, a hash ('sha256-fMtOu4CF/4bYGHZuo6ltgNQyLcxFW9rBnAYSk3yz53w='), or a nonce ('nonce-...') is required to enable inline execution.默认情况下，浏览器插件权限是非常低的，不允许访问除了插件本身的文件以外的文件，不能调用页面内脚本（inline script），也不能使用 eval 之类的函数。你需要在 manifest 文件中配置好 Content Security Policy（CSP）才能使用 Vue。{ \"manifest_version\": 2, // ... \"browser_action\": { // ... }, \"content_security_policy\": \"style-src 'self' 'unsafe-inline';script-src 'self' 'unsafe-eval' https://cdn.bootcss.com; object-src 'self' ;\"}因为这个 CSP 写起来实在不怎么友好，伟大的网友做了一个工具可以帮你一把。 https://github.com/foundeo/content-security-policy.com/接下来，把页面内的 script 内容搬到单独的文件。// popup.html&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;body&gt; &lt;div id=\"app\"&gt;&lt;/div&gt; &lt;script src=\"https://cdn.bootcss.com/vue/2.6.6/vue.js\"&gt;&lt;/script&gt; &lt;script src=\"app.js\"&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt;// app.js new Vue({ el: '#app', data: { message: 'Hello Vue!' } })刷新一下插件，搞定了。如何调试插件调试插件和调试一个普通的网页一样简单，右键选择审查元素就好了。包括插件的配置页面，新弹出的页面等等，都可以用一样的方法调试。如何发布插件当你完成插件开发后，在启用开发者模式的插件中心就可以看到打包插件按钮，这个按钮可以帮你快速打包 crx 文件，第一次打包你不需要提供密钥，它会帮你生成一个密钥，之后的版本升级你需要用同一个密钥打包，否则就被认为是一个新的插件了，所以切记保存好密钥。拿着打包好的 crx 文件你就可以到商店发布啦，不过发布到谷歌商店是要交钱的，一年 9.9 美刀的开发者会员。国内的各种商店收不收费不知道。比较恶心的是，如果你的插件没有在谷歌浏览器的商店里上架，Chrome 浏览器是不认的，以前还可以拖到插件页面安装，现在怎么都绕不过去了。但基于 Chromium 开发的第三方浏览器还是可以装的，比如 Opera，QQ，360 等等。一些技巧他山之石可能你要做的插件别人已经做过了，或者你想借鉴别人的插件，有两个方法。 右键审查别人的插件页面，看看代码怎么工作的。 安装一个下载 crx 的插件，然后把别人的插件从商店下载到本地，重命名为 zip 并解压，就可以看到源码了。当然啦，别人的源码可能做过混淆加密。插件页面大小如果你的插件会弹出一个页面，浏览器默认会根据内容自适应页面大小，就像上面例子里的那个 hello world，很丑是吧。一般插件页面都是限制 body 高度和宽度的，这样才不会歪。安全请求现在很难找到不是 https 的页面里，所以你的插件里如果会往后台发送请求的话，也是需要支持 https 协议的，否则会被拦截的。插件配置如果你的插件是可配置的，怎么保存配置信息呢？直接用localStorage就行了。localStorage对每个站点都是独立的，每一个插件可以看成独立的站点，所以当你在插件里调用localStorage对象时就是当前插件的localStorage。如果你希望配置是可同步的，那么请考虑chrome.storage对象，里面提供了storage.local 和 storage.sync 。完整的例子不想推荐文档什么的，自己需要会去搜索的。那么有没有一个完整的例子？当然有啦，去看我的 github 吧，觉得不错就点个赞。 https://github.com/tobyqin/chrome_vue_ext_demo" }, { "title": "反向代理和内网穿透", "url": "/posts/2019-02-22/reverse-proxy-and-intranet-through/", "categories": "Tech", "tags": "reverse-proxy, frp, ngrok", "date": "2019-02-22 00:00:00 +0800", "snippet": "学习一下正向代理和反向代理。概念反向代理看上去看深奥，其实不然，只是因为汉语言文化的差异导致它看上去深奥。一般反派感觉都比较厉害和神秘。要理解反向代理，我们就不得不说一下正向代理。正向代理 （Forward Proxy）所谓正向代理，就是大家通常说的代理。打个通俗的比方，你想跟你舅舅借钱，但不好开口（或者你舅妈会设法阻拦），就跟你妈说。这时母亲大人就是个正向代理。此时代理本质就是个桥的作用，...", "content": "学习一下正向代理和反向代理。概念反向代理看上去看深奥，其实不然，只是因为汉语言文化的差异导致它看上去深奥。一般反派感觉都比较厉害和神秘。要理解反向代理，我们就不得不说一下正向代理。正向代理 （Forward Proxy）所谓正向代理，就是大家通常说的代理。打个通俗的比方，你想跟你舅舅借钱，但不好开口（或者你舅妈会设法阻拦），就跟你妈说。这时母亲大人就是个正向代理。此时代理本质就是个桥的作用，这个桥让你能和桥对面的人交换信息。正向代理是多对一的概念，例如你姐，你妹你可以通过你妈去跟舅舅借钱，但舅舅只有一个舅舅。舅舅有可能并不知道到底是谁真正在借钱，只知道钱给了你妈。反向代理 （Reserve Proxy）大家都有打客服电话的经历，比如 10086，一般上来就是个语音系统，转接人工服务后嘟嘟嘟好几声才有人接听，说我是工号 xxx，很高兴为你服务。这个客服总机号码 10086 就是个反向代理，反向代理隐藏了真实的服务端，有可能有 N 个客服对应 N 个号码，但你只需要记一个 10086，它会平衡客服之间的压力给你安排合适的人。反向代理是一对多的概念，刚好和正向代理反过来了。 正向代理代理的对象是客户端 反向代理代理的对象是服务端反向代理最常见的作用就是负载均衡。比如你访问 baidu 的域名后，baidu 会根据你的 ip 地址和网络情况给你分配最快的服务器，这个分配服务器的服务器就是反向代理。反向代理还有一个场景就是内网穿透，因为服务对象是在内网里，你需要通过代理才能访问到。内网穿透从外网是没办法直接访问到内网的资源的，因为内网是一个局域网不在一个网段，而且还有防火墙在。这时候你弄个反向代理就可以解决这个问题： 内网服务器访问代理服务器 握手，建立通道 外网用户访问代理，代理通过通道和内网通信举一个具体例子，TeamViewer 的服务端（外网）就是个反向代理，它需要和 TeamViewer 客户端（内网）一直保持通信，建立一个通道（TeamViewer ID）。当远程连接这台机器时，你需要登录到 TeamViewer 服务器，然后通过代理通道（TeamViewer ID）和远程机器连接。一些反向代理服务远程连接内网机器的桌面服务是最常见的需求，有时候我们希望做的是自己的机器上跑一些服务能够从外网访问，比如 demo，博客，甚至私有云等等。TeamViewer 和向日葵大家可能都知道，我说一些不一样的。frp开源界最流行的反向代理之一，frp 全称 FaskReverseProxy，它的目标是做最快速可靠的反向代理，用 GO 语言实现，在 Github 上正在快速迭代中。安装和配置都非常简单，只需要几个命令就可以完成。frp 支持的客户端非常丰富，树莓派，路由器，安卓手机等等，可玩性很高。frp 服务可以让你本地的 web 项目提供给外网访问，特别适合向别人展示你本机的 web demo 以及调试一些远程的 API (比如微信公众号，企业号的开发)。FRP 还可以轻松代理 TCP，HTTPS，SSH 等等协议，你需要有一台具有公网 IP 的机器，最好加一个域名。ngrok曾经是开源界反向代理软件的老大，到 2.0 以后选择闭源，最后开源的版本 2016 年后就没有再更新，止于 1.7。基于 C 语言实现，配置略复杂，不过据说灵活性和稳定性超好。ngrok 也可以代理常见的各种协议，自己搭建只能用早期的开源版本。或者选择商业公司提供的收费服务，国内外可以搜到很多提供 NGROK 服务的网站，可不可靠不太敢说，但真的很多。这里列举一些知乎推荐过的，你也可以通过 ngrok 这个关键字搜索到很多。 natapp.cn 小米球 Sunny-Ngrok echositedog-tunnel翻译过来就是狗洞吧，国人做的，基于 GO 语言开发，在 GitHub 上活跃度还不错，有 1k+的星星，有兴趣可以试一下。serveo.net无需注册，无需配置，只需要 ssh 就行，没有客户端，支持多端口映射，支持自定义子域名，只要一行代码。ssh -R 80:localhost:3000 http://serveo.net我试了一下，临时用一下真的很棒！写在最后内网服务本来就是比较敏感的，所以从数据安全的角度看我觉得还是自己搭建代理服务更可靠。用不靠谱的服务有很大风险，还有可能很坑，非常坑。比如 nat123 和花生壳，一步一步诱导你付费，协议，端口，流量，速度，域名每个细节都要收费，还不一次说清楚，你付完钱才知道后面还要付钱的，别问我怎么知道的。更多讨论，你也可以去看知乎：https://www.zhihu.com/question/49629610/" }, { "title": "从手机截图报Bug扯到工具论", "url": "/posts/2019-02-13/sync-screenshots-from-mobile-devices-to-pc/", "categories": "Tech", "tags": "tips, mobile", "date": "2019-02-13 00:00:00 +0800", "snippet": "我发现手机端的测试怎么截图报 bug 是个不可忽视的小问题，传统的做法真的很烦。在这里我提供一些思路给大家。自动同步截图文件夹这是一个看上去很不错的思路，现成有个工具可以达到这个目的：坚果云。在手机端安装一个坚果云，配置好要同步的截图目录，每次截图后它会帮你自动同步。在电脑端安装客户端后直接就能看到新同步的文件，也可以直接在网页端刷新就能预览。这个方案的问题： 多台手机将登录同一个账号（实...", "content": "我发现手机端的测试怎么截图报 bug 是个不可忽视的小问题，传统的做法真的很烦。在这里我提供一些思路给大家。自动同步截图文件夹这是一个看上去很不错的思路，现成有个工具可以达到这个目的：坚果云。在手机端安装一个坚果云，配置好要同步的截图目录，每次截图后它会帮你自动同步。在电脑端安装客户端后直接就能看到新同步的文件，也可以直接在网页端刷新就能预览。这个方案的问题： 多台手机将登录同一个账号（实际情况必然如此，便于测试多台设备） 多台手机同步的截图目录会混在一起（N 到 1）， 图片很混乱 老设备很久以前的截图也会同步进来，数据量更大更混乱，你还不想删 同步的 App 在后台很有可能也很容易被杀掉所以这个方案适合新手机或者只用一台手机测试的情况，不是特别推荐。手动分享新图片这是目前大家私人手机上很常用的方式，在测试机就不太合适了。比如你不会在测试机登录自己的微信 QQ，就算有公共的账号，在电脑上也只能登录一个实例，你用了其他人就用不了了。N 台设备需要 N 个账号，明显不合适。所以这个方案的关键是，找到一个合适的可以多设备登录，分享后能在网页端预览内容的 App，并且还不能是公开分享，我的建议还是坚果云。在手机端登录坚果云后，截图后直接分享到坚果云的某个目录，电脑上网页端刷新一下就可以看到截图，整个流程很顺畅。很多手机还可以在分享前编辑一下图片，这时候你还能用涂鸦工具标注 bug 区域等等。再退一步，也可以考虑用邮箱来代替这样的 App，截图，分享到邮件，填收件人，不算太爽还凑合，还有延迟可能比较高。这个方案我用下来没有太大问题，支持安卓和苹果设备。唯一的问题是弄一个公共账号，不难。集成截图工具到被测应用这是不少大厂的做法，比如支付宝应用截图后就会提示你是否要反馈问题，还有一些 App 在你摇一摇后就自动截屏反馈问题。如果你们的开发团队有精力并且愿意为质量部门添砖加瓦，那么这个世界将会非常美好。这需要各部门的通力合作和强力支持，最主要还是老板和业务部门的点头，给资源和时间。这样的集成可以做的很深入，不仅截图，还有日志，当前运行数据等等一并捕获提交到 bug 管理工具，省心啊。DIY 一个同步工具这是最后考虑的方案，简单来说就是自己写一个 App，比如安装后在状态栏加一个同步按钮，或者贴在屏幕边缘等等。当你需要时点击一下进行同步，同时也提供个分享接口。做这样的一个 App 不算太难，不过还是需要时间和精力的投入，如果你有兴趣我们可以聊一聊。基本功能大概是这样的： 监控指定文件夹（截图目录），自动上传到远程设备目录 提供分享接口 收集设备状态 提供 Web 管理端，方便访问截图，查看设备信息 不需要连接数据线或许已经有类似的工具了，我没找到。但如果外部工具都不顺手的时候，自己做一个可能更符合需求。关于坚果云坚果云是目前唯一值得推荐的云盘，不限速只限流量，每月上传 1G 下载 3G，没广告不推销，作为效率软件完全足够。每个项目组可以自己申请一个公用账号。国内外的网盘因为各种原因都已经不值得推荐了，各种笔记类 App 也已经加上很很多限制，比如多端登录和流量限制等等。坚果云作为一个要盈利的公司将来怎么样也不好说，而且是公网软件，敏感数据还是不要全往里面放。有朋友说可以考虑搭建私有云，我稍微对比总结了一下： seafile - 国内团队开发的开源企业级云存储方案，提供全平台客户端，口碑较好。 owncloud - 开源的个人云解决方案，貌似吐槽比较多，占资源，不太推荐。 nextcloud - 据说是从 owncloud 团队分出来的，核心差不多，颜值比较高，口碑也一般。如果将来公有云都挂了，那么我们就整一个。我的工具论有一些同学认为不能用太顺手的工具，因为会形成依赖，一旦离开就会浑身难受。我认为这种担心是多余的，工具用得好，下班回家早。只有你工作效率提高了，才能更深入去了解业务和提高自己，如果总是忙于繁琐的事物，日复一日终将被工具替代。古人云了，工欲善其事必先利其器。古人还云了，磨刀不误砍柴工。好的工具是不会消失的，但有可能收费。当你觉得值的话，就买下它吧，免费的有可能更贵。" }, { "title": "LeetCode第二题 - 两数相加", "url": "/posts/2019-02-12/leetcode-add-two-numbers/", "categories": "Tech", "tags": "leetcode, algorithm", "date": "2019-02-12 00:00:00 +0800", "snippet": "LeetCode 备忘。题目给定两个非空的链表，分别代表两个正整数。链表中存储的数字和实际的位数刚好相反，要求将这两个数字相加并以链表的结构返回。举例说明：Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)Output: 7 -&gt; 0 -&gt; 8Explanation: 342 + 465 = 807.假设给定的数字没有0开头（链表末位...", "content": "LeetCode 备忘。题目给定两个非空的链表，分别代表两个正整数。链表中存储的数字和实际的位数刚好相反，要求将这两个数字相加并以链表的结构返回。举例说明：Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)Output: 7 -&gt; 0 -&gt; 8Explanation: 342 + 465 = 807.假设给定的数字没有0开头（链表末位数肯定不是0），并且任意相加数也不为0。解法一这道题目基本上就是模拟学生时代的加法，主要考虑遍历和进位的问题。比较直接的做法就是： 先遍历链表1，同时加上链表2对应数位的数字存入结果，暂时不考虑进位的问题。 如果链表1遍历结束后，链表2还没结束就直接剩下的直接加入结果。 遍历结果集，大于10的进位取余，直至结束。且看代码：# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = Noneclass Solution(object): def addTwoNumbers(self, l1, l2): \"\"\" :type l1: ListNode :type l2: ListNode :rtype: ListNode \"\"\" # 相加结果集 r = [] # 遍历链表1 while l1: if l2: # 加上链表2相同位数的数字，忽略进位 r.append(l1.val + l2.val) l2 = l2.next else: # 如果链表2已经结束，直接补位链表1 r.append(l1.val) # 处理下一位数 l1 = l1.next # 如果链表2没结束，直接补位 while l2: r.append(l2.val) l2 = l2.next head = ListNode(0) # 结果链表 current = head carry =0 # 进位数 length = len(r) #遍历结果集 for i in range(length): current.val = r[i] + carry # 大于10需要进位 carry = current.val // 10 # 取余为当前位数 current.val = current.val % 10 # 只处理到倒数第2位，重置current if i &lt; length - 1: current.next = ListNode(0) current = current.next # 如果末位数还有进位，补一下 if carry: current.next = ListNode(carry) return head提交看看，68ms，打败92%的玩家，还不错。解法二加法我们当然可以自己算啦，也可以让CPU给我们算啊。所以解法二是一种赖皮的做法，就是把两个链表变成真正的整数，然后相加，然后再转成链表，你猜猜速度是更快还是更慢？class Solution: def addTwoNumbers(self, l1, l2): \"\"\" :type l1: ListNode :type l2: ListNode :rtype: ListNode \"\"\" data_1 = \"\" # 字符串 data_2 = \"\" # 字符串 # 链表1转字符串 while (l1 != None): data_1 += str(l1.val) l1 = l1.next # 链表2转字符串 while (l2 != None): data_2 += str(l2.val) l2 = l2.next # 字符串翻转后转整数 data_1 = int(data_1[::-1]) data_2 = int(data_2[::-1]) # 相加后再转成字符串然后翻转 ans = str(data_1 + data_2)[::-1]\t\t # 字符串拆开存放到数组 ret = [] for i in range(len(ans)): ret.append(ListNode(int(ans[i]))) # 遍历数组生成链表 for i in range(len(ret) - 1): ret[i].next = ret[i+1] return ret[0]提交看看，80ms，打败了52%的玩家！看来这个来回倒腾的过程挺费CPU的，但是不费脑子啊。" }, { "title": "关于吃的几个段子", "url": "/posts/2019-02-11/joke-about-eating/", "categories": "Life", "tags": "joke", "date": "2019-02-11 00:00:00 +0800", "snippet": "一不论台湾，还是西藏新疆，一寸一厘的国土都不能让，谁知道上面能长出什么好吃的来。二我这辈子，唯一拿得起放不下的，就是筷子了。三作为入侵物种，小龙虾在中国颜面扫地，居然沦落到要靠人工养殖才能活下去……如果有外来物种入侵中国成功了，一定是因为它不好吃。四在我国，东西分三类，直接吃的，看着好像可以吃的，得想点办法才能吃的。五“说，你除了吃还会什么？”“还会饿。”六亚当和夏娃吃了蛇给他们的禁果，遭到...", "content": "一不论台湾，还是西藏新疆，一寸一厘的国土都不能让，谁知道上面能长出什么好吃的来。二我这辈子，唯一拿得起放不下的，就是筷子了。三作为入侵物种，小龙虾在中国颜面扫地，居然沦落到要靠人工养殖才能活下去……如果有外来物种入侵中国成功了，一定是因为它不好吃。四在我国，东西分三类，直接吃的，看着好像可以吃的，得想点办法才能吃的。五“说，你除了吃还会什么？”“还会饿。”六亚当和夏娃吃了蛇给他们的禁果，遭到了上帝的惩罚！被逐出伊甸园，所以有了人类。如果亚当和夏娃是中国人，那被吃的，应该是那条蛇。七你们吃是为了活着，我们活着是为了吃。八晚上睡不着觉就开始数羊：一只羊、两只羊、三只羊、喜羊羊，美羊羊，懒羊羊，沸羊羊，小肥羊，海底捞，麻酱，小料，金针菇，虾滑，宽粉，海带，豆芽，大海螺，茼蒿，菠菜……TMD，下楼！不睡了！！！" }, { "title": "LeetCode第一题 - 两数之和", "url": "/posts/2019-02-10/leetcode-two-sum/", "categories": "Tech", "tags": "leetcode, algorithm", "date": "2019-02-10 00:00:00 +0800", "snippet": "LeetCode 备忘。题目给定一个整数数组，找出和为指定值的两个元素的下标。举例说明：Given nums = [2, 7, 11, 15], target = 9,Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1].假设数组中有且只有一种组合可以得到正确答案，并且相同元素不可以重复使用。解法一很容易想到暴力破解，只要做两层循环就可以搜索...", "content": "LeetCode 备忘。题目给定一个整数数组，找出和为指定值的两个元素的下标。举例说明：Given nums = [2, 7, 11, 15], target = 9,Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1].假设数组中有且只有一种组合可以得到正确答案，并且相同元素不可以重复使用。解法一很容易想到暴力破解，只要做两层循环就可以搜索出答案。实现起来和冒泡排序类似。class Solution(object): def twoSum(self, nums, target): length = len(nums) for i in range(length): for j in range(i+1,length): if nums[i] + nums[j] == target: return [i,j] 这个解法效率很低，运行2900ms，只打败了全球20%的玩家。解法二我们可以优化一下，用哈希表（字典）来保存数字的索引和值，这样搜索的复杂度就变成了O(1)，而遍历的复杂度是N。class Solution(object): def twoSum(self, nums, target): length = len(nums) # 建立index和value的反向索引 d = {x:i for i,x in enumerate(nums)} for i in range(length): part = target - nums[i] # 取差值 if part in d and not d[part]==i: # 在字典中搜索差值 return [i,d[part]]提交看疗效，20ms，打败全球100%玩家。解法三其实还可以优化一下，这个哈希表可以延迟建立，这样可以省掉建表时的那次遍历。但效果嘛，不一定是优化，且看代码。class Solution(object): def twoSum(self, nums, target): length = len(nums) d = {} # 空字典 for i in range(length): part = target - nums[i] if part in d: # 检索字典，有则直接返回 return [i,d[part]] else: # 没找到，加入字典 d[nums[i]]=i提交，也是20ms，依然打败100%全球玩家。不过要注意一点，这种算法返回的下标都是反的，比如上面两种算法返回的是[0,1]，但是这里返回的就是[1,0]了。" }, { "title": "2019年1月书单", "url": "/posts/2019-02-09/book-list-for-2019-jan/", "categories": "Reading", "tags": "book", "date": "2019-02-09 00:00:00 +0800", "snippet": "一月书单备忘。##《凤凰项目，一个IT运维的传奇故事》作者：Gene Kim，Kevin Behr，George Spafford，软件工程以小说的形式讲述了主人公如何将一个公司曾经痛苦的业务，开发，测试，运维混乱互相撕逼的状况，实现浴火重生的故事。纯理论的絮叨很多人没办法看下去，故事化以后我只花了3天时间就看完了，而且大概也明白了三步工作法的套路： 第一工作法是从开发到技术运营，再到客户...", "content": "一月书单备忘。##《凤凰项目，一个IT运维的传奇故事》作者：Gene Kim，Kevin Behr，George Spafford，软件工程以小说的形式讲述了主人公如何将一个公司曾经痛苦的业务，开发，测试，运维混乱互相撕逼的状况，实现浴火重生的故事。纯理论的絮叨很多人没办法看下去，故事化以后我只花了3天时间就看完了，而且大概也明白了三步工作法的套路： 第一工作法是从开发到技术运营，再到客户的整个自左向右的工作流。主要依赖自动化。 第二工作法是建立各阶段自右向左的快速持续反馈流，以确保防治问题再次发生或者更快发现问题。主要为了保证上游质量，依赖价值指标。 第三工作法是创造公司文化，不断尝试，这需要承担风险并从成功和失败中吸取经验教训。主要为了持续改进。这本书评价还挺高，不管是外行还是内行都可以宏观了解到到开发运维的必要性。开发运维并不仅仅是简单的自动化工具的集成，虽然自动化是开发运维的很大一部分内容。更重要的是价值流导向，自始至终拥有共同的目标并共同解决问题。《北京折叠》《弦歌》《繁华中央》作者：郝景芳，科幻这是第二次读《北京折叠》，作者通过科幻的主题去映射社会和阶级问题，二刷依然能让人反思很久。这也是中国第二个雨果奖获得者的获奖作品，不管你喜不喜欢，现实纵然是挺无奈的，在折叠的北京里三个阶层的人不公平地分着一样的城市和时间，跟现在社会一样，科幻版的朱门酒肉臭，路有冻死骨。标题里的三部小说都是长篇《孤独深处》里的选篇，整部我并没有看完，可能以后也不想看完，毕竟它就是个小说集，喜欢的我就看，不喜欢的就不看。《弦歌》和《繁华中央》其实是下上篇，嗯，先下后上。脑洞挺大，文明也可以成为最厉害的武器。如果地球上只允许文明存在，任何的武力抵抗都被消灭殆尽，想象一下。豆瓣上很多人认为这两篇才应该是雨果奖作品。《地球往事 - 三体I》作者：刘慈欣，科幻第二次读《三体》，感觉没有第一次那么强烈了。还记得第一次读的时候，恨不得马上把整部一下读完，几个星期上班都想着剧情会怎么发展，宇宙社会学，宇宙哲学这些跟自己没关系的事情。再读就淡定很多，难道是我年纪上去了？随着时间的推进，我觉得《三体I》会越来越难被接受，按现在的看法里面的背景设定的确有点out。这也是为什么很多人没办法体会三体迷们对作者的崇拜，因为三体最值得阅读的是后面两部，读完后面两部才算读过。 给岁月以文明，而不是给文明以岁月。无论如何，这也不影响我对刘慈欣的敬佩，雨果奖实至名归。《流浪地球》作者：刘慈欣，科幻大年初二看完电影后去补了一下原著，中篇，不是很长，2个多小时就能看完。相对于电影情节来说，原著里表达的东西更丰富，涉及到了社会，生存这些问题。人总归是很难一直保持理智的，尤其是在危难的时候。大多数科幻都是以灾难和悲剧收场的，因为作者或者说我们自己对人的本质都是质疑的，如果人都是无私的，那么还哪来的战争杀戮。正义的出现是因为反派的存在，如果没有邪恶，就无所谓正义。最后地球是不是真的要流浪我不知道，但是人类的未来一定是孤独的，当他足够强大的时候。《乌合之众》作者：古斯塔夫・勒庞，哲学，心理学这是我读的第一本哲学著作？不太确定了。这本书主要对比了个体和群体的各方各面，1984年的观点在现在看来依然针针见血。所以这本书在社会心理学领域也是最有影响力的一本。其实哲学的书挺枯燥的，里面说的你看都是对的（或者说没错）。我读的过程就是，哦，知道了，是这样的，的确是这样的，可是我能怎样，心灵也不会震动。我来引用一些大家感受一下。 形成集体的个人会感觉到一种势不可挡的力量，使他敢于发泄出自本能的欲望。 群体在智力上总是低于孤立的个人，但是从感情及其激发的行动这个角度看，群体可以比个人表现得更好或更差，这全看环境如何。 孤立的个人很清楚，在孤身一人时，他不能焚烧宫殿或洗劫商店，即使受到这样做的诱惑，他也很容易抵制这种诱惑。但是在成为群体的一员时，他就会意识到人数赋予他的力量，这足以让他生出杀人劫掠的念头，并且会立刻屈从于这种诱惑 群体表现出来的感情不管是好是坏，其突出的特点就是极为简单而夸张。 群体因为夸大自己的感情，因此它只会被极端感情所打动。希望感动群体的演说家，必须出言不逊，信誓旦旦。 群体可以杀人放火，无恶不作，但是也能表现出极崇高的献身、牺牲和不计名利的举动，即孤立的个人根本做不到的极崇高的行为。不知道以后我还会不会读哲学，也许是我阅历还不够。但是你看，多少小说的终极问题都是哲学问题，我们看的津津有味。" }, { "title": "一些 PyCharm 的使用和设置建议", "url": "/posts/2019-02-08/pycharm-tips/", "categories": "Tech", "tags": "python, pycharm, tips", "date": "2019-02-08 00:00:00 +0800", "snippet": "PyCharm 是笔者强烈推荐的 Python IDE，个人认为体验比 VSCode 好的不只是一点半点。如果是首次安装 PyCharm，有一些设置项建议还是按照自己习惯修改掉，所谓磨刀不误砍柴工。注意不同版本的PyCharm 可能对本文所提及的设置项重新调整，大家可以根据提示摸索寻找。显示工具栏默认 PyCharm 并不显示工具栏（Toolbar），在大多数 IDE 工具栏都放了最常用的操...", "content": "PyCharm 是笔者强烈推荐的 Python IDE，个人认为体验比 VSCode 好的不只是一点半点。如果是首次安装 PyCharm，有一些设置项建议还是按照自己习惯修改掉，所谓磨刀不误砍柴工。注意不同版本的PyCharm 可能对本文所提及的设置项重新调整，大家可以根据提示摸索寻找。显示工具栏默认 PyCharm 并不显示工具栏（Toolbar），在大多数 IDE 工具栏都放了最常用的操作，你可以通过主菜单-外观-工具栏来显示工具栏。工具栏显示出来后你还可以通过右键定制上面的按钮，我会把一些跟 VCS 相关的操作放到上面，比如 Fetch，Push，默认它只加了 Pull 和 Commit。智能提示匹配大小写可能是出于动态语言和性能的考虑，PyCharm 的代码提示默认是大小写敏感的。例如你敲b会提示你back但不会提示你BACK，坦白讲挺不方便的，你可以改掉它。在设置里搜索match case就可以进行调整。鼠标滚轮调整字体大小有时候我们讨论或者分享代码时，已经设置好的字体大小可能不太合适，很多 IDE 或者软件都是支持使用鼠标滚轮实时调整字体大小的，PyCharm 中你需要手动启用这个功能。在设置中搜索change font size就可以找到对应设置项。修改单元测试框架如果你也有写单元测试的习惯，想必一定知道 pytest，PyCharm 可以很好地和很多知名的测试框架，但是默认它配置的是 unittest，在设置中搜索test就可以调整成你常用的框架。比如调整成 pytest 之后，只要你的方法名前缀是test_，那么 IDE 就会提示你这是一个 test，在前面会多出一个小三角形，让你很方便地运行或者调试。PyCharm 支持的测试框架很多，但我喜欢的还是 pytest。顺带一提的是，PyCharm 可以自定义的类似配置还有很多，比如 terminal 使用的 shell，虚拟环境选用的工具，Flask 模板语言等等。提交代码前的选项假设你已经默认显示工具栏，那么以后你提交代码只需要点击工具栏里的 Commit 按钮即可，这时候会弹出一个对话框，你在这里可以很方便地看到你要提交的文件，可以随意 diff，add, remove 甚至直接 edit。很多时候我们在 diff 时发现有些旮旯里总漏点东西，一般的流程时关掉 diff，回到编辑器，找到那个地方改掉，在 PyCharm 这个提交对话框，你可以一气呵成，爽歪歪。更厉害的是，你还可以选择提交前格式化代码，优化 import 区等等。命令行区域的快捷键我们经常要切换不同的 IDE，继承的命令行工具很方便，不过快捷键一般都不太一样，我会全都改成 Ctrl + `。这是我认为最好盲按的快捷键组合。设置路径：Preference - KeyMap - Search \"Terminal\"另外在 PyCharm Terminal 中如果按了 Escape 键就会跳到编辑器区域，这个默认设定很烦，会导致我们用 ECS 退出 VI 时特别偷偷，所以这个快捷键也要去掉。设置路径：Preference - KeyMap - Search \"Switch Focus to Editor\"其他可以调整的设置 外观和主题，包括编辑器字体，背景等等。 快捷键，如果你记不住它默认的快捷键，那么就改成你能记住的。 隐藏某些项目文件，治愈强迫症患者。（设置中搜索“ignore files”） 安装自己顺手的插件。（设置中搜索“plugins”）一些使用心得总结内置的 VCS 很好用内置的 Version Control 提供了日常操作需要的所有功能，而且触手可及，关键是非常直观，用过之后欲罢不能。它还提供了 changlist 和 shelvset 功能，让你在合并或者提交代码前暂存不想处理的修改，这是很多开发者都想要的功能。内置的命令行工具很好用IDE 内置命令行工具其实是一个硬需求，你看现在，几乎你找不到一个不带命令行的 IDE。PyCharm 带的 IDE 最方便的地方在于，可以自动识别项目里的虚拟环境并启用它，这是外部命令行工具没法比拟的。内置的 Python Console 很好用写 Python 肯定是离不开即时解释器的，在 PyCharm 里你随手就可以用 Python Console 测试代码片段，它不仅提供了智能提示，还可以查看运行中的变量，甚至还能绘图画表，集成 iPython Notebook。修改运行时状态很爽当你用 PyCharm 调试代码时，可以直接在 Variables 窗口看到运行变量，也可以直接修改这些变量的值，更厉害的是，你可以直接执行语句，点那个计算器一样的图标就行。这个功能 Visual Studio 里也有，叫 ImmediateWindow，可以节约你大把的调试时间。然而 PyCharm 少了一个 Visual Studio 里我非常喜欢的功能，拖拽当前断点。假设当前断点停在第 40 行，VS 里可以直接拖到前面几行，例如第 30 行，人为控制这块代码反复运行。总是为新项目建立虚拟环境千万不要只用默认的 Python 环境写多个项目，2 个也不行，以后你会后悔的。如果你能真的确定这台机器的 Python 只跑一个项目，那你可以不用虚拟环境。在 PyCharm 建立一个新的虚拟环境只需要点几下，不麻烦的。导入导出配置最靠谱前面我们说了很多配置选择，如果你有 N 台机器都安装了 PyCharm，每台都重新配置一遍多累啊，特别是快捷键如果不用默认的，换机器都想哭。PyCharm 提供了一个同步配置的方案，你可以新建一个空的 git repo，填到 Tools / Settings / Repository 里就可以自动上传配置。别的机器也同样配置一样，理论上配置就云同步了。但是我亲身体验告诉你，这个真不靠谱，Mac 和 Windows 多倒腾几次就错乱了，想哭啊。还好我有方案 B。方案 B 很简单，在某一台机器配置好后，选择主菜单 - 文件 - 导出配置。导出的配置是一个 jar 文件，随便扔到印象笔记或者坚果云里，新机器里用主菜单 - 文件 - 导入配置即可。专业版和社区版的区别刚好两个版本我都在用，大概说说专业版多出来可能会用到的东西。 和 Flask，Django 深度集成，智能提示到你惊讶的级别。 支持调试多线程，提供性能优化工具。 快速获得和显示单元测试覆盖率。 集成数据库工具，可以在 IDE 里直接连接任何数据库。 支持 Live Edit，让你在编辑代码同时，实时在浏览器中展示。 支持一键部署 docker。专业版还是很厉害的，不过也很贵。多出来的功能挺方便，但也不是必须的，大家可以酌情选择。最后，祝大家 happy coding。" }, { "title": "关于 DevOps ，咱们聊的可能不是一回事", "url": "/posts/2019-01-29/about-devops-we-may-not-be-talking-about-the-same-thing/", "categories": "Reprint", "tags": "DevOps, Interview, Networking", "date": "2019-01-29 00:00:00 +0800", "snippet": " 原文： https://www.jianshu.com/p/645bb1283a77在过去的三年中，我作为 DevOps 的咨询师参与了很多企业的 DevOps 转型咨询以及技术实施，也在不同的社区活动中分享了自己在 DevOps 上的实践、理解和观点。随着 DevOps 的盛行，我在很多场合和越来越多的人聊起 DevOps。也在不同的渠道听到了很多人在讲 DevOps。然而，讨论的背后...", "content": " 原文： https://www.jianshu.com/p/645bb1283a77在过去的三年中，我作为 DevOps 的咨询师参与了很多企业的 DevOps 转型咨询以及技术实施，也在不同的社区活动中分享了自己在 DevOps 上的实践、理解和观点。随着 DevOps 的盛行，我在很多场合和越来越多的人聊起 DevOps。也在不同的渠道听到了很多人在讲 DevOps。然而，讨论的背后，我发现每个人对 DevOps 所指并不是同一件事情，也由于各执一词导致不欢而散。于是我通过 DevOpsDays 的官方网站整理所有 DevOps 的有关材料，随着学习和了解的不断增多，我也渐渐的对 DevOps 有了更进一步的认识。我把学到的材料经过整理后把陆续放在了简书上，形成了” DevOps 前世今生” 这个系列，这个系列还在不断补充新的材料。含义越来越丰富的 DevOpsDevOps 至今都缺乏一个清晰和统一的认识。对于一场运动来说，这是一件好事，也同样是一件坏事。虽然 Patrick 曾经在自己的博客里一再提到自己对 DevOps 的”正确认识’‘，但社区似乎不以为然。缺乏“官方定义”好处是人人都可以定义，因此没有一个人或者组织可以垄断 DevOps 定义权。所以每个人都自己可以参与到这一运动中去，不断为其增加新的概念、新的实践和新的工具。这会使 DevOps 社区不断的繁荣。而坏处也很明显，对于 DevOps 的后来者 —— 那些没有参与进来的人，需要学习和理解的 DevOps 知识的广度和深度也越来越大。以至于后来出现了这幅众所周知的“盲人摸象图”：这幅图中包含了很多概念，但主要表现的意义 DevOps 是一系列概念的总和，任何一个单方面的定义只是 DevOps 的一个部分，而不是 DevOps 的整体，随着 DevOps 这个概念的不断膨胀，人们就更难理解 DevOps 了。那么，你理解的 DevOps 是指的什么？在接触了各类客户和社区之后，我开始尝试理解每个人谈到 DevOps 的时候，他们分别指的是什么，以及所指内容背后的目标和动机。渐渐的，我把我所听到的 DevOps 概念分成如下四类，分别是： DevOps 是一组技术/实践 DevOps 是一个角色 DevOps 是一种工作方式 DevOps 是一种组织结构那么，我们分别来谈谈这四类 DevOps。当 DevOps 是一组技术/实践在工程师文化的组织里，对先进技术的渴望是最常见的学习动机。可以促进工程师用更有效率，更优雅的方式解决问题。而对于非工程师文化的组织，新的技术往往是提升其 KPI 的工具。以下是我听到 DevOps 的时候，经常触及的话题： 高频部署 持续交付 云计算/虚拟化技术 基础设施即代码 Docker 自动化运维高频部署曾经和某跨国著名银行的外汇交易产品的 IT 产品负责人交流 DevOps。对方很自豪的告诉我，他们产品每天的部署频率超过 500 次，我听了不以为然。因为，部署频率高不见得是件好事。于是我问了以下几个问题： 为什么你们需要这么频繁的部署？有这么频繁变动的业务需求吗？ 在这么多次部署里，是发布业务价值的部署更多，还是修复问题的部署更多？ 这些生产环境的变更难道完全是不可规划的吗？由于对方的金融业务有相应的法律法规，理论上没有这么频繁的变更需求，除非清理技术债，否则没有很强烈的变更动机。但对方并没有直接回答我的问题，而是换到了其它问题上，因此我最终也不清楚对方这么频繁变更的驱动力。这对我有一个重要的：指标导向的 DevOps 往往是一种 DevOps 的反模式，它会忽略和掩盖真正的问题。指标的背后是某种度量，如果部署频率一直很高，一定反应了某种现象。而这些现象不一定是个好现象：不是业务的变动很频繁，就是技术的变动很频繁。但如果二者都频繁，我们应该衡量变更带来的价值和风险（当然，DevOps 可以降低变更的风险），并优先变更价值较高的请求。有可能新的业务尝试让我们从市场上获得了更多的关注，也有可能新的技术提升了生产率。但无论是哪一种，部署频率应该是一个有多到少不断循环的过程。这表明系统在走向成熟和稳定的同时，能够及时响应变化，无论是对技术还是对业务，对变更产生的影响都需要一段时间去积累和总结数据。此外，DevOps 绝不是为了提升部署频率而牺牲了软件质量和业务价值，甚至是安全措施。换句话说，DevOps 不是一种对质量的平衡和妥协，它是一种全局改进。全局的改进就意味着以价值为最高原则所度量的相关指标是不能有所下降的。持续交付持续交付是 DevOps 中非常重要的实践，持续交付的思想远早于 DevOps 。但直到第二届欧洲的 DevOpsDays 才有了持续交付这个重量级话题。因为持续交付本身也通过技术手段和实践解决了 DevOps 最初所面临的 Dev 和 Ops 的合作问题。不夸张的说，如果 Patrick Debois 早一点读到持续交付中运维相关的话题，说不定就没有 DevOps 了。然而，随着 DevOps 的理念的发展比持续交付融汇了更多的概念（这就是没有一个人能垄断定义的好处），使得 DevOps 更加广泛和盛行。因此， DevOps 所涵盖的范围已经超出了持续交付本身。我把 持续交付 列为 DevOps 的核心实践之一，因为如果你没有实践 持续交付。那么根本不能称之为 DevOps，但是如果你完整实践了持续交付，那么你离完整的 DevOps 也不远了。云计算/虚拟化技术随着分布式应用的井喷式发展。基础设施的管理成为了分布式应用的新瓶颈。在集中式管理的时代，大型应用只能运行在昂贵的小型机上，只有微软，SAP， IBM ，Oracle 和 EMC 这样的企业才有能力提供相应的产品完成这样复杂度很高的架构。因此企业需要单独的运维部门（Ops）来管理这些软件和设备。而随着虚拟技术和云计算的兴起，企业的基础设施管理工作往往变得很简单。VMWare 这样的虚拟技术企业和 AWS 这样的云计算供应商提供了更加成熟和稳定的产品。大大的节约了企业机房管理的开支。而 Ops 也不再需要进出机房，只需要通过远程桌面的方式就可以使用各种 SDK 开发工具去完成过去很多只有在机房才能做到的操作。然而，即使云计算和虚拟化技术提升了 Ops 的生产率，减轻了 Ops 的痛苦。但仍没有解决 Dev 和 Ops 之间的矛盾 —— 开发团队和维护团队仍然各自为政，仍然通过制度谈判而不是合作共赢来工作，毕竟目标是相对立的。基础设施即代码随着设备和网络的持续增多，加之更加复杂的应用部署和初始化。基础设施的管理成为了一个十分尖锐的问题。当复杂度上升一个量级，就需要专业的管理工具来管理这类问题。于是 Puppet 这样的框架顺势而出。以至于在 《DevOps Handbook》中，合著者之一的 John Willis 在理解了 PuppetLab 的创始人 Luke Kanies 的想法之后，才有了 DevOps 的最初理解。基础设施即代码利用了编程语言和虚拟化工具 API 的无缝连接达到这一目的。它在很大程度上把基础设施的管理当做其问题域，采用正确的面向对象方式，让开发人员和运维人员能够理解并设计出更加稳定和灵活的基础设施。大大降低基础设施变更的风险：提升了运维知识的透明度并使基础设施变更具备幂等性。此外，它在一定程度上解决了不同环境（开发，测试，生产）之间的不一致问题，也让开发人员能够学习到 Ops 领域的知识并用软件开发的优秀思想解决运维领域的问题。因此，基础设施即代码除了工具以外，更是一种 Dev 和 Ops 之间相互沟通的媒介，能够让开发人员和运维人员相互理解。所以，基础设施即代码毫无疑问的是 DevOps 的核心实践之一。DockerDocker 是含着 DevOps 的金钥匙出生的，它诞生的第一天就带着 DevOps 的基因：更简单的解决了基础设施即代码和虚拟化在实践中的问题，进一步提升了自动化能力以提升效率，并且对开发人员和运维人员都十分友好。甚至很多地方都会以是否采用 docker 来评判是否采用了 DevOps 的相关技术。Docker 一定程度上简化了基础设施的初始化和状态管理问题。通过镜像和运行时容器封装了应用运行时的复杂度。并通过容器的编排实现轻量级的分布式架构，也更加经济快捷。但是，Docker 和任何一种工具一样，都不是”黄金锤“。当用错了场景，使用 docker 可能是一场灾难。我曾经参与并帮客户完成了一个数据中心迁移的项目，就是采用的 docker 作为统一的运行时容器。最初是因为 docker 镜像的移植性好，在各种异构 Linux 系统上可以正确执行，且镜像构建过程透明。但是客户为了能让这个业务场景更加通用，又分别采用了另外两种工具对其部署场景进行封装，并写出了第三个工具。由于这个工具并没有很好的分离其业务关注点和技术关注点，导致这个工具使用异常繁琐，需要增加更多额外的配置去定制化容器运行环境。原本为了提升生产效率的手段反而成为了阻碍效率的绊脚石。自动化运维看了以上那么多的工具和技术，很多对 DevOps 望文生义 � 或有些技术了解的运维工程师认为提高了自动化运维的水平，就是 DevOps。虽然 DevOps 里的一个重要特征是“自动化”，但拥有自动化运维，并不代表你就正在实践 DevOps，很可能你仅仅提升了运维部门的效率，但并没有从全局的角度提升开发和运维之间的效率和端到端价值的流动。因此，仅仅有自动化运维，还不足以称之为 DevOps。关于 “ DevOps 技术”以上列举了很多所谓 “DevOps 技术”，是从技术的角度来认识 DevOps。然而，不探索 DevOps 真正的问题，以及技术背后的目的和最佳实践。往往会使导致对 DevOps 的片面了解而适得其反。从 DevOps 运动发展的历史上来看，DevOps 相关技术是解决 DevOps 相关问题的结果，而非起因。因此，对于 DevOps 的理解如果本末倒置，则很有可能起到东施效颦的结果。你会发现你拿着一堆 DevOps 的锤子，看见了可能并不存在的钉子。此外，我相信掌握工具对于工程师群体来说不是一件难事，并且随着技术的发展，工具和平台的使用会越来越容易。但是，能够跳出自己的舒适区和思维习惯，从全局的角度观察并解决问题的能力则是很多工程师所欠缺的。当 DevOps 是一个岗位角色当 DevOps 传播开来，大家都会倾向于去找叫做 “DevOps” 的人，希望通过招聘和培训来提升自己的 DevOps 能力。 于是设置了一些称之为 “DevOps 工程师” 的岗位和角色。通过对这些招聘需求以及客户对 DevOps 的需求，我发现了四个不同但是相关的 “ DevOps 工程师 “ ： 作为 Dev 的 Ops（会开发技能的运维工程师） 作为 Ops 的 Dev（会运维技能的开发工程师） 基础设施开发工程师 全栈工程师作为 Dev 的 Ops有很多人也会认为，只要让开发工程师掌握运维技能，运维工程师掌握开发技能，就做到了 DevOps。这招来了很多运维工程师的反感。我采访过一些运维工程师，当初他们就是不喜欢也不想写代码，才选择了运维方向。这种想法的其中一个动机是在于架构的逐渐稳定带来的运维工作减少，特别是使用了云计算技术和虚拟化技术的企业。这会让管理层有一种错觉，认为运维团队的空闲状态，一定程度上是浪费。因此，为了达到“人尽其用”，让运维工程师进入开发团队去写业务代码。并用“DevOps”作为对这种措施这一合理化的幌子。这种想法的天真在于忽视了开发和运维的专业性和差异性。这让我想起一个段子： 老板：“我怎么觉得在公司的运营中你们部门没起多大作用？” 运维经理：“你走过大桥吗？” 老板：“走过。“ 运维经理：“桥上有栏杆吗？” 老板：“有。” 运维经理：“您过桥的时候扶栏杆吗？” 老板：“不扶。” 运维经理：“那么，栏杆对您来说就没用了？” 老板：“那当然有用了，没用栏杆护着，掉下去怎么办？” 运维经理：“可是您没有扶栏杆啊！？” 老板：“…… 可是 …… 可是没有栏杆，我会害怕！“ 运维经理：“那么，运维就是桥上的栏杆。“虽然我不否认技术的发展对二者来说难度和门槛在不断降低。而且掌握一定开发技能的运维工程师前景更加光明。但是强人所难并不会让事情变好。此外，这类人才可遇不可求，也不要因为招不到这样的人而阻止了 DevOps 实践。作为 Ops 的 Dev同样的误解也会发生在开发工程师身上。对于开发工程师来说，其实难度并没有增加。无非是把 Ops 的工作当做需要通过别的工具完成的开发需求而已，甚至很多开发工程师自己也这么认为。运维除了知识以外，很大一部分的不可替代性来源于生产环境的维护经验。然而这些经验不可复制，因为有些问题作为开发人员来说你很难碰到。我曾打趣的说，当你听到有人说“这不可能啊”，他一定是个运维新手。就像我在上文强调的，软件开发和软件维护是相互关联但是各自独立的专业领域。DevOps 并不是要消除任何一方，而是要通过更加深入的合作成为彼此工作的润滑剂而非绊脚石。对于开发工程师来说，掌握更多的技能绝对是一件好事。但也不要低估运维的专业性和经验性。基础设施开发工程师由于有了虚拟化和基础设施即代码这样的技术，“通过 Dev 的方式完成 Ops 的工作，就是 DevOps “ 也很自然的成为了很多 Ops 对 DevOps 的认识。指的是通过 SDK，相关工具和配置文件，利用现有的平台资源，为应用程序构建基础设施。而他们往往有一个新的称谓：基础设施开发者 （Infrastructure Developer）或这 云计算工程师 （Cloud Engineer）。有一次到马来西亚出差，我称自己是 Infrastructure Developer 被 Uber 司机当做政府基建项目开发商 � 问了一堆稀奇古怪的问题，当然我并没有澄清，而是继续逗他 ;-D在一些企业里，基础设施开发工程师都会肩负着推行企业 DevOps 的责任。但很少有企业能够明确 DevOps 是要做什么（这就是 DevOps 缺乏基准定义的坏处），而这些基础设施开发工程师会慢慢变成一个孤立的“平台团队”，这对 DevOps 是不利的。全栈工程师当然绝对不排除有些工程师是既懂开发也懂运维的”复合型人才”。但这样的人才的成本也十分高昂：一方面是寻找这样的人所花费的时间。另一方面是雇用这样的人所花费的资金。此外，对于某些企业来说还有培养这样人才的成本。但是，仅仅认为有了这样的人才就具备 DevOps 的能力也并不现实。首先，DevOps 是一个团队属性，而不是一个人属性。一个人的力量相较于一个团队来说，还是很有限。其次，招聘这样的人主要还是为了胜任纷繁多变的工作，创业公司尤其如此。因此，我有时候会戏称全栈工程师为“全干工程师”，听起来很厉害，但工作境遇并不见的很好。你可能只需要一个 “DevOps 晃动器”软件开发和软件运维，是两类不同但联系很密切的事务，在过去很长的时间里。由于专业性和责任的不同从甲乙双方的矛盾变成了企业内部的矛盾。这是企业在互联网转型过程中的必经阶段，因为运维的开发不密切合作带来的问题日渐突出。而如何平滑的过渡，则是 DevOps 成败关键所在。你所需要不光是工程人才，你还需要新型的管理人才或者外部顾问来推动这项改进。一般来说，DevOps 的变革一定会调整组织的制度和做事方式。而制度层面的改变从企业内部是很难做到的。企业越大，“不求有功，但求无过”的鸵鸟心态普遍存在，因此越是大型的组织，所面临的组织僵化会越严重。组织僵化不见得是一件坏事，这意味着你的企业组织形态更加的问题和高效，这是长时间积累的结果。但由于过于高效，组织僵化的负面效应就是缺乏创新。所以，要推动企业的 DevOps 转型，特别是制度方面的创新，往往需要从组织外部引入“晃动器”（无论是聘用新的管理人才，还是外部顾问）来松动一下过于高效的组织，这都是能够帮助组织解除僵化的方式。DevOps 是一种工作方式这算是最贴近 DevOps 的目标的定义。但是在理解和时间上也是问题百出，片面的理解和机械的模仿都会造成 DevOps 之痛。对于 DevOps 的工作方式，有以下四个常见的理解： 用 Dev 的方法做 Ops 的事 换了名字的 Ops 团队 一个有 Ops 的 Dev 团队 一个 Dev 和 Ops 合作的团队用 Dev 的方式做 Ops 的事当你采用了上文中的 “基础设施即代码”，或者你有了“基础设施开发工程师”的时候。很自然的会想“我已经做到 DevOps 了”。然而，如果你并没有注意我在上述概念中特别提到的情况，那么你可能得到的只是下面所述的”换了名字的 Ops 团队“。换了名字的 Ops 团队这其实是很多公司的做法，认为 DevOps 所做的事情只是技术的更新，并无其它。在 2016 年底我在悉尼的一个 DevOps 项目上做转型咨询，客户的应用系统是基于 AWS 构建的。并且客户始终认为 DevOps 工程师就是上文所述的基础设施开发团队，只是工作的内容全都在 AWS 上面，并没有什么变化。而且给这个团队一个很高大上的名字：Enablers。然而，这个团队仅仅用新工具是清偿了之前运维工程师留下的技术债，并没有帮助开发团队、测试团队甚至是业务团队从自己的角度提供帮助来提升价值的流动速度和工作效率。不光如此，因为这个团队掌握了关键的基础设施资源，成为了所有团队前进的阻力，导致其它部门有更多积压的工作并需要更多人的人来处理。由于出现了这样的结果，“DevOps doesn’t work in my orgnization”（DevOps 在我的组织里不好使）的批评也不绝于耳。在 DevOps 转型的初期，我们需要一个这样的团队从运维的角度提出统一的方案并提供统一的服务支持。但随着 DevOps 能力和成熟度的提升，这样一个实体团队而不是虚拟团队的存在则会成为 DevOps 继续发展的阻力。一个有 Ops 的 Dev 团队最天真的想法莫不如把两类工程师放在一个团队里，在同一个负责人的范围内消化 Dev 和 Ops 的问题。这样，Dev 和 Ops 就能统一目标，平衡矛盾和冲突，共同解决问题。但实际上很少有企业能够走出这一步，一方面是 IT 部门的岗位设置和预算归属，另一方面是团队变更后的 KPI 考核。一件很小的举动就会牵扯更多的问题，使 DevOps 难以进行下去。此外，如果缺乏有效的 DevOps 实践或者外部教练 d 额指引，那么使 Dev 和 Ops 的融合将是一个漫长的旅程。在这种情况下，我建议采用 DevOps 项目制的方式来进行 DevOps 的体验： 首先根据项目汇聚资源，在项目中预留 Ops 角色。 从运维部门借调运维工程师到项目中。运维部门要提前安排好运维工作的交接，或者至少把日常性的运维任务的 80%剥离出来，分配给现有团队。保证进入项目团队的运维工程师的工作不被打扰 Ops 所在的部门绩效分为两块：一块为常规运维绩效（保证系统稳定性），另一块为 DevOps 项目绩效（保证开发顺利性），可以根据具体工作状况来设置这样的工作比率。 保证运维团队人员能够有机会进入项目实践 DevOps ，同时要把项目开发中的运维痛点带回给运维团队处理。在上述 2 的悉尼项目里，我就成为了加入到了产品开发团队中的运维工程师。一方面解决开发团队痛点，一方面和 Enablers 团队沟通。一方面解决 开发团队的痛点，另一方面获得相应的权限和知识，并把 开发团队的反馈及时传达给 Enablers 团队。一个 Dev 和 Ops 合作的团队这就是 DevOps 所要达到的目标，它不是一个人的属性，而是一个团队的属性。它让利益相关方坐在一起解决问题，而不是相互甩锅。然而，由于”合作“的定义很简单，也很空泛，导致”合作“难以落地。以下是我认为”关键”的 DevOps 合作方式： 共同进行架构设计 共同进行技术决策 持续交付流水线的建立 共同 Pair 和 Review 代码和环境的配置 共同参与回顾会议 通过定期的内部 Session 增加相互的理解 共同处理运维的问题此外，还有很多其他的合作方式能够提升 DevOps 的效果，在此不一一列举，这里仅做参考。如果你是一个敏捷的团队，只需要把 Ops 作为团队的一份子，参加所有的活动就可以了。DevOps 是一种组织文化在著名在 Velocity 09 大会上，来自 Flicker 的著名演讲”10+ Deploys Per Day: Dev and Ops Cooperation“ 明确的指出工具和文化是他们成功的原因。这也第一届 DevOpsDays 也将工具和文化这两个话题进一步细化。在会后 Patrick Debois 把 DevOps 定义为“管理改进”和技术提升“。John Willis 和 Damon Edwards 也在 2010 年 MoutainView 举办的 DevOpsDays 中重新强调了文化的重要性。相对于可以看得见的工具，文化显得华而不实，也有人认为 DevOps 文化是一种“空谈陷阱”。有一篇关于企业文化的文章写的非常好，这篇文章叫做”Culture is the Behavior You Reward and Punish“。翻译过来就是：文化就是你奖励和惩罚的行为。就是说对行为的惩罚和奖励构成了你的文化，对 DevOps 也一样。奖励符合 DevOps 的行为（而不仅仅是鼓励），惩罚不符合 DevOps 的行为。就形成了 DevOps 的文化。而我所说的“建立 DevOps 的文化“则是建立一种规则约束，这种约束不但包含了 DevOps 的行为准则，而且包含了奖励和惩罚的机制。而这种规则约束不能变成一纸空文，更要切实执行下去，形成一种行为习惯。习惯的力量则能够保证一种好的制度和实践顺利的延续下去。当然这种规则约束不是一成不变的，这些约束和规则也需要根据团队的发展不断的变化以适应新的状况。然而，就如上文所说的，由于企业并不存在产生 DevOps 的基因（否则你早就有 DevOps 了）。这些制度很难从内部产生，必须要的话，请引入外部资源，例如 DevOps 顾问或者 DevOps 教练。我经常看到一些 ”KTV 式转型”，这种转型就像是唱 KTV：当人们在 KTV 里面对歌词字幕你总能唱出来，也能唱对。但如果没有歌词，人们往往就唱不出来了。这里的歌词字幕就相当于是转型教练，当教练在的时候，每个人都知道怎么做。当教练不在，什么都没有了。很多情况下，顾问和教练在短期内起到从”0 到 1“的转变，然而从”1-100“则不是一朝一夕就能实现的。文化的形成是一个长期的塑造过程，不是能够买来的。你需要有足够的耐心来不断的评估和反馈当前的状况。以下是 DevOps 所鼓励的行为。尽管每个人都鼓励以下的行为，但实际效果则千差万别，往往抓住了形式而不是本质。 信任 沟通 学习 分享/共担 不要指责信任你的团队里的 Dev 和 Ops 之间是相互信任的吗？你信任你的团队成员吗？如果回答是。那么你的团队成员信任你吗？信任是相互的，而且是高效团队成功的基石。获得信任很难，需要时间去建立。信任同样也很脆弱，很容易就会失去。你是否明确哪些行为对信任有帮助，而哪些行为会伤害信任？你能说出那些帮助构建信任和伤害信任的行为吗？你的团队都清楚吗？当想到以上这些问题，你还信任你自己和你的团队吗？这里有一个很重要的原理：没有无条件的信任，信任是需要建立的。除了《凤凰项目》中所介绍的构建信任的方式——把自己最脆弱的一面告诉大家——以外，这里我推荐一种构建信任的方式： 回顾团队中的每一个人。 把你不信任的人说出来，并且说出你不信任的点。 为了消除这种不信任，你自己愿意做什么事情（而不是让对方做什么事情） 其它人为了消除团队中的不信任，也可以轮流发言。 如果消除了这种不信任，也请说出来。并为之前你不信任的人和整个团队故障欢呼。第三点最为重要，我们给出的建议往往不起效的原因就在于你在对别人提要求，而不是提供帮助。而人们对于提要求的感受都不会很好，只有提供自己的帮助，才是真正能解决问题的有效方式。另外，作为同一个团队的成员，你也必须想办法相信对方，并且让对方相信自己，没有选择。很多人都觉得难以启齿，难以启齿的原因就是因为人们不愿意相信对方能够接纳这些不信任。而这么做恰恰能表明你对对方的信任，相信经历过一系列的措施之后，能改善当前的状况。如果你觉得信任很难达成，那么这就是一个风险点，他会影响团队成员的行为和判断，造成不利的影响。所以，请多检查团队内部的信任情况，及时排除风险。沟通沟通是一个泛滥的话题，各种打着“高效沟通”的方法也层出不穷，但人们虽然都懂各种道理，也知道沟通的重要性，可沟通仍然被用作为”命令“的幌子，或用来实施语言暴力。沟通的主要目的在于对齐交换意见和看法，达成理解。沟通不仅仅是信息交流的通道，同样也是情绪宣泄的出口。我们在沟通中，有多少是发泄情绪占了很大的比重，但我们往往没有察觉。人们对表达自己的情绪是难以启齿的，因此用各种各样的“道理”来掩盖真实的意图。如果团队成员的大脑被不良情绪占据，那么无论如何他在团队中都不会有很好的表现的。人们往往会用其它的方式宣泄自己的情绪，而缺乏正确的发泄渠道则会导致灾难。你的团队里有没有比较沉默的人或者是不喜欢主动沟通的人？由于信任的逐渐缺失，有些人往往不再沟通。而这类不再沟通的人，往往是项目中的定时炸弹。而情绪积累到某一个点后，这个炸弹就会爆炸，造成很恶劣的影响。所以，尽早的介入并让每个人能够很顺畅的沟通，对降低情绪风险，尤为重要。此外，在沟通里，你是听的多？还是说的多？如果作为听者，你真正明白对方讲的是什么吗？如果作为说者，你在沟通之前，你是否有计划，是否明确沟通的目的，沟通后如何确认达到了沟通的目的？如果不确认这些问题，那么沟通往往就是没有意义的闲聊。学习在英文里， 学习是一个词——Learn 。而在中文里“学习”是两个词，对应的英文分别是 Learn （学）和 Practice（习）。比如：learnt 就可以因为上下文的不同表示两种意思。一种是”经历过学习的过程，但不一定掌握”，另一种则是真正学会了。当说到学习，往往想到的都是“输入”：看书（虽然买了也未必会看），看博客，看代码，看视频…… 然后练习，直到掌握。然而，仅有输入是不够的，学习还应当有”输出“：形成博客、开源软件、演讲甚至是培训工作坊。有一句很著名的话叫做：“教是检验学习成果的唯一标准。”是不是真的掌握了，教一下别人，你会意识到“学习的错觉”。在这里，我要强调一种重要的输入途径：从过往的经验教训中反思，总结，并形成团队的经验。很多事情过去了，无论成败，往往缺乏总结。这无法让团队成长，因为成败全凭”运气“。学习的目的在于指导今后的实践，无论成败，都会降低未来失败的概率，多做“正确的事”，少做“错误的事”。而只有学，没有习。只有输入，没有输出，或者只向外看，不向内看，都是片面的学习方式。我推荐的学习方式则是以输出作为学习目标，对知识和信息进行加工，思考，实践，提炼的过程。毕竟，判断一个人的知识不再于他的输入，而在于他的输出。因为讲出来，才是自己的。不要指责很多问题棘手是因为人们不关注如何解决问题，而关注这个问题究竟是谁该负责。如果团队在责任归属的问题上花的时间很多，那么这就是一个指责文化的制度。在这种情况下，团队成员为了自保，会避免承担责任和解决问题。因此，很多事情没有进展，于是，整个组织沉浸在一种”不求有功，但求无过“的氛围下慢慢凝结，最后僵化。我们常常听到“零容忍”，然而对问题的”零容忍“往往是很漂亮的口号。但它往往指的是”发现问题掩盖问题“。以前人们都说，不怕有问题，就怕看不见问题。而现在很多问题的出现并不是“黑天鹅”“事件，而是”灰犀牛”事件。恰恰是对问题的选择性失明导致了不可挽回的结果。在实践 DevOps 的时候，需要先测试一下有多少装睡的人。因为没有解决不了的问题，只有不愿承担的责任。分享/共担Share 在英文里有两个意思，一个和别人分享，另一个是和别人共同承担。在 DevOps 的上下文里二者兼有，一方面是作为学习的结果的产出。另一方面是避免组织陷入不愿承担责任的文化。对于团队作战来说，一个人犯错，不是他一个人的责任，而是集体的责任。”当你用一个指头指着别人的同时，另外四个指头也指着自己。我们要相信没有不良的人，只有不良的制度。当出现了问题，从制度上而不是从个人的角度分析问题出现的原因。而且要能总结原因，形成新的制度。如果一个问题不在制度上去避免，那么还会发成下一次。如果什么都是 DevOps ，那么 DevOps 实际上什么也不是如果把所有 DevOps 相关的内容加总就能得到 DevOps，那和没有定义 DevOps 一样。如果我们没办法确定”什么不是 DevOps“，那同理我们也很难定义 DevOps 是什么。我试图从上文中的认识里，提取出一些 DevOps 的必要元素来构成 DevOps 的概念。这些元素缺一不可，但单独拿出来又不能构成完整 DevOps 的概念。这样既可以保证对 DevOps 的完整理解，又避免 DevOps 概念过大难以下手。根据我自己的实践，我认为 DevOps 包括以下几点原则： DevOps 有一个明确的目标：通过充分的合作解决由于责任模糊而相互推诿的问题。（没有 DevOps 痛点的团队自然也没有 DevOps 的动力） DevOps 是一个团队属性而不是个人属性，这个团队需要处理开发和维护任务。（有单一任务都不算是 DevOps 团队，因为没有合作解决 DevOps 痛点的动机） DevOps 是一种团队改进，对于团队的表现有明确目标和度量。（没有度量的改进就是耍流氓） DevOps 是一种团队工作方式和文化，它包括了一系列促进 Dev 和 Ops 合作的具体技术和实践以达到上述目标。（ DevOps 也不是缺乏技术的理论空谈 ）因此，以下的描述都不是 DevOps： DevOps 不是一个职务或者角色，因为 DevOps 是团队属性。 不存在” DevOps 团队“，只存在”以 DevOps 方式工作的团队“。以上是我过去三年的 DevOps 实践和咨询经历，希望能给正在做 DevOps 的你一些参考和提示，并祝愿你在 DevOps 的实践过程中更加顺利。" }, { "title": "当你在浏览器中输入“google.com”并回车，会发生什么？", "url": "/posts/2019-01-25/what-happens-when-you-type-googlecom-into-your-browser-and-return/", "categories": "Reprint", "tags": "Interview, Networking", "date": "2019-01-25 00:00:00 +0800", "snippet": " 原文： https://www.cnbeta.com/articles/tech/808191.htm我遇到过的最喜欢的面试问题是：”你键入’google. com’到一个浏览器的地址栏中, 并点击Enter, 之后会发生什么呢？”有人可以滔滔不绝几天, 试图以某种形式的完备性来回答此问题。他们会走多深？纯粹出于兴趣, 我要把我的答案罗列在此。当我在一次实际面试中被问到这个问题时, 在他...", "content": " 原文： https://www.cnbeta.com/articles/tech/808191.htm我遇到过的最喜欢的面试问题是：”你键入’google. com’到一个浏览器的地址栏中, 并点击Enter, 之后会发生什么呢？”有人可以滔滔不绝几天, 试图以某种形式的完备性来回答此问题。他们会走多深？纯粹出于兴趣, 我要把我的答案罗列在此。当我在一次实际面试中被问到这个问题时, 在他们阻止我之前我漫谈了 10 分钟。之后即使在面试结束后，我一直记得当时我所遗漏的东西。我将把这个格式化为文本墙, 因为在谈话中回答这个问题就是这样的感觉.那么发生了什么呢?浏览器将分析输入。通常情况下, 如果输入中有”. com”, 它不会认为你在输入搜索词。一旦它决定其必定是一个 url 时, 它会检查输入是否有协议头，如果没有, 它会在其开头添加”http://”。由于你没有指定一系列 http 协议功能, 因此它将假定使用默认值, 如端口 80、GET 方法和无基本身份认证。然后, 它将创建一个 http 请求并发送该请求。我对我的底层网络知识没有信心, 但如果我确实要说, 我会说一些关于 MAC 地址, TCP 数据包传输, 丢包处理等。但无论如何, 一个对”google. com”DNS 的查找将会发生, 如果它还没有对此的缓存，DNS 服务将应答一系列 IP 地址列表, 因为”google. com”不只单 IP 的。我认为在默认情况下浏览器会选择第一个。不确定它们是区域性的以及它是如何工作的, 但我知道它就在那里。因此, http 请求从一个节点跳转到另一个节点, 直到它找到 google. com 负载均衡器的 IP 地址。这不会持续很久, 谷歌会回应说, 你需要使用 https-假定是 301 永久重定向。因此, 它会原路返回到你的浏览器, 浏览器将协议更改为 https, 默认使用 443 端口并重新发送。这一次,TLS 握手将在负载均衡器和浏览器客户端之间进行。我不是 100%确定其工作原理, 但我知道该请求会告诉谷歌, 它支持什么协议 (TLS 1.0, 1.1, 1.2) ，然后谷歌将响应 “让我们使用 1.2 吧”。之后使用 TLS 加密发送请求。我认为谷歌接下来要做的是将其放到负载均衡器上的网络应用程序防火墙规则集上, 看看它是否是一个恶意请求。当这通过之后, 安全连接可能已被终止 (因为 PCI-DSS 规则规定你不需要加密内部流量), 请求将被分配到其 CDN 中的某个池上, 而 google 端缓存主页将在 http 响应中返回。可能是预先压缩的。谷歌的响应头将由浏览器读取，根据响应头的缓存策略进行缓存，然后正文将被解压缩。而且因为这是谷歌，它可能是超优化的：压缩，可能是许多预渲染内容、内联 CSS、JavaScript 和图像，以减少网络请求和首次渲染时间。但该请求将触发一系列其他请求，所有这些请求都是并发的，因为它应该运行 HTTP/2。当这些请求正在进行时，JavaScript 会被解析，可能没有阻塞，因为他们在标签上使用了 defer 属性 - 或者 async，我从来没有单独阅读过这里他们做了些什么的资料。但浏览器可能已经渲染了搜索框并且正在顶部的工具栏上工作，这将需要一些额外的网络请求 - 我可能已经有一个 cookie 或可能是带有 OAuth 令牌的本地存储 - 或我可能是使用 Chrome 并且它已经知道我是谁，并且使用 auth 的请求会被发送到他们的 Google+ API 上，告诉 Google 搜索页面的应用程序我的身份。另一个请求将被发送, 以获取我的头像图像。在这一点上, 他们已经浏览器可嗅探的, 看看我是否未使用 chrome, 在这种情况下, 他们会有弹出一个工具栏提示, 告诉我：chrome 是真棒, 我应该使用它, 而不是其他任何浏览器。我想此时需要冷静下来。所有这些都发生在一秒的时间内。何为显著地不同?让我们看看对应的 DNS:我知道我以前见过 google.com 返回包中带有多个 IP 地址，但似乎不再是这种情况了。似乎他们之前常常使用轮巡策略，但现在不再使用了。 这个StackOverflow提问涉及了此情况。我已忘记了它被称为轮 2。网络层在一个正式结构化回答中，你可能会参考我有所了解但并不精通的 OSI 模型。在查阅资料之后，我将它视为如下的网络分层映射： 应用 - 触发请求的逻辑 表示层 - HTTP 会话 - TLS 传输 - TCP 网络 - 路由 (IP) 数据链路 - 帧 (可看做数据包的容器) 物理层 - 比特流我记得在 TLS 中他们会在协议协商时交换证书。网络并不是我的强项。在我的浏览器中打开 google.com，并禁用缓存：我记得主机名规范化——这是一个 301。从 HTTP 到 HTTPS 的校正是一个 307 内部重定向。然后它下载字体、商标图像和我的头像图像。如果没有 API 调用，这意味着他们会在页面中推送我的个人资料信息并将其与返回数据捆绑在一起 - 因此当你点击 google.com 而不仅仅是提供缓存资产时，他们会进行实际的数据检索。响应以上是 IE 11 和 Chrome 响应数据的对比——所有都处于退出状态。 IE11 和 Chrome 之间没有太大的差别。但这意味着他们是用户代理嗅探服务器端而不是客户端。在我的答案中可能提到了这一点。 出乎意料的是，Chrome 的响应体大了 22kB。我想知道它是否是由在 IE 11 中明显缺席的语音搜索功能引起的。IE11 可能需要 polyfill 和 Chrome 的广告，但它都被混淆了，我不会再进一步折磨自己了。 即使我在 Chrome 中清除了 Cookie，它仍会在第一次请求时发送 Cookie。它在 IE 11 中并没有这样做。深入理解渲染!上图是 Chrome 将为你提供的第一个屏幕截图。 脚本标签中没有任何 async 或 defer 属性，只有 nonce 属性。我目前正在学习有关 nonce 的知识，这似乎与安全性有关。我估计他们想要那些阻塞式脚本。我确信他们在某些方面尝试过有/无 aync/defer 的情况，并决定反对之。 自我提示：完全响应是对 JavaScript、CSS 和 HTML 的乱七八糟的混合体。相比于其独立性，他们没有遵守任何控制其位置的规则。问题本身是什么呢?你知道吗？ 对于人员而言，这可能不是一个很好的面试问题，因为答案涉及到如此多的网络知识。这是我喜欢的问题的格式，一些开放的事物，包括一些猜测。这使得面试官有机会跟进诸如“你认为 TLS 是如何建立的？”之类的问题，以查看候选人如何思考，看看他们有多少创意，看看他们的极限何在（有多耐心？）。你最喜欢的面试问题是什么？" }, { "title": "2018年，再见", "url": "/posts/2018-12-24/goodbye-my-2018/", "categories": "Life", "tags": "Life, Book", "date": "2018-12-24 00:00:00 +0800", "snippet": "去年的这个时候，我也想写一篇年底总结，无奈自己给自己找了各种理由借口，没写出来。懒今年从 8 月份就不爱动笔了，内心里一直有两个小恶魔，争论不休想要干架。一个说，一周 7 天你能蹦出 8 个想法，不写出来谁知道你他娘的是个天才？另外一个说，别老想着当网红，你那屁大的 idea 毛线都不是，写出来自己都懒得看。其实内心并没什么小恶魔，只是因为懒。羞怎么说呢？博客这东西写的好的可以字字珠玑，让人...", "content": "去年的这个时候，我也想写一篇年底总结，无奈自己给自己找了各种理由借口，没写出来。懒今年从 8 月份就不爱动笔了，内心里一直有两个小恶魔，争论不休想要干架。一个说，一周 7 天你能蹦出 8 个想法，不写出来谁知道你他娘的是个天才？另外一个说，别老想着当网红，你那屁大的 idea 毛线都不是，写出来自己都懒得看。其实内心并没什么小恶魔，只是因为懒。羞怎么说呢？博客这东西写的好的可以字字珠玑，让人读的醉生梦死，醍醐灌顶。写的不好的也可以记个流水账。写了就不要后悔，它可以锻炼你的大脑，提前防止老年痴呆。而且多年以后自己翻翻很大概率还能把自己弄的一把鼻涕一把泪（羞的）。戒2018 年的社会已经是个相当浮躁的社会，每个人都说自己没时间，可是一刷手机能刷半天，碎片化的时间被各种应用塞满。年初给自己订的读书目标（每月一本），一半都没完成，马上就 2019 了。翻开 kindle 看到都是自己喜欢的书名标题，但是还没找回上次阅读的线索时，手边的手机就亮了，拿起手机开始不亦乐乎地处理各种推送，仿佛整个世界都非常需要我，我好忙啊？？还好，我读完了一本《受戒》，让我依稀感觉得到时光流逝，文字还是有感动人的魅力。 在一起时，恩恩义义；分开时，潇潇洒洒。 她挎着一篮子荸荠回去了，在柔软的田埂上留了一串脚印。明海看着她的脚印，傻了。五个小小的趾头，脚掌平平的，脚跟细细的，脚弓部分缺了一块。明海身上有一种从来没有过的感觉，他觉得心里痒痒的。这一串美丽的脚印把小和尚的心搞乱了。 田彼南山， 荒秽不治， 种一顷豆， 落而为箕， 人生行乐耳， 须富贵何时。点2018 年去了一趟南京，南京的老鸭粉丝汤真的是好吃，金陵是个风水宝地。2018 年游了一次西湖，西湖的春风拂面很是惬意，和大橙子来回在苏堤上走了三遍还恋恋不舍。2018 年回了一次老家，熟悉的鸡鸭叫声和虫鸣狗吠，让我感觉自己好像没出过远门。2018 年南方酷热的夏天和没有空调的房间也让我意识到，我来自农村，但已渐渐不习惯农村。2018 年大哥大嫂把侄子带到人间，父母的笑容因此增添了许多。2018 年父亲大人第一次上手术台，岁月会无情带走容颜和健康，不允许商量。2018 年给自己和大橙子办了健身卡。从第一次进健身房累到晕倒，到现在可以一口气跑 6 公里只经历了一个多月，我很感谢自己做的选择，流汗的感觉真好。2018 年已过而立，在上海看了几次房子，最终还是没有成为房奴。2018 年在 Github 提交了 376 次，相比去年的 971 次，着实少了许多。没有拿得出来说的项目，都是小猫小狗过家家。2018 年打了至少 2000 场农药，上过王者，然而有什么意义？终于弃坑，毁我青春。2018 年买了一个尤克里里，已经可以熟练弹唱小星星和生日快乐歌，从乐盲到明白了全全半全全全全半的含义，也知道了四大和弦原来这么厉害。2018 年花了一个月时间系统学习了移动端自动化测试的原理还提了方案，但最后老板说没时间给你折腾了，公司暂时不打算招人。2018 年我们公司也裁员了，我没有成为可以 N+3 的人，不知道是幸运还是不幸运。2018 年公司把我们带来澳门开年会，让我看见了什么叫纸醉金迷，什么叫一掷千金，什么叫有钱真好。2018 年混进各种测试群，原来大家都在努力用牛逼的技术解决多年以来一直都有的 UI 测试问题。在我看来，自动化测试真不应该测 UI，但又不得不测。2018 年开始摸索着使用 docker 去部署自己的项目，不骗你说，真的很好用。2018 年用 Vue 去重构了几个项目，发现 Vue 真是个好东西，易学易用上手快，前端工程师也可以很快乐。2018 年走了 Ract 的 walkthrough，发现它不太适合我，前端工程师要纠结的东西真多，还好我不是前端。2018 年写了第一个浏览器插件，第一个油猴脚本，感觉会 JavaScript 真的可以为所欲为。2018 年我想把后端的代码部署到本地，可是还是停留在想的阶段。2018 年在蚂蚁森林收了 500 个鸡蛋，种了 2 棵树，支付宝一直在怂恿我们使劲花钱。2018 年初买了两万的基金，年底亏了五千，今年市场到底发生了什么。我开了股票账号，但啥也不敢买。2018 年工资没怎么涨，但是 5 毛钱的硬币和纸币，已经开始花不出去了。2018 年越来越发现选择远比努力重要，但努力也远比不努力好的多。2018 年有很多伟大的人走了，但是还好身边的家人和朋友一个不少。2018 年和大橙子在一起刚好十年，昨天一起看了照片，没啥变化，真好。2018 年没有认识很多新面孔，也意味着不用告别很多老面孔。2018 年平平淡淡，但也真真实实。" }, { "title": "用 Python 实现简单的 switch/case 语句", "url": "/posts/2018-09-16/python-switch-case/", "categories": "Tech", "tags": "Python, Quiz", "date": "2018-09-16 00:00:00 +0800", "snippet": "在Python中是没有Switch / Case语句的，很多人认为这种语句不够优雅灵活，在Python中用字典来处理多条件匹配问题字典会更简单高效，对于有一定经验的Python玩家不得不承认，的确如此。但今天我们还是来看看如果一定要用Python来Switch / Case，可以怎么玩。语法约束我们先定义一下Switch/Case应该怎么表达，为了简单我们可以让它长成这样。def cn():...", "content": "在Python中是没有Switch / Case语句的，很多人认为这种语句不够优雅灵活，在Python中用字典来处理多条件匹配问题字典会更简单高效，对于有一定经验的Python玩家不得不承认，的确如此。但今天我们还是来看看如果一定要用Python来Switch / Case，可以怎么玩。语法约束我们先定义一下Switch/Case应该怎么表达，为了简单我们可以让它长成这样。def cn(): print('cn')def us(): print('us')switch(lang).case('cn',cn)\t\t\t.case('us',us) \t\t\t.default(us)类实现一通过以上约束，我们可以把switch当成一个类来实现，传入的参数在构造函数里处理，然后再分别实现case和default方法即可。class switch(object): def __init__(self, case_path): self.switch_to = case_path self._invoked = False def case(self, key, method): if self.switch_to == key and not self._invoked: self._invoked = True method() return self def default(self, method): if not self._invoked: self._invoked = True method()在构造函数中我们记住了case_path 和执行状态_invoked，在case()里如果当前的key和switch_to匹配并且函数没有被执行过，那么就更新_invoked并执行对应的方法。在default()里检查一下_invoked，如果从没执行过，那么就调用default分支的函数。看上去还不错，我们来试用一下。switch('cn').case('cn',cn).case('us',us).default(fail)&gt;&gt;&gt; cnswitch('us').case('cn',cn).case('us',us).default(fail)&gt;&gt;&gt; cnswitch('jp').case('cn',cn).case('us',us).default(fail)&gt;&gt;&gt; failswitch('cn').case('cn',cn).case('us',us)&gt;&gt;&gt; cn让我们来看几个奇葩一点的case。# duplicate caseswitch('us').case('us',cn).case('us',us).default(fail)&gt;&gt;&gt; cndef cn() return 'cn'def us() return 'us'# return valueresult = switch('cn').case('cn',cn).case('us',us)result&gt;&gt;&gt; &lt;python_switch_case.switch object at 0x11034fb70&gt;发现了没有，上面的实现不会处理重复的case，当然你可以加强一下case方法，最好是抛出异常，其他编程语言通常都这样做。第二个问题，你希望从case里拿到返回值，像上面的写法是没希望了，因为扔掉了。我们可以考虑在switch类里加一个result的变量来保存执行结果。class switch(object): def __init__(self, case_path): ... self.result = None def case(self, key, method): ... self.result = method() ...在调用结束后，就可以通过result拿到结果了。_ = switch('cn').case('cn',cn).case('us',us)_.result&gt;&gt;&gt; cn类实现二我大概在网上搜了一下，你还可以参考Brian Beck通过类来实现Swich/Case。class switch(object): def __init__(self, value): self.value = value self.fall = False def __iter__(self): \"\"\"Return the match method once, then stop\"\"\" yield self.match raise StopIteration def match(self, *args): \"\"\"Indicate whether or not to enter a case suite\"\"\" if self.fall or not args: return True elif self.value in args: self.fall = True return True else: return Falsec = 'z'for case in switch(c): if case('a'): pass # only necessary if the rest of the suite is empty if case('c'): pass # ... if case('y'): pass if case('z'): print(\"c is lowercase!\") break if case('A'): pass # ... if case('Z'): print(\"c is uppercase!\") break if case(): # default print(\"I dunno what c was!\")这种实现相对复杂一点，而且用起来也不是很舒服，又需要for又需要if（还不如直接if/else痛快）。当然也有好处，就是可以把相同结果的case放一起，而且case里可以写更多东西，不仅仅是一个方法名。写在最后最后我们还是回到Python推崇的方法来处理switch/case问题，一般我们可以通过字典来处理这种多分支的问题，举例说明。MAPPING = { 'cn': cn, 'us': us}lang = 'cn'result = MAPPING.get(lang, default=us)是不是一目了然，不仅易于阅读也易于维护。在字典中key是唯一的，value可以是任意类型的数据，可以是类或者是方法，所以足够灵活。" }, { "title": "Auto Update Your Pypi Package", "url": "/posts/2018-07-29/pypi-package-auto-update/", "categories": "Tech", "tags": "python, pypi, pip", "date": "2018-07-29 00:00:00 +0800", "snippet": "Sometimes we mgiht want to make our package update to latest version, let me show you how do I accomplish this.Determine VersionsWe have to determine current installed package version.def get_pkg_v...", "content": "Sometimes we mgiht want to make our package update to latest version, let me show you how do I accomplish this.Determine VersionsWe have to determine current installed package version.def get_pkg_version(name): \"\"\"Get current version of a installed pip package.\"\"\" import pkg_resources try: return pkg_resources.require(name)[0].version except pkg_resources.DistributionNotFound: return NoneThen detemine latest published version, if this is an internal package, you have to implement a custom method like bellow.def get_latest_version(name, server='https://pypi.org'): import re import urllib.request, urllib.error try: content = str(urllib.request.urlopen('{}/simple/{}/'.format(server, name)).read()) versions = re.findall('([^-&lt;&gt;]+).tar.gz', content) return versions[-1] except urllib.error.HTTPError: return NoneUpdate MethodsWe will use pip to update the package, here is the implementation.import osimport sysdef get_python_cmd(): \"\"\"Get current running python executable\"\"\" return sys.executabledef update_pkg(name, *args): \"\"\"Update a pypi package with pip.\"\"\" arguments = [get_python_cmd(), '-m pip install -U', name] arguments.extend(args) cmd = ' '.join(arguments) print('Update {}: \\n{}\\n'.format(name, cmd)) os.system(cmd)The update method leaves *args is for internal package, you might want to parse in --extra-index-url and --trust-host.Combine TogetherFinally, we implement the auto update method.# auto_update.pyimport osfrom utility import get_pkg_version, get_latest_version, update_pkgNAME = 'your_pkg_name'def check_update(install=True): \"\"\"Check update for the package.\"\"\" latest_version = get_latest_version(NAME) installed_version = get_pkg_version(NAME) if latest_version is None or install_version is None: return if latest_version != installed_version: if install: update_pkg(NAME) else: print('New version of {} is available, {}=&gt;{}.'. format(NAME, installed_version, latest_version))Then, we place it in __init__.py in root of package, every time the package be imported, it will run the auto checker.# your_pkg/__init__.pyfrom auto_update import check_updatecheck_update()OK, we have done the auto update.Can Be ImprovedIn above example, we did not reload the module if there is an update, that depends on you.Another thing can be improved is, we might not want to update the pacakge when there is an update, we just want to update it if there is a major / breaking update, the updator should be smarter." }, { "title": "将xmind文件转成可编程数据类型", "url": "/posts/2018-07-01/parse-xmind-to-programmable-data-type/", "categories": "Tech", "tags": "python, xmind, pypi, json", "date": "2018-07-01 00:00:00 +0800", "snippet": "一个新的轮子。前言最近升级了一下xmind2testlink，顺带产生了一个中间轮子：xmindparser。xmind是知名的思维导图软件，可以用来整理思路，设计测试案例等等。一旦完稿后软件本身支持导出为图片，PDF，Excel 等等文件格式。免费版相对于 Pro 版能导出的文件种类少一些，但有时候你可能想我做的 xmind 能不能通过编程再加工一下，比如集成到某个网页，或者通过 api ...", "content": "一个新的轮子。前言最近升级了一下xmind2testlink，顺带产生了一个中间轮子：xmindparser。xmind是知名的思维导图软件，可以用来整理思路，设计测试案例等等。一旦完稿后软件本身支持导出为图片，PDF，Excel 等等文件格式。免费版相对于 Pro 版能导出的文件种类少一些，但有时候你可能想我做的 xmind 能不能通过编程再加工一下，比如集成到某个网页，或者通过 api 和某某系统集成。那么xmindparser就是这么一个项目，了解一下。安装 xmindparser这个项目已经打包到 PyPI，可以通过 pip 安装。pip install xmindparserXmind 转 Python 数据类型xmindparser 可以将 xmind 转成dict数据类型，比如下面这么一个 xmind 文件：转换代码的示例：from xmindparser import xmind_to_dictout = xmind_to_dict(xmind_file)例子中out的数据结构如下：[ { \"title\": \"Sheet 1\", \"topic\": { \"makers\": [ \"star-orange\" ], \"topics\": [ { \"link\": \"http://test.com\", \"topics\": [ { \"topics\": [...] \"title\": \"e\" }, ... ], \"title\": \"test\" }, \"structure\": \"org.xmind.ui.map.unbalanced\" }, { \"title\": \"Sheet 2\", ... }]通过遍历 sheet 和 topics 就可以获取到 xmind 中每个节点的信息。Xmind 转 JSON转成 JSON 非常简单，如果你还是使用 Python 编程，可以这样写：from xmindpraser import xmind_to_jsonout_file = xmind_to_json(xmind_file)或者你直接调用命令行工具：xmindparser your.xmind -jsonXmind 转 XML转成 XML 是类似的，使用 Python 编程，这样写：from xmindpraser import xmind_to_xmlout_file = xmind_to_xml(xmind_file)或者你直接调用命令行工具：xmindparser your.xmind -xml结束语单个工具本身可能作用有限，但如果你能将各种工具融合起来，威力也许大很多。我们常说 1+1，很多时候都是大于 2 的。" }, { "title": "NodeJS起步两三事", "url": "/posts/2018-06-01/steps-to-start-nodejs-in-china/", "categories": "Tech", "tags": "nodejs, mirror, proxy", "date": "2018-06-01 00:00:00 +0800", "snippet": "主要是为了备忘，开始接触NodeJS有一段时间，断断续续，年纪也大了时间一长容易忘事情，汗。安装Node直接到官网下载LTS版本安装即可，没必要追新功能用最新版。安装Node基本没什么坑，记得加到PATH就好。Windows双击安装，macOS推荐使用brew安装，完成后在命令行里测试一下。$ node -v后期如果没有啥breaking的API改动基本也不用升级。必要的配置NodeJS的包...", "content": "主要是为了备忘，开始接触NodeJS有一段时间，断断续续，年纪也大了时间一长容易忘事情，汗。安装Node直接到官网下载LTS版本安装即可，没必要追新功能用最新版。安装Node基本没什么坑，记得加到PATH就好。Windows双击安装，macOS推荐使用brew安装，完成后在命令行里测试一下。$ node -v后期如果没有啥breaking的API改动基本也不用升级。必要的配置NodeJS的包管理器npm，如果在墙内及有可能在使用过程中很不稳定，一般推荐使用国内的镜像源，目前最知名的也就是淘宝家的了。 https://npm.taobao.org/.npmrc你可以通过修改~/.npmrc来设置默认的包源:registry=https://registry.npm.taobao.org/cnpm你也可以安装 cnpm 来代替 npm ：npm install cnpm -g之后的大部分npm 都可以直接用 cnpm 代替（发布相关的除外）：cnpm install &lt;package&gt;nrm其实我还推荐你了解另外一种切换源的方式 nrm:nmp install nrm -g使用方法如下，超级简单：$ nrm ls* npm ---- https://registry.npmjs.org/ cnpm --- http://r.cnpmjs.org/ taobao - https://registry.npm.taobao.org/ nj ----- https://registry.nodejitsu.com/ rednpm - http://registry.mirror.cqupt.edu.cn/ npmMirror https://skimdb.npmjs.com/registry/ edunpm - http://registry.enpmjs.org/ $ nrm use taobao Registry has been set to: https://registry.npm.taobao.org/使用 nrm ls 列出可以切换的源，然后nrm use &lt;name&gt; 瞬间切换，爽！proxy镜像源毕竟是copy的，同步状态有可能你不甚满意，最近taobao的源可能还有以下错误：npm ERR! registry error parsing json作为一个资深码农你也许有一个本地代理（SS懂？）让你无障碍访问国际互联网，那么你可以这么做：npm config set proxy http://server:portnpm config set https-proxy http://server:port配置好 npm 的代理后你又可以开心地玩耍了。Node入门须知三分钟入门NodeJS，如果你已经有其他语言的编程经验，是可以的。NodeJS的核心可执行程序node[.exe]你可以简单理解成代码解释器，类似于Java的虚拟机，C#的.net Framework，Python里的python[.exe]，作用是把你的代码翻译成计算机行为。node hello.js以上就是运行NodeJS代码的不二法则。项目启动很多知名框架都会提供所谓的脚手架命令，但是对于萌新玩家，我是不建议直接去使用脚手架的，这些脚手架做出来的目录结构对于萌新玩家来说是懵逼的，虽然有可能都是最佳实践的结果，但没有1，2，3步骤和手拉手，萌新也许直接退出游戏了。新手真正的入门法则还是踏踏实实按照各种教程一步一步走，如果教程不好就换，没学会走路就想跑是不可能的。一般项目是这样开始的： 明确项目需求（略） 创建项目目录 初始化项目信息 安装必要的依赖 模块划分，编码 系统集成，测试 项目发布，维护升级这个流程用NodeJS来实践大致是这样的：# create project mkdir [project-name]cd [project-name]# init projectnpm init...# install dependenciesnpm install &lt;package...&gt;# install dev dependenciesnpm install &lt;package...&gt; -D# coding...# run and testnpm run buildnpm run startnpm run testnpm run stop# publish projectnpm publish .前面一节全都是在介绍npm，通过这个例子你应该明白它在NodeJS中的重要性了吧，所以让你的npm好用意义非凡。例子中安装了两次依赖可能你有点困惑，可以这样理解，第一次依赖是项目运行时必要的依赖--save-prod，在发布时必须安装的；第二次依赖主要是用于开发或者测试的--save-dev，比如某些debug包或者test框架，方便开发才需要的包，在项目部署时没必要安装。其实还可能安装第三种依赖--save-optional，比如是用来做数据分析或者别的enhancement的，目前Node支持区分对待这三类依赖包。语法演示NodeJS里的JS就是JavaScript，属于动态语言，命名规则类似Java，但是语法更接近各种动态语言，比如Python或者Ruby。上手不难，了解一下标准库和数据基本类型，在IDE的加持下你就可以开始写代码了。// index.js 项目的入口文件var fs = require('fs'); // 导入标准库模块var _ = require('lodash'); // 导入已安装的包var m = require('./hello');  // 导入同目录下的模块import hello from './test'; // 导入模块的部分对象m.say('yo..'); // 调用模块方法hello('toby');fs.copyFileSync(src,dst) // 调用标准库方法模块的编写范例：// hello.jsvar a = 'hello world!'; // 模块的全局变量不会被导出function say(word) { console.warn('say ' + word);}function hello(word) { console.log('hello, ' + word);}// 导出就是对 module.exports 进行赋值module.exports = { say: say, hello: hello}包管理小贴士对于npm包的安装的位置我们来了解一下，简单来说就是这个包所作用的范围。如果安装包不带-g参数那么默认就是安装在当前目录。npm install &lt;package&gt;# =&gt; will install to ./node_modules这个包也就只有在当前目录（项目）里可用，这样方便做到环境隔离，不同项目可以用同样包的不同版本等等。-g如果安装过程中带了-g参数那么就意味这个包是全局（global）安装的，在系统的任何位置都是可用的。npm install &lt;package&gt; -g# =&gt; will install to /usr/local/lib/node_modules# =&gt; or %AppData%\\npm\\node_modules一般的包安装都是不用带-g的，除了一些工具类的包，例如第一节介绍那些，这样系统干净一些，也可以避免全局包污染项目导致各种灵异事件。–depth如果要查看安装了哪些global包可以用这个命令：npm list -g --depth=0如果不加--depth，哎我去真没法看，也不知设计这个list的人为啥不默认带上这个参数，脑子被门夹了。为了方便你可以配上以下两个alias。alias ng=\"npm list -g --depth=0 2&gt;/dev/null\"alias nl=\"npm list --depth=0 2&gt;/dev/null\"ncu使用NodeJS就是要面对各种各样的包，有些包升级很勤快，你也想升级怎么办呢？哪些是outdated哪些不是，npm的升级命令真的很难用（记）哎。我推荐你了解一下npm-check-updates：npm install npm-check-updates -g这么好用的东西当然要全局安装啦，用法很简单，检查当前项目所有包的更新状态：$ cd my-project$ ncuUsing /Users/tobyqin/src/blog/package.json[..................] | :The following dependencies are satisfied by their declared version range, but the installed versions are behind. You can install the latest versions without modifying your package file by using npm update. If you want to update the dependencies in your package file anyway, run ncu -a. hexo ^3.5.0 → ^3.7.1 hexo-generator-search ^2.1.1 → ^2.2.5 hexo-server ^0.3.1 → ^0.3.2使用 ncu -a就可以一键更新项目里的所有包，当然它也提供了一些过滤参数，你可以查阅文档。如果要看全局的包有没有可以更新的，试试ncu -g，非常方便。有一点要注意，虽然命令是ncu但是包名不是，因为ncu的包名已经被一个天气预报的包占用了，无语。总结现在写NodeJS项目已经很容易了，JS经过了两三年的野蛮生长，诞生了成千上万个包（框架），其中不乏精品。作为搬砖的码农，经过一顿npm install操作就可以做出一个不错的demo，你还犹豫什么，赶快上车吧！" }, { "title": "使用浏览器的HEADLESS模式进行自动化测试", "url": "/posts/2018-05-18/automation-tests-with-selenium-and-headless/", "categories": "Tech", "tags": "python, selenium, headless", "date": "2018-05-18 00:00:00 +0800", "snippet": "自动化测试的进阶内容。了解HEADLESS模式HEADLESS BROWSER 指的是不需要用户界面的浏览器，这种浏览器在自动化测试和爬虫领域有着广泛的应用。例如你想在网页上运行一些测试，从网页抓取信息，检查浏览器访问某些资源的状态，定时截取网页等等，你需要的是浏览器处理网页但不一定需要浏览器界面，这些情况都是HEADLESS BROWSER的应用场景。Chrome 从 59.0 开始支持H...", "content": "自动化测试的进阶内容。了解HEADLESS模式HEADLESS BROWSER 指的是不需要用户界面的浏览器，这种浏览器在自动化测试和爬虫领域有着广泛的应用。例如你想在网页上运行一些测试，从网页抓取信息，检查浏览器访问某些资源的状态，定时截取网页等等，你需要的是浏览器处理网页但不一定需要浏览器界面，这些情况都是HEADLESS BROWSER的应用场景。Chrome 从 59.0 开始支持HEADLESS模式（2017年5月），Firefox从 55.0 开始也支持了HEADLESS模式（2017年9月）。也就是在今年2018年的4月份，老牌的无头浏览器 PhantomJS 的核心开发者宣布不再维护该项目，因为Chrome 和Firefox的HEADLESS模式已经足够好并可以替代PhantomJS。实践 Selenium + HEADLESS使用浏览器的HEADLESS模式进行自动化测试，你需要先满足以下前提： Python + Selenium 运行环境 Chrome 59+ 或者 Firefox 55+ ChromeDriver 或者 GeckoDriver 最新版已加入PATH万事俱备，废话不多说我们直接上演示代码。Chrome版实例from time import sleepfrom selenium import webdriverfrom selenium.webdriver.chrome.options import Optionsoptions = Options()options.add_argument('--headless')options.add_argument('--disable-gpu') # 允许在无GPU的环境下运行，可选options.add_argument('--window-size=1920x1080') # 建议设置browser = webdriver.Chrome(chrome_options=options)browser.get('https://www.baidu.com')browser.find_element_by_id('kw').send_keys('HELLO')browser.find_element_by_id('su').click()sleep(1) # 简单粗暴的等待，实际项目中勿用assert browser.title == u'HELLO_百度搜索'browser.save_screenshot('chrome-headless-test.png')Firefox版实例from time import sleepfrom selenium import webdriverfrom selenium.webdriver.firefox.options import Optionsoptions = Options()options.add_argument('--headless')# options.add_argument('--window-size=1920x1080') # Firefox无效browser = webdriver.Firefox(firefox_options=options)browser.set_window_size(1280, 1024) # 启动后设置浏览器大小，但是高度会随着访问的网页变化browser.get('https://www.baidu.com')browser.find_element_by_id('kw').send_keys('HELLO')browser.find_element_by_id('su').click()sleep(1)assert browser.title == u'HELLO_百度搜索'browser.save_screenshot('firefox-headless-test.png')总结浏览器HEADLESS模式可以让程序运行的环境更贴近用户访问的真实环境，相对于模拟UserAgent等方式得出的数据也会更加准确可靠。尤其在自动化测试领域，HEADLESS也有取代传统的带界面的自动化测试的趋势，有一些公司已经将实践投入生产中。我们可以在调试自动化测试时使用用户界面，当部署到持续集成环境中是启用HEADLESS，并开启多线程使用并行的方式来运行测试案例，这样效率会大大提高，而且因为界面被干扰而导致测试失败的概率也会降低。总的来说，至少在端对端的自动化测试中，HEADLESS模式没有明显的缺点，甚至可以成为网页自动化测试进化的下一个目标。参考文档 https://developer.mozilla.org/en-US/Firefox/Headless_mode https://intoli.com/blog/running-selenium-with-headless-firefox/ https://developers.google.com/web/updates/2017/04/headless-chrome https://about.gitlab.com/2017/12/19/moving-to-headless-chrome/" }, { "title": "Sentry - 处理异常日志的正确姿势", "url": "/posts/2018-05-11/collect-error-events-via-sentry/", "categories": "Tech", "tags": "python, error, logging", "date": "2018-05-11 00:00:00 +0800", "snippet": "在各种系统和应用里，无论你的代码再完美也还是会抛异常，出错误。今天的主角是当今比较流行的异常记录框架 - Sentry，来了解一下。关于日志管理应用越做越复杂，输出日志五花八门，有 print 的，有写 stdout 的，有写 stderr 的, 有写 logging 的，也有自定义 xxx.log 的。那么这将导致平台应用日志分布在各个地方，无法统一管理。而且可能用的还不止一种开发语言，想...", "content": "在各种系统和应用里，无论你的代码再完美也还是会抛异常，出错误。今天的主角是当今比较流行的异常记录框架 - Sentry，来了解一下。关于日志管理应用越做越复杂，输出日志五花八门，有 print 的，有写 stdout 的，有写 stderr 的, 有写 logging 的，也有自定义 xxx.log 的。那么这将导致平台应用日志分布在各个地方，无法统一管理。而且可能用的还不止一种开发语言，想规范和统一日志不是一件容易的事。为什么使用 SentrySentry 是一个集中式日志管理系统。它具备以下优点： 多项目，多用户 界面友好 可以配置异常出发规则，例如发送邮件 支持主流语言接口从 Sentry 的文档首页截下来的一张图，可以看到它支持目前主流的编程语言。安装和快速上手Sentry 支持部署到本地服务器，具体可以参考以下文档： https://docs.sentry.io/server/installation/但作为大多数个人开发者和中小企业，我更建议使用 Sentry 官网（https://sentry.io/）提供的云服务，你只需要注册一个Sentry账号，就可以快速享受到集中处理异常日志的服务。Sentry 免费版可以： 每月 10k 错误日志上限 支持所有平台和语言，功能无缩水 无限项目数量，仅单用户访问，不提供团队功能具体的价格表可以看这里： https://sentry.io/pricing/开始配置 DSN你可以认为 DSN（Data Source Name）是 Sentry 管理项目需要的PROJECT_ID，每个应用都需要对应一个 PROJECT_ID，以及用于身份认证的 PUBLIC_KEY 和 SECRET_KEY。由此组成一个这样的 DSN：{PROTOCOL}://{PUBLIC_KEY}:{SECRET_KEY}@{HOST}/{PATH}{PROJECT_ID}PROTOCOL 通常会是 http 或者 https，HOST 为 Sentry 服务的主机名和端口，PATH 通常为空。在你登入 Sentry 后台之后，你可以新建一个项目，之后就可以得到类似于下面这样一个 DSN。https://e055040d5@sentry.io/12345有了 DSN 以后，你就可以在客户端中将错误日志上传到 Sentry 了。配置客户端这里我主要以 Python 为例，其他编程语言的客户端配置可以参考官网文档，步骤大同小异。 https://docs.sentry.io/quickstart/首先通过 pip 安装 Sentry SDK。pip install raven --upgrade然后初始化客户端。from raven import ClientDSN = 'https://****@sentry.io/****'client = Client(DSN)最后，在你需要记录异常的代码为止调用client.captureException()即可。try: 1 / 0except ZeroDivisionError: client.captureException()很多时候我们的异常信息应该包含更多的上下文信息，这样对于我们做后续分析会有更多帮助，那么你可以在 Sentry 捕获异常前加入这些上下文。try: processing(user, data)except: client.user_context({ 'user': user.email, 'data': json.dumps(data) }) client.captureException()一些经验之谈当然，我们不可能在每处可能发生异常的代码为止都调用 Sentry，也不可能去修补过去的代码将 Sentry 一一植入，一个好的建议是，无论何时，你的程序都有统一的异常处理机制，最好是全局的。这样的话，你只要将 Sentry 写在全局的异常处理器即可。另外 Sentry 还对流行的开发框架提供了特别的支持，比如 Flask，Django 等等，在这些应用中你只要配置就行，不需要你去写什么全局的异常处理（虽然写起来也不难）。Flask 的例子：sentry = Sentry(dsn='http://public_key:secret_key@example.com/1')def create_app(): app = Flask(__name__) sentry.init_app(app) return appDjango 的例子：import osimport ravenINSTALLED_APPS = ( 'raven.contrib.django.raven_compat',)RAVEN_CONFIG = { 'dsn': 'http://public_key:secret_key@example.com/1', # If you are using git, you can also automatically # configure the release based on the git info. 'release': raven.fetch_git_sha(os.path.abspath(os.pardir)),}异常报告和提醒一旦你完成上面的配置，以后系统发生的所有错误异常都会被自动记录到 Sentry，查看报告就是一件轻松愉快的事情了。默认情况下，一旦异常发生，5 分钟内就会有一封邮件送到你邮箱，包含了异常信息的大致描述。当然你还可以将异常报警集成到更多系统中，比如 HICHAT，SLACK，IRC，WEBHOOKS，在 Sentry 后台提供了相应的入口。在 Sentry 的项目 Dashboard 你可以浏览到更详细的报告，比如按照异常信息的类别进行分类和过滤，也可以统计近期异常的状态和频率，非常方便。Sentry 还提供了异常信息的聚合，同样的错误有可能在多处抛出，传统的日志统计起来就不是很方便，在 Sentry 一目了然。另外你还可以针对异常问题进行分配和跟踪，例如指派团队的某个成员去处理某一类问题，对于长时间没有再发生的问题自动标记为解决等等。总结Sentry 还有有很多亮点，比如敏感信息过滤， release 版本跟踪，关键字查找，受影响用户统计，权限管理等。Sentry 的 plugin 模块还可以集成大量的第三方工具如： SLACK ， JIRA 。对我们来说最大的便利就是利用日志进行错误发现和排查的效率变高了。但是，我们能不能完全依赖 Senry 呢？有几点值得探讨：不是日志的替代品Sentry 的目的是为了让我们专注于系统与程序的异常信息，目的是提高排查问题的效率，日志事件的量到达一个限制时甚至丢弃一些内容。官方也提倡正确设置 Sentry 接收的日志 level 的同时，用户也能继续旧的日志备份。不是排查错误的万能工具Sentry 是带有一定策略的问题分析工具，以样本的形式展示部分原始日志的信息。信息不全面的同时，使用过程中也可能出现 Sentry 聚合所带来的负面影响，特别是日志记录质量不够的情况下。不是传统监控的替代品与传统的监控系统相比，Sentry 更依赖于发出的日志报告，而另外一些隐藏的逻辑问题或者业务问题很可能是不会得到反馈的。参考文档 https://docs.sentry.io/quickstart/ https://blog.csdn.net/bigsec/article/details/54091109" }, { "title": "说说Python中的单元测试", "url": "/posts/2018-04-08/unit-test-with-python/", "categories": "Tech", "tags": "python, unittest, pytest", "date": "2018-04-08 00:00:00 +0800", "snippet": "单元测试是每种编程语言必学的课题，是保护开发者的强力护盾，每个程序员都在时间允许的情况下尽可能多的写单元测试，今天我们不讨论其必要性，只抛砖引玉聊一聊 Python 中的单元测试，本文仅代表个人看法。标准库中难以忍受的 unittest很多时候我们总是认为标准库里的带的总是精挑细选的，如果不经过仔细打磨怎么可能入选为一等公民？但我要告诉你，Python 标准库里的单元测试框架真不是最好的，随...", "content": "单元测试是每种编程语言必学的课题，是保护开发者的强力护盾，每个程序员都在时间允许的情况下尽可能多的写单元测试，今天我们不讨论其必要性，只抛砖引玉聊一聊 Python 中的单元测试，本文仅代表个人看法。标准库中难以忍受的 unittest很多时候我们总是认为标准库里的带的总是精挑细选的，如果不经过仔细打磨怎么可能入选为一等公民？但我要告诉你，Python 标准库里的单元测试框架真不是最好的，随着你对 Python 的熟悉你甚至会讨厌这个 unittest。Python 一直崇尚简单，优雅，高效地完成事情，当你写完一个函数需要测试一下时，使用标准库的 unittest 你需要做这些事情： 新建单元测试脚本 导入单元测试依赖 继承单元测试类 实现单元测试方法具体的实例代码如下：import unittestclass IntegerArithmeticTestCase(unittest.TestCase): def testAdd(self): # test method names begin with 'test' self.assertEqual((1 + 2), 3) self.assertEqual(0 + 1, 1)if __name__ == '__main__': unittest.main()看上去还行，不是很难。但是渐渐地你会吐槽： 为啥我要新建一个文件来写测试？ 为啥我要继承一个类来写测试？ 为啥我要用 unittest 的 Assertion 来做断言？ 为啥 unitunit 的命名规则跟最佳实践不一样（mixedCase vs lower_case）？要回答以上问题，答案只有一个：历史原因。很久很久以前，Python 从 Java 借鉴了单元测试框架，包括命名规则和实现方式，一直沿用至今。不得不说这个框架没啥毛病，该有的功能的都有，想做的事都可以做，但是用起来总是没有爽的感觉。但是为啥伟大的社区力量为啥不把这个框架改的爽一点呢？没办法，我估计是为了世界和平，你要知道 Python 这个庞然大物能健康地活着，后面有无数的类库和方法在支撑，而这些类库和方法都被单元测试保护着，如果修改了单元测试框架导致兼容性问题，就成了千古罪人。见识简洁的单元测试 pytestPython 中很多大牛其实都有严重的强迫症，追求简洁和优雅的代码。必然的，他们会抛弃标准库中的 unittest，使用或者发明自己心仪的单元测试框架。正如其名，pytest 是一个无数人推荐并在使用的 Python 单元测试框架，它使用起来非常简单，只要你的方法名以 test 开头就可以，你可以和需要测试的方法放在一起，亦或是新建一个文件来专门整理单元测试，都可以。def your_func(): passdef test_your_func(): assert result这样的设计，就让你写单元测试成了顺手拈来的事，假如你写完了一个方法，想看看是否工作，在旁边直接写上一个test 开头的方法，稍微准备一下数据就可以验证这个方法好不好用，岂不妙哉？ The idioms that pytest first introduced brought a change in the Python community because they made it possible for test suites to be written in a very compact style, or at least far more compact than was ever possible before. Pytest basically introduced the concept that Python tests should be plain Python functions instead of forcing developers to include their tests inside large test classes.pytest 的发明让大家意识到单元测试原来可以这么轻松和随意，完全没有必要去继承一个所谓的测试类或者按照复杂的规则才能开始书写测试代码，这也是我选择和推荐它的理由。当然，如果原来你的单元测试时 unittest 写的话，pytest 其实也是有可能兼容的的。pytest 能够识别 unittest.TestCase 子类中的测试方法，如果文件名符合 test_*.py 或者 *_test.py 这样的规则。并且大多数 unittest 的功能都是被支持的，例如： @unittest.skip 装饰器; setUp/tearDown; setUpClass/tearDownClass();我觉得，pytest 有以下优点： 上手和使用足够简单 当 case 失败时信息足够丰富和直观，比如最后导致失败的变量值会打印出来 更丰富的运行参数 可以使用 assert 而不是 self.assert* 被广大 IDE 支持，社区资源丰富，用户群体大让单元测试和 IDE 无缝集成毕竟我们大多数人都不是神，不能用记事本写代码，IDE 才是我们正确搬砖的方式。Python 的首选 IDE 毋庸置疑就是 JetBrain 公司出品的 PyCharm。在 PyCharm 中只要你将默认的单元测试驱动改成 pytest，就可以在任意test开头的方法上通过右键菜单运行或者调试这个测试案例，非常方便。如果你要运行当前文件的所有测试，只要从非test方法的其他区域点击右键即可。或者修改任意已经运行过的 Configuration，添加你想要的参数，比如最多运行挂 3 个 case 就终止测试等等。闲话和总结单元测试的重要性大家都知道，大名鼎鼎的 TDD 应该都听过，但是真正在实践的少之又少。究其原因，一些人会说时间写代码都不够，哪还有空写单元测试。还有一些人就是嫌麻烦，在绝大多数编程语言里单元测试都是需要单独建立工程和目录的，写单元测试需要很多基础工作要做，本以为顺手就可以写的单元测试，实际上需要费九牛二虎之力还是在搭架子，太沮丧了。Python 的动态特性和灵活性让它有可能让单元测试超级简单，有可能你认为单元测试还是不要和业务代码混合在一起的好，那就多辛苦一点新建一个文件导入要测试的方法，写一个 test 开头的方法即可，不算太难，不要找推辞的理由。最后我的个人观点，单元测试其实还有一个非常重要的作用，就是替代函数文档注释。比如你写了一个函数，使用起来可能有那么一点复杂，你可以给它写一份清晰的注释文档，但是千言万语不如给我来个例子，单元测试可以充当例子的角色，什么样的输入，输出结果如何，一目了然。希望从今天起，你的代码也都有单元测试。" }, { "title": "Python 查找重复文件升级版 - photodup", "url": "/posts/2018-04-01/find-duplicate-photos-by-photodup/", "categories": "Tech", "tags": "python, flask", "date": "2018-04-01 00:00:00 +0800", "snippet": "之前写了一个简化版的使用 Python 查找目录中的重复文件，现在升级了一下，我们来提供一个友好的网页界面。思路上一个版本我们非常简单粗暴地将所有文件的 hash 扫描后保存到一个字典中，字典结构大概是这样的：files = [{'hash1':['file/path...','file/path...']}, {'hash2':['file/path...','file/p...", "content": "之前写了一个简化版的使用 Python 查找目录中的重复文件，现在升级了一下，我们来提供一个友好的网页界面。思路上一个版本我们非常简单粗暴地将所有文件的 hash 扫描后保存到一个字典中，字典结构大概是这样的：files = [{'hash1':['file/path...','file/path...']}, {'hash2':['file/path...','file/path...','file/path...']}, {'hash3':['file/path...']}]然后通过一个循环找出 hash 值对应的数组长度大于 1 的数组，现在我们把这个扫描结果保存到数据库中，之后只要查询数据库即可找到重复的文件。步骤我们大致需要几个步骤就可以让程序跑起来：git clone https://github.com/tobyqin/photodup.git # 克隆代码cd photoduppip install -r requirements.txt # 安装必要的依赖包python db.py # 创建DB表结构表结构不需要太复杂： id hash name path Existed 1 ab3d DCS_001.JPG path/to/DSC_001.JPG 1 2 1d2c DCS_002.JPG path/to/DSC_002.JPG 2 然后开始扫描你要检查的目录。python scan.py dir1 dir2你可以传入一个或者多个目录，默认只检索 jpg 文件，也可以修改config.py里的配置项来自定义。扫描结束后，启动 web 服务即可。python web.py顺利的话用浏览器打开 http://127.0.0.1:5001 就可以看到一个友好的网页，可以通过文件 hash 或者文件名来清理重复文件，可以预览图片文件。原理&amp;总结升级后的重复文件清理工具总共也不过两三百行代码，但是已经算是一个比较完整的程序，使用起来也方便了很多。升级过程中用到了前后端数据库各方面的知识，不管你的想法多简单，真正动手去实现才会有收获。 项目地址：https://github.com/tobyqin/photodup 技术栈：Python, SQL, Flask, Bootstrap, Jquery, CSS." }, { "title": "使用Python查找目录中的重复文件", "url": "/posts/2018-03-22/find-duplicate-files-by-python/", "categories": "Tech", "tags": "python", "date": "2018-03-22 00:00:00 +0800", "snippet": "是这样的，电脑上的堆积的照片有点多，而且重复的照片被放在了不同的目录，占用的空间越来越大，数量也多得已经不太适合人工分辨整理，写个Python脚本来处理吧。文件的唯一标识 - MD5假如你要处理的重复文件有不同的文件名，最简单的办法就是通过MD5来确定两个文件是不是一样的。def md5sum(filename, blocksize=65536): hash = hashlib.md5...", "content": "是这样的，电脑上的堆积的照片有点多，而且重复的照片被放在了不同的目录，占用的空间越来越大，数量也多得已经不太适合人工分辨整理，写个Python脚本来处理吧。文件的唯一标识 - MD5假如你要处理的重复文件有不同的文件名，最简单的办法就是通过MD5来确定两个文件是不是一样的。def md5sum(filename, blocksize=65536): hash = hashlib.md5() with open(filename, \"rb\") as f: for block in iter(lambda: f.read(blocksize), b\"\"): hash.update(block) return hash.hexdigest()这个方法可以快速获得一个文件的MD5值，blocksize 可以根据文件大小和CPU性能调整，一般选择的值约等于文件的平均大小。保存所有文件标识和路径接下来遍历所有文件，使用MD5作为key，路径作为value，保存起来。dup = {}def build_hash_dict(dir_path, pattern='*.jpg'): def save(file): hash = md5sum(file) if hash not in dup.keys(): dup[hash] = [file] else: dup[hash].append(file) p = Path(dir_path) for item in p.glob('**/' + pattern): save(str(item))处理重复文件最后一步非常简单，把上一步建立的字典做一个简单的过滤就能找到重复文件。def get_duplicate(): return {k: v for k, v in dup.items() if len(v) &gt; 1}for hash, files in get_duplicate().items(): print(\"{}: {}\".format(hash, files))接下来你可以根据自己的需要删除或者保留某个路径下的文件，本文到此为止。 完整的脚本代码： https://gist.github.com/tobyqin/9299d27bdb429ffaa7713ed760a44fbb" }, { "title": "自动为Flask写的API生成帮助文档", "url": "/posts/2018-02-27/auto-document-flask-api/", "categories": "Tech", "tags": "python, flask, api-doc", "date": "2018-02-27 00:00:00 +0800", "snippet": "Flask 是 Python 一个非常轻量的库，可以让你毫不费力地写一个简单的网站。如果你需要写一些后台 API 或者准备自动化测试数据时，Flask 是一个非常不错的选择。一个 API 例子举个例子，我们可以这样写几个 API，具体实现暂时略过：# views/api.pyapi = Blueprint('api', __name__)@api.route('/get_todo', met...", "content": "Flask 是 Python 一个非常轻量的库，可以让你毫不费力地写一个简单的网站。如果你需要写一些后台 API 或者准备自动化测试数据时，Flask 是一个非常不错的选择。一个 API 例子举个例子，我们可以这样写几个 API，具体实现暂时略过：# views/api.pyapi = Blueprint('api', __name__)@api.route('/get_todo', methods=['GET'])def get_todo(): \"\"\"Get all todo tasks.\"\"\" pass@api.route('/add_todo', methods=['POST'])def add_todo(): \"\"\" Add a todo task, please post data in json format, e.g. data = { \"name\":\"the title\", \"task\":\"the detail\" } \"\"\" pass@api.route('/delete_todo', methods=['GET', 'POST'])def delete_todo(): \"\"\"Delete a todo task.\"\"\" pass一旦你的 API 完成，你可能需要和调用方沟通调用的细节，最好给一些例子。明明你已经在代码里给所有方法都写了注释，难道还要再把这些注释拿出来重新组织排版一下？我猜你和我一样，听过这么一句话。 read the fucking manual!可是谁会去翻代码去看你的注释呢，何况你的代码他们还不一定能看到。如果能自动生成一个帮助页面那就好了。自动化 API 帮助文档假设我们的 API 都是以 http://127.0.0.1/api/* 的形式书写的，那么最好把 API 的完整列表就放在根目录下面，比如这样：view 方法的实现主要依靠 app.url_map 来获取 Flask 中所有的 API：# views/api.pydef get_api_map(): \"\"\"Search API from rules, if match the pattern then we said it is API.\"\"\" for rule in get_app().url_map.iter_rules(): if re.search(r'/api/.+', str(rule)): yield str(rule), rule.endpoint@api.route('/', methods=['GET'])def index(): \"\"\"List all API to this page, api_map contains each api url + endpoint.\"\"\" api_map = sorted(list(get_api_map())) index_url = url_for('main.index', _external=True) api_map = [(index_url + x[0][1:], x[1]) for x in api_map] return render_template('api_index.html', api_map=api_map)模板的实现：# templates/api_index.html {% extends \"./layout.html\" %} {% block title %}APIRoot{% endblock %} {% block breadcrumb_nav %}&lt;li&gt;&lt;a href=\"{{ url_for('api.index') }}\"&gt;Api Root&lt;/a&gt;&lt;/li&gt;{% endblock %} {% block page_header %}&lt;h1&gt;Api Root&lt;/h1&gt;{% endblock %} {% block content_area %}&lt;pre&gt;{{% for i in api_map %} \"&lt;a href=\"/docs/{{ i[1] }}\"&gt;{{ i[0] }}&lt;/a&gt;\"{{ \",\\n\" if not loop.last }}{% endfor %}}&lt;/pre&gt;{% endblock %}接下来我们来文档化每个具体的 API 方法，最终的展示结果会是这样的。view 方法的实现思路其实也很明确，我们可以通过 app.view_functions 这个字典找到每个 API 的 endpoint 所绑定的方法，然后访问方法的名字和文档即可。# views/main.pymain = Blueprint('main', __name__)@main.route('/', methods=['GET'])def index(): \"\"\"Redirect home page to docs page.\"\"\" return redirect(url_for('api.index'))@main.route('/docs/&lt;endpoint&gt;', methods=['GET'])def docs(endpoint): \"\"\"Document page for an endpoint.\"\"\" api = { 'endpoint': endpoint, 'methods': [], 'doc': '', 'url': '', 'name': '' } try: func = get_app().view_functions[endpoint] api['name'] = _get_api_name(func) api['doc'] = _get_api_doc(func) for rule in get_app().url_map.iter_rules(): if rule.endpoint == endpoint: api['methods'] = ','.join(rule.methods) api['url'] = str(rule) except: api['doc'] = 'Invalid api endpoint: \"{}\"!'.format(endpoint) return render_template('api_docs.html', api=api)def _get_api_name(func): \"\"\"e.g. Convert 'do_work' to 'Do Work'\"\"\" words = func.__name__.split('_') words = [w.capitalize() for w in words] return ' '.join(words)def _get_api_doc(func): if func.__doc__: return func.__doc__ else: return 'No doc found for this API!'模板的实现：{% extends \"./layout.html\" %} {% block title %}API - {{ api['name'] }}{%endblock %} {% block breadcrumb_nav %}&lt;li&gt;&lt;a href=\"{{ url_for('api.index') }}\"&gt;Api Root&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\"{{ api['url'] }}\"&gt;{{ api['name'] }}&lt;/a&gt;&lt;/li&gt;{% endblock %} {% block page_header %}&lt;h1&gt;{{ api['name'] | upper }}&lt;/h1&gt;{% endblock %} {% block content_area %}&lt;pre&gt;&lt;b&gt;Target:&lt;/b&gt;&lt;span&gt;&lt;a href=\"{{ api['url'] }}\"&gt;{{ api['url'] }}&lt;/a&gt;&lt;/span&gt;&lt;b&gt;Allow :&lt;/b&gt; &lt;span&gt;{{ api['methods'] }}&lt;/span&gt;&lt;b&gt;Usage :&lt;/b&gt; &lt;span&gt;{{ api['doc'] }}&lt;/span&gt;&lt;/pre&gt;{% endblock %}GitHub 项目地址如果你想看完整的例子，可以到我的 GitHub 去拉一份代码。 https://github.com/tobyqin/flask_api_doc只需要三步就可以在你的机器上运行 Demo：cd /path/to/flask_api/docpip install -r requirements.txtpython main.py如果你觉得 Demo 不错，欢迎给个 Star。有建议或者想法也可以拿来讨论。" }, { "title": "在Windows上搭建Jekyll运行环境", "url": "/posts/2018-01-26/setup-jekyll-environment-on-windows/", "categories": "Tech", "tags": "Ruby, Jekyll, Windows, Hexo", "date": "2018-01-26 00:00:00 +0800", "snippet": "静态页面博客的鼻祖就是Jekyll。Jekyll 和 Hexo静态博客目前最流行的也就是 Hexo 和 Jekyll，我一直都是 Hexo 的粉丝和用户，相对于 Jekyll 我想大多数人选择 Hexo 的原因跟我差不多： 安装本地环境简单，只需要 nodejs 和一行命令即可 官网文档非常优秀，极易上手 众多优秀的主题可选，配置功能完善 目录结构清晰易懂，内容和配置分离简单来说，H...", "content": "静态页面博客的鼻祖就是Jekyll。Jekyll 和 Hexo静态博客目前最流行的也就是 Hexo 和 Jekyll，我一直都是 Hexo 的粉丝和用户，相对于 Jekyll 我想大多数人选择 Hexo 的原因跟我差不多： 安装本地环境简单，只需要 nodejs 和一行命令即可 官网文档非常优秀，极易上手 众多优秀的主题可选，配置功能完善 目录结构清晰易懂，内容和配置分离简单来说，Hexo 可以让你快速开始写文字，但是 Jekyll 却不见得，Jekyll 的罪状我大致列一下： 本地环境在 Windows 上坑超多，很多人在这一步就放弃了，官方文档很挫 没有专门的主题目录，导致使用新主题需要覆盖安装 脚本和内容混合存放，不易管理和使用 托管后部署如果有错无法获取报错信息，如果没有本地环境根本没法调查另外，据说 Jekyll 站点的生成效率也比 Hexo 慢很多，不过我相信这对大多数人都没影响，我们的文章数量也不多。但是，Jekyll 比 Hexo 有一个让你欲罢不能的优点，那就是天然被 GitHub Pages 支持，当然国内的 Coding Pages，OSC Pages 等等产商也直接支持 Jekyll，俨然这就是一个静态页面的标准。使用 Jekyll，你可以不用考虑编译生成的问题，写完直接 commit，几分钟后就能看到效果。然而使用Hexo，你要么在本地生成页面后上传，要么找一个持续集成的服务（比如 Travis CI）帮你编译后上传，不是很简单。因为 Jekyll 那个欲罢不能的原因，今天就说说如果在 Windows 上用最快的速度准备一个Jekyll环境。参考资料： https://jekyllrb.com/docs/windows/通过Bash准备Jekyll环境如果你是 Windows 10，可以考虑使用 Bash 来运行Linux脚本和软件，详见 Bash on Ubuntu on Windows。启动 Bash 后，运行以下命令即可完成 Jekyll 的准备工作：sudo apt-get update -y &amp;&amp; sudo apt-get upgrade -ysudo apt-add-repository ppa:brightbox/ruby-ngsudo apt-get updatesudo apt-get install ruby2.3 ruby2.3-dev build-essentialsudo gem updatesudo gem install jekyll bundler可能遇到的坑： 在 Windows 10 启用 Bash 并不容易，不是所有系统版本都支持 就算版本支持，你的 Windows 如果是盗版或者不完整也有可能装不上 就算你能装上，这个 Bash 需要 Linux 子系统是一个大家伙，会吃掉你系统盘很多空间 就算你系统盘有足够的空间，从服务器下载数GB的文件网络不一定稳定，电脑还不能随便关机 不就是个Jekyll吗？至于嘛，Bash on Windows听起来简单，做起来就难了。通过 Ruby Installer 安装Ruby 的安装包可以从 https://rubyinstaller.org/ 下载安装，如果你了解Ruby或者运气很好，选择了正确Ruby版本，那么恭喜你，一切会非常顺利。不废话，直接说最佳答案。 下载Ruby 2.3.3 x64 后双击运行安装。 下载Development KIT x64 后解压到 c:\\devkit 目录 打开命令行工具，运行：cd c:\\devkitruby dk.rb initruby dk.rb reviewruby dk.rb install 安装Jekyllgem install jekyll bundler在本地运行 Jekyll更多命令建议参考官方文档 https://jekyllrb.com/docs/quickstart/# 创建一个新博客 ./myblogjekyll new myblog# 进入新建博客目录cd myblog# 安装必要的依赖bundle# 在本地启动预览jekyll serve# 打开浏览器 http://localhost:4000 即可看到效果可能遇到的坑如果有错误信息错误信息：ERROR: While executing gem ... (Encoding::UndefinedConversionError)U+200F to IBM862 in conversion from UTF-16LE to UTF-8 to IBM862解决办法：从Ruby安装目录找到registry.rb，修改默认Encoding为UTF-8。LOCALE = Encoding::UTF_8#LOCALE = Encoding.find(Encoding.locale_charmap)错误信息：compiling ruby_http_parser.ccompiling ryah_http_parser.clinking shared-object ruby_http_parser.soc:/devkit/mingw/bin/../lib/gcc/x86_64-w64-mingw32/4.7.2/../../../../x86_64-w64-mingw32/bin/ld.exe: cannot find -lgmpcollect2.exe: error: ld returned 1 exit statusmake: *** [ruby_http_parser.so] Error 1解决办法：Ruby版本不对，没有gmp这个库。建议卸载掉重装2.3.3。其他的一些问题 不要安装Ruby2.5，除非你有强烈的需求。 Ruby2.4 以后，在安装完成后会让你选择 MSYS2 Devkit，但是国内的网络环境你基本上装不了。 Ruby2.4 以后，你可以通过 ridk install 安装 Devkit，国内网络环境，难。 Ruby2.4 以后，缺少Jekyll需要的依赖，目前我没办法解决。综上，不要使用Ruby2.4来准备Jekyll环境，不然你会很难过。小贴士&amp;小技巧很多朋友可能不知道，如果你已经初始化了Hexo或者Jekyll，后面写博时就可以完全抛开本地环境，专注于内容就行。如果你是Hexo，安装完成后并且配置了自动化部署，以后写博客只需要在/source/_posts/目录下新建Markdown文件，完成后提交即可。新建的文章样式可以直接从该目录复制后修改，或者你从模板目录 /scaffolds/ 中拷贝过来也行。如果你是Jekyll，直接从/_posts/新建文件即可，操作同上。新博客的文件名最好也都符合yyyy-mm-dd-name.md的样式，主要是方便排序和查阅，另外Jekyll也只认识这种样式。" }, { "title": "认识 Python 中的 defaultdict", "url": "/posts/2018-01-20/python-default-dict-intro/", "categories": "Tech", "tags": "python, defaultdict", "date": "2018-01-20 00:00:00 +0800", "snippet": "今天我们的主角是defaultdict，同时也会介绍一下魔法方法__missing__()，本文主要来源于网友博客，分享给有需要的人。默认值可以很方便众所周知，在Python中如果访问字典中不存在的键，会引发KeyError异常。但是有时候，字典中的每个键都存在默认值是非常方便的。例如下面的例子：strings = ('puppy', 'kitten', 'puppy', 'puppy', ...", "content": "今天我们的主角是defaultdict，同时也会介绍一下魔法方法__missing__()，本文主要来源于网友博客，分享给有需要的人。默认值可以很方便众所周知，在Python中如果访问字典中不存在的键，会引发KeyError异常。但是有时候，字典中的每个键都存在默认值是非常方便的。例如下面的例子：strings = ('puppy', 'kitten', 'puppy', 'puppy', 'weasel', 'puppy', 'kitten', 'puppy')counts = {}for kw in strings: counts[kw] += 1该例子统计strings中某个单词出现的次数，并在counts字典中作记录。单词每出现一次，在counts相对应的键所存的值数字加1。但是事实上，运行这段代码会抛出KeyError异常，出现的时机是每个单词第一次统计的时候，因为Python的dict中不存在默认值的说法，可以在Python命令行中验证：&gt;&gt;&gt; counts = dict()&gt;&gt;&gt; counts{}&gt;&gt;&gt; counts['puppy'] += 1Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;KeyError: 'puppy'使用判断语句检查既然如此，首先可能想到的方法是在单词第一次统计的时候，在counts中相应的键存下默认值1。这需要在处理的时候添加一个判断语句：strings = ('puppy', 'kitten', 'puppy', 'puppy', 'weasel', 'puppy', 'kitten', 'puppy')counts = {}for kw in strings: if kw not in counts: counts[kw] = 1 else: counts[kw] += 1# counts:# {'puppy': 5, 'weasel': 1, 'kitten': 2}使用dict.setdefault()方法也可以通过dict.setdefault()方法来设置默认值：strings = ('puppy', 'kitten', 'puppy', 'puppy', 'weasel', 'puppy', 'kitten', 'puppy')counts = {}for kw in strings: counts.setdefault(kw, 0) counts[kw] += 1dict.setdefault()方法接收两个参数，第一个参数是健的名称，第二个参数是默认值。假如字典中不存在给定的键，则返回参数中提供的默认值；反之，则返回字典中保存的值。利用dict.setdefault()方法的返回值可以重写for循环中的代码，使其更加简洁：strings = ('puppy', 'kitten', 'puppy', 'puppy', 'weasel', 'puppy', 'kitten', 'puppy')counts = {}for kw in strings: counts[kw] = counts.setdefault(kw, 0) + 1使用collections.defaultdict类以上的方法虽然在一定程度上解决了dict中不存在默认值的问题，但是这时候我们会想，有没有一种字典它本身提供了默认值的功能呢？答案是肯定的，那就是collections.defaultdict。defaultdict类就好像是一个dict，但是它是使用一个类型来初始化的：&gt;&gt;&gt; from collections import defaultdict&gt;&gt;&gt; dd = defaultdict(list)&gt;&gt;&gt; dddefaultdict(&lt;type 'list'&gt;, {})defaultdict类的初始化函数接受一个类型作为参数，当所访问的键不存在的时候，可以实例化一个值作为默认值：&gt;&gt;&gt; dd['foo'][]&gt;&gt;&gt; dddefaultdict(&lt;type 'list'&gt;, {'foo': []})&gt;&gt;&gt; dd['bar'].append('quux')&gt;&gt;&gt; dddefaultdict(&lt;type 'list'&gt;, {'foo': [], 'bar': ['quux']})需要注意的是，这种形式的默认值只有在通过dict[key]或者dict.__getitem__(key)访问的时候才有效，这其中的原因在下文会介绍。&gt;&gt;&gt; from collections import defaultdict&gt;&gt;&gt; dd = defaultdict(list)&gt;&gt;&gt; 'something' in ddFalse&gt;&gt;&gt; dd.pop('something')Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;KeyError: 'pop(): dictionary is empty'&gt;&gt;&gt; dd.get('something')&gt;&gt;&gt; dd['something'][]defaultdict类除了接受类型名称作为初始化函数的参数之外，还可以使用任何不带参数的可调用函数，到时该函数的返回结果作为默认值，这样使得默认值的取值更加灵活。下面用一个例子来说明，如何用自定义的不带参数的函数zero()作为defaultdict类的初始化函数的参数：&gt;&gt;&gt; from collections import defaultdict&gt;&gt;&gt; def zero():... return 0...&gt;&gt;&gt; dd = defaultdict(zero)&gt;&gt;&gt; dddefaultdict(&lt;function zero at 0xb7ed2684&gt;, {})&gt;&gt;&gt; dd['foo']0&gt;&gt;&gt; dddefaultdict(&lt;function zero at 0xb7ed2684&gt;, {'foo': 0})利用collections.defaultdict来解决最初的单词统计问题，代码如下：from collections import defaultdictstrings = ('puppy', 'kitten', 'puppy', 'puppy', 'weasel', 'puppy', 'kitten', 'puppy')counts = defaultdict(lambda: 0) # 使用lambda来定义简单的函数for s in strings: counts[s] += 1defaultdict类是如何实现的通过上面的内容，想必大家已经了解了defaultdict类的用法，那么在defaultdict类中又是如何来实现默认值的功能呢？这其中的关键是使用了看__missing__()这个方法：&gt;&gt;&gt; from collections import defaultdict&gt;&gt;&gt; print defaultdict.__missing__.__doc____missing__(key) # Called by __getitem__ for missing key; pseudo-code: if self.default_factory is None: raise KeyError(key) self[key] = value = self.default_factory() return value通过查看__missing__()方法的docstring，可以看出当使用__getitem__()方法访问一个不存在的键时dict[key]这种形式实际上是__getitem__()方法的简化形式)，会调用__missing__()方法获取默认值，并将该键添加到字典中去。关于__missing__()方法的具体介绍可以参考Python官方文档中的”Mapping Types — dict“一节。文档中介绍，从2.5版本开始，如果派生自dict的子类定义了__missing__()方法，当访问不存在的键时，dict[key]会调用__missing__()方法取得默认值。从中可以看出，虽然dict支持__missing__()方法，但是在dict本身是不存在这个方法的，而是需要在派生的子类中自行实现这个方法。可以简单的验证这一点：&gt;&gt;&gt; print dict.__missing__.__doc__Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;AttributeError: type object 'dict' has no attribute '__missing__'同时，我们可以进一步的做实验，定义一个子类Missing并实现__missing__()方法:&gt;&gt;&gt; class Missing(dict):... def __missing__(self, key):... return 'missing'...&gt;&gt;&gt; d = Missing()&gt;&gt;&gt; d{}&gt;&gt;&gt; d['foo']'missing'&gt;&gt;&gt; d{}返回结果反映了__missing__()方法确实发挥了作用。在此基础上，我们稍许修改__missing__()方法,使得该子类同defautldict类一样为不存在的键设置一个默认值：&gt;&gt;&gt; class Defaulting(dict):... def __missing__(self, key):... self[key] = 'default'... return 'default'...&gt;&gt;&gt; d = Defaulting()&gt;&gt;&gt; d{}&gt;&gt;&gt; d['foo']'default'&gt;&gt;&gt; d{'foo': 'default'}在旧版本的Python中实现defaultdictdefaultdict类是从2.5版本之后才添加的，在一些旧版本中并不支持它，因此为旧版本实现一个兼容的defaultdict类是必要的。这其实很简单，虽然性能可能未必如2.5版本中自带的defautldict类好，但在功能上是一样的。首先，__getitem__()方法需要在访问键失败时，调用__missing__()方法：class defaultdict(dict): def __getitem__(self, key): try: return dict.__getitem__(self, key) except KeyError: return self.__missing__(key)其次，需要实现__missing__()方法用来设置默认值：class defaultdict(dict): def __getitem__(self, key): try: return dict.__getitem__(self, key) except KeyError: return self.__missing__(key) def __missing__(self, key): self[key] = value = self.default_factory() return value然后，defaultdict类的初始化函数__init__()需要接受类型或者可调用函数参数:class defaultdict(dict): def __init__(self, default_factory=None, *a, **kw): dict.__init__(self, *a, **kw) self.default_factory = default_factory def __getitem__(self, key): try: return dict.__getitem__(self, key) except KeyError: return self.__missing__(key) def __missing__(self, key): self[key] = value = self.default_factory() return value最后，综合以上内容，通过以下方式完成兼容新旧Python版本的代码：try: from collections import defaultdictexcept ImportError: class defaultdict(dict): def __init__(self, default_factory=None, *a, **kw): dict.__init__(self, *a, **kw) self.default_factory = default_factory def __getitem__(self, key): try: return dict.__getitem__(self, key) except KeyError: return self.__missing__(key) def __missing__(self, key): self[key] = value = self.default_factory() return value参考文档https://docs.python.org/2/library/collections.html#collections.defaultdict" }, { "title": "识别图片中的文字 - Tesseract 和 百度云OCR的对比", "url": "/posts/2018-01-16/chinese-text-ocr-via-python/", "categories": "Tech", "tags": "python, ocr, tesseract, baidu-ocr", "date": "2018-01-16 00:00:00 +0800", "snippet": "当今时代人工智能都已经是烂大街的词了，OCR 应该也很多人都知道。 OCR （Optical Character Recognition，光学字符识别）是指电子设备（例如扫描仪或数码相机）检查纸上打印的字符，通过检测暗、亮的模式确定其形状，然后用字符识别方法将形状翻译成计算机文字的过程。本文主要记录了通过 Python 使用 OCR 的两次尝试。TesseractTesseract，一款由...", "content": "当今时代人工智能都已经是烂大街的词了，OCR 应该也很多人都知道。 OCR （Optical Character Recognition，光学字符识别）是指电子设备（例如扫描仪或数码相机）检查纸上打印的字符，通过检测暗、亮的模式确定其形状，然后用字符识别方法将形状翻译成计算机文字的过程。本文主要记录了通过 Python 使用 OCR 的两次尝试。TesseractTesseract，一款由 HP 实验室开发由 Google 维护的开源 OCR（Optical Character Recognition , 光学字符识别）引擎，特点是开源，免费，支持多语言，多平台。项目地址：https://github.com/tesseract-ocr/tesseract安装使用Tesseract 的安装比较简单，在 mac 可以通过 brew 安装。brew install --with-training-tools tesseract在 windows 可以通过 exe 安装包安装，下载地址可以从 GitHub 项目中的 wiki 找到。安装完成后记得将 Tesseract 执行文件的目录加入到 PATH 中，方便后续调用。另外，默认安装会包含英文语言训练包，如果需要支持简体中文或者繁体中文，需要在安装时勾选。或者安装结束后到项目地址下载：https://github.com/tesseract-ocr/tessdata下载好的语言包放入到安装目录中的 testdata 下即可。在 windows 系统你还需要将 testdata 目录也加入环境变量。TESSDATA_PREFIX=C:\\Program Files (x86)\\Tesseract-OCR\\tessdata如果一切就绪，你在命令行中就可以使用 Tesseract 命令。# tesseractUsage: tesseract --help | --help-psm | --help-oem | --version tesseract --list-langs [--tessdata-dir PATH] tesseract --print-parameters [options...] [configfile...] tesseract imagename|stdin outputbase|stdout [options...] [configfile...]OCR options: --tessdata-dir PATH Specify the location of tessdata path. --user-words PATH Specify the location of user words file. --user-patterns PATH Specify the location of user patterns file. -l LANG[+LANG] Specify language(s) used for OCR. -c VAR=VALUE Set value for config variables. Multiple -c arguments are allowed. --psm NUM Specify page segmentation mode. --oem NUM Specify OCR Engine mode.NOTE: These options must occur before any configfile.通过命令行你就可以完成简单的图片文字识别任务。tesseract test.png outfile -l chi_sim通过 Python 调用Tesseract 安装完成后可以很方便的被 Python 调用，你需要安装两个包。pip install pillowpip install pytesseract一个简单的图片转文字的函数实现如下。from PIL import Imageimport pytesseractclass Languages: CHS = 'chi_sim' CHT = 'chi_tra' ENG = 'eng'def img_to_str(image_path, lang=Languages.ENG): return pytesseract.image_to_string(Image.open(image_path), lang)print(img_to_str('image/test1.png', lang=Languages.CHS))print(img_to_str('image/test2.png', lang=Languages.CHS))测试图片- test1.png：识别结果：process image file \"image/test1.png\" in 1.4782530478747697 seconds8 所 调 人 , 在 - 方 。深 从 久 , 定 中 央。 所 澈 伊 人 , 圭 水 淳。 淇 渡 从 之 , 定 圭 北 中 坂 。。 所 澈 伊人 , 圭 水 浩从 丿 , 定 圭 水 中 沥 。测试图片 - test2.png识别结果：process image file \"image/test2.png\" in 1.2131140296607923 seconds清 明 时 节 雨 纷 纷 , 路 上 行 人 欲 断 魂信 问 酒 家 何 处 有 , 牧 奕 通 指 枪 花 村 。小结Tesseract 在识别清晰的标准中文字体效果还行，稍微复杂的情况就很糟糕，而且花费的时间也很多，我个人觉得唯一的优点就是免费了。如果你不介意多花时间，可以考虑使用它提供的训练功能自定义你的语言库，那样在特定场景下识别率应该能上一个台阶。百度云 OCR这是偶然的发现，百度云提供了一定额度的免费的 OCR API，目前是每日 500 次，做做研究或者小应用还勉强够用，本文主要为了测试其效果。文档地址：https://cloud.baidu.com/doc/OCR/OCR-Python-SDK.html安装使用首先你需要注册一个百度云 BCE 账号，然后从控制面板新建一个文字识别应用。之后你就可以获得调用 API 需要的 AppID，API Key 和 Secret Key。后面只要根据官方文档一步一步走就可以了。pip install baidu-aip封装和调用参考文档： https://cloud.baidu.com/doc/OCR/OCR-Python-SDK.html#.E6.8E.A5.E5.8F.A3.E8.AF.B4.E6.98.8Efrom aip import AipOcrconfig = { 'appId': 'your-id', 'apiKey': 'your-key', 'secretKey': 'your-secret-key'}client = AipOcr(**config)def get_file_content(file): with open(file, 'rb') as fp: return fp.read()def img_to_str(image_path): image = get_file_content(image_path) result = client.basicGeneral(image) if 'words_result' in result: return '\\n'.join([w['words'] for w in result['words_result']])测试图片- test1.png：识别结果：process image file \"image/test1.png\" in 0.6331169034812572 seconds蒹葭先秦:佚名蒹葭苍苍,白露为霜。所谓伊人,在水一方。溯洄从之,道阻且长。溯游从之,宛在水中央。蒹葭萋萋,白露未晞。所谓伊人,在水之湄。溯洄从之,道阳且跻。溯游从之,宛在水中坻。蒹葭采采,白露未已。所谓伊人,在水之涘。溯洄从之,道阻且右。溯游从之,宛在水中沚。测试图片 - test2.png识别结果：process image file \"image/test2.png\" in 0.6621812639450142 seconds清明时节雨纷纷,路上行人欲断魂。借问酒家何处有,牧童遥指杏花村。小结测试结果很明显，我只能说百度云这个 OCR 真是挺厉害的，一个错别字都没有，不服不行。论中文，还是百度比谷歌更懂一点。而且百度 OCR 提供了更多的参数让你更灵活的处理图片，比如自定义旋转，返回可信度，特定类型证件识别等等。更多的 OCR除了本文提到的 OCR，其实还是有不少其他选择。有一些直接提供 Demo 页面，你直接上传一张图片就可以直接看到识别效果，比如： 微软 Azure 图像识别：https://azure.microsoft.com/zh-cn/services/cognitive-services/computer-vision/ 有道智云文字识别：http://aidemo.youdao.com/ocrdemo 阿里云图文识别：https://www.aliyun.com/product/cdi/ 腾讯 OCR 文字识别： https://cloud.tencent.com/product/ocr你有没有发现所有的大公司都有这样的服务？以后我们买买买就行，花大力气去发明轮子就没多大意义了。" }, { "title": "【问题】使用Python将字符串过滤并保留关键字", "url": "/posts/2018-01-15/filter-string-by-keyword/", "categories": "Quiz", "tags": "python, quiz", "date": "2018-01-15 00:00:00 +0800", "snippet": "Python 算法备忘。问题描述给出一个关键词列表:keys = ['aaa','bbb','ccc']给出一个字符串 str，如果字符串中有包含列表 keys 中的子串，则过滤并保留下来，其余部分则删除。请问可以如何实现？例子:str = 'aaaawtf he heheccc'过滤后变成:'aaa ccc'例子二：str = 'aaabbb/&amp;edfg cccaaa'过滤后变成：...", "content": "Python 算法备忘。问题描述给出一个关键词列表:keys = ['aaa','bbb','ccc']给出一个字符串 str，如果字符串中有包含列表 keys 中的子串，则过滤并保留下来，其余部分则删除。请问可以如何实现？例子:str = 'aaaawtf he heheccc'过滤后变成:'aaa ccc'例子二：str = 'aaabbb/&amp;edfg cccaaa'过滤后变成：'aaabbb cccaaa'要求尽可能保留原字符串的相对位置信息，比如aaa和bbb是连在一块的，就连在一块被保留下来。实现思路解决这个问题可以分两步走，第一步，找出关键字位置并记录；第二步，重新组合拼接。str = 'aaabbb/&amp;edfg cccaaa'keys = ['aaa', 'bbb', 'ccc']found = {k: [] for k in keys}total_length = len(str)# 按key依次遍历字符串，保存出现的位置for key in keys: length, i = len(key), 0 while i + length &lt;= total_length: s = str[i:i + length] if s == key: found[key].append(i) i += length else: i += 1print(found)# {'aaa': [0, 16], 'bbb': [3], 'ccc': [13]}result, next_match_index = '', -1# 重新组合，如果坐标重叠连接符为空，否则为空格for i in range(total_length): for k, v in found.items(): if i in v: split = '' if next_match_index == i else ' ' result = result + split + k next_match_index = i + len(k)print(result)# aaabbb cccaaa改进方案其实可以考虑以上两步可以合并一起做掉，不过代码就相对没那么好理解了。str = 'aaaabbb/&amp;edfg cccaaa'keys = ['aaa', 'bbb', 'ccc']total_length = len(str)result, next_match_index, skip = '', -1, 0for i in range(total_length): if skip: skip -= 1 continue for key in keys: # 查找当前位置是否有match的key length = len(key) if i + length &lt;= total_length: # 确保index不越界 s = str[i:i + length] if s == key: # 如果有match的key，添加到结果 split = '' if next_match_index == i else ' ' result = result + split + key next_match_index = i + length #预测相邻key的位置 skip = length - 1 #需要跳过当前key后匹配下一个key break # 已经找到匹配key，可以结束keys的遍历print(result)" }, { "title": "【问题】从一长串数字中找到重复多次的三个数字", "url": "/posts/2018-01-03/get-repeat-digits-from-a-long-number/", "categories": "Quiz", "tags": "quiz, python", "date": "2018-01-03 00:00:00 +0800", "snippet": "Python 算法备忘。问题描述 https://stackoverflow.com/questions/47581326/given-a-string-of-a-million-numbers-return-all-repeating-3-digit-numbers假设给定一个很长的数字，比如PI精确到100万位，找到其中重复出现相邻三个数字。比如给定的数字是12332233323212...", "content": "Python 算法备忘。问题描述 https://stackoverflow.com/questions/47581326/given-a-string-of-a-million-numbers-return-all-repeating-3-digit-numbers假设给定一个很长的数字，比如PI精确到100万位，找到其中重复出现相邻三个数字。比如给定的数字是1233223332321234323123，那么结果应该是：123 repeat 3 times233 repeat 2 times323 repeat 2 times332 repeat 2 times解决思路如果要统计相邻三个数字的重复次数，那么必然需要将其所有可能都列出来，通过Python的切片我们很容易实现：number = '1233223332321234323123'split = [number[position:position + 3] for position in range(len(number) - 2)]print(split)# ['123', '233', '332', '322', '223', '233', '333', '332', '323', '232', '321', '212', '123', '234', '343', '432', '323', '231', '312', '123']接下来我们需要统计切好的序列里各个数字出现的次数，因为需要处理是3位数字，可以考虑新建一个长度为1000的空序列，如果数字出现就在对应位置加一，达到统计的目的。seq = [0] * 1000for x in split: seq[int(x)] += 1最后我们只要把新序列里统计值大于1的打印出来即可。for i in range(1000): if seq[i] &gt; 1: print('{} repeat {} times'.format(i, seq[i]))# 123 repeat 3 times# 233 repeat 2 times# 323 repeat 2 times# 332 repeat 2 times我们可以用更加优雅的方式来呈现以上算法，简洁但不简单。seq = [0] * 1000for val in [int(number[pos:pos+3]) for pos in range(len(number) - 2)]: seq[val] += 1print ([(num, seq[num]) for num in range(1000) if seq[num] &gt; 1])以上便是Stack Overflow上原题的最佳答案。拓展思考如果这个问题给定的不是数字，而是字符串比如abccdbadfdaabc，依然是要找到相邻的3个重复字母，你有没有好办法？" }, { "title": "教你使用50行Python代码刷王者荣耀金币", "url": "/posts/2017-12-14/hack-way-to-get-golden-coins-for-king-of-glory/", "categories": "Tech", "tags": "adb, android, python, kog, game", "date": "2017-12-14 00:00:00 +0800", "snippet": "用脚本来刷金币。原理王者荣耀的冒险模式里有个挑战模式，第一次过关可以获得比较多的金币，后面重新挑战还是会获得少量金币，这不算是bug，你不嫌烦手动蛮力也可以刷金币。 推荐关卡：陨落的废都 - 魔女回忆此关卡使用纯输出英雄20秒左右可以打BOSS，50秒左右可以通关，每次重复通关可以获得奖励19金币。在开挂前建议你手动通关体验一下。此为游戏原理。简单来说，需要执行以下步骤： 界面打开至挑战...", "content": "用脚本来刷金币。原理王者荣耀的冒险模式里有个挑战模式，第一次过关可以获得比较多的金币，后面重新挑战还是会获得少量金币，这不算是bug，你不嫌烦手动蛮力也可以刷金币。 推荐关卡：陨落的废都 - 魔女回忆此关卡使用纯输出英雄20秒左右可以打BOSS，50秒左右可以通关，每次重复通关可以获得奖励19金币。在开挂前建议你手动通关体验一下。此为游戏原理。简单来说，需要执行以下步骤： 界面打开至挑战关卡：陨落的废都 - 魔女回忆 【点击下一步】 进入阵容调整界面，提前安排好阵容。【点击闯关】 进入挑战界面。【点击右上角-自动-等待挑战结束】 进入挑战完成界面。【点击屏幕继续】 进入关卡奖励界面。【点击再次挑战】 进入阵容调整界面，循环至步骤1或步骤2【貌似取决于游戏区和版本】只要你能模拟屏幕点击就可以完成刷金币的脚本，在安卓模拟界面点击最简单的方式就是使用ADB发送命令，不需要root手机，不需要安装第三方软件，方便快捷。ADB命令点击屏幕坐标[x, y] 可以使用命令：adb shell input tap x yIOS 是否有类似工具和命令，我不清楚，如果有那么实现自动刷金币也很简单。准备 本脚本适用于安卓游戏区，需要真实安卓手机。 手机需开启USB调试模式，允许电脑调试。 电脑需安装好安卓驱动，一般豌豆荚或者各种管家可以自动帮你装好。 电脑需要有ADB工具集，很多方式可以获取。 ADB工具需要加入环境变量PATH中，方便随时调用。 电脑上需要安装Python，因为这是我选择的脚本语言。专业的开发测试人员，也可以参考我的另外两篇博客： 在 Windows 下搭建 Appium + Android 自动化测试环境 在Mac OSX 上配置Appium+Android自动化测试环境如果只是为了刷金币，只需要安装好驱动和ADB工具即可。步骤如果万事具备，那么步骤就非常简单。环境检测 用USB连接手机，如果弹出警告，请允许电脑调试手机。 使用命令 adb devices 检验adb和手机状态已经就绪。$ adb devicesList of devices attachedb******4 device模拟点击屏幕，比如你可以打开画图软件，然后运行命令：adb shell input tap 500 500如果如果一切OK，那么你将看到画图软件在坐标（500,500）的位置有一个点。代码实现通关需要点击的屏幕位置是固定的，加上注释我们只需要不到30行代码就可以完成。def tap_screen(x, y): os.system('adb shell input tap {} {}'.format(x, y))def do_money_work(): print('#0 start the game') tap_screen(1600, 970) sleep(3) print('#1 ready, go!!!') tap_screen(1450, 910) sleep(15) print('#2 auto power on!') tap_screen(1780, 40) for i in range(25): tap_screen(1000, 500) sleep(1) print('#3 do it again...\\n') tap_screen(1430, 980) sleep(3)然后我们写一个主函数来循环刷钱。if __name__ == '__main__': for i in range(repeat_times): print('round #{}'.format(i + 1)) do_money_work()拿来主义如果你喜欢拿来主义，请访问本文项目地址： https://github.com/tobyqin/kog-money然后： 下载项目中的 kog.py 到本地。 将游戏打开，进入挑战模式，魔女回忆，阵容调整界面。 根据手机性能和分辨率，调整kog.py中的参数。（手机分辨率，刷金次数等等） 运行以下命令，手机上就可以查看实时运行效果。python kog.py注意： 每周金币上限4200，需要接近4个小时，不建议一次刷满，手机和你都要休息。 铭文，手机性能，英雄选择都会影响通关速度，自己微调等待时间。 如果你不想被USB数据线束缚，可以考虑使用无线连接Android真机。声明本脚本纯属娱乐和探索的心得，如果你因为违反了游戏规则导致被封号，我概不负责。" }, { "title": "使用ADB无线连接Android真机进行调试", "url": "/posts/2017-12-12/connect-adb-via-wifi/", "categories": "Tech", "tags": "adb, android, automation", "date": "2017-12-12 00:00:00 +0800", "snippet": "其实这已经是一个很古老的知识了，记录一下备忘。准备工作 手机和电脑需要在同一个局域网内 电脑上已经安装好ADB工具，可以是Mac或者Windows开始1. 打开手机端口让手机在指定的端口可以接收到TCP/IP连接。 确保手机开启了usb调试 用usb线把手机和电脑连接起来 执行命令：adb tcpip 5555执行成功后就可以把usb线拔掉了，端口可以不是5555，这个官方默认使用...", "content": "其实这已经是一个很古老的知识了，记录一下备忘。准备工作 手机和电脑需要在同一个局域网内 电脑上已经安装好ADB工具，可以是Mac或者Windows开始1. 打开手机端口让手机在指定的端口可以接收到TCP/IP连接。 确保手机开启了usb调试 用usb线把手机和电脑连接起来 执行命令：adb tcpip 5555执行成功后就可以把usb线拔掉了，端口可以不是5555，这个官方默认使用的。2. 找到手机的IP地址一般在 设置-关于手机-状态信息-IP地址可以找到。比如，我这里看到手机的IP地址是192.168.1.1003. 通过IP地址连接手机执行命令：adb connect 192.168.1.100:5555如果提示： connected to 192.160.1.100:5555则表示连接成功，如果端口号是5555可以省略，直接：adb connect 192.168.1.1004. 如果没有连接成功如果确定你的网络和端口都没问题，可以尝试重启一下adb服务： adb kill-server然后再进行连接，实在还是不行就Google吧。5. 连接成功如果连接成功的话，执行以下命令查看当前连接的设备列表：adb devices可以看到连接的设备，像这样 $ adb devicesList of devices attached192.168.1.100:5555\tdevice以后没有数据线也可以调试手机或者在上面运行自动化测试了。注意事项 更换一个网络环境需要使用新IP重新connect即可。 但是如果手机重启了，就需要重新连接数据线再次开启端口。 开启端口可以通过adb，也可以直接在手机上打开，但一般需要root权限和特殊软件。" }, { "title": "在Mac OSX 上配置 Appium + Android 自动化测试环境", "url": "/posts/2017-12-10/setup-appium-test-environment-on-mac-osx/", "categories": "Tech", "tags": "python, appium, mac, automation", "date": "2017-12-10 00:00:00 +0800", "snippet": "Appium是手机端自动化测试的必备知识。前提准备开始正文之前，你需要准备好一些基本条件： 安装好Mac OSX 操作系统的设备 能够访问中国局域网以外资源的方法（没有也行，但很痛苦） 已经安装好 homebrew 已经安装好 Python3.x，可以通过brew安装 已经安装好 Java Runtime Environment，可以通过brew安装安装 Android Studi...", "content": "Appium是手机端自动化测试的必备知识。前提准备开始正文之前，你需要准备好一些基本条件： 安装好Mac OSX 操作系统的设备 能够访问中国局域网以外资源的方法（没有也行，但很痛苦） 已经安装好 homebrew 已经安装好 Python3.x，可以通过brew安装 已经安装好 Java Runtime Environment，可以通过brew安装安装 Android Studio / SDK本文主要为了测试安卓应用，那么这里我们就需要安装Android Studio或者Android SDK。 Android Studio - 完整的开发以及测试工具，需要梯子 Android SDK + Platform Tools - 足够完成自动化测试，通过homebrew安装如果只是为了自动化测试建议安装SDK足矣，使用brew命令轻松搞定。brew cask install android-sdkbrew cask install android-platform-tools在国内使用brew可以事先配置好国内源，速度会快很多。如果有梯子可以选择Android Studio，安装方法很简单，官网下载后一路Next，启动后会让你把SDK等等一系列依赖都装好，一步到位。准备Android 模拟器或者使用真机如果SDK已经安装完毕，应该可以使用adb命令来检查可用的模拟器或者已经连接到电脑上的实体手机。adb devices如果不知道adb工具在哪，可以先在命令行里通过find搜索。find /Users -name adb # 搜索用户目录find / -name adb # 搜索全盘找到之后可以把 adb 目录加入PATH，方便后续使用。一般在 ~/Library/Android/sdk/platform-tools/adb，如果通过brew安装，会自动建立软链接后加入PATH。模拟器可以使用官方模拟器（Android Studio自带），或者口碑较好的 Genymotion，具体请查阅其他文章，搭模拟器其实也挺不容易的。安装AppiumAppium 可以通过多种方式安装。方式一：使用 NodeJS 安装首先通过brew安装nodejs：brew install node配置国内源，在个人目录下新建一个.npmrc文件，写入：registry=https://registry.npm.taobao.org/开始安装Appium：npm install -g appiumnpm install -g appium-doctorAppium-doctor 可以帮你诊断测试环境，建议安装。方式二：下载Appium桌面版安装官方的Appium桌面安装包可以从github下载，需要梯子。 https://github.com/appium/appium-desktop/releases下载到的dmg文件双击装载，把Appium拖到Application里完成安装。安装 Appium-Client本文只讨论Python实现的Appium测试，所以你只需要允许以下命令：pip install Appium-Python-Client如果需要使用其他编程语言，下表供参考： 语言/框架 Github版本库以及安装指南 Ruby https://github.com/appium/ruby_lib Python https://github.com/appium/python-client Java https://github.com/appium/java-client JavaScript (Node.js) https://github.com/admc/wd Objective C https://github.com/appium/selenium-objective-c PHP https://github.com/appium/php-client C# (.NET) https://github.com/appium/appium-dotnet-driver RobotFramework https://github.com/jollychang/robotframework-appiumlibrary 必要的环境变量设置如果你已经安装了appium-doctor，那么你只要运行appium-doctor命令就可以知道你还需要设置哪些环境变量，比如：tobyqin@CatBook ~&gt; appium-doctorinfo AppiumDoctor Appium Doctor v.1.4.3info AppiumDoctor ### Diagnostic starting ###info AppiumDoctor ✔ The Node.js binary was found at: /usr/local/bin/nodeinfo AppiumDoctor ✔ Node version is 7.10.0info AppiumDoctor ✔ Xcode is installed at: /Applications/Xcode.app/Contents/DeveloperWARN AppiumDoctor ✖ Xcode Command Line Tools are NOT installed!info AppiumDoctor ✔ DevToolsSecurity is enabled.info AppiumDoctor ✔ The Authorization DB is set up properly.WARN AppiumDoctor ✖ Carthage was NOT found!info AppiumDoctor ✔ HOME is set to: /Users/tobyqininfo AppiumDoctor ✔ ANDROID_HOME is set to: /Users/tobyqin/Library/Android/sdk/info AppiumDoctor ✔ JAVA_HOME is set to: /Library/Java/JavaVirtualMachines/jdk1.8.0_112.jdk/Contents/Homeinfo AppiumDoctor ✔ adb exists at: /Users/tobyqin/Library/Android/sdk/platform-tools/adbinfo AppiumDoctor ✔ android exists at: /Users/tobyqin/Library/Android/sdk/tools/androidinfo AppiumDoctor ✔ emulator exists at: /Users/tobyqin/Library/Android/sdk/tools/emulatorinfo AppiumDoctor ✔ Bin directory of $JAVA_HOME is setinfo AppiumDoctor ### Diagnostic completed, 2 fixes needed. ###info AppiumDoctorinfo AppiumDoctor ### Manual Fixes Needed ###info AppiumDoctor The configuration cannot be automatically fixed, please do the following first:WARN AppiumDoctor - Please install Carthage. Visit https://github.com/Carthage/Carthage#installing-carthage for more information.info AppiumDoctor ###info AppiumDoctorinfo AppiumDoctor Bye! Run appium-doctor again when all manual fixes have been applied!其实你不一定需要把通过所有检查项，如果只是为了完成Android的Appium测试，只要确保ANDROID_HOME 和 JAVA_HOME 正确配置，另外SDK Tools 和Platform Tools都加入PATH就基本完成了。可以参考我个人目录下的.bash_profile设置：export ANDROID_HOME=~/Library/Android/sdk/export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_112.jdk/Contents/Homeexport PATH=~/bin:$PATH:/usr/local/bin:$ANDROID_HOME/platform-tools/:$JAVA_HOME/bin开始编写自动化测试终于到了开始写代码的时候了，相信你已经迫不及待了，别急，你还要准备以下条件： 模拟器或者测试机必须是Ready的状态，每次启动模拟器都很费时间，所以建议模拟器不要关闭，通过代码来启动模拟器是一个办法，但是时间成本有点高。 如果是调试代码阶段，建议保持Appium桌面版长期运行，但是Appium和uiautomator有冲突，只能二选一。 Appium会根据你的测试代码去寻找符合要求的设备，如果你启动了多台虚拟机或者连接了多台实体机，请显式地在代码中指定设备名称或者版本号。自动化测试代码例子如下，启动内置拨号软件，搜索关键字。from appium import webdriverdesired_caps = {}desired_caps['platformName'] = 'Android'desired_caps['platformVersion'] = '7.1.1'desired_caps['deviceName'] = 'Android Emulator'desired_caps['appPackage'] = 'com.android.dialer'desired_caps['appActivity'] = 'DialtactsActivity'driver = webdriver.Remote('http://localhost:4723/wd/hub', desired_caps)driver.find_element_by_id('com.android.dialer:id/search_box_collapsed').click()search_box = driver.find_element_by_id('com.android.dialer:id/search_view')search_box.click()search_box.send_keys('hello toby')恭喜你，解锁了移动应用测试的新成就！参考 在 Windows 下搭建 Appium + Android 自动化测试环境" }, { "title": "如何使用Python优雅地处理时间数据", "url": "/posts/2017-09-26/excellent-python-time-ultility-arrow/", "categories": "Tech", "tags": "python, arrow, datetime, pypi", "date": "2017-09-26 00:00:00 +0800", "snippet": "Python处理时间数据的好方法。缘起很多时候我们不得不和时间打交道，但在Python标准库中处理时间的模块其实设计的不是很友好，为什么我会这么说？因为我相信大部分人几乎每次在处理时间数据时一而再，再而三的去查文档，比如时间和文本格式互转，时间增减等看起来非常基本的操作，在Python中处理起来并不轻松。最要命的是，在Python标准库中居然有两个名字差不多的模块可以处理时间，一个叫time...", "content": "Python处理时间数据的好方法。缘起很多时候我们不得不和时间打交道，但在Python标准库中处理时间的模块其实设计的不是很友好，为什么我会这么说？因为我相信大部分人几乎每次在处理时间数据时一而再，再而三的去查文档，比如时间和文本格式互转，时间增减等看起来非常基本的操作，在Python中处理起来并不轻松。最要命的是，在Python标准库中居然有两个名字差不多的模块可以处理时间，一个叫time，另外一个叫datetime，里面提供了类似的方法但是两个完全不是一回事。到这还没完，标准库里还有一个叫calendar的模块，也是用来处理时间的。你是不是纠结到底该用哪一个？今天我不带大家去理解他们三者的关系，因为现在你记住了不代表你以后不会忘记。今天的主角是一个优雅到我不能放弃的时间处理库 - arrow。简介arrow是一个专门处理时间和日期的轻量级Python库，它提供了一种合理、智能的方式来创建、操作、格式化、转换时间和日期。安装pip install arrow使用我们直接看代码，注释既分割线。&gt;&gt;&gt; import arrow# 获取当前时间&gt;&gt;&gt; utc = arrow.utcnow()&gt;&gt;&gt; utc&lt;Arrow [2017-05-11T21:23:58.970460+00:00]&gt;# 调整时间&gt;&gt;&gt; utc = utc.shift(days=+1, hours=-1)&gt;&gt;&gt; utc&lt;Arrow [2017-05-12T20:23:58.970460+00:00]&gt;# 修改时间&gt;&gt;&gt; utc.replace(hour=4, minute=40)&lt;Arrow [2017-05-12T04:40:58.970460+00:00]&gt;# 转换时区&gt;&gt;&gt; local = utc.to('US/Pacific')&gt;&gt;&gt; local&lt;Arrow [2017-05-11T13:23:58.970460-07:00]&gt;# 从文本转为时间对象&gt;&gt;&gt; arrow.get('2017-05-11T21:23:58.970460+00:00')&lt;Arrow [2017-05-11T21:23:58.970460+00:00]&gt;&gt;&gt;&gt; arrow.get(1367900664)&lt;Arrow [2017-05-07T04:24:24+00:00]&gt;&gt;&gt;&gt; arrow.get('June was born in May 1980', 'MMMM YYYY')&lt;Arrow [1980-05-01T00:00:00+00:00]&gt;# 获取时间戳&gt;&gt;&gt; local.timestamp1368303838# 格式化输出&gt;&gt;&gt; local.format()'2017-05-11 13:23:58 -07:00'&gt;&gt;&gt; local.format('YYYY-MM-DD HH:mm:ss')'2017-05-11 13:23:58'&gt;&gt;&gt; local.humanize()'an hour ago'# 转为标准库对象&gt;&gt;&gt; a.date()datetime.date(2017, 5, 7)&gt;&gt;&gt; a.time()datetime.time(4, 38, 15, 447644)总结arrow是不是很智能很易用？如果以后你的Python项目需要处理时间，请果断抛弃标准库，arrow将拯救你无数脑细胞。附上arrow官方文档，更多酷炫用法还是前往官网。 http://arrow.readthedocs.io/en/latest/" }, { "title": "让你的项目模板化和专业化 - Cookiecutter", "url": "/posts/2017-08-16/cookiecutter-intro/", "categories": "Tech", "tags": "python, cookiecutter", "date": "2017-08-16 00:00:00 +0800", "snippet": "如果快速应用优秀模板或者框架到你的项目？简介Cookiecutter 英文的意思大概是饼干模型这么一类东西，可以让你快速做出某种形状的饼干。实际上你在 google 搜索到的 cookiecutter 是一个托管在 GitHub 的开源项目。 https://github.com/audreyr/cookiecutter这是一个就算你不用也应该了解的工具，cookiecutter 可以让你...", "content": "如果快速应用优秀模板或者框架到你的项目？简介Cookiecutter 英文的意思大概是饼干模型这么一类东西，可以让你快速做出某种形状的饼干。实际上你在 google 搜索到的 cookiecutter 是一个托管在 GitHub 的开源项目。 https://github.com/audreyr/cookiecutter这是一个就算你不用也应该了解的工具，cookiecutter 可以让你快速从各种模板中建立工程，这个项目本身是 python 写的，但是支持的模板跨越了多种语言和各种领域，看图说话。安装这是一个命令行工具，需要 python 支持，所以你要确保 python 已经正确安装，版本可以是 2.x 或者 3.x。pip install -U cookiecutter上手首先你要确定新建的项目是何种类型，这是一个很严肃的问题。一般 IDE 会提供新建项目的功能，为什么我们还要 cookiecutter？此新建非彼新建。IDE 的新建项目一般指的是空项目，而 cookiecutter 新建的项目一般是已经有一定完成度的框架。举一个简单例子，你可以从 IDE 新建一个 django 项目，新建的项目可以直接运行，但也仅仅是能运行。如果你从 cookiecutter 新建一个 django 项目你可以有很多选择，比如是否使用 bootstrap，是否集成 rest framework，是否要发布到 aws，是否使用 docker，测试框架使用什么等等。IDE 建房子是从地基开始，cookiecutter 可以帮你把架子也搭好。第一步，确定你要新建的项目类型，假设我要新建一个使用 bootstrap 的 flask 项目。从 cookiecutter 的 GitHub 页面找到我心仪的模板 （Ctrl + F）。第二步，启动命令行，输入 cookiecutter [template-path/url/zip]，比如：cookiecutter https://github.com/sloria/cookiecutter-flask.git第三步，按照模板预设的问题一路 next，你就新建了一个标准和专业的 Flask 工程。优点和局限cookiecutter 的主要局限来自于它的优点，太模板化的东西会导致灵活性不足。而且目前可用的各种模板质量参差不齐，不过主流的项目模板都是非常棒的，比如各种前后端框架，机器学习等等，有很多人在维护和更新。一个框架搭到什么程度比较合适，这就不能一概而论了。如果你要做一个 Django 应用，模板里默认就集成了用户注册和登录功能，有时候你觉得太棒了我刚好需要，有时候你觉得我没这样的需求，还得从新建好的项目一点一点删掉没用的代码还可能改错导致跑不起来。其实我认为 cookiecutter 也是一个很好的学习渠道，使用 cookiecutter 新建项目你可以看到别人是如何组织代码，如何管理配置，如何管理依赖等等，比如 Python 写的项目，理论上你可以把代码扔在任何目录，大拿扔的好看，自己扔的就很丑。最后再提一点，cookiecutter 支持自定义模板，你也可以把自己常用的项目功能打包成模板，后续只要有重用需求，cookiecutter 一下，立马开始业务功能的 cooding，岂不妙哉？" }, { "title": "xmind2testlink - 快速设计测试案例并导入TestLink", "url": "/posts/2017-07-27/use-xmind-to-design-testcase/", "categories": "Tech", "tags": "xmind, testlink, QA, xmind2testlink", "date": "2017-07-27 00:00:00 +0800", "snippet": "前面我有介绍过思维导图和xmind，现在我们再往前一步，让生活再美好一些。 上集回顾：你听说过思维导图吗？ 原文链接： https://tobyqin.github.io/posts/2017-07-26/the-power-of-mindmap/本文我们将使用xmind设计测试案例，并导入到TestCase管理系统TestLink。原理Xmind生成的思维导图以 .xmind 为扩展名...", "content": "前面我有介绍过思维导图和xmind，现在我们再往前一步，让生活再美好一些。 上集回顾：你听说过思维导图吗？ 原文链接： https://tobyqin.github.io/posts/2017-07-26/the-power-of-mindmap/本文我们将使用xmind设计测试案例，并导入到TestCase管理系统TestLink。原理Xmind生成的思维导图以 .xmind 为扩展名，其实这本质上是一个zip压缩文件。这里略带一点小知识。 zip这一世界通用压缩标准是美国20世纪80年代著名程序员Phil Katz 发明的。当时为了对抗商业压缩软件ARC（缺钱买不起），Philip Katz 制作出了PKZIP，因为免费而且开放，越来越多的软件都内嵌支持zip，包括Windows操作系统。 你可以使用任何一种文本编辑器打开zip文件，文件的头两个字母为 PK。xmind解压以后，里面主要由一些xml文件构成，解析content.xml 和 comment.xml 就可以获得思维导图的结构和主要文字内容。xmind2testlink这是一个我使用Python实现对xmind进行解析的PyPI包，有了它你可以很方便地将xmind转化成其他系统使用的格式，比如TestLink。安装和使用使用pip可以快速安装xmind2testlink。pip install xmind2testlink -U安装后默认就提供了命令行转换功能，可以将xmind转成可以导入testlink的xml文件。xmind2testlink /path/to/testcase.xmindGenerated: testcase.xml如果你想自己编程使用中间对象，可以导入xmind_parser或者testlink_parser中的方法。from xmind2testlink.xmind_parser import *from xmind2testlink.testlink_parser import *# do your stuff使用须知 v1并不是所有的xmind都可以顺利被xmind2testlink识别，因为我是按照一定规律去分析xmind结构的，所以如果你要使用这个小工具，那么请你遵循一些简单的游戏规则。输出结果：如图，你的xmind应该和上图结构一致： 默认的中心主题不会被转换，默认从第一层子主题开始转换。 第一层子主题会被识别为 TestSuite。 TestSuite 的子主题 会被识别为 TestCase。 TestCase 的下级分支为 TestStep 和 Expected Result。 你可以给 TestSuite，TestCase加上 Note，这会被识别为Summary 字段。 你可以给TestCase 加上 Comment，这会被识别为 Preconception 字段。 你可以使用数字Marker来为TestCase定义优先级。 你可以使用感叹号!来注释掉不想导入的任意分支。如果觉得太复杂了，可以下载示例的xmind文件（Test case by xmind v1.xmind），看一眼就懂了。使用须知 v2在使用V1的规则一段时间后，发现不是特别xmind，xmind真正强大的地方在于发散思维整理，如果按照前面的规则使用xmind，会有很大的限制，于是我升级了xmind2testlink，称之为V2。看图：输出结果：基于V1，补充的规则如下： 根主题必须加上一个小星星，这是用来区分V1和V2的标识。 第一层子主题还是会被识别为 TestSuite。 之后的主题可以自由扩展，如果一个主题被标记了priority那么意味着case到此结束。 如果没有主题被标记priority，默认case取到最后一个主题。 默认使用空格连接case子主题，你可以指定其他连接符（根主题的最后一个字符）。 TestCase 的下级分支为 TestStep 和 Expected Result。 所有case子主题的Summary和Preconception会被连接起来。 你可以给 TestSuite，TestCase加上 Note，这会被识别为Summary 字段。 !开头的所有主题都会被自动忽略，可以用来隐藏或者注释某些不想导入的内容。照旧，这里有一个示例文件（Test case by xmind v2.xmind），看一下就明白了。其实Github上的英文文档描述更清楚一下，有能力的你还是去看一下。进阶用法可能不是每个人都了解Python或者安装了Python，那么这是你可以将xmind2testlink部署成一个网站，步骤也非常简单。# clone this git repo aheadcd /path/to/xmind2testlink/webpip install -r requirements.txt -Upython application.py* Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)* Restarting with stat这时你启动浏览器就可以看到一个web版的转换界面。这是一个由Flask写的简单程序，你可以将其部署到专门的服务器，详情请查阅官方文档。小结其实在实现一个小工具的过程中，从构思想法到实现，有很多内容和未知需要去探索。xmind2testlink 涉及到的知识点也不少，比如 PyPI 打包发布，python读取zip文件，解析xml，Flask，网站前后期，服务器部署，持续集成，单元测试等等，我个人收获不小。如果你工作或生活也有各种想法，不如动手去做，失败了没啥大不了的，万一成功了呢。" }, { "title": "你听说过思维导图吗？", "url": "/posts/2017-07-26/the-power-of-mindmap/", "categories": "Tech", "tags": "xmind, ideas", "date": "2017-07-26 00:00:00 +0800", "snippet": "如果你没听说过思维导图，那么你可能错过了很美妙的一个工具。不过没关系，现在了解一下也不算迟。 思维导图又叫心智导图是表达发散性思维的有效的图形思维工具 ，它简单却又极其有效，是一种革命性的思维工具。名词解释大家都不爱看，所谓的思维导图其实就是类似于下面这样一张图。是不是觉得好复杂，徒手画图？我可没说。我们现在接触到的文档大多数都是电子化的，所以你经常看到的思维导图应该像这个样子。是不是挺清...", "content": "如果你没听说过思维导图，那么你可能错过了很美妙的一个工具。不过没关系，现在了解一下也不算迟。 思维导图又叫心智导图是表达发散性思维的有效的图形思维工具 ，它简单却又极其有效，是一种革命性的思维工具。名词解释大家都不爱看，所谓的思维导图其实就是类似于下面这样一张图。是不是觉得好复杂，徒手画图？我可没说。我们现在接触到的文档大多数都是电子化的，所以你经常看到的思维导图应该像这个样子。是不是挺清晰易懂的？思维导图也叫 MindMap，脑图等等。作为一个头脑风暴的工具，灵活运用「思维导图」将会对你在学习和工作帮助甚大！上面这张思维导图就是我在分享从 Python2 迁移到 Python3 的知识点总结。思维导图有用吗这玩意有用吗？这是你在学习任何一个东西之前都必须弄明白的一件事。建议阅读知乎问答：思维导图真的有效吗？。简单总结一下： 作为一种工具它当然有效，但必然有它擅长和不擅长的事 但不要高估它的价值，它不是万能的 思维导图主要用于激发思维，整理思路，系统分析等脑力劳动上举例说明它擅长的事： 问题解决，项目计划，知识管理，思考写作，做笔记，项目演示，做计划缺点也提一下： 结构固定，一般用于主题或者树状信息整理，不适合交互复杂的信息处理 制图费时，尤其是手动绘图，时间成本很高所以说，我们尽量用它的长处，避免用它的短处。说到绘制思维导图的学习和时间成本，其实不能一口咬死这玩意真的很难画，关键是你有没有选对工具。思维导图工具当你在电脑上使用思维导图工具绘制思维导图时，你会发现，真的很不费事，甚至是自然而然，因为你只需要记住两个快捷键： TAB - 添加子主题 ENTER - 发散思维基本上 99%的思维导图软件都使用了以上两个快捷键，当你的手指放在键盘上时，你只要集中精力去整理思路，不需要去关心图是怎么画出来的。使用 TAB 进行大纲整理，使用 ENTER 添加平行内容。在这里我推荐大家尝试使用 Xmind 来制作思维导图，它提供免费版，跨平台而且兼容很多其他同类软件的文件格式。Xmind 可谓是杀人越货，居家必备之良品，优点多多，可以用下面这张思维导图来总结。如果你不想或者没条件在每台电脑上都装 Xmind，那么网页版也有不少选择方案。我特别推荐 ProcessOn 和百度脑图。 ProcessOn：https://www.processon.com/ 百度脑图：http://naotu.baidu.com/思维导图实例思维导图主要还是用于思维发散或者思路整理，我举一些我在实际工作中用到思维导图的例子。做工作计划思维导图非常适合做规划类的事情，因为规划需要有条理和步骤，需要细化和调整。当你用 Xmind 做好一个初步计划后，可以通过鼠标去拖动子项目来调整顺序优先级，并且还可以添加一些图标来标注状态或者优先级，例如下图。做知识梳理当你需要做读书笔记或者归纳总结知识点时，思维导图也十分有效。下图是我开始学习 Python 后做的思维导图，里面包含了读书笔记和经验总结，通过思维导图我能很方便的回顾各个知识点，查缺补漏。协助软件开发软件开发过程中你需要了解业务，设计模型，整理 API，其实思维导图也是一个不错的帮手。设计测试案例不知道你发现没有，其实设计测试案例（TestCase Desgin）其实就是发散思维的一个典型应用。作为测试人员你需要尽可能多的考虑测试路径，如果用图来表示测试案例，那么其实就是一棵树，树的根节点就是你要测试的功能，发散出来的分支就是你要考虑的各种情况。用思维导图来设计测试案例再合适不过。小结写到这应该收尾了，如果你对思维导图感兴趣，不如现在就动手起来，应用到你的生活或者工作中去，实践才是检验真理的唯一办法。" }, { "title": "Windows UI自动化测试的XPATH实现 - WPATH", "url": "/posts/2017-07-23/xpath-for-windows-desktop-ui-automation-wpath/", "categories": "Tech", "tags": "Windows UIAutomation, XPATH, WPATH", "date": "2017-07-23 00:00:00 +0800", "snippet": "从事Windows 桌面应用自动化测试也有一些年了，现在谈这个话题并不流行。因为除了企业级应用，很少有公司会只选择Windows桌面作为目标用户平台，一般都会考虑跨平台的浏览器解决方案，桌面应用的地位渐渐下降，这是事实。当年初入测试行业时就被外包公司看上了，在微软的圈子里一待就是4年，时间真快。不得不说，一个大学刚毕业的毛头小子看到微软里各种技术和工具真像极了刘姥姥进大观园，那时候还没有iP...", "content": "从事Windows 桌面应用自动化测试也有一些年了，现在谈这个话题并不流行。因为除了企业级应用，很少有公司会只选择Windows桌面作为目标用户平台，一般都会考虑跨平台的浏览器解决方案，桌面应用的地位渐渐下降，这是事实。当年初入测试行业时就被外包公司看上了，在微软的圈子里一待就是4年，时间真快。不得不说，一个大学刚毕业的毛头小子看到微软里各种技术和工具真像极了刘姥姥进大观园，那时候还没有iPhone，也没有Android，微软一统天下。本文主要介绍一下我对Windows UI自动化的一些看法以及WPATH的实现和应用，如果你还在从事Windows桌面应用的自动化测试，应该能有一些帮助。为何发明WPATHWindows UI 自动化，顾名思义就是在Windows平台实现软件的界面自动化，比如自动打开Excel填入一些数据，输入公式，获取结果。正经的用途就是软件自动化测试，避免重复的手工操作；不正经的用途就是写外挂，各种投机取巧的工具等等。最简单粗暴的实现方案就是录制回放，优点很明显，简单快速；缺点也一样明显，不可靠因素太多。主要的代表就是QTP，来自HP公司，这应该是很多同学都听过的一款测试工具。进阶的方案就是使用微软提供的自动化工具集：UI Automation。UI Automation是Microsoft .NET 3.0框架下提供的一种用于自动化测试的技术，是在MSAA基础上建立的，MSAA就是Microsoft Active Accessibility。如果你使用过.NET 提供的UI Automation相关的类库，应该有一个直观的感受，就是非常啰嗦，举一个例子：AutomationElement ControlTypeComboBox = grdClassBook.FindFirst( TreeScope.Children, new PropertyCondition(AutomationElement.ControlTypeProperty, ControlType.ComboBox));AutomationElement cellElement = ControlTypeComboBox.FindFirst( TreeScope.Children, new PropertyCondition(AutomationElement.AutomationIdProperty, \"ListBox\"));每当你尝试去获取一个UI元素时，都需要使用FindFirst之类的方法去查询指定的PropertyCondition，而PropertyCondition使用起来也不简单，特别是当你需要拼接多个AND或者OR多个条件时。var btnCondition = new AndCondition( new PropertyCondition(AutomationElement.ControlTypeProperty, ControlType.Button), new PropertyCondition(AutomationElement.NameProperty, \"ok\"));才两个条件就这么多代码了？你看看搞Web自动化的同学都可以用XPATH，快速定位和查询元素 /div[@id='ok']，多好。既然我们那么羡慕XPATH，那我们就搞一个出来，让做Windows桌面自动化的同学也可以High一把。WPATH实现原理具体代码我就不在此展开，想刨根的同学可以直接移步至Github：https://github.com/tobyqin/wpath。WPATH的主要原理就是通过反射的方式去获取当前方法或者属性的Attribute，在Attribute中我们可以定义类似于XPATH的语法，我 且称之为WPATH。最后经过表达式解析转换成对应的Find方法和Condition，举一个例子说明：[WPath(\"/Edit[@id='txtId' or @Class='TextBox']\")]public AutomationElement EditControl{ get { return this.AppElement.FindByWPath(); }}当调用FindByWPath()时，该属性上的WPath Attribute就会被解析出来，其中的 /会被解析成FindFirst，Edit会被解析成ControlType.Edit，中括号里的条件最后被组合起来，调用的最终结果大致如下：public AutomationElement EditControl{ get { return this.AppElement.FindFirst(TreeScope.Children, new AndCondition( new PropertyCondition(AutomationElement.ControlTypeProperty, ControlType.Edit), new OrCondition( new PropertyCondition(AutomationElement.AutomationId, \"txtId\"), new PropertyCondition(AutomationElement.Class, \"TextBox\")))); }}痛苦的感觉一下减轻许多，有没有？更详细的WPATH用法如果你要在项目中使用WPATH，可以通过nuget包安装：PM&gt; Install-Package WPath简单说明 WPath 和 XPath 类似，以 ‘/’ 开头。 可以使用多个 ‘/’ 来定位目标元素。 节点名字来自于MSDN定义好的 control type。 目前WPath支持的查询属性如下: Name (NameProperty) ID (AutomationIdProperty) Class (ClassNameProperty) Enabled (IsEnabledProperty) FrameworkID (FrameworkIdProperty)举例子 /Group/Button 获取第一个Group下的第一个Button。 //Button[@Name='Save'] 在子孙节点中获取第一个Name为 “Save” 的元素。 /[@Name='TabContainer']/Button[2] 获取Name为 “TabContainer”的控件下的第二个Button，注意，控件类型名称可以为空。 /Button[@ID='AddButton' and @Name='Add'] 获取一个automation ID 为 ‘AddButton’ 且 name 为 ‘Add’ 的Button。 /Button[@ID='AddButton' or @Name='Add'] 获取一个automation ID 为 ‘AddButton’ 或 name 为’Add’的Button。 /Button[first()] 获取当前元素下第一个Button。 /Button[last()] 获取当前元素下最后一个Button。实际运用推荐使用Attribute的方式进行调用，可用于类方法或者属性。[WPath(\"/Edit[@id='txtId' or @Class='TextBox']\")]public AutomationElement EditControl{ get { return this.AppElement.FindByWPath(); }}[WPath(\"/Button[first()]\")]public AutomationElement GetFirstButton(){ return this.AppElement.FindByWPath();}或者直接调用 FindByWPath(path) 来定位目标元素。var path = \"/Edit[3]\";var e = this.AppElement.FindByWPath(path);Assert.AreEqual(\"txtKey\", e.Current.AutomationId);Assert.AreEqual(ControlType.Edit, e.Current.ControlType);path = \"/Button[@name='OK']/Text[1]\";e = this.AppElement.FindByWPath(path);Assert.AreEqual(\"OK\", e.Current.Name);Assert.AreEqual(ControlType.Text, e.Current.ControlType);小贴士 元素类型节点是大小写不敏感的，比如： @name = @Name /edit = /Edit 父节点定位 ../ 目前不支持，因为有点复杂。更多的说明建议还是去看Github中的说明文档，或者直接看单元测试。后记Windows UI 自动化的坑还是挺深的，填坑的人也不少，我推荐有需要的同学去学习和了解一下 White。White是一个非常好UI Automation 封装框架，相信我，能省下你不少时间。" }, { "title": "一款优秀的代码高亮库 - rainbow.js", "url": "/posts/2017-07-17/rainbow-js-highlight-lib/", "categories": "Tech", "tags": "javascript, code-highlight", "date": "2017-07-17 00:00:00 +0800", "snippet": "介绍一个优秀的 js 库。缘起代码高亮的 js 库也不少，最知名的莫过于 highlightjs，支持你听过的没听过的各种编程语言，兼容你用过没用过的各种浏览器，有着多姿多彩的配色方案。然而，唯有一点我还是选择放弃了它，因为它不能很方便的自定义高亮语言。现在我的需求是是这样的，有一个自动化测试结果的页面，里面会显示一个测试案例运行的数据，比如控制台输出 stdout， 我需要高亮控制台输出的...", "content": "介绍一个优秀的 js 库。缘起代码高亮的 js 库也不少，最知名的莫过于 highlightjs，支持你听过的没听过的各种编程语言，兼容你用过没用过的各种浏览器，有着多姿多彩的配色方案。然而，唯有一点我还是选择放弃了它，因为它不能很方便的自定义高亮语言。现在我的需求是是这样的，有一个自动化测试结果的页面，里面会显示一个测试案例运行的数据，比如控制台输出 stdout， 我需要高亮控制台输出的一些信息，例如：INFO 级别是默认色，WARN 级别是橙色，ERROR 级别是红色。一句话，我需要自定义日志输出高亮。...2017-07-14 11:53:55,668 INFO : Go to my account page2017-07-14 11:53:58,071 DEBUG : Now check: MyAccountPage2017-07-14 11:53:59,804 WARNING: Page loaded time &gt; 2000 ms2017-07-14 11:54:01,535 ERROR : Test failed!!!...像这样的需求使用 highlightjs 来实现就显得不够灵活，甚至有点无从下手。初试 RainbowJS RainbowJS 项目地址： https://github.com/ccampbell/rainbowRainbowJS 虽然简单而且支持的编程语言也不多（压缩后大小只有不到 3kb），但是恰恰能满足自定义高亮的需求。入门只需要三步即可：1. 导入配色文件 - css官方的 github 仓库里提供了 20 多种配色，常见主题配色都可以找到。&lt;link href=\"/rainbow/css/theme.css\" rel=\"stylesheet\" type=\"text/css\" /&gt;2. 使用 &lt;pre&gt;&lt;code&gt; 包住你的代码在 code 标签里你可以使用data-language 指定代码语言。&lt;pre&gt;&lt;code data-language=\"python\"&gt;def openFile(path): file = open(path, \"r\") content = file.read() file.close() return content&lt;/code&gt;&lt;/pre&gt;3. 开始高亮你的代码如果整个过程是同步的，那么你只需要在页面最后导入 RainbowJS 和你需要的高亮语言库，就可以自动高亮代码块。&lt;script src=\"/js/rainbow.js\"&gt;&lt;/script&gt;&lt;script src=\"/js/language/generic.js\"&gt;&lt;/script&gt;&lt;script src=\"/js/language/python.js\"&gt;&lt;/script&gt;如果你的代码块是异步生成的，你可以选择提前引入 Rainbow 及相关语言的 js 文件，然后调用Rainbow.color()方法来给代码块着色。// load rainbow js and language support...// call your function to generate dyanmc code blocks...// finally, highligh your code blocksRainbow.color();// optionally, you can pass in a callback function in color()// for example:Rainbow.color(function() { console.log('The new blocks are now highlighted!');});高亮自定义语言从前面的例子可以看到 rainbow 的上手还是很简单的，如果要自定义高亮规则应该怎么办？非常简单，只要调用extend方法即可。比如给True，False，None添加constant的 css 类：Rainbow.extend( \"python\", [ { name: \"constant\", pattern: /True|False|None/g, }, ], \"generic\");用extend方法可以给指定语言添加高亮规则，规则的名字就是即将添加的 css 类的名字，只要匹配了规则中指定的正则表达式，RainbowJS 就会给匹配的结果添加上对应的 css 类。接下来我们要给 log 添加高亮规则，为了避免去写新的 css 类，我们可以重用主题配色里已经存在的类，根据主题颜色我们暂定高亮规则如下：1. debug - 灰色 - css: comment2. info - 白色 - css: support3. warn - 橙色 - css: string4. error - 红色 - css: keyword5. 时间日期格式 - 灰色 - css: comment对应的 extend 实现如下：// log.jsRainbow.extend( \"log\", [ // debug level { name: \"comment\", pattern: /([^ ]*debug).*/gi, }, // info level { name: \"support.tag\", pattern: /([^ ]*info).*/gi, }, // warn level { name: \"string\", pattern: /([^ ]*warn).*/gi, }, // error level { name: \"keyword\", pattern: /([^ ]*error[^(]).*|([^ ]*fatal).*|([^ ]*failure).*|([^ ]*failed).*|([^ ]*exception[^(]).*/gi, }, // time format { name: \"comment\", pattern: /\\b([\\d\\-:,]+)\\b/gi, }, ], \"python\");当 log 行正确匹配后就会被添加上对应规则的 css 类，并且所有高亮规则继承自 python 语言，因为我的 log 是从 python 程序中记录的，当中可能会有一些 python 代码，我希望这些代码也能正常被着色。最后就是在网页中生成对应的代码块，指定高亮语言为 log：&lt;pre&gt;&lt;code data-language=\"log\"&gt;...2017-07-14 11:53:55,668 INFO : Go to my account page2017-07-14 11:53:58,071 DEBUG : Now check: MyAccountPage2017-07-14 11:53:59,804 WARNING: Page loaded time &gt; 2000 ms2017-07-14 11:54:01,535 ERROR : Test failed!!!...&lt;/code&gt;&lt;/pre&gt;效果图如下：一些改进方法在页面中加载多个 js 文件的写法挺不方便也不好维护，而且也会影响页面加载的速度。比如上文的例子中如果是直接把&lt;script&gt;片段写到页面里会是这个样子。&lt;body&gt; ... &lt;pre /&gt; &lt;code /&gt; ... &lt;script src=\"/js/rainbow.js\"&gt;&lt;/script&gt; &lt;script src=\"/js/language/generic.js\"&gt;&lt;/script&gt; &lt;script src=\"/js/language/python.js\"&gt;&lt;/script&gt; &lt;script src=\"/js/language/log.js\"&gt;&lt;/script&gt;&lt;/body&gt;一个改进的建议是就是当页面加载完成后再加载 RainbowJS，然后调用高亮函数，你可以这样写：// page html&lt;script&gt;$(highlightLog);&lt;/script&gt;;// app.jsfunction highlightLog() { $.getScript(\"/libs/rainbow/rainbow.min.js\", function () { $.getScript(\"/libs/rainbow/language/generic.js\", function () { $.getScript(\"/libs/rainbow/language/python.js\", function () { $.getScript(\"/libs/rainbow/language/log.js\", function () { Rainbow.color(); }); }); }); });}虽然有点丑，但是功能没问题。如果你使用的是比较流行的requirejs，那么可以这样使用 RainbowJS：// config.jsrequirejs.config({ baseUrl: '/libs', shim: { rainbow: { exports: 'Rainbow' }, rainbow_generic: { deps: ['rainbow'] }, rainbow_python: { deps: ['rainbow_generic'] }, rainbow_log: { deps: ['rainbow_python'] } }, paths: { rainbow: 'rainbow/rainbow', rainbow_generic: 'rainbow/language/generic', rainbow_python: 'rainbow/language/python', rainbow_log: 'rainbow/language/log' }});// app.jsfunction highlightLog() { require(['rainbow'], function (Rainbow) { window.Rainbow = Rainbow; // must require(['rainbow_log'], function () { Rainbow.color(); }); });}// page embeded&lt;script src=\"/require.js\"&gt;&lt;/script&gt;&lt;script&gt; require(['/config.js'], function () { require(['app'], function (app) { app.highlightLog(); }); });&lt;/script&gt;再或者先通过 js 的压缩和打包工具将写好的代码进行优化，亦是目前比较流行和推荐的做法。本文旨在介绍和使用 RainbowJS，不做过多拓展，希望对你有所启发和帮助。如果需要完整的演示代码，可以查看我得 GitHub 项目：https://github.com/tobyqin/testcube" }, { "title": "在 Windows 下搭建 Appium + Android 自动化测试环境", "url": "/posts/2017-05-03/setup-appium-automation-test-environment/", "categories": "Tech", "tags": "python, selenium, appium, android", "date": "2017-05-03 00:00:00 +0800", "snippet": "Appium 是移动端自动化测试的必学内容。前言本来并不打算写这么一篇文章，但是实践下来发现网上的各种教程里大致有两个问题。一是文章有些跟不上时代，目前 android 开发和测试的技术更新都比较快，内容有些过期。二是细节部分不是太完整，拼拼凑凑也能完成，但对新手来说就比较痛苦。那么，我也来试着总结一下自己踩过的坑。备注：Android 自动化测试环境和开发环境并不完全相同，测试环境可以很简...", "content": "Appium 是移动端自动化测试的必学内容。前言本来并不打算写这么一篇文章，但是实践下来发现网上的各种教程里大致有两个问题。一是文章有些跟不上时代，目前 android 开发和测试的技术更新都比较快，内容有些过期。二是细节部分不是太完整，拼拼凑凑也能完成，但对新手来说就比较痛苦。那么，我也来试着总结一下自己踩过的坑。备注：Android 自动化测试环境和开发环境并不完全相同，测试环境可以很简单粗暴，很多工具可以不用安装，比如 JDK，SDK Tools，测试脚本用 C#，Python 都可以完成；但是开发环境一般都是需要 JDK 和不少编译工具。实践平台Windows 10 Pro 64bit + Python 3.5.3安装 JAVA 环境如果只是自动化测试用，安装 JRE 就可以了，如果需要开发或者调试 APK，那么请安装 JDK。 JRE = JVM + Java SE 标准类库，相当于 Java 程序最基本的运行环境。 JDK = JRE + 开发工具集，包括 javac 编译工具等等。JRE 只有 50 多 MB，JDK 则接近 200MB，请前往Java 官网下载最新版安装，选择 64 位。安装 Android Studio / SDK以前的教程里都会让你去装 Android SDK，但现在你从 Google 或者 Bing 里很难搜索到 Android SDK 的下载链接，因为目前官网推荐的做法有两个： 安装 Android Studio （包含 Android SDK） – 推荐 仅安装 Android SDK 命令行工具新版本的 Android SDK 和以前也不太一样，以前我们有一个 SDK Manager.exe 的工具用于更新和下载各版本的 API，还有一个 AVD Manager.exe 的工具可以模拟各种型号的安卓设备。最新的 SDK 工具把 UI 界面基本都去掉了，只留下命令行工具，具体的使用可以参阅官方文档： https://developer.android.com/studio/releases/sdk-tools.html那么多一事不如少一事，我建议推荐你直接安装 Android Studio，这样不仅省事，而且万一你想写个 App 玩玩，也是极其方便的。下载地址：https://developer.android.com/studio/index.html安装过程非常简单，双击后一路 Next，中间你也可以另外指定 SDK 的安装目标路径（不建议修改）。安装好之后，直接启动 Android Studio，首先会提示你联网下载一些必要的工具（你需要一个好的网络和梯子）。一切就绪后，你可以在启动界面就可以打开 SDK Manager。或者新建一个工程，从工程界面打开 SDK Manager。SDK Manager 打开之后，使用的方法就一目了然了。这就是个让你更新 API 和各种开发工具的工具。如果只是为了自动化测试其实你只要记住 SDK 安装目录就可以了，不需要安装任何多余的工具。SDK 的安装目录在配置环境变量时需要用到。如果你的网络不畅通，那么需要先设置代理。接下来才能安装你想要的 SDK 版本和开发者工具。安装 Android 模拟器如果你已经安装了 Android Studio，模拟器也已经有了，从工程界面找到 AVD Manager 的按钮，按照下图三个步骤就可以添加并启动一个模拟器。每当你安装新版本的模拟器都是需要翻墙或者代理的，最开始启动 Android Studio 时它已经给你下一个最新版的 Android，我当前模拟器中的 Android 版本是 7.1.1。如果一切顺利，那么当你启动模拟器后，你就可以看到一台虚拟的 Android 设备了，手动测试基本条件已经达成，自动化测试指日可待。多说几句，除了使用 Android SDK 自带的模拟器外，我们还有两个选择，一是使用真机，速度和体验上会更好。另外一个选择就选择别的模拟器产品，比如 Genymotion，因为是商业软件，所以对个人用户（免费）会有诸多限制，尽管如此，其成熟度也比 Android SDK 自带的模拟器高很多。因为这两个方案的具体实现涉及到的内容比较多，故不在本文讨论。安装 AppiumAppium 是开源的自动化测试框架，主要用于 iOS，Android 以及 Windows apps 等移动平台的自动化测试。官网的介绍说是它实现一套适用于移动端的 WebDriver 协议，所以使用 Appium 时用的还是依赖于 Selenium，和 Web 自动化测试的主要区别就在 Driver 不一样。举一个例子，如果我们需要用 Google Chrome 来跑 Selenium 的自动化测试，那么首先需要一个 ChromeDriver。如果需要跑在 IE 上，那么需要一个 IEDriver。那么现在需要在移动端比如 Android 里跑 Selenium，这时候你需要一个 Appium 就够了，它担当了 Driver 的角色。Appium 实现了一套标准的 WebDriver，只要 Appium 服务起来之后，你的代码只需要和 Appium 交互，Appium 会去告诉设备该干嘛干嘛。这里提到的设备可以是 iOS 或者 Android，甚至是 Windows Phone 和 Firefox OS。Appium 官网： http://appium.io/安装方式一： 使用 NodeJS 安装首先到NodeJS 官网下载安装最新的 NodeJS，Windows 下属于傻瓜安装。安装好之后你可以配置 NodeJS 的安装源，在国内一般都用 taobao 的镜像，速度还不错。在个人目录下新建一个 .npmrc 文件，写入：registry=https://registry.npm.taobao.org/然后使用 npm 命令安装 Appiumnpm install -g appium建议顺便安装一下 appium-doctor，通过运行 appium-doctor 命令可以快速检查 appium 的环境问题。npm install -g appium-doctor如果安装成功，那么就可以通过 appium 命令启动 appium server。关闭命令行或者按 Ctrl - C 就可以停止 Appium Server。安装方式二： 使用 Appium 安装包网上很多教程所引导的 Appium 安装包一般在百度网盘或者 bitbucket 里，其实这两者都不是最新的。最新版的安装包应该从官网下载，Appium 目前托管在 github，正确的下载地址应该为： https://github.com/appium/appium-desktop/releases最新版的 Appium 桌面安装后启动是这样的。功能上和老的版本没太大区别，但是日志和 UI 显示更加清晰，一旦错误发生让你更容易找到问题所在。注意，你可以不安装 Appium 桌面版，但是命令行版应该还是需要安装的，因为自动化测试运行时一般都是通过命令启动和关闭 Appium，桌面版并不提供命令行功能，只是为了调试方便。关于 Appium 的介绍，这里有一份非常好的文档：http://appium.io/slate/cn/master安装 Appium-Client本文只讨论 Python 实现的 Appium 测试，所以你只需要允许以下命令：pip install Appium-Python-Client如果需要使用其他编程语言，下表供参考： 语言/框架 Github 版本库以及安装指南 Ruby https://github.com/appium/ruby_lib Python https://github.com/appium/python-client Java https://github.com/appium/java-client JavaScript (Node.js) https://github.com/admc/wd Objective C https://github.com/appium/selenium-objective-c PHP https://github.com/appium/php-client C# (.NET) https://github.com/appium/appium-dotnet-driver RobotFramework https://github.com/jollychang/robotframework-appiumlibrary 必要的环境变量设置如果你已经安装了 appium-doctor，那么你只要运行 appium-doctor 命令就可以知道你还需要设置哪些环境变量，比如：不要慌，其实你只需要设置以下环境变量： 环境变量 值 ANDROID_HOME Android SDK 的安装位置 JAVA_HOME JDK 或者 JRE 的安装位置 加入 PATH %ANDROID_HOME%\\tools 加入 PATH %ANDROID_HOME%\\platform-tools 加入 PATH %JAVA_HOME%\\bin 加入 PATH %ANDROID_HOME%\\build-tools\\??version?? (可选) 最后一个环境变量是为了更方便地使用 aapt 这个工具，完成环境变量配置后你可以再次运行 appium-doctor 进行检查。不出意外，你应该能通过检查。完成第一个自动化测试终于来到了动真刀真枪的时候了，很多人一开始就放弃了，更多人开始了之后就放弃了，走到这一步真的挺不容易的。开始写代码之前有些事情你应该清楚： 模拟器或者测试机必须是 Ready 的状态，每次启动模拟器都很费时间，所以建议模拟器不要关闭，通过代码来启动模拟器是一个办法，但是时间成本有点高。 如果是调试代码阶段，建议保持 Appium 桌面版长期运行，远程运行时再通过代码自动启动和关闭 Appium。 Appium 会根据你的测试代码去寻找符合要求的设备，如果你启动了多台虚拟机或者连接了多台实体机，请显式地在代码中指定设备名称或者版本号。第一个自动化测试需求很就简单，就是启动内置的拨号软件，搜索 “hello toby”。代码如下：from appium import webdriverdesired_caps = {}desired_caps['platformName'] = 'Android'desired_caps['platformVersion'] = '7.1.1'desired_caps['deviceName'] = 'Android Emulator'desired_caps['appPackage'] = 'com.android.dialer'desired_caps['appActivity'] = 'DialtactsActivity'driver = webdriver.Remote('http://localhost:4723/wd/hub', desired_caps)driver.find_element_by_id('com.android.dialer:id/search_box_collapsed').click()search_box = driver.find_element_by_id('com.android.dialer:id/search_view')search_box.click()search_box.send_keys('hello toby')运行效果：恭喜你，你已经开始进入移动端的自动化测试的大门了！参考 在 Mac OSX 上配置 Appium+Android 自动化测试环境" }, { "title": "如何开发一个 PyCharm 插件", "url": "/posts/2017-04-01/steps-to-create-a-pycharm-plugin/", "categories": "Tech", "tags": "pycharm, plugin", "date": "2017-04-01 00:00:00 +0800", "snippet": "PyCharm 是很多 Python 开发者优先选择的 IDE，功能强大，跨平台，提供免费社区版，非常良心。如果你想自己给 PyCharm 添加一些功能怎么办呢？有两个办法： 通过提需求实现，到 JetBrains 的 github 去提 issue 或者自己发 Pull Request 请他们 merge。 通过安装插件实现，你可以查找现有的插件仓库，或者，自己写一个。今天我们说说怎么...", "content": "PyCharm 是很多 Python 开发者优先选择的 IDE，功能强大，跨平台，提供免费社区版，非常良心。如果你想自己给 PyCharm 添加一些功能怎么办呢？有两个办法： 通过提需求实现，到 JetBrains 的 github 去提 issue 或者自己发 Pull Request 请他们 merge。 通过安装插件实现，你可以查找现有的插件仓库，或者，自己写一个。今天我们说说怎么搭建环境自己写一个 PyCharm 插件。前期准备先普及一下知识，开发 PyCharm 插件和开发 IntellJ IDEA 插件需要的环境是一样的，因为 PyCharm 本身就是 IDEA 的一个子集，说白了就是 IDEA 上套了一个 Python 语言支持的插件。其他系列的 IDEA IDE 其实也是一样的道理，都是套了对应语言支持的框架外加一点外观修改，就成了新的产品，比如 WebStrom，PhpStorm，RubyMine。到这里你应该有个印象，JetBrains 这个公司太能玩了，就一个 IDEA 能整出那么多产品来，很厉害吧？开发 PyCharm 插件你需要： 对 Java 语言有一定了解，因为你只能用 Java 开发插件 安装最新版的 IntelliJ IDEA 安装 PyCharm Community Edition 到本地 确保 IntelliJ 安装并启用了 Plugin DevKit 插件，默认自带 配置 IntelliJ Platform SDK， 下文会涉及相关步骤 （非必需）将IntellJ IDEA Community Edition 的代码克隆到本地，方便调试 如果你英文还可以，也可以阅读官方的帮助文档。 http://www.jetbrains.org/intellij/sdk/docs/basics/getting_started.html新建插件工程从文件菜单选择 New Project， 选择 IntelliJ Platform Plugin，如果你没有配置SDK，点击New 菜单。选择你本地 PyCharm Community Edition（社区版）的安装路径作为 SDK 目录，Java SDK 选择 1.8 以上的版本。 请注意，你也可以使用 PyCharm Professional (旗舰版) 的安装路径作为 SDK 目录，不过当你调试插件碰到核心代码时，社区版你可以一步一步跟到最里面，但旗舰版不行，因为旗舰版并不是开源的，你拿不到源代码。回到 New Project 的界面，点击 Next，输入 Project name 和 Project location，点击完成。小贴士：如果你是打开别人的写的插件，那么你直接选择打开工程目录是没有用的，因为 IntelliJ IDEA 不认为这是个插件工程，所以你没法运行和调试这个插件，一个不怎么优雅的办法就是从现有代码新建一个插件工程，StackOverflow 关于这个的吐槽问题你搜到，如果你有更好的办法请告诉我。当你换一台机器把插件代码克隆下来之后应该就知道我在说什么了。插件工程目录结构一个典型的插件目录结构就像下图。 .idea 目录 - JetBrains IDE 生成的工程都会有这么一个目录，存放用户配置和缓存，无需关心。 doc 目录 - 插件的文档，可选。 out 目录 - 编译后的代码字节，无需关心。 resources 目录 - 资源存放目录，插件的配置文件在此。 src 目录 - 代码存放的位置。 *.iml 文件 - 项目的配置文件。修改插件信息打开 /resources/META-INF/plugin.xml， 更新插件信息，举例说明。&lt;idea-plugin version=\"2\"&gt; &lt;id&gt;com.eflabs.plugin.efcommon&lt;/id&gt; &lt;name&gt;EF Common for PyCharm&lt;/name&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;vendor email=\"toby.qin@live.com\"&gt;Toby Qin&lt;/vendor&gt; &lt;description&gt;&lt;![CDATA[ &lt;b&gt;Able to run and debug ef common tests easily.&lt;/b&gt;&lt;br&gt; &lt;br&gt; &lt;ul&gt; &lt;li&gt;Support run/debug ef-common tests via context menu.&lt;/li&gt; &lt;li&gt;Show run button in the line of test case.&lt;/li&gt; &lt;/ul&gt;]]&gt; &lt;/description&gt; &lt;change-notes&gt;&lt;![CDATA[ &lt;b&gt;v3.0&lt;/b&gt;&lt;br&gt; &lt;p&gt;Support PyCharm 171.*&lt;/p&gt; &lt;p&gt;Support nested ef-common project.&lt;/p&gt; &lt;br&gt; &lt;b&gt;Early version&lt;/b&gt;&lt;br&gt; &lt;p&gt;Bug fix: failed to get run.template in resource.&lt;/p&gt; &lt;p&gt;The baby version.&lt;/p&gt; &lt;br&gt;]]&gt; &lt;/change-notes&gt; &lt;!-- please see http://www.jetbrains.org/intellij/sdk/docs/basics/getting_started/build_number_ranges.html for description --&gt; &lt;idea-version since-build=\"171.1\"/&gt; &lt;!-- please see http://confluence.jetbrains.com/display/IDEADEV/Plugin+Compatibility+with+IntelliJ+Platform+Products on how to target different products --&gt; &lt;depends&gt;com.intellij.modules.python&lt;/depends&gt; &lt;extensions defaultExtensionNs=\"com.intellij\"&gt; &lt;!-- Add your extensions here --&gt; &lt;configurationType implementation=\"com.eflabs.efcommon.runConfiguration.EfCommonConfigurationType\" order=\"FIRST\"/&gt; &lt;runConfigurationProducer implementation=\"com.eflabs.efcommon.runConfiguration.EfCommonConfigurationProducer\" order=\"FIRST\"/&gt; &lt;runLineMarkerContributor implementationClass=\"com.eflabs.efcommon.runLineMarker.EfCommonRunLineMarkerContributor\" language=\"Python\"/&gt; &lt;/extensions&gt; &lt;actions&gt; &lt;!-- Add your actions here --&gt; &lt;/actions&gt;&lt;/idea-plugin&gt;这个配置文件里有几点要注意的： &lt;id&gt;和&lt;version&gt; 用于声明你的插件唯一标识，同 id 和 version 的插件不能够重复上传。 &lt;depends&gt; 节点声明了此插件的依赖条件，如果是 PyCharm 适用的，那么就写 com.intellij.modules.python &lt;extenstions 节点用于声明你要扩展的类，只要继承和实现对应的接口就可以了。 &lt;actions&gt; 节点用于注册你要实现的 Action，比如你先写一些 Action，然后注册到某个菜单。实现具体的业务代码这里我略过最核心的部分，因为每个人的需求和代码能力都不一样，这应该去查阅 Java 编程规范。简而言之，就是根据你自己的需求用 Java 实现一些接口和方法。运行和调试你的插件如果你的代码已经实现了，那么运行和调试就比较简单。 使用 **Run Run** 菜单来运行你的插件，这时候会启动一个新的 PyCharm，默认安装好你的插件。 使用 **Run Debug** 菜单来调试你的插件，你可以设置断点进行调试。 发布你的插件你可以选择本地发布你的插件，也可以选择上传到 JetBrains 的插件仓库。本地发布安装如果你的插件是内部小范围使用，并且可能带有敏感信息，那么这样的方式会比较适合你。从主菜单选择 Build &gt; Prepare plugin ‘my_plugin’ For Deployment。如果成功那么在工程目录就会生成一个同名的 jar 文件。将这个文件 copy 到目标机器就可以通过 **Install Plugin from disk … ** 完成安装。发布插件到 JetBrains Plugin 仓库生成插件的步骤和本地发布是一样的，唯一不同的就是你需要到 JetBrains Plugins 网站去注册一个账号。 https://plugins.jetbrains.com/登录之后选择 UPLOAD PLUGIN 菜单，上传之后大概需要 2 个工作日审核。审核通过后其他用户就可以直接从 Browse Repositories… 里搜索到你的插件并安装。通过插件仓库安装的插件，一旦有新版本发布，用户将收到更新提示。写在最后关于如何实现具体的插件业务代码，一个偷懒的办法就是去看现有功能大概是怎么实现的，你既然可以拿到 PyCharm Community Edition 的所有代码，还有啥看不到的，看懂只是时间问题。再或者去 github 搜搜看，万一有惊喜呢？就 PyCharm 本身来说，我觉得作为 IDE 提供的功能已经很丰富了，为啥还要写插件呢？对啊，哪里来的需求，会不会是一个伪需求呢。写插件前请你想一想这个问题。" }, { "title": "在Windows平台使用IIS部署Flask网站", "url": "/posts/2017-03-27/deploy-flask-to-iis/", "categories": "Tech", "tags": "python, flask, iis, deployment", "date": "2017-03-27 00:00:00 +0800", "snippet": "在 Windows 平台部署基于 Python 的网站是一件非常折腾的事情，Linux/Unix 平台下有很多选择，本文记录了 Flask 部署到 IIS 的主要步骤，希望对你有所帮助。涉及工具和平台 Windows 7 x64 Python 3.4+ Flask完成 Hello Flask 网站这是一个最简单的 Flask 网站：# hello.pyfrom flask import...", "content": "在 Windows 平台部署基于 Python 的网站是一件非常折腾的事情，Linux/Unix 平台下有很多选择，本文记录了 Flask 部署到 IIS 的主要步骤，希望对你有所帮助。涉及工具和平台 Windows 7 x64 Python 3.4+ Flask完成 Hello Flask 网站这是一个最简单的 Flask 网站：# hello.pyfrom flask import Flaskapp=Flask(__name__)@app.route('/',methods=['GET'])def index(): return \"Hello Flask!\"if __name__=='__main__': app.run(debug=True)运行python hello.py后没有错误说明你的 Python 环境一切正常，可以继续后面的步骤。安装 IIS，启用 CGI在控制面板中找到打开或者关闭 Windows 功能，安装 IIS 和 CGI，如下图。安装 URL 重写组件IIS 需要安装 URL 重写组件，这个可以通过Microsoft Web Platform Installer来安装。下载Microsoft Web Platform Installer后运行，搜索url，分别安装。注：据说 Windows10 上的 IIS 10 现在不支持 url 重写？待验证安装 wfastcgi通过 pip 就可以安装：pip install wfastcgi启用 wfastcgi剩下的事情就只有一些配置了。首先以管理员身份运行wfastcgi-enable来在 IIS 上启用 wfastcgi，这个命令位于c:\\python_dir\\scripts，也就是你需要确保此目录在系统的 PATH 里，或者你需要 cd 到这个目录后再执行。# cd to python_dir\\scripts if it is not in PATHwfastcgi-enable记住命令执行成功后返回的信息：C:\\Python34\\Scripts&gt; wfastcgi-enableApplied configuration changes to section \"system.webServer/fastCgi\" for \"MACHINE/WEBROOT/APPHOST\" at configuration commit path \"MACHINE/WEBROOT/APPHOST\"\"C:\\Python34\\python.exe|C:\\Python34\\lib\\site-packages\\wfastcgi.py\" can now be used as a FastCGI script processor “C:\\Python34\\python.exe C:\\Python34\\lib\\site-packages\\wfastcgi.py” 在下文的配置文件中需要使用。 Tips: 使用命令 wfastcgi-disable 可以将其移除。创建 web.config 文件下面是一个web.config文件的例子，你只需要修改对应部分就可以使用。&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;system.webServer&gt; &lt;handlers&gt; &lt;!-- scriptProcessor 的值来自命令行工具 wfastcgi-enable --&gt; &lt;add name=\"FlaskFastCGI\" path=\"*\" verb=\"*\" modules=\"FastCgiModule\" scriptProcessor=\"C:\\Python34\\python.exe|C:\\Python34\\lib\\site-packages\\wfastcgi.py\" resourceType=\"Unspecified\" requireAccess=\"Script\" /&gt; &lt;/handlers&gt; &lt;security&gt; &lt;!-- URL 重写中的特殊字符，比如加号+等等 --&gt; &lt;requestFiltering allowDoubleEscaping=\"true\"&gt;&lt;/requestFiltering&gt; &lt;/security&gt; &lt;/system.webServer&gt; &lt;appSettings&gt; &lt;!-- Required settings --&gt; &lt;!-- 在这里指定Falsk app在模块中的具体位置 --&gt; &lt;add key=\"WSGI_HANDLER\" value=\"hello.app\" /&gt; &lt;add key=\"PYTHONPATH\" value=\"~/\" /&gt; &lt;!-- Optional settings --&gt; &lt;!-- 需要先创建日志目录，否则报错 --&gt; &lt;add key=\"WSGI_LOG\" value=\"C:\\logs\\oboeqa_web.log\" /&gt; &lt;add key=\"WSGI_RESTART_FILE_REGEX\" value=\"\" /&gt; &lt;/appSettings&gt;&lt;/configuration&gt;配置 IIS 目录及权限假设你的 Flask 程序将部署在 C:\\website\\hello 下面，那么你的目录结构大致如此。C:\\WEBSITE└───hello hello.py web.config现在你需要让 IIS 用户拥有访问和执行你的网站脚本的权限，进入 C:\\website 目录，执行下面两条命令：cd C:\\websiteicacls . /grant \"NT AUTHORITY\\IUSR:(OI)(CI)(RX)\"icacls . /grant \"Builtin\\IIS_IUSRS:(OI)(CI)(RX)\"创建并访问你的网站现在你离成功只差一步之遥，打开 IIS 管理面板，新建一个网站。你只需要填上网站名称，物理地址和相应的端口号，点击确认。打开浏览器，就可以访问你配置好的网站。如果有错误，可以去检查 web.config 中配置的日志文件。简单总结写完之后发现其实要完成的步骤并不是特别复杂，但是从摸索到实践的过程确实不易。本文仅讨论了部署的主要步骤，其实真正的生产环境你要考虑的问题可能更多，比如使用 virtualenv 对网站进行隔离，安全问题，静态文件解析等等。最后的惊喜据说部署 Python 网站到 IIS 还有更简单的办法，那就是安装宇宙最强的 IDE - Visual Studio 2015 （VS2017 暂不支持 Python 开发），个人开发者可以免授权使用社区版。在 VS 中你可以使用 PTVS 来快捷开发并部署Python 程序，真正让你一键无忧。PTVS 支持了常见的 Python Web 框架，比如 Flask，Django，Bottle，Jade 等等，调试的时候只需要按 F5，部署右键选择 publish，跟着向导一步两步你就可以完成魔鬼的步伐。参考链接 http://stackoverflow.com/questions/5072166/how-do-i-deploy-a-flask-application-in-iis http://stackoverflow.com/questions/20134329/how-to-deploy-a-flask-application-in-iis-8-windows-server-2012 http://blog.csdn.net/firefox1/article/details/46438769 http://www.cnblogs.com/liulixiang/p/4999608.html http://www.cnblogs.com/xiaolecn/p/5111076.html" }, { "title": "理解 Git Diff 命令", "url": "/posts/2017-03-10/git-diff-tip/", "categories": "Tech", "tags": "git, tips", "date": "2017-03-10 07:04:51 +0800", "snippet": "你确定自己会git diff 吗？在 git 提交过程中，存在三大环节： working tree index file (staged) commit这三大环节中，你应该有一个大概的了解： working tree：就是你所工作在的目录，每当你在代码中进行了修改，working tree 的状态就改变了。 index file：是索引文件，它是连接working tree和com...", "content": "你确定自己会git diff 吗？在 git 提交过程中，存在三大环节： working tree index file (staged) commit这三大环节中，你应该有一个大概的了解： working tree：就是你所工作在的目录，每当你在代码中进行了修改，working tree 的状态就改变了。 index file：是索引文件，它是连接working tree和commit的桥梁，每当我们使用git add命令来登记修改的文件后，index file的内容就改变了，此时index file就和working tree同步了。 commit：这是提交更改完成的最后阶段，commit 后我们的代码才真正进入了 git 仓库。我们使用git commit就是将index file里的内容提交到commit中。总结一下： git diff：是查看working tree与index file的差别。 git diff –cached：是查看index file与commit的差别。 git diff HEAD：是查看working tree和commit的差别。（你一定没有忘记，HEAD 代表的是最近的一次 commit 的信息）参考文档： http://www.cnblogs.com/Alight/p/3571042.html" }, { "title": "上传并发布你自己发明的轮子 - Python PyPI 实践", "url": "/posts/2017-03-09/upload-your-pypi-package/", "categories": "Tech", "tags": "python, PyPI", "date": "2017-03-09 00:00:00 +0800", "snippet": "Pypi 的发布实践。本文仅讨论上传相关的步骤，关于如何给写一个setup.py 请参阅官方文档： https://docs.python.org/2/distutils/setupscript.html上传前的注意事项 假设你的包已经开发完成，并且根目录必须要有一个setup.py。 最好有一个README.rst 用来描述你的轮子，虽然这不是必须的，但文档就像内裤，你最好还是要有的...", "content": "Pypi 的发布实践。本文仅讨论上传相关的步骤，关于如何给写一个setup.py 请参阅官方文档： https://docs.python.org/2/distutils/setupscript.html上传前的注意事项 假设你的包已经开发完成，并且根目录必须要有一个setup.py。 最好有一个README.rst 用来描述你的轮子，虽然这不是必须的，但文档就像内裤，你最好还是要有的。 如果你需要打包代码文件夹以外的文件，比如版权信息等等，你还需要写一个 MANIFEST.in。关于setup.py的补充说明 name 必须是唯一的，允许使用数字和字母，推荐使用中划线（-）而不是下划线（_），因为 pip 安装只支持中划线，比如pip install my-pkg，为了不给自己找麻烦请听话。 version推荐遵循语义化版本号规则，简单说就像这样：1.2.0 作者姓名和邮箱地址不一定要和你的 PyPI 账号一致。测试本地打包命令如果上面的都没问题，在本地目录执行以下命令应该能成功在 dist 目录下生成*.tar.gz 的包文件。python setup.py sdist上传并发布包文件到 PyPI创建 PyPI 账号非常简单，直接通过官网注册 https://pypi.python.org/pypi?%3Aaction=register_form， 但是需要验证邮件并确认激活。创建用户验证文件 ~/.pypirc在自己的用户目录下新建一个空白文件命名为.pypirc，内容如下：[distutils]index-servers=pypi[pypi]repository = https://upload.pypi.org/legacy/username = &lt;username&gt;password = &lt;password&gt;用户名和密码就是上一步骤所创建的，直接明文输入。如果你觉得明文密码不安全也可以留空，在后面的上传过程中会提示你手动输入。注册你的包你需要到 PyPI 注册并验证你的包，之后才能开始真正上传，注册的方式有以下几种。 使用命令python setup.py register，最简单但官网不推荐，因为使用的是 HTTP 未加密，有可能会被攻击人嗅探到你的密码。 通过PyPI 网站提交表单完成注册验证。 安装 pip install twine 然后在通过命令 twine register dist/mypkg.whl 完成注册。上传并完成发布你可以任选以下两种方式之一发布你的轮子。 使用命令：python setup.py sdist upload，还是和上面一样，最简单但是有安全隐患。 使用 twine： twine upload dist/*管理你的包如果你的包已经上传成功，那么当你登录 PyPI 网站后应该能在右侧导航栏看到管理入口。点击包名进去后你可以对你的包进行管理，当然你也可以从这里删除这个包。让别人使用你的包包发布完成后，其他人只需要使用 pip 就可以安装你的包文件。比如：pip install package-name如果你更新了包，别人可以可以通过--update参数来更新：pip install package-name --update可能遇到的错误Upload failed (403): Invalid or non-existent authentication information.错误的用户验证信息，你需要创建一个用户验证文件 ~/.pypirc。请参阅上文。Upload failed (403): You are not allowed to edit ‘xxx’ package information你需要先注册你的包才可以开始上传，运行注册命令：python setup.py registerServer response (401): Incomplete registration; check your email你的 PyPI 账户还没完成邮箱验证，你需要去注册邮箱找到一封验证邮件完成验证后再重试失败的步骤。Server response (400): Invalid classifier “Topic :: Software Development :: Utilities”你的 setup.py 文件中的classifier信息有误，请按官网的正确分类书写classifier.error: No dist file created in earlier command你还没打包就开始了上传命令，建议打包和上传的操作放在一起做，比如：python setup sdist uploaderror: Upload failed (499): Client Disconnected这应该是网络问题，多重试几次。Upload failed (400): File already exists文件已经存在了，你每一次上次都应该更新版本号。参考文档 https://packaging.python.org/distributing/" }, { "title": "Move on to Python 3", "url": "/posts/2017-02-06/move-on-to-python-3/", "categories": "Tech", "tags": "Python", "date": "2017-02-06 00:00:00 +0800", "snippet": "Do we want to move on to Python 3?Well, what is your concerns? Here is a slide made by me probably can help you out. (Use the left/right arrow key to navigate back/forward.)Slides Resources View t...", "content": "Do we want to move on to Python 3?Well, what is your concerns? Here is a slide made by me probably can help you out. (Use the left/right arrow key to navigate back/forward.)Slides Resources View the slide in full screen: Move on to python 3 Download the mindmap file: move on to python 3.xmind" }, { "title": "总结：Python中的异常处理", "url": "/posts/2016-12-04/Python-exception-handling/", "categories": "Tech", "tags": "python, exception handling", "date": "2016-12-04 00:00:00 +0800", "snippet": "异常处理在任何一门编程语言里都是值得关注的一个话题，良好的异常处理可以让你的程序更加健壮，清晰的错误信息更能帮助你快速修复问题。在Python中，和不部分高级语言一样，使用了try/except/finally语句块来处理异常，如果你有其他编程语言的经验，实践起来并不难。异常处理语句 try…excpet…finally实例代码def div(a, b): try: pr...", "content": "异常处理在任何一门编程语言里都是值得关注的一个话题，良好的异常处理可以让你的程序更加健壮，清晰的错误信息更能帮助你快速修复问题。在Python中，和不部分高级语言一样，使用了try/except/finally语句块来处理异常，如果你有其他编程语言的经验，实践起来并不难。异常处理语句 try…excpet…finally实例代码def div(a, b): try: print(a / b) except ZeroDivisionError: print(\"Error: b should not be 0 !!\") except Exception as e: print(\"Unexpected Error: {}\".format(e)) else: print('Run into else only when everything goes well') finally: print('Always run into finally block.')# testsdiv(2, 0)div(2, 'bad type')div(1, 2)# Mutiple exception in one linetry: print(a / b)except (ZeroDivisionError, TypeError) as e: print(e)# Except block is optional when there is finallytry: open(database)finally: close(database)# catch all errors and log ittry: do_work()except: # get detail from logging module logging.exception('Exception caught!') # get detail from sys.exc_info() method error_type, error_value, trace_back = sys.exc_info() print(error_value) raise总结如下 except语句不是必须的，finally语句也不是必须的，但是二者必须要有一个，否则就没有try的意义了。 except语句可以有多个，Python会按except语句的顺序依次匹配你指定的异常，如果异常已经处理就不会再进入后面的except语句。 except语句可以以元组形式同时指定多个异常，参见实例代码。 except语句后面如果不指定异常类型，则默认捕获所有异常，你可以通过logging或者sys模块获取当前异常。 如果要捕获异常后要重复抛出，请使用raise，后面不要带任何参数或信息。 不建议捕获并抛出同一个异常，请考虑重构你的代码。 不建议在不清楚逻辑的情况下捕获所有异常，有可能你隐藏了很严重的问题。 尽量使用内置的异常处理语句来 替换try/except语句，比如with语句，getattr()方法。抛出异常 raise如果你需要自主抛出异常一个异常，可以使用raise关键字，等同于C#和Java中的throw语句，其语法规则如下。raise NameError(\"bad name!\")raise关键字后面需要指定你抛出的异常类型，一般来说抛出的异常越详细越好，Python在exceptions模块内建了很多的异常类型，通过使用dir()函数来查看exceptions中的异常类型，如下：import exceptions# ['ArithmeticError', 'AssertionError'.....]print dir(exceptions)当然你也可以查阅Python的文档库进行更详细的了解。 https://docs.python.org/2.7/library/exceptions.html#bltin-exceptions自定义异常类型Python中也可以自定义自己的特殊类型的异常，只需要要从Exception类继承(直接或间接)即可：class SomeCustomException(Exception): pass一般你在自定义异常类型时，需要考虑的问题应该是这个异常所应用的场景。如果内置异常已经包括了你需要的异常，建议考虑使用内置 的异常类型。比如你希望在函数参数错误时抛出一个异常，你可能并不需要定义一个InvalidArgumentError，使用内置的ValueError即可。经验案例传递异常 re-raise Exception捕捉到了异常，但是又想重新引发它（传递异常），使用不带参数的raise语句即可：def f1(): print(1/0)def f2(): try: f1() except Exception as e: raise # don't raise e !!!f2()在Python2中，为了保持异常的完整信息，那么你捕获后再次抛出时千万不能在raise后面加上异常对象，否则你的trace信息就会从此处截断。以上是最简单的重新抛出异常的做法。还有一些技巧可以考虑，比如抛出异常前对异常的信息进行更新。def f2(): try: f1() except Exception as e: e.args += ('more info',) raise如果你有兴趣了解更多，建议阅读这篇博客。 http://www.ianbicking.org/blog/2007/09/re-raising-exceptions.htmlPython3对重复传递异常有所改进，你可以自己尝试一下，不过建议还是同上。Exception 和 BaseException当我们要捕获一个通用异常时，应该用Exception还是BaseException？我建议你还是看一下 官方文档说明，这两个异常到底有啥区别呢？ 请看它们之间的继承关系。BaseException +-- SystemExit +-- KeyboardInterrupt +-- GeneratorExit +-- Exception +-- StopIteration... +-- StandardError... +-- Warning...从Exception的层级结构来看，BaseException是最基础的异常类，Exception继承了它。BaseException除了包含所有的Exception外还包含了SystemExit，KeyboardInterrupt和GeneratorExit三个异常。有此看来你的程序在捕获所有异常时更应该使用Exception而不是BaseException，因为另外三个异常属于更高级别的异常，合理的做法应该是交给Python的解释器处理。except Exception as e和 except Exception, e代码示例如下：try: do_something()except NameError as e: # should passexcept KeyError, e: # should not pass在Python2的时代，你可以使用以上两种写法中的任意一种。在Python3中你只能使用第一种写法，第二种写法被废弃掉了。第一个种写法可读性更好，而且为了程序的兼容性和后期移植的成本，请你也抛弃第二种写法。raise “Exception string”把字符串当成异常抛出看上去是一个非常简洁的办法，但其实是一个非常不好的习惯。if is_work_done(): passelse: raise \"Work is not done!\" # not cool上面的语句如果抛出异常，那么会是这样的：Traceback (most recent call last): File \"/demo/exception_hanlding.py\", line 48, in &lt;module&gt; raise \"Work is not done!\"TypeError: exceptions must be old-style classes or derived from BaseException, not str这在Python2.4以前是可以接受的做法，但是没有指定异常类型有可能会让下游没办法正确捕获并处理这个异常，从而导致你的程序挂掉。简单说，这种写法是是封建时代的陋习，应该扔了。使用内置的语法范式代替try/exceptPython 本身提供了很多的语法范式简化了异常的处理，比如for语句就处理的StopIteration异常，让你很流畅地写出一个循环。with语句在打开文件后会自动调用finally中的关闭文件操作。我们在写Python代码时应该尽量避免在遇到这种情况时还使用try/except/finally的思维来处理。# should nottry: f = open(a_file) do_something(f)finally: f.close()# should with open(a_file) as f: do_something(f)再比如，当我们需要访问一个不确定的属性时，有可能你会写出这样的代码：try: test = Test() name = test.name # not sure if we can get its nameexcept AttributeError: name = 'default'其实你可以使用更简单的getattr()来达到你的目的。name = getattr(test, 'name', 'default')最佳实践最佳实践不限于编程语言，只是一些规则和填坑后的收获。 只处理你知道的异常，避免捕获所有 异常然后吞掉它们。 抛出的异常应该说明原因，有时候你知道异常类型也猜不出所以然的。 避免在catch语句块中干一些没意义的事情。 不要使用异常来控制流程，那样你的程序会无比难懂和难维护。 如果有需要，切记使用finally来释放资源。 如果有需要，请不要忘记在处理异常后做清理工作或者回滚操作。" }, { "title": "Gif截屏工具 - GifCam", "url": "/posts/2016-11-23/gif-screenshot-tool-gifcam/", "categories": "Tech", "tags": "tools", "date": "2016-11-23 00:00:00 +0800", "snippet": "如果你需要录制截屏并保存成 gif 图片格式，那么你一定不能错过 GifCam 这个神奇的小工具。它虽然只有 600K，但功能不可小觑。GifCam (Gif 相机) 是一款免费且非常优秀的视频录制/剪辑的 GIF 动画制作软件，它的使用非常简单直观，譬如想要将某一小段视频录制成 Gif 图片，你只需将其窗口的取景框拖放到视频播放的区域，然后按下录制按钮即开始录制。它就像一个摄像机一样能将取...", "content": "如果你需要录制截屏并保存成 gif 图片格式，那么你一定不能错过 GifCam 这个神奇的小工具。它虽然只有 600K，但功能不可小觑。GifCam (Gif 相机) 是一款免费且非常优秀的视频录制/剪辑的 GIF 动画制作软件，它的使用非常简单直观，譬如想要将某一小段视频录制成 Gif 图片，你只需将其窗口的取景框拖放到视频播放的区域，然后按下录制按钮即开始录制。它就像一个摄像机一样能将取景框拍摄下来并保存成 GIF 图片。借助 GifCam 你可以快速方便地制作演示教程或者将视频一些搞笑经典片段制作成动画图片。你也可以将录制的屏幕导出成 avi 的视频格式，并根据指定的码率做压缩。GifCam 官网：http://blog.bahraniapps.com/gifcam/#download从本站下载：/files/GifCam.zip" }, { "title": "Python装饰器的另类用法", "url": "/posts/2016-10-30/python-decorator-more/", "categories": "Tech", "tags": "python, python decorator", "date": "2016-10-30 00:00:00 +0800", "snippet": "之前有比较系统介绍过 Python 的装饰器（请查阅《详解 Python 装饰器》），本文算是一个补充。今天我们一起探讨一下装饰器的另类用法。语法回顾开始之前我们再将 Python 装饰器的语法回顾一下。@decoratedef f(...): pass等同于:def f(...): passf = decorate(f)@语法的好处在于： 相同的函数名只出现一次，避免了f =...", "content": "之前有比较系统介绍过 Python 的装饰器（请查阅《详解 Python 装饰器》），本文算是一个补充。今天我们一起探讨一下装饰器的另类用法。语法回顾开始之前我们再将 Python 装饰器的语法回顾一下。@decoratedef f(...): pass等同于:def f(...): passf = decorate(f)@语法的好处在于： 相同的函数名只出现一次，避免了f = decorate(f)这样的语句。 可读性更高，让读代码的人一眼就明白这个函数被装饰了哪些功能。@call()装饰器假设你要创建一个整数平方的列表，你可以这样写：&gt;&gt;&gt; table = [0, 1, 4, 9, 16]&gt;&gt;&gt; len(table), table[3](5, 9)也可以使用列表表达式，因为比较简单。&gt;&gt;&gt; table = [i * i for i in range(5)]&gt;&gt;&gt; len(table), table[3](5, 9)但是假如这个列表的逻辑比较复杂的时候，最好是写成一个方法，这样会更好维护。&gt;&gt;&gt; def table(n):... value = []... for i in range(n):... value.append(i*i)... return value&gt;&gt;&gt; table = table(5)注意看最后一句，是不是很符合装饰器的语法规则？什么情况下你会写这样的代码呢？ 你需要把相对复杂业务写成一个方法。 这个方法和返回值可以同名，而且你不希望对外公开此方法，只公开结果。 你想尽量使用装饰器。（无厘头的理由）那么这时候@call()装饰器就登场了。def call(*args, **kwargs): def call_fn(fn): return fn(*args, **kwargs) return call_fn这个装饰器会把你传入的参数送给目标函数然后直接执行。@call(5)def table(n): value = [] for i in range(n): value.append(i*i) return valueprint len(table), table[3] # 5 9@call()装饰器适用于任何函数，你传入的参数会被直接使用然后结果赋值给同名函数。这样避免了你重新定义一个变量来存储结果。@list 装饰器假如你有一个这样一个生成器函数。def table(n): for i in range(n): yield i当你要生成n=5的序列时，可以直接调用。table = table(5)print table # &lt;generator object table at 0x027DAC10&gt;使用@call()装饰器，也能得到一样的结果。@call(5)def table(n): for i in range(n): yield iprint table # &lt;generator object table at 0x0340AC10&gt;你还可以直接将其转换成列表。（使用list(generator_object)函数）@list@call(5)def table(n): for i in range(n): yield iprint table # [0, 1, 2, 3, 4]这等同于列表表达式，但是可读性也许差了不少。例子本身只是演示了装饰器的一种用法，但不是推荐你就这样使用装饰器。你这样用也许会被其他同事拖到墙角里打死。类装饰器在 Python 2.6 以前，还不支持类装饰器。也就是说，你不能使用这样的写法。@decoratorclass MyClass(object): pass你必须这样写：class MyClass(object): passMyClass = decorator(MyClass)也就是说，@语法对类是做了特殊处理的，类不一定是一个 callable 对象（尽管它有构造函数），但是也允许使用装饰器。那么基于以上语法，你觉得类装饰器能实现什么功能呢？举一个例子，ptest中的@TestClass()用于声明一个测试类，其源代码大致如此。def TestClass(enabled=True, run_mode=\"singleline\"): def tracer(cls): cls.__pd_type__ ='test' cls.__enabled__ = enabled cls.__run_mode__ = run_mode.lower() return cls return tracer当我们在写一个测试类时，发生了什么？@TestClass()class TestCases(object): # your test case ...print TestCases.__dict__ # {'__module__': '__main__', '__enabled__': True, '__pd_type__': 'test', '__run_mode__': 'singleline', ...}居然装饰器的参数全都变成了变成这个类的属性，好神奇！我们把语法糖一一展开。class TestCases(object): passdecorator = TestClass()print decorator # &lt;function tracer at 0x033128F0&gt;TestCases = decorator(TestCases)print TestCases # &lt;class '__main__.TestCases'&gt;print TestCases.__dict__ # {'__module__': '__main__', '__enabled__': True, '__pd_type__': 'test', '__run_mode__': 'singleline', ...}当装饰器在被使用时，TestClass()函数会马上被执行并返回一个装饰器函数，这个函数是一个闭包函数，保存了enabled和run_mode两个变量。另外它还接受一个类作为参数，并使用之前保存的变量为这个类添加属性，最后返回。所以经过@TestClass()装饰过的类都会带上__enabled__、__pd_type__以及__run_mode__的属性。由此可见，类装饰器可以完成和 Java 类似的注解功能，而且要比注解强大的多。后记装饰器就是一个语法糖，当你看不懂一个装饰器时，可以考虑将其依次展开，分别带入。这个语法糖给了我们不少方便，但是也要慎用。毕竟可维护的代码才是高质量的代码。" }, { "title": "详解Python的装饰器", "url": "/posts/2016-10-27/python-decorator/", "categories": "Tech", "tags": "python, python decorator", "date": "2016-10-27 00:00:00 +0800", "snippet": "Python 中的装饰器是你进入 Python 大门的一道坎，不管你跨不跨过去它都在那里。为什么需要装饰器我们假设你的程序实现了say_hello()和say_goodbye()两个函数。def say_hello(): print \"hello!\"def say_goodbye(): print \"hello!\" # bug hereif __name__ == '__mai...", "content": "Python 中的装饰器是你进入 Python 大门的一道坎，不管你跨不跨过去它都在那里。为什么需要装饰器我们假设你的程序实现了say_hello()和say_goodbye()两个函数。def say_hello(): print \"hello!\"def say_goodbye(): print \"hello!\" # bug hereif __name__ == '__main__': say_hello() say_goodbye()但是在实际调用中，我们发现程序出错了，上面的代码打印了两个 hello。经过调试你发现是say_goodbye()出错了。老板要求调用每个方法前都要记录进入函数的时间和名称，比如这样：[DEBUG] 2016-10-27 11:11:11 - Enter say_hello()Hello![DEBUG] 2016-10-27 11:11:11 - Enter say_goodbye()Goodbye!好，小 A 是个毕业生，他是这样实现的。def say_hello(): print \"[DEBUG]: enter say_hello()\" print \"hello!\"def say_goodbye(): print \"[DEBUG]: enter say_goodbye()\" print \"hello!\"if __name__ == '__main__': say_hello() say_goodbye()很 low 吧？ 嗯是的。小 B 工作有一段时间了，他告诉小 A 应该这样写。def debug(): import inspect caller_name = inspect.stack()[1][3] print \"[DEBUG]: enter {}()\".format(caller_name)def say_hello(): debug() print \"hello!\"def say_goodbye(): debug() print \"goodbye!\"if __name__ == '__main__': say_hello() say_goodbye()是不是好一点？那当然，但是每个业务函数里都要调用一下debug()函数，是不是很难受？万一老板说 say 相关的函数不用 debug，do 相关的才需要呢？那么装饰器这时候应该登场了。 装饰器本质上是一个 Python 函数，它可以让其他函数在不需要做任何代码变动的前提下增加额外功能，装饰器的返回值也是一个函数对象。它经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量与函数功能本身无关的雷同代码并继续重用。概括的讲，装饰器的作用就是为已经存在的函数或对象添加额外的功能。怎么写一个装饰器在早些时候 (Python Version &lt; 2.4，2004 年以前)，为一个函数添加额外功能的写法是这样的。def debug(func): def wrapper(): print \"[DEBUG]: enter {}()\".format(func.__name__) return func() return wrapperdef say_hello(): print \"hello!\"say_hello = debug(say_hello) # 添加功能并保持原函数名不变上面的 debug 函数其实已经是一个装饰器了，它对原函数做了包装并返回了另外一个函数，额外添加了一些功能。因为这样写实在不太优雅，在后面版本的 Python 中支持了@语法糖，下面代码等同于早期的写法。def debug(func): def wrapper(): print \"[DEBUG]: enter {}()\".format(func.__name__) return func() return wrapper@debugdef say_hello(): print \"hello!\"这是最简单的装饰器，但是有一个问题，如果被装饰的函数需要传入参数，那么这个装饰器就坏了。因为返回的函数并不能接受参数，你可以指定装饰器函数wrapper接受和原函数一样的参数，比如：def debug(func): def wrapper(something): # 指定一毛一样的参数 print \"[DEBUG]: enter {}()\".format(func.__name__) return func(something) return wrapper # 返回包装过函数@debugdef say(something): print \"hello {}!\".format(something)这样你就解决了一个问题，但又多了 N 个问题。因为函数有千千万，你只管你自己的函数，别人的函数参数是什么样子，鬼知道？还好 Python 提供了可变参数*args和关键字参数**kwargs，有了这两个参数，装饰器就可以用于任意目标函数了。def debug(func): def wrapper(*args, **kwargs): # 指定宇宙无敌参数 print \"[DEBUG]: enter {}()\".format(func.__name__) print 'Prepare and say...', return func(*args, **kwargs) return wrapper # 返回@debugdef say(something): print \"hello {}!\".format(something)至此，你已完全掌握初级的装饰器写法。高级一点的装饰器带参数的装饰器和类装饰器属于进阶的内容。在理解这些装饰器之前，最好对函数的闭包和装饰器的接口约定有一定了解。(参见 https://tobyqin.cn/posts/2016-10-22/python-closure/)带参数的装饰器假设我们前文的装饰器需要完成的功能不仅仅是能在进入某个函数后打出 log 信息，而且还需指定 log 的级别，那么装饰器就会是这样的。def logging(level): def wrapper(func): def inner_wrapper(*args, **kwargs): print \"[{level}]: enter function {func}()\".format( level=level, func=func.__name__) return func(*args, **kwargs) return inner_wrapper return wrapper@logging(level='INFO')def say(something): print \"say {}!\".format(something)# 如果没有使用@语法，等同于# say = logging(level='INFO')(say)@logging(level='DEBUG')def do(something): print \"do {}...\".format(something)if __name__ == '__main__': say('hello') do(\"my work\")是不是有一些晕？你可以这么理解，当带参数的装饰器被打在某个函数上时，比如@logging(level='DEBUG')，它其实是一个函数，会马上被执行，只要这个它返回的结果是一个装饰器时，那就没问题。细细再体会一下。基于类实现的装饰器装饰器函数其实是这样一个接口约束，它必须接受一个 callable 对象作为参数，然后返回一个 callable 对象。在 Python 中一般 callable 对象都是函数，但也有例外。只要某个对象重载了__call__()方法，那么这个对象就是 callable 的。class Test(): def __call__(self): print 'call me!'t = Test()t() # call me像__call__这样前后都带下划线的方法在 Python 中被称为内置方法，有时候也被称为魔法方法。重载这些魔法方法一般会改变对象的内部行为。上面这个例子就让一个类对象拥有了被调用的行为。回到装饰器上的概念上来，装饰器要求接受一个 callable 对象，并返回一个 callable 对象（不太严谨，详见后文）。那么用类来实现也是也可以的。我们可以让类的构造函数__init__()接受一个函数，然后重载__call__()并返回一个函数，也可以达到装饰器函数的效果。class logging(object): def __init__(self, func): self.func = func def __call__(self, *args, **kwargs): print \"[DEBUG]: enter function {func}()\".format( func=self.func.__name__) return self.func(*args, **kwargs)@loggingdef say(something): print \"say {}!\".format(something)带参数的类装饰器如果需要通过类形式实现带参数的装饰器，那么会比前面的例子稍微复杂一点。那么在构造函数里接受的就不是一个函数，而是传入的参数。通过类把这些参数保存起来。然后在重载__call__方法是就需要接受一个函数并返回一个函数。class logging(object): def __init__(self, level='INFO'): self.level = level def __call__(self, func): # 接受函数 def wrapper(*args, **kwargs): print \"[{level}]: enter function {func}()\".format( level=self.level, func=func.__name__) func(*args, **kwargs) return wrapper #返回函数@logging(level='INFO')def say(something): print \"say {}!\".format(something)内置的装饰器内置的装饰器和普通的装饰器原理是一样的，只不过返回的不是函数，而是类对象，所以更难理解一些。@property在了解这个装饰器前，你需要知道在不使用装饰器怎么写一个属性。def getx(self): return self._xdef setx(self, value): self._x = valuedef delx(self): del self._x# create a propertyx = property(getx, setx, delx, \"I am doc for x property\")以上就是一个 Python 属性的标准写法，其实和 Java 挺像的，但是太罗嗦。有了@语法糖，能达到一样的效果但看起来更简单。@propertydef x(self): ...# 等同于def x(self): ...x = property(x)属性有三个装饰器：setter, getter, deleter ，都是在property()的基础上做了一些封装，因为setter和deleter是property()的第二和第三个参数，不能直接套用@语法。getter装饰器和不带getter的属性装饰器效果是一样的，估计只是为了凑数，本身没有任何存在的意义。经过@property装饰过的函数返回的不再是一个函数，而是一个property对象。&gt;&gt;&gt; property()&lt;property object at 0x10ff07940&gt;@staticmethod，@classmethod有了@property装饰器的了解，这两个装饰器的原理是差不多的。@staticmethod返回的是一个staticmethod类对象，而@classmethod返回的是一个classmethod类对象。他们都是调用的是各自的__init__()构造函数。class classmethod(object): \"\"\" classmethod(function) -&gt; method \"\"\" def __init__(self, function): # for @classmethod decorator pass # ...class staticmethod(object): \"\"\" staticmethod(function) -&gt; method \"\"\" def __init__(self, function): # for @staticmethod decorator pass # ...装饰器的@语法就等同调用了这两个类的构造函数。class Foo(object): @staticmethod def bar(): pass # 等同于 bar = staticmethod(bar)至此，我们上文提到的装饰器接口定义可以更加明确一些，装饰器必须接受一个 callable 对象，其实它并不关心你返回什么，可以是另外一个 callable 对象（大部分情况），也可以是其他类对象，比如 property。装饰器里的那些坑装饰器可以让你代码更加优雅，减少重复，但也不全是优点，也会带来一些问题。位置错误的代码让我们直接看示例代码。def html_tags(tag_name): print 'begin outer function.' def wrapper_(func): print \"begin of inner wrapper function.\" def wrapper(*args, **kwargs): content = func(*args, **kwargs) print \"&lt;{tag}&gt;{content}&lt;/{tag}&gt;\".format(tag=tag_name, content=content) print 'end of inner wrapper function.' return wrapper print 'end of outer function' return wrapper_@html_tags('b')def hello(name='Toby'): return 'Hello {}!'.format(name)hello()hello()在装饰器中我在各个可能的位置都加上了 print 语句，用于记录被调用的情况。你知道他们最后打印出来的顺序吗？如果你心里没底，那么最好不要在装饰器函数之外添加逻辑功能，否则这个装饰器就不受你控制了。以下是输出结果：begin outer function.end of outer functionbegin of inner wrapper function.end of inner wrapper function.&lt;b&gt;Hello Toby!&lt;/b&gt;&lt;b&gt;Hello Toby!&lt;/b&gt;错误的函数签名和文档装饰器装饰过的函数看上去名字没变，其实已经变了。def logging(func): def wrapper(*args, **kwargs): \"\"\"print log before a function.\"\"\" print \"[DEBUG] {}: enter {}()\".format(datetime.now(), func.__name__) return func(*args, **kwargs) return wrapper@loggingdef say(something): \"\"\"say something\"\"\" print \"say {}!\".format(something)print say.__name__ # wrapper为什么会这样呢？只要你想想装饰器的语法糖@代替的东西就明白了。@等同于这样的写法。say = logging(say)logging其实返回的函数名字刚好是wrapper，那么上面的这个语句刚好就是把这个结果赋值给say，say的__name__自然也就是wrapper了，不仅仅是name，其他属性也都是来自wrapper，比如doc，source等等。使用标准库里的functools.wraps，可以基本解决这个问题。from functools import wrapsdef logging(func): @wraps(func) def wrapper(*args, **kwargs): \"\"\"print log before a function.\"\"\" print \"[DEBUG] {}: enter {}()\".format(datetime.now(), func.__name__) return func(*args, **kwargs) return wrapper@loggingdef say(something): \"\"\"say something\"\"\" print \"say {}!\".format(something)print say.__name__ # sayprint say.__doc__ # say something看上去不错！主要问题解决了，但其实还不太完美。因为函数的签名和源码还是拿不到的。import inspectprint inspect.getargspec(say) # failedprint inspect.getsource(say) # failed如果要彻底解决这个问题可以借用第三方包，比如wrapt。后文有介绍。不能装饰@staticmethod 或者 @classmethod当你想把装饰器用在一个静态方法或者类方法时，不好意思，报错了。class Car(object): def __init__(self, model): self.model = model @logging # 装饰实例方法，OK def run(self): print \"{} is running!\".format(self.model) @logging # 装饰静态方法，Failed @staticmethod def check_model_for(obj): if isinstance(obj, Car): print \"The model of your car is {}\".format(obj.model) else: print \"{} is not a car!\".format(obj)\"\"\"Traceback (most recent call last):... File \"example_4.py\", line 10, in logging @wraps(func) File \"C:\\Python27\\lib\\functools.py\", line 33, in update_wrapper setattr(wrapper, attr, getattr(wrapped, attr))AttributeError: 'staticmethod' object has no attribute '__module__'\"\"\"前面已经解释了@staticmethod这个装饰器，其实它返回的并不是一个 callable 对象，而是一个staticmethod对象，那么它是不符合装饰器要求的（比如传入一个 callable 对象），你自然不能在它之上再加别的装饰器。要解决这个问题很简单，只要把你的装饰器放在@staticmethod之前就好了，因为你的装饰器返回的还是一个正常的函数，然后再加上一个@staticmethod是不会出问题的。class Car(object): def __init__(self, model): self.model = model @staticmethod @logging # 在@staticmethod之前装饰，OK def check_model_for(obj): pass如何优化你的装饰器嵌套的装饰函数不太直观，我们可以使用第三方包类改进这样的情况，让装饰器函数可读性更好。decorator.pydecorator.py 是一个非常简单的装饰器加强包。你可以很直观的先定义包装函数wrapper()，再使用decorate(func, wrapper)方法就可以完成一个装饰器。from decorator import decoratedef wrapper(func, *args, **kwargs): \"\"\"print log before a function.\"\"\" print \"[DEBUG] {}: enter {}()\".format(datetime.now(), func.__name__) return func(*args, **kwargs)def logging(func): return decorate(func, wrapper) # 用wrapper装饰func你也可以使用它自带的@decorator装饰器来完成你的装饰器。from decorator import decorator@decoratordef logging(func, *args, **kwargs): print \"[DEBUG] {}: enter {}()\".format(datetime.now(), func.__name__) return func(*args, **kwargs)decorator.py实现的装饰器能完整保留原函数的name，doc和args，唯一有问题的就是inspect.getsource(func)返回的还是装饰器的源代码，你需要改成inspect.getsource(func.__wrapped__)。wraptwrapt是一个功能非常完善的包，用于实现各种你想到或者你没想到的装饰器。使用 wrapt 实现的装饰器你不需要担心之前 inspect 中遇到的所有问题，因为它都帮你处理了，甚至inspect.getsource(func)也准确无误。import wrapt# without argument in decorator@wrapt.decoratordef logging(wrapped, instance, args, kwargs): # instance is must print \"[DEBUG]: enter {}()\".format(wrapped.__name__) return wrapped(*args, **kwargs)@loggingdef say(something): pass使用 wrapt 你只需要定义一个装饰器函数，但是函数签名是固定的，必须是(wrapped, instance, args, kwargs)，注意第二个参数instance是必须的，就算你不用它。当装饰器装饰在不同位置时它将得到不同的值，比如装饰在类实例方法时你可以拿到这个类实例。根据instance的值你能够更加灵活的调整你的装饰器。另外，args和kwargs也是固定的，注意前面没有星号。在装饰器内部调用原函数时才带星号。如果你需要使用 wrapt 写一个带参数的装饰器，可以这样写。def logging(level): @wrapt.decorator def wrapper(wrapped, instance, args, kwargs): print \"[{}]: enter {}()\".format(level, wrapped.__name__) return wrapped(*args, **kwargs) return wrapper@logging(level=\"INFO\")def do(work): pass关于 wrapt 的使用，建议查阅官方文档，在此不在赘述。 http://wrapt.readthedocs.io/en/latest/quick-start.html小结Python 的装饰器和 Java 的注解（Annotation）并不是同一回事，和 C#中的特性（Attribute）也不一样，完全是两个概念。装饰器的理念是对原函数、对象的加强，相当于重新封装，所以一般装饰器函数都被命名为wrapper()，意义在于包装。函数只有在被调用时才会发挥其作用。比如@logging装饰器可以在函数执行时额外输出日志，@cache装饰过的函数可以缓存计算结果等等。而注解和特性则是对目标函数或对象添加一些属性，相当于将其分类。这些属性可以通过反射拿到，在程序运行时对不同的特性函数或对象加以干预。比如带有Setup的函数就当成准备步骤执行，或者找到所有带有TestMethod的函数依次执行等等。至此我所了解的装饰器已经讲完，但是还有一些内容没有提到，比如装饰类的装饰器。有机会再补充。谢谢观看。 本文源码 https://github.com/tobyqin/python_decorator" }, { "title": "说说Python中的闭包 - Closure", "url": "/posts/2016-10-23/python-closure/", "categories": "Tech", "tags": "python, python closure", "date": "2016-10-23 00:00:00 +0800", "snippet": "Python 中的闭包不是一个一说就能明白的概念，但是随着你往学习的深入，无论如何你都需要去了解这么一个东西。闭包的概念我们尝试从概念上去理解一下闭包。 在一些语言中，在函数中可以（嵌套）定义另一个函数时，如果内部的函数引用了外部的函数的变量，则可能产生闭包。闭包可以用来在一个函数与一组“私有”变量之间创建关联关系。在给定函数被多次调用的过程中，这些私有变量能够保持其持久性。—— 维基百科...", "content": "Python 中的闭包不是一个一说就能明白的概念，但是随着你往学习的深入，无论如何你都需要去了解这么一个东西。闭包的概念我们尝试从概念上去理解一下闭包。 在一些语言中，在函数中可以（嵌套）定义另一个函数时，如果内部的函数引用了外部的函数的变量，则可能产生闭包。闭包可以用来在一个函数与一组“私有”变量之间创建关联关系。在给定函数被多次调用的过程中，这些私有变量能够保持其持久性。—— 维基百科用比较容易懂的人话说，就是当某个函数被当成对象返回时，夹带了外部变量，就形成了一个闭包。看例子。def make_printer(msg): def printer(): print msg # 夹带私货（外部变量） return printer # 返回的是函数，带私货的函数printer = make_printer('Foo!')printer()支持将函数当成对象使用的编程语言，一般都支持闭包。比如 Python, JavaScript。如何理解闭包闭包存在有什么意义呢？为什么需要闭包？我个人认为，闭包存在的意义就是它夹带了外部变量（私货），如果它不夹带私货，它和普通的函数就没有任何区别。同一个的函数夹带了不同的私货，就实现了不同的功能。其实你也可以这么理解，闭包和面向接口编程的概念很像，可以把闭包理解成轻量级的接口封装。 接口定义了一套对方法签名的约束规则。def tag(tag_name): def add_tag(content): return \"&lt;{0}&gt;{1}&lt;/{0}&gt;\".format(tag_name, content) return add_tagcontent = 'Hello'add_tag = tag('a')print add_tag(content)# &lt;a&gt;Hello&lt;/a&gt;add_tag = tag('b')print add_tag(content)# &lt;b&gt;Hello&lt;/b&gt;在这个例子里，我们想要一个给content加tag的功能，但是具体的tag_name是什么样子的要根据实际需求来定，对外部调用的接口已经确定，就是add_tag(content)。如果按照面向接口方式实现，我们会先把add_tag写成接口，指定其参数和返回类型，然后分别去实现 a 和 b 的add_tag。但是在闭包的概念中，add_tag就是一个函数，它需要tag_name和content两个参数，只不过tag_name这个参数是打包带走的。所以一开始时就可以告诉我怎么打包，然后带走就行。上面的例子不太生动，其实在我们生活和工作中，闭包的概念也很常见。比如说手机拨号，你只关心电话打给谁，而不会去纠结每个品牌的手机是怎么实现的，用到了哪些模块。再比如去餐馆吃饭，你只要付钱就可以享受到服务，你并不知道那桌饭菜用了多少地沟油。这些都可以看成闭包，返回来的是一些功能或者服务（打电话，用餐），但是这些功能使用了外部变量（天线，地沟油等等）。你也可以把一个类实例看成闭包，当你在构造这个类时，使用了不同的参数，这些参数就是闭包里的包，这个类对外提供的方法就是闭包的功能。但是类远远大于闭包，因为闭包只是一个可以执行的函数，但是类实例则有可能提供很多方法。何时使用闭包其实闭包在 Python 中很常见，只不过你没特别注意这就是一个闭包。比如 Python 中的装饰器 Decorator，假如你需要写一个带参数的装饰器，那么一般都会生成闭包。为什么？因为 Python 的装饰器是一个固定的函数接口形式。它要求你的装饰器函数（或装饰器类）必须接受一个函数并返回一个函数：# how to definedef wrapper(func1): # 接受一个callable对象 return func2 # 返回一个对象，一般为函数# how to usedef target_func(args): # 目标函数 pass# 调用方式一，直接包裹result = wrapper(target_func)(args)# 调用方式二，使用@语法，等同于方式一@wrapperdef target_func(args): passresult = target_func()那么如果你的装饰器如果带参数呢？那么你就需要在原来的装饰器上再包一层，用于接收这些参数。这些参数（私货）传递到内层的装饰器里后，闭包就形成了。所以说当你的装饰器需要自定义参数时，一般都会形成闭包。（类装饰器例外）def html_tags(tag_name): def wrapper_(func): def wrapper(*args, **kwargs): content = func(*args, **kwargs) return \"&lt;{tag}&gt;{content}&lt;/{tag}&gt;\".format(tag=tag_name, content=content) return wrapper return wrapper_@html_tags('b')def hello(name='Toby'): return 'Hello {}!'.format(name)# 不用@的写法如下# hello = html_tag('b')(hello)# html_tag('b') 是一个闭包，它接受一个函数，并返回一个函数print hello() # &lt;b&gt;Hello Toby!&lt;/b&gt;print hello('world') # &lt;b&gt;Hello world!&lt;/b&gt;关于装饰器的更深入剖析，可以看我写的另外一篇博客。再深入一点其实也不必太深入，理解这上面的概念，很多看起来头疼的代码也不过如此。下面让我们来了解一下闭包的包到底长什么样子。其实闭包函数相对与普通函数会多出一个__closure__的属性，里面定义了一个元组用于存放所有的cell对象，每个cell对象一一保存了这个闭包中所有的外部变量。&gt;&gt;&gt; def make_printer(msg1, msg2): def printer(): print msg1, msg2 return printer&gt;&gt;&gt; printer = make_printer('Foo', 'Bar') # 形成闭包&gt;&gt;&gt; printer.__closure__ # 返回cell元组(&lt;cell at 0x03A10930: str object at 0x039DA218&gt;, &lt;cell at 0x03A10910: str object at 0x039DA488&gt;)&gt;&gt;&gt; printer.__closure__[0].cell_contents # 第一个外部变量'Foo'&gt;&gt;&gt; printer.__closure__[1].cell_contents # 第二个外部变量'Bar'原理就是这么简单。参考链接 https://www.the5fire.com/closure-in-python.html http://stackoverflow.com/questions/4020419/why-arent-python-nested-functions-called-closures" }, { "title": "Python中不尽如人意的断言Assertion", "url": "/posts/2016-10-20/assertion-in-python/", "categories": "Tech", "tags": "python, software testing", "date": "2016-10-20 00:00:00 +0800", "snippet": "断言是测试的氧气，无断言，不测试。Python Assert 为何不尽如人意Python 中的断言用起来非常简单，你可以在assert后面跟上任意判断条件，如果断言失败则会抛出异常。&gt;&gt;&gt; assert 1 + 1 == 2&gt;&gt;&gt; assert isinstance('Hello', str)&gt;&gt;&gt; assert isinstance('...", "content": "断言是测试的氧气，无断言，不测试。Python Assert 为何不尽如人意Python 中的断言用起来非常简单，你可以在assert后面跟上任意判断条件，如果断言失败则会抛出异常。&gt;&gt;&gt; assert 1 + 1 == 2&gt;&gt;&gt; assert isinstance('Hello', str)&gt;&gt;&gt; assert isinstance('Hello', int)Traceback (most recent call last): File \"&lt;input&gt;\", line 1, in &lt;module&gt;AssertionError其实assert看上去不错，然而用起来并不爽。就比如有人告诉你程序错了，但是不告诉哪里错了。很多时候这样的assert还不如不写，写了我就想骂娘。直接抛一个异常来得更痛快一些。改进方案 #1一个稍微改进一丢丢的方案就是把必要的信息也放到assert语句后面，比如这样。&gt;&gt;&gt; s = \"nothin is impossible.\"&gt;&gt;&gt; key = \"nothing\"&gt;&gt;&gt; assert key in s, \"Key: '{}' is not in Target: '{}'\".format(key, s)Traceback (most recent call last): File \"&lt;input&gt;\", line 1, in &lt;module&gt;AssertionError: Key: 'nothing' is not in Target: 'nothin is impossible.'看上去还行吧，但是其实写的很蛋疼。假如你是一名测试汪，有成千上万的测试案例需要做断言做验证，相信你面对以上做法，心中一定有千万只那种马奔腾而过。改进方案 #2既然你是搞测试的，相比听过不少测试框架。你猜到我要说什么了吧？对，不用测试框架里的断言机制，你是不是洒。py.testpy.test 是一个轻量级的测试框架，所以它压根就没写自己的断言系统，但是它对 Python 自带的断言做了强化处理，如果断言失败，那么框架本身会尽可能多地提供断言失败的原因。那么也就意味着，用py.test实现测试，你一行代码都不用改。import pytestdef test_case(): expected = \"Hello\" actual = \"hello\" assert expected == actualif __name__ == '__main__': pytest.main()\"\"\"================================== FAILURES ===================================__________________________________ test_case __________________________________ def test_case(): expected = \"Hello\" actual = \"hello\"&gt; assert expected == actualE assert 'Hello' == 'hello'E - HelloE ? ^E + helloE ? ^assertion_in_python.py:7: AssertionError========================== 1 failed in 0.05 seconds ===========================\"\"\"\"unittestPython 自带的unittest单元测试框架就有了自己的断言方法 self.assertXXX() ，而且不推荐使用assert XXX 语句。import unittestclass TestStringMethods(unittest.TestCase): def test_upper(self): self.assertEqual('foo'.upper(), 'FoO')if __name__ == '__main__': unittest.main()\"\"\"FailureExpected :'FOO'Actual :'FoO'Traceback (most recent call last): File \"assertion_in_python.py\", line 6, in test_upper self.assertEqual('foo'.upper(), 'FoO')AssertionError: 'FOO' != 'FoO'\"\"\"ptest我非常喜欢ptest，感谢 Karl 大神写了这么一个测试框架。ptest 中的断言可读性很好，而且智能提示也很方便你通过 IDE 轻松完成各种断言语句。from ptest.decorator import *from ptest.assertion import *@TestClass()class TestCases: @Test() def test1(self): actual = 'foo' expected = 'bar' assert_that(expected).is_equal_to(actual)\"\"\"Start to run following 1 tests:------------------------------...[demo.assertion_in_python.TestCases.test1@Test] Failed with following message:...AssertionError: Unexpectedly that the str &lt;bar&gt; is not equal to str &lt;foo&gt;.\"\"\"改进方案 #3不仅仅是你和我对 Python 中的断言表示不满足，所以大家都争相发明自己的 assert 包。在这里我强烈推荐assertpy 这个包，它异常强大而且好评如潮。pip install assertpy看例子:from assertpy import assert_thatdef test_something(): assert_that(1 + 2).is_equal_to(3) assert_that('foobar')\\ .is_length(6)\\ .starts_with('foo')\\ .ends_with('bar') assert_that(['a', 'b', 'c'])\\ .contains('a')\\ .does_not_contain('x')从它的github 主页 主页文档上你会发现它支持了几乎你能想到的所有测试场景，包括但不限于以下列表。 Strings Numbers Lists Tuples Dicts Sets Booleans Dates Files Objects而且它的断言信息简洁明了，不多不少。Expected &lt;foo&gt; to be of length &lt;4&gt;, but was &lt;3&gt;.Expected &lt;foo&gt; to be empty string, but was not.Expected &lt;False&gt;, but was not.Expected &lt;foo&gt; to contain only digits, but did not.Expected &lt;123&gt; to contain only alphabetic chars, but did not.Expected &lt;foo&gt; to contain only uppercase chars, but did not.Expected &lt;FOO&gt; to contain only lowercase chars, but did not.Expected &lt;foo&gt; to be equal to &lt;bar&gt;, but was not.Expected &lt;foo&gt; to be not equal to &lt;foo&gt;, but was.Expected &lt;foo&gt; to be case-insensitive equal to &lt;BAR&gt;, but was not.在发现 assertpy 之前我也想写一个类似的包，尽可能通用一些。但是现在，我为毛要重新去造轮子？完全没必要！总结断言在软件系统中有非常重要的作用，写的好可以让你的系统更稳定，也可以让你有更多真正面对对象的时间，而不是在调试代码。Python 中默认的断言语句其实还有一个作用，如果你写了一个类型相关的断言，IDE 会把这个对象当成这种类型，这时候智能提示就有如神助。要不要把内置的断言语句换成可读性更好功能更强大的第三方断言，完全取决于实际情况。比如你真的需要验证某个东西并且很关心验证结果，那么必须不能用简单的 assert；如果你只是担心某个点可能有坑或者让 IDE 认识某个对象，用内置的 assert 既简单又方便。总之，你自己看着办。" }, { "title": "Improve Assertion In Python", "url": "/posts/2016-10-20/assertion-in-python-en/", "categories": "Tech", "tags": "python, software testing", "date": "2016-10-20 00:00:00 +0800", "snippet": "Assertion is the basics of testing.Why not using Python AssertAssertion in Python is pretty simple, you can assert any condition by assert statement.&gt;&gt;&gt; assert 1 + 1 == 2&gt;&gt;&gt; asser...", "content": "Assertion is the basics of testing.Why not using Python AssertAssertion in Python is pretty simple, you can assert any condition by assert statement.&gt;&gt;&gt; assert 1 + 1 == 2&gt;&gt;&gt; assert isinstance('Hello', str)&gt;&gt;&gt; assert isinstance('Hello', int)Traceback (most recent call last): File \"&lt;input&gt;\", line 1, in &lt;module&gt;AssertionErrorIt is great that assert can stop your application/tests when something goes wrong. However, it is not good enough that the AssertionError does not expose more information. In above example, we received the error message only with file name and line number, you have to start debugger to discover more.Improved Solution #1An improved solution is always appending message in your assertion.&gt;&gt;&gt; s = \"nothin is impossible.\"&gt;&gt;&gt; key = \"nothing\"&gt;&gt;&gt; assert key in s, \"Key: '{}' is not in Target: '{}'\".format(key, s)Traceback (most recent call last): File \"&lt;input&gt;\", line 1, in &lt;module&gt;AssertionError: Key: 'nothing' is not in Target: 'nothin is impossible.' Well, it fixed the problem, but it not elegant. If you are a QA engineer, you have to do a lot of assertions in thousands of test cases. With above solution, I would choose to die :- Improved Solution #2You might know about test frameworks, how do they do assertion? Yes, using test framework assertion is a nice alternation.py.testIf you are running tests with py.test, you can keep everything unchanged in your code, the failure message will tell you what is going on in failed assertion.import pytestdef test_case(): expected = \"Hello\" actual = \"hello\" assert expected == actualif __name__ == '__main__': pytest.main()\"\"\"================================== FAILURES ===================================__________________________________ test_case __________________________________ def test_case(): expected = \"Hello\" actual = \"hello\"&gt; assert expected == actualE assert 'Hello' == 'hello'E - HelloE ? ^E + helloE ? ^assertion_in_python.py:7: AssertionError========================== 1 failed in 0.05 seconds ===========================\"\"\"\"unittestPython unittest module provides assertion feature in itself, it recommends self.assertXXX() methods, but not assert XXX statements.import unittestclass TestStringMethods(unittest.TestCase): def test_upper(self): self.assertEqual('foo'.upper(), 'FoO')if __name__ == '__main__': unittest.main()\"\"\"FailureExpected :'FOO'Actual :'FoO'Traceback (most recent call last): File \"assertion_in_python.py\", line 6, in test_upper self.assertEqual('foo'.upper(), 'FoO')AssertionError: 'FOO' != 'FoO'\"\"\"ptestI like ptest very much, its assertion feature is more readable and smart. Thanks its author Karl :-)from ptest.decorator import *from ptest.assertion import *@TestClass()class TestCases: @Test() def test1(self): actual = 'foo' expected = 'bar' assert_that(expected).is_equal_to(actual)\"\"\"Start to run following 1 tests:------------------------------...[demo.assertion_in_python.TestCases.test1@Test] Failed with following message:...AssertionError: Unexpectedly that the str &lt;bar&gt; is not equal to str &lt;foo&gt;.\"\"\"Improved Solution #3It is not only you and me are frustrating on python assertion, so people created packages to replace default assertion. I strongly recommend you should have a try for assertpy package, which is high rating and powerful.pip install assertpyExample:from assertpy import assert_thatdef test_something(): assert_that(1 + 2).is_equal_to(3) assert_that('foobar')\\ .is_length(6)\\ .starts_with('foo')\\ .ends_with('bar') assert_that(['a', 'b', 'c'])\\ .contains('a')\\ .does_not_contain('x')From its github home page you will see it supports assertion in most test scenarios. Strings Numbers Lists Tuples Dicts Sets Booleans Dates Files ObjectsThe assertion message is really helpful, they looks like:Expected &lt;foo&gt; to be of length &lt;4&gt;, but was &lt;3&gt;.Expected &lt;foo&gt; to be empty string, but was not.Expected &lt;False&gt;, but was not.Expected &lt;foo&gt; to contain only digits, but did not.Expected &lt;123&gt; to contain only alphabetic chars, but did not.Expected &lt;foo&gt; to contain only uppercase chars, but did not.Expected &lt;FOO&gt; to contain only lowercase chars, but did not.Expected &lt;foo&gt; to be equal to &lt;bar&gt;, but was not.Expected &lt;foo&gt; to be not equal to &lt;foo&gt;, but was.Expected &lt;foo&gt; to be case-insensitive equal to &lt;BAR&gt;, but was not.Before I found this package I am thinking about writing common assertion package for Labs, but now, I don’t think I should spend time to invent the wheel again.SummaryAssertion is pretty important to a system, it can increase stability and save your time in debugging.Replacing all built-in assertion to 3rd party assertion in your code is not a good idea, because IDE like PyCharm knows nothing about that, so it will not provide auto-completion for those assertion.So my suggestion is, using more powerful assert functions in scenarios that you really want to verify something, keeping built-in assertion where you might fall in a pitfall, and with essential message. Keep It Simple and Stupid." }, { "title": "解决 Jenkins中TFS Plugin Mapping错误的问题", "url": "/posts/2016-10-19/how-to-fix-TFS-workspace-mapping-error-in-Jenkins/", "categories": "Tech", "tags": "tips, tfs, jenkins", "date": "2016-10-19 22:29:04 +0800", "snippet": "处理 TFS 的问题备忘。问题描述Once you had update in TFS workspace for Jenkin TFS plugin, you might get error like bellow:如果你把 Jenkins 中 TFS 插件更新过，那么你有可能会遇到 Mapping 错误的问题。[workspace] $ \"C:\\Program Files (x86)\\M...", "content": "处理 TFS 的问题备忘。问题描述Once you had update in TFS workspace for Jenkin TFS plugin, you might get error like bellow:如果你把 Jenkins 中 TFS 插件更新过，那么你有可能会遇到 Mapping 错误的问题。[workspace] $ \"C:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\Common7\\IDE\\TF.exe\" workspaces -format:brief -server:http://tfs.xxx.com:8080/tfs/Default ********Collection: tfs.xxx.com\\DefaultWorkspace Owner Computer Comment----------- ---------- ----------- --------------------------------------------MyServer newUser MyServer[workspace] $ \"C:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\Common7\\IDE\\TF.exe\" workspace -new \"Hudson-My build job-MASTER;nam\\newUser\" -noprompt -server:http://tfs.xxx.com:8080/tfs/Default ********The path D:\\hudson\\jobs\\My build job\\workspace is already mapped in workspace Hudson-My build job-MASTER;NAM\\oldUser.FATAL: Executable returned an unexpected result code [100]ERROR: null解决办法You should follow bellow steps to fix it.Step 1: Remove the TFS workspace From VS: Open Team Explorer Click Source Control Explorer In the nav bar of the tool window there is a drop down labeled “Workspaces”. Extend it and click on the “Workspaces…” option (yeah, a bit un-intuitive) The “Manage Workspaces” window comes up. Click edit and you can add / remove / edit your workspace From the command line Type “tf workspace” from a developer command promt. It will bring up the “Manage Workspaces” directly! Step 2: Remove cache on this computerManually delete all the files in the TFS cache, they located at: C:\\Users{UserName}\\AppData\\Local\\Microsoft\\Team Foundation\\3.0\\Cache If there is a \\4.0\\Cache and \\5.0\\Cache existed, delete them all. 你可以尝试通过以下步骤解决。Step 1: 删除该 TFS workspace 从 Visual Studo 操作: 打开 Team Explorer 打开 Source Control Explorer 从工具栏下拉列表中找到 “Workspaces”，展开 “Workspaces…” 这时 “Manage Workspaces” 窗口会打开，在这里你可以编辑或者删除当前用户所有的 workspace 从命令提示符操作 在 VS 命令提示符中输入 “tf workspace” 可以看到相关命令，不行就查一下 MSDN Step 2: 删除 TFS 相关 Cache手动清除 TFS 的 Cache 文件，参考以下路径。 C:\\Users{UserName}\\AppData\\Local\\Microsoft\\Team Foundation\\3.0\\Cache 如果 3.0 找不到就 4.0，如果 4.0 也没有就 5.0，取决于你的 VS 版本。" }, { "title": "Chrome, Andriod, JRE, Selenium各种开源工具的国内镜像", "url": "/posts/2016-10-19/mirror-sites-in-china/", "categories": "Tech", "tags": "tips", "date": "2016-10-19 21:29:04 +0800", "snippet": "在国内很多时候不翻墙真的很难做开发，本篇博客收集了一些知名工具和类库的国内镜像，当你没有 VPN 时，说不定能帮上你的大忙。淘宝镜像淘宝的镜像更新速度非常及时，安装它在官网上说的，大概没 10 分钟会同步一次。 https://npm.taobao.org/ https://npm.taobao.org/mirrors 部分镜像列表-  Node.js  镜像: h...", "content": "在国内很多时候不翻墙真的很难做开发，本篇博客收集了一些知名工具和类库的国内镜像，当你没有 VPN 时，说不定能帮上你的大忙。淘宝镜像淘宝的镜像更新速度非常及时，安装它在官网上说的，大概没 10 分钟会同步一次。 https://npm.taobao.org/ https://npm.taobao.org/mirrors 部分镜像列表-  Node.js  镜像: http://npm.taobao.org/mirrors/node-  phantomjs 镜像: http://npm.taobao.org/mirrors/phantomjs-  ChromeDriver 镜像: http://npm.taobao.org/mirrors/chromedriver-  OperaDriver 镜像: http://npm.taobao.org/mirrors/operadriver-  Selenium 镜像: http://npm.taobao.org/mirrors/selenium-  NPM 镜像: https://npm.taobao.org/mirrors/npm/-  Python 镜像: https://npm.taobao.org/mirrors/python/-  Atom 镜像: https://npm.taobao.org/mirrors/atom/中国科学院镜像中国科技网是中国科学院领导下的学术性、非盈利的科研计算机网络。提供了 Linux 和 Android 开发相关镜像。 http://www.opencas.org/mirrors/部分镜像列表 Name android anthonos apache archlinux centos chaos_calmer cran ctan cygwin gmirror 镜像这好像是一个个人镜像点，能活多久不知道，提供了 Google Chrome，Android 和 Java 相关工具的镜像。 http://gmirror.org/部分镜像列表 Chrome Atom Android SDK Tools Only Android Studio Android NDK Go Lang JDK, JRE VirtualBox" }, { "title": "获取 Google Chrome 谷歌浏览器离线安装包", "url": "/posts/2016-10-19/get-chrome-full-installer/", "categories": "Tech", "tags": "tips, google", "date": "2016-10-19 05:35:01 +0800", "snippet": "谷歌浏览器的离线安装包还真有用。安装到个人用户目录，请使用以下链接： Download Google Chrome Standalone Offline Installer (32-bit) Download Google Chrome Standalone Offline Installer (64-bit)安装后所有用户可用，请使用以下链接： Google Chrome Offli...", "content": "谷歌浏览器的离线安装包还真有用。安装到个人用户目录，请使用以下链接： Download Google Chrome Standalone Offline Installer (32-bit) Download Google Chrome Standalone Offline Installer (64-bit)安装后所有用户可用，请使用以下链接： Google Chrome Offline Installer for All User Accounts (32-bit) Google Chrome Offline Installer for All User Accounts (64-bit)如果你需要安装 Beta 版本，请使用： Google Chrome Beta Version Offline Installer (32-bit) Google Chrome Beta Version Offline Installer (64-bit)如果你需要安装 Dev 版本，请使用： Google Chrome Dev Version Offline Installer (32-bit) Google Chrome Dev Version Offline Installer (64-bit) 以上安装包适用于 Windows 平台。" }, { "title": "Python中的反转字符串问题", "url": "/posts/2016-10-18/reverse-by-word-in-python/", "categories": "Quiz", "tags": "python, regex", "date": "2016-10-18 17:46:00 +0800", "snippet": "按单词反转字符串是一道很常见的面试题。在 Python 中实现起来非常简单。def reverse_string_by_word(s): lst = s.split() # split by blank space by default return ' '.join(lst[::-1])s = 'Power of Love'print reverse_string_by_wo...", "content": "按单词反转字符串是一道很常见的面试题。在 Python 中实现起来非常简单。def reverse_string_by_word(s): lst = s.split() # split by blank space by default return ' '.join(lst[::-1])s = 'Power of Love'print reverse_string_by_word(s)# Love of Powers = 'Hello World!'print reverse_string_by_word(s)# World! Hello上面的实现其实已经能满足大多数情况，但是并不完美。比如第二个字符串中的感叹号并没有被翻转，而且原字符串中的空格数量也没有保留。（在上面的例子里其实 Hello 和 World 之间不止一个空格）我们期望的结果应该是这样子的。print reverse_string_by_word(s)# Expected: !World Hello要改进上面的方案还不把问题复杂化，推荐使用re模块。你可以查阅re.split() 的官方文档。我们看一下具体例子。&gt;&gt;&gt; import re&gt;&gt;&gt; s = 'Hello World!'&gt;&gt;&gt; re.split(r'\\s+', s) # will discard blank spaces['Hello', 'World!']&gt;&gt;&gt; re.split(r'(\\s+)', s) # will keep spaces as a group['Hello', ' ', 'World!']&gt;&gt;&gt; s = '&lt; Welcome to EF.COM! &gt;'&gt;&gt;&gt; re.split(r'\\s+', s) # split by spaces['&lt;', 'Welcome', 'to', 'EF.COM!', '&gt;']&gt;&gt;&gt; re.split(r'(\\w+)', s) # exactly split by word['&lt; ', 'Welcome', ' ', 'to', ' ', 'EF', '.', 'COM', '! &gt;']&gt;&gt;&gt; re.split(r'(\\s+|\\w+)', s) # split by space and word['&lt;', ' ', '', 'Welcome', '', ' ', '', 'to', '', ' ', '', 'EF', '.', 'COM', '!', ' ', '&gt;']&gt;&gt;&gt; ''.join(re.split(r'(\\s+|\\w+)', s)[::-1])'&gt; !COM.EF to Welcome &lt;'&gt;&gt;&gt; ''.join(re.split(r'(\\s+)', s)[::-1])'&gt; EF.COM! to Welcome &lt;'&gt;&gt;&gt; ''.join(re.split(r'(\\w+)', s)[::-1])'! &gt;COM.EF to Welcome&lt; '如果你觉得用切片将序列倒序可读性不高，那么其实也可以这样写。&gt;&gt;&gt; ''.join(reversed(re.split(r'(\\s+|\\w+)', s)))'&gt; !COM.EF to Welcome &lt;'一句话搞定，so easy!" }, { "title": "Reverse string by word with Python", "url": "/posts/2016-10-18/reverse-by-word-in-python-en/", "categories": "Quiz", "tags": "python, regex", "date": "2016-10-18 17:46:00 +0800", "snippet": "Reverse string by word is a very popular interview question. In python you can solve it easily with code like below.def reverse_string_by_word(s): lst = s.split() # split by blank space by defa...", "content": "Reverse string by word is a very popular interview question. In python you can solve it easily with code like below.def reverse_string_by_word(s): lst = s.split() # split by blank space by default return ' '.join(lst[::-1])s = 'Power of Love'print reverse_string_by_word(s)# Love of Powers = 'Hello World!'print reverse_string_by_word(s)# World! HelloWe can see above implementation is good but not enough, in 2nd string we are expecting the ! symbol should be reversed as well, and keep original blank spaces between words. (multiple spaces between Hello and World in the example)print reverse_string_by_word(s)# Expected: !World HelloTo improve the solution, a better choice should be re module. You might want to take a look at re.split() method.&gt;&gt;&gt; import re&gt;&gt;&gt; s = 'Hello World!'&gt;&gt;&gt; re.split(r'\\s+', s) # will discard blank spaces['Hello', 'World!']&gt;&gt;&gt; re.split(r'(\\s+)', s) # will keep spaces as a group['Hello', ' ', 'World!']&gt;&gt;&gt; s = '&lt; Welcome to EF.COM! &gt;'&gt;&gt;&gt; re.split(r'\\s+', s) # split by spaces['&lt;', 'Welcome', 'to', 'EF.COM!', '&gt;']&gt;&gt;&gt; re.split(r'(\\w+)', s) # exactly split by word['&lt; ', 'Welcome', ' ', 'to', ' ', 'EF', '.', 'COM', '! &gt;']&gt;&gt;&gt; re.split(r'(\\s+|\\w+)', s) # split by space and word['&lt;', ' ', '', 'Welcome', '', ' ', '', 'to', '', ' ', '', 'EF', '.', 'COM', '!', ' ', '&gt;']&gt;&gt;&gt; ''.join(re.split(r'(\\s+|\\w+)', s)[::-1])'&gt; !COM.EF to Welcome &lt;'&gt;&gt;&gt; ''.join(re.split(r'(\\s+)', s)[::-1])'&gt; EF.COM! to Welcome &lt;'&gt;&gt;&gt; ''.join(re.split(r'(\\w+)', s)[::-1])'! &gt;COM.EF to Welcome&lt; 'If you would like to increase the readability a little bit, replacing list slicing to reversed() is a choice.&gt;&gt;&gt; ''.join(reversed(re.split(r'(\\s+|\\w+)', s)))'&gt; !COM.EF to Welcome &lt;'Bingo, so easy!" }, { "title": "Python中的下划线和魔法方法", "url": "/posts/2016-10-12/underscore-in-python/", "categories": "Tech", "tags": "python, python underscore, tips", "date": "2016-10-12 06:26:46 +0800", "snippet": "下划线在 Python 中有很特别的意义。开门见山下划线在 Python 中有特殊的意义，简单来说，可以总结成三点。 单下划线在前一般用于声明私有成员，比如 _private_var 单下划线在后一般用于命名已经被保留关键字占用的变量，比如 class_,type_ 双下划线一般被用于 Python 内置的特殊方法或者属性，比如 __name__,__file__，有时候也被称之为魔法...", "content": "下划线在 Python 中有很特别的意义。开门见山下划线在 Python 中有特殊的意义，简单来说，可以总结成三点。 单下划线在前一般用于声明私有成员，比如 _private_var 单下划线在后一般用于命名已经被保留关键字占用的变量，比如 class_,type_ 双下划线一般被用于 Python 内置的特殊方法或者属性，比如 __name__,__file__，有时候也被称之为魔法方法。更多细节的讨论，可以看 StackOverflow 上的这个主题：What is the meaning of single and double underscore before an object name?。 __foo__: this is just a convention, a way for the Python system to use names that won’t conflict with user names. _foo: this is just a convention, a way for the programmer to indicate that the variable is private (whatever that means in Python). __foo: this has real meaning: the interpreter replaces this name with _classname__foo as a way to ensure that the name will not overlap with a similar name in another class. No other form of underscores have meaning in the Python world. There’s no difference between class, variable, global, etc in these conventions.有时候我们还能看到就仅仅命名为一个下划线的的变量，这种情况一般是这个变量不重要或者只是一个临时工，连名字都不配拥有。for _,value in func(): # 假如func每次会返回两个值，我们只关心第二个值 use(value)思维导图下面是思维导图的总结如何调用魔法方法一些魔法方法直接和内建函数对应，这种情况下，如何调用它们是显而易见的。这有个附录可以作为调用魔法方法的参考。 魔法方法 什么时候被调用 解释 __new__(cls [,...]) instance = MyClass(arg1, arg2) __new__在实例创建时调用 __init__(self [,...]) instance = MyClass(arg1,arg2) __init__在实例创建时调用 __cmp__(self) self == other, self &gt; other 等 进行比较时调用 __pos__(self) self 一元加法符号 __neg__(self) -self 一元减法符号 __invert__(self) ~self 按位取反 __index__(self) x[self] 当对象用于索引时 __nonzero__(self) bool(self) 对象的布尔值 __getattr__(self, name) self.name #name 不存在 访问不存在的属性 __setattr__(self, name) self.name = val 给属性赋值 __delattr__(self, name) del self.name 删除属性 __getattribute__(self,name) self.name 访问任意属性 __getitem__(self, key) self[key] 使用索引访问某个元素 __setitem__(self, key) self[key] = val 使用索引给某个元素赋值 __delitem__(self, key) del self[key] 使用索引删除某个对象 __iter__(self) for x in self 迭代 __contains__(self, value) value in self, value not in self 使用 in 进行成员测试 __call__(self [,...]) self(args) “调用”一个实例 __enter__(self) with self as x: with 声明的上下文管理器 __exit__(self, exc, val, trace) with self as x: with 声明的上下文管理器 __getstate__(self) pickle.dump(pkl_file, self) Pickling __setstate__(self) data = pickle.load(pkl_file) Pickling 如果你还想了解关于魔法方法的更多细节，那么你一定不能错过： 魔法方法指南 Magic method guide" }, { "title": "在Python中查找和替换文本", "url": "/posts/2016-10-10/python-text-replacement/", "categories": "Tech", "tags": "python, regex", "date": "2016-10-10 21:32:03 +0800", "snippet": "Python 编程中的小技巧。最简单的查找替换在 Python 中查找和替换非常简单，如果当前对象是一个字符串str时，你可以使用该类型提供的find()或者index()方法查找指定的字符，如果能找到则会返回字符第一次出现的索引，如果不存在则返回-1。&gt;&gt;&gt; s = 'Cat and Dog'&gt;&gt;&gt; s.find('Dog')8&gt;&gt;&gt; ...", "content": "Python 编程中的小技巧。最简单的查找替换在 Python 中查找和替换非常简单，如果当前对象是一个字符串str时，你可以使用该类型提供的find()或者index()方法查找指定的字符，如果能找到则会返回字符第一次出现的索引，如果不存在则返回-1。&gt;&gt;&gt; s = 'Cat and Dog'&gt;&gt;&gt; s.find('Dog')8&gt;&gt;&gt; s.index('Dog')8&gt;&gt;&gt; s.find('Duck')-1如果要替换目标字符串，用replace()方法就好了。&gt;&gt;&gt; s = 'Cat and Dog'&gt;&gt;&gt; s.replace('Cat', 'Dog')'Dog and Dog'通配符查找匹配当然，如果你觉得上面的功能还不能满足你，你想使用通配符来查找字符串？没问题！fnmatch这个库就能满足你的要求，看例子！&gt;&gt;&gt; s = 'Cat and Dog'&gt;&gt;&gt; import fnmatch&gt;&gt;&gt; fnmatch.fnmatch(s,'Cat*')True&gt;&gt;&gt; fnmatch.fnmatch(s,'C*and*D?')False&gt;&gt;&gt; fnmatch.fnmatch(s,'C*and*D*')True正则表达式查找替换如果你需要查找比较复杂的字符规则，正则表达式是你不二的选择。下面是正则查找的简单示例。&gt;&gt;&gt; import re&gt;&gt;&gt; s = 'We will fly to Thailand on 2016/10/31'&gt;&gt;&gt; pattern = r'\\d+'&gt;&gt;&gt; re.findall(pattern, s)['2016', '10', '31']&gt;&gt;&gt; re.search(pattern, s)&lt;_sre.SRE_Match object at 0x03A8FD40&gt;&gt;&gt;&gt; re.search(pattern, s).group()'2016'接下来你可能需要用正则表达式去替换某些字符，那么你需要了解re.sub()方法，看例子。&gt;&gt;&gt; s = \"I like {color} car.\"&gt;&gt;&gt; re.sub(r'\\{color\\}','blue',s)'I like blue car.'&gt;&gt;&gt; s = 'We will fly to Thailand on 10/31/2016'&gt;&gt;&gt; re.sub('(\\d+)/(\\d+)/(\\d+)', r'\\3-\\1-\\2', s)'We will fly to Thailand on 2016-10-31'其实re.sub()远比你相像的强大的多。在上面的例子里你可以替换类似于{color}这样的模板字符，也可以把正则匹配到的所有分组调换顺序，例如第二个例子一共匹配了 3 个分组，然后把第 3 个分组放到最前面 r'\\3-\\1-\\2'，看明白了吗？接下来看另外一个例子。s = \"Tom is talking to Jerry.\"name1 = \"Tom\"name2 = \"Jerry\"pattern = r'(.*)({0})(.*)({1})(.*)'.format(name1, name2)print re.sub(pattern, r'\\1\\4\\3\\2\\5', s)# Jerry is talking to Tom.其实你还可以自定义替换函数，也就是re.sub()的第二个参数。def change_date(m): from calendar import month_abbr mon_name = month_abbr[int(m.group(1))] return '{} {} {}'.format(m.group(2), mon_name, m.group(3))s = 'We will fly to Thailand on 10/31/2016'pattern = r'(\\d+)/(\\d+)/(\\d+)'print re.sub(pattern, change_date, s)# We will fly to Thailand on 31 Oct 2016最后给大家一个终极版的例子，里面用到了函数的闭包，着酸爽，你懂的！def match_case(word): def replace(m): text = m.group() if text.isupper(): return word.upper() elif text.islower(): return word.lower() elif text[0].isupper(): return word.capitalize() else: return word return replaces = \"LOVE PYTHON, love python, Love Python\"print re.sub('python', match_case('money'), s, flags=re.IGNORECASE)# LOVE MONEY, love money, Love Money写在最后其实正则表达式还有很多玩法，如果你想让正则和通配符混合着用，一点问题都没有，因为fnmatch还有一个translate()的方法，可以让你把通配符无痛转换成正则表达式，你爱怎么玩就怎么玩。&gt;&gt;&gt; fnmatch.translate('C*and*D*')'C.*and.*D.*'" }, { "title": "Find and replace text with Python", "url": "/posts/2016-10-10/python-text-replacement-en/", "categories": "Tech", "tags": "python, regex", "date": "2016-10-10 21:32:03 +0800", "snippet": "Tips of Python programming.Basic find and replaceSearch and replace text in Python is simple, you can find a specific string with find() or index() method, it will return the index of first match o...", "content": "Tips of Python programming.Basic find and replaceSearch and replace text in Python is simple, you can find a specific string with find() or index() method, it will return the index of first match occasion.&gt;&gt;&gt; s = 'Cat and Dog'&gt;&gt;&gt; s.find('Dog')8&gt;&gt;&gt; s.index('Dog')8&gt;&gt;&gt; s.find('Duck')-1To replace Cat to Dog, you can simply call replace() method.&gt;&gt;&gt; s = 'Cat and Dog'&gt;&gt;&gt; s.replace('Cat', 'Dog')'Dog and Dog'Wildcards matchingSo how about searching string with wildcards pattern? You should try fnmatch library, it is built-in python.&gt;&gt;&gt; s = 'Cat and Dog'&gt;&gt;&gt; import fnmatch&gt;&gt;&gt; fnmatch.fnmatch(s,'Cat*')True&gt;&gt;&gt; fnmatch.fnmatch(s,'C*and*D?')False&gt;&gt;&gt; fnmatch.fnmatch(s,'C*and*D*')TrueRegex find and replaceTo use advanced text search and replacement, regular expression is your best friend. To find string with pattern, here is an example:&gt;&gt;&gt; import re&gt;&gt;&gt; s = 'We will fly to Thailand on 2016/10/31'&gt;&gt;&gt; pattern = r'\\d+'&gt;&gt;&gt; re.findall(pattern, s)['2016', '10', '31']&gt;&gt;&gt; re.search(pattern, s)&lt;_sre.SRE_Match object at 0x03A8FD40&gt;&gt;&gt;&gt; re.search(pattern, s).group()'2016'To replace string with pattern, hmm, it is an advanced feature, you might want to try re.sub() function(sub =&gt; substitution).&gt;&gt;&gt; s = \"I like {color} car.\"&gt;&gt;&gt; re.sub(r'\\{color\\}','blue',s)'I like blue car.'&gt;&gt;&gt; s = 'We will fly to Thailand on 10/31/2016'&gt;&gt;&gt; re.sub('(\\d+)/(\\d+)/(\\d+)', r'\\3-\\1-\\2', s)'We will fly to Thailand on 2016-10-31'The re.sub() function is really powerful, in above example, {color} is a pattern that might be updated when string finally published. You can create pattern like this as a template. And r'\\3-\\1-\\2' is the reference to regex matching groups.Let’s see another example:s = \"Tom is talking to Jerry.\"name1 = \"Tom\"name2 = \"Jerry\"pattern = r'(.*)({0})(.*)({1})(.*)'.format(name1, name2)print re.sub(pattern, r'\\1\\4\\3\\2\\5', s)# Jerry is talking to Tom.Let’s see how to customize the replace function.def change_date(m): from calendar import month_abbr mon_name = month_abbr[int(m.group(1))] return '{} {} {}'.format(m.group(2), mon_name, m.group(3))s = 'We will fly to Thailand on 10/31/2016'pattern = r'(\\d+)/(\\d+)/(\\d+)'print re.sub(pattern, change_date, s)# We will fly to Thailand on 31 Oct 2016OK, the ultimate example goes here. Hope you enjoy :)def match_case(word): def replace(m): text = m.group() if text.isupper(): return word.upper() elif text.islower(): return word.lower() elif text[0].isupper(): return word.capitalize() else: return word return replaces = \"LOVE PYTHON, love python, Love Python\"print re.sub('python', match_case('money'), s, flags=re.IGNORECASE)# LOVE MONEY, love money, Love MoneySummaryOh, last but not least, do you want to do use re.sub() for wildcards, yes, you can do it! fnmatch provide a function to let you translate wildcards pattern into regular expression pattern.&gt;&gt;&gt; fnmatch.translate('C*and*D*')'C.*and.*D.*'" }, { "title": "Python中的logging模块", "url": "/posts/2016-10-09/use-logging-in-python/", "categories": "Tech", "tags": "python, logging", "date": "2016-10-09 04:57:43 +0800", "snippet": "最近修改了项目里的 logging 相关功能，用到了 python 标准库里的 logging 模块，在此做一些记录。主要是从官方文档和 stackoverflow 上查询到的一些内容。 官方文档 技术博客基本用法下面的代码展示了 logging 最基本的用法。# -*- coding: utf-8 -*-import loggingimport sys# 获取logger实例，如果参数...", "content": "最近修改了项目里的 logging 相关功能，用到了 python 标准库里的 logging 模块，在此做一些记录。主要是从官方文档和 stackoverflow 上查询到的一些内容。 官方文档 技术博客基本用法下面的代码展示了 logging 最基本的用法。# -*- coding: utf-8 -*-import loggingimport sys# 获取logger实例，如果参数为空则返回root loggerlogger = logging.getLogger(\"AppName\")# 指定logger输出格式formatter = logging.Formatter('%(asctime)s %(levelname)-8s: %(message)s')# 文件日志file_handler = logging.FileHandler(\"test.log\")file_handler.setFormatter(formatter) # 可以通过setFormatter指定输出格式# 控制台日志console_handler = logging.StreamHandler(sys.stdout)console_handler.formatter = formatter # 也可以直接给formatter赋值# 为logger添加的日志处理器logger.addHandler(file_handler)logger.addHandler(console_handler)# 指定日志的最低输出级别，默认为WARN级别logger.setLevel(logging.INFO)# 输出不同级别的loglogger.debug('this is debug info')logger.info('this is information')logger.warn('this is warning message')logger.error('this is error message')logger.fatal('this is fatal message, it is same as logger.critical')logger.critical('this is critical message')# 2016-10-08 21:59:19,493 INFO : this is information# 2016-10-08 21:59:19,493 WARNING : this is warning message# 2016-10-08 21:59:19,493 ERROR : this is error message# 2016-10-08 21:59:19,493 CRITICAL: this is fatal message, it is same as logger.critical# 2016-10-08 21:59:19,493 CRITICAL: this is critical message# 移除一些日志处理器logger.removeHandler(file_handler)除了这些基本用法，还有一些常见的小技巧可以分享一下。格式化输出日志# 格式化输出service_name = \"Booking\"logger.error('%s service is down!' % service_name) # 使用python自带的字符串格式化，不推荐logger.error('%s service is down!', service_name) # 使用logger的格式化，推荐logger.error('%s service is %s!', service_name, 'down') # 多参数格式化logger.error('{} service is {}'.format(service_name, 'down')) # 使用format函数，推荐# 2016-10-08 21:59:19,493 ERROR : Booking service is down!记录异常信息当你使用 logging 模块记录异常信息时，不需要传入该异常对象，只要你直接调用logger.error() 或者 logger.exception()就可以将当前异常记录下来。# 记录异常信息try: 1 / 0except: # 等同于error级别，但是会额外记录当前抛出的异常堆栈信息 logger.exception('this is an exception message')# 2016-10-08 21:59:19,493 ERROR : this is an exception message# Traceback (most recent call last):# File \"D:/Git/py_labs/demo/use_logging.py\", line 45, in &lt;module&gt;# 1 / 0# ZeroDivisionError: integer division or modulo by zerologging 配置要点GetLogger()这是最基本的入口，该方法参数可以为空，默认的 logger 名称是 root，如果在同一个程序中一直都使用同名的 logger，其实会拿到同一个实例，使用这个技巧就可以跨模块调用同样的 logger 来记录日志。另外你也可以通过日志名称来区分同一程序的不同模块，比如这个例子。logger = logging.getLogger(\"App.UI\")logger = logging.getLogger(\"App.Service\")FormatterFormatter 对象定义了 log 信息的结构和内容，构造时需要带两个参数： 一个是格式化的模板fmt，默认会包含最基本的level和 message信息 一个是格式化的时间样式datefmt，默认为 2003-07-08 16:49:45,896 (%Y-%m-%d %H:%M:%S)fmt中允许使用的变量可以参考下表。 %(name)s Logger 的名字 %(levelno)s 数字形式的日志级别 %(levelname)s 文本形式的日志级别 %(pathname)s 调用日志输出函数的模块的完整路径名，可能没有 %(filename)s 调用日志输出函数的模块的文件名 %(module)s 调用日志输出函数的模块名 %(funcName)s 调用日志输出函数的函数名 %(lineno)d 调用日志输出函数的语句所在的代码行 %(created)f 当前时间，用 UNIX 标准的表示时间的浮点数表示 %(relativeCreated)d 输出日志信息时的，自 Logger 创建以来的毫秒数 %(asctime)s 字符串形式的当前时间。默认格式是“2003-07-08 16:49:45,896”。逗号后面的是毫秒 %(thread)d 线程 ID。可能没有 %(threadName)s 线程名。可能没有 %(process)d 进程 ID。可能没有 %(message)s 用户输出的消息SetLevelLogging 有如下级别: DEBUG，INFO，WARNING，ERROR，CRITICAL默认级别是 WARNING，logging 模块只会输出指定 level 以上的 log。这样的好处, 就是在项目开发时 debug 用的 log，在产品 release 阶段不用一一注释，只需要调整 logger 的级别就可以了，很方便。Handler最常用的是 StreamHandler 和 FileHandler, Handler 用于向不同的输出端打 log。Logging 包含很多 handler, 可能用到的有下面几种 StreamHandler instances send error messages to streams (file-like objects). FileHandler instances send error messages to disk files. RotatingFileHandler instances send error messages to disk files, with support for maximum log file sizes and log file rotation. TimedRotatingFileHandler instances send error messages to disk files, rotating the log file at certain timed intervals. SocketHandler instances send error messages to TCP/IP sockets. DatagramHandler instances send error messages to UDP sockets. SMTPHandler instances send error messages to a designated email address.Configurationlogging 的配置大致有下面几种方式。 通过代码进行完整配置，参考开头的例子，主要是通过 getLogger 方法实现。 通过代码进行简单配置，下面有例子，主要是通过 basicConfig 方法实现。 通过配置文件，下面有例子，主要是通过 logging.config.fileConfig(filepath)logging.basicConfigbasicConfig 提供了非常便捷的方式让你配置 logging 模块并马上开始使用，可以参考下面的例子。具体可以配置的项目请查阅官方文档。import logginglogging.basicConfig(filename='example.log',level=logging.DEBUG)logging.debug('This message should go to the log file')logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)logging.debug('This message should appear on the console')logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')logging.warning('is when this event was logged.')备注： 其实你甚至可以什么都不配置直接使用默认值在控制台中打 log，用这样的方式替换 print 方法对日后项目维护会有很大帮助。通过文件配置 logging如果你希望通过配置文件来管理 logging，可以参考这个官方文档。在 log4net 或者 log4j 中这是很常见的方式。# logging.conf[loggers]keys=root[logger_root]level=DEBUGhandlers=consoleHandler#,timedRotateFileHandler,errorTimedRotateFileHandler#################################################[handlers]keys=consoleHandler,timedRotateFileHandler,errorTimedRotateFileHandler[handler_consoleHandler]class=StreamHandlerlevel=DEBUGformatter=simpleFormatterargs=(sys.stdout,)[handler_timedRotateFileHandler]class=handlers.TimedRotatingFileHandlerlevel=DEBUGformatter=simpleFormatterargs=('debug.log', 'H')[handler_errorTimedRotateFileHandler]class=handlers.TimedRotatingFileHandlerlevel=WARNformatter=simpleFormatterargs=('error.log', 'H')#################################################[formatters]keys=simpleFormatter, multiLineFormatter[formatter_simpleFormatter]format= %(levelname)s %(threadName)s %(asctime)s: %(message)sdatefmt=%H:%M:%S[formatter_multiLineFormatter]format= ------------------------- %(levelname)s ------------------------- Time: %(asctime)s Thread: %(threadName)s File: %(filename)s(line %(lineno)d) Message: %(message)sdatefmt=%Y-%m-%d %H:%M:%S假设以上的配置文件放在和模块相同的目录，代码中的调用如下。import osfilepath = os.path.join(os.path.dirname(__file__), 'logging.conf')logging.config.fileConfig(filepath)return logging.getLogger()日志重复输出的坑你有可能会看到你打的日志会重复显示多次，可能的原因有很多，但总结下来无非就一个，日志中多个重复的 handler。第一坑import logginglogging.basicConfig(level=logging.DEBUG)fmt = '%(levelname)s:%(message)s'console_handler = logging.StreamHandler()console_handler.setFormatter(logging.Formatter(fmt))logging.getLogger().addHandler(console_handler)logging.info('hello!')# INFO:root:hello!# INFO:hello!上面这个例子出现了重复日志，因为在第 3 行调用basicConfig()方法时系统会默认创建一个 handler，如果你再添加一个控制台 handler 时就会出现重复日志。第二坑import loggingdef get_logger(): fmt = '%(levelname)s:%(message)s' console_handler = logging.StreamHandler() console_handler.setFormatter(logging.Formatter(fmt)) logger = logging.getLogger('App') logger.setLevel(logging.INFO) logger.addHandler(console_handler) return loggerdef call_me(): logger = get_logger() logger.info('hi')call_me()call_me()# INFO:hi# INFO:hi# INFO:hi在这个例子里hi居然打印了三次，如果再调用一次call_me()呢？我告诉你会打印 6 次。why? 因为你每次调用get_logger()方法时都会给它加一个新的 handler，你是自作自受。正常的做法应该是全局只配置 logger 一次。第三坑import loggingdef get_logger(): fmt = '%(levelname)s: %(message)s' console_handler = logging.StreamHandler() console_handler.setFormatter(logging.Formatter(fmt)) logger = logging.getLogger('App') logger.setLevel(logging.INFO) logger.addHandler(console_handler) return loggerdef foo(): logging.basicConfig(format='[%(name)s]: %(message)s') logging.warn('some module use root logger')def main(): logger = get_logger() logger.info('App start.') foo() logger.info('App shutdown.')main()# INFO: App start.# [root]: some module use root logger# INFO: App shutdown.# [App]: App shutdown.为嘛最后的App shutdown打印了两次？所以在 Stackoverflow 上很多人都问，我应该怎么样把 root logger 关掉，root logger 太坑爹坑妈了。只要你在程序中使用过 root logger，那么默认你打印的所有日志都算它一份。上面的例子没有什么很好的办法，我建议你招到那个没有经过大脑就使用 root logger 的人，乱棍打死他或者开除他。如果你真的想禁用 root logger，有两个不是办法的办法：logging.getLogger().handlers = [] # 删除所有的handlerlogging.getLogger().setLevel(logging.CRITICAL) # 将它的级别设置到最高小结Python 中的日志模块作为标准库的一部分，功能还是比较完善的。个人觉得上手简单，另外也支持比如过滤，文件锁等高级功能，能满足大多数项目需求。不过切记，小心坑。" }, { "title": "读书 - 《霍乱时期的爱情》", "url": "/posts/2016-10-04/book-love-in-the-time-of-cholera/", "categories": "Reading", "tags": "book", "date": "2016-10-04 22:35:21 +0800", "snippet": " 文/大橙子作者歌颂的应该不是爱情，至于男女主最后终在一起，我也不认为那是爱情。文章开篇写了医生一个老朋友的自杀，有意的自杀，无非想表达，衰老，有些人不愿意面对，而像医生、女主、男主，都最终到了衰老的年纪，衰老会面临很多问题，最大的问题应该是孤独。老人需要陪伴，费尔明娜最后和男主在一起，是因为她需要最后的陪伴而已，不是爱情。纵观男主弗洛伦蒂诺一生，那扭曲的爱情观所，他对费尔明娜的爱情，他认...", "content": " 文/大橙子作者歌颂的应该不是爱情，至于男女主最后终在一起，我也不认为那是爱情。文章开篇写了医生一个老朋友的自杀，有意的自杀，无非想表达，衰老，有些人不愿意面对，而像医生、女主、男主，都最终到了衰老的年纪，衰老会面临很多问题，最大的问题应该是孤独。老人需要陪伴，费尔明娜最后和男主在一起，是因为她需要最后的陪伴而已，不是爱情。纵观男主弗洛伦蒂诺一生，那扭曲的爱情观所，他对费尔明娜的爱情，他认为的永恒的忠诚和不渝的爱情，真让人唏嘘。弗洛伦蒂诺和费尔明娜只不过青春期有过信件往来嘛，没有任何现实基础啊，话也没正儿八经说过几句啊，都是幻想啊幻想啊，有木有！以至于最后费尔明娜在街头看见弗洛伦蒂诺的时候，不禁讶异：我怎么会喜欢这个人！才有了后来的索还信件，断绝往来之事。这哪里是真爱？弗洛伦蒂诺让我觉得恶心，他的一生都在意淫。不仅如此，他的桃色笔记，51 年里的 25 个笔记本 622 个与他有较长情史的角色，大部分的寡妇，难道都是表达对费尔明娜的思念吗？对，寡妇，他看到过那些寡妇的饥渴，所以一直期望费尔明娜成为寡妇的那天，幻想着费尔明娜也会饥渴的扑向他的怀抱扑向他的床，Sick。还有他糟蹋的那个 14 岁的小萝莉，人家父母把孩子交给你，让你做监护人，你却把小朋友睡了，这搁现代，这就是嫖宿幼女啊，70 多岁的老头和 14 岁的少女，最后还让人自杀的，良知何在？而当他们最终睡在一起时，不要脸的弗洛伦蒂诺还说我为你保留了童真，我呸，Sick。世人没能揭穿你这虚伪的面纱而已，在门后偷袭了女佣后，害怕被揭穿，还找了个替死鬼。相比较来说，费尔明娜同医生的感情到是让我觉得正常的多。虽然他们结婚时并没有感情基础，却有长达 50 多年的陪伴，人不是说嘛，陪伴是最长情的告白。两人后经历了热恋、生子、家庭矛盾、出轨，那难道不是人世间大多数夫妻所经历的嘛。看看人家医生，生活规律，专业上有建树，还不忘教书育人，参与公益，参与社会建设，虽也有短暂的出轨，但不会影响社会对他的评价。再看看弗洛伦蒂洛的一生，除了 25 本桃色日记，还留下了什么。最后 72 岁和费尔明娜和 76 的弗洛伦蒂洛终于睡在一起了，就像是现代社会的屌丝男终于泡上白富美，在白富美老公死后，在 50 多年后。有人这么说道：“被许多人津津乐道的半个多世纪的爱情等待，怎么看都像是一场’吃着碗里看着锅里的‘阴险猎捕计划’。踩过 622 朵浮云，弗洛伦蒂诺终于吃到了梦寐以求的终极猎物”。这个故事告诉我们，好好活着，别纱布垃圾就知道挣钱，你要是死的早，你的枕边人被别人睡了多可惜！还好故事里的医生活了 80 多岁，这让男主在垂暮之前，基本丧失生理能力的时候，才得以如愿以偿。再次证明，作者根本没有歌颂他的爱情的意思。马尔克斯的文章还是很精彩的，看过《百年孤独》，惊叹不已。有机会你自己也应该好好去看一遍吧。" }, { "title": "读书 - 《月亮与六便士》", "url": "/posts/2016-10-03/book-moon-and-peny/", "categories": "Reading", "tags": "book", "date": "2016-10-03 22:35:21 +0800", "snippet": " 文/大橙子一个伟大的艺术家，40 岁时，有稳定的家庭及职业，却突然放弃了一切，只为追求自己心中所深信的真理：“我必须画画！”我必须得说，我等普通老板姓是无法理解伟大艺术家自私、奔放、狂野、无道德约束的灵魂的，更别说那些食不果腹的日子。有人说，这时高更人物传记。我也不了解。抛却不能理解的部分，故事本事还是很精彩的。不剧透，有兴趣自己了解。", "content": " 文/大橙子一个伟大的艺术家，40 岁时，有稳定的家庭及职业，却突然放弃了一切，只为追求自己心中所深信的真理：“我必须画画！”我必须得说，我等普通老板姓是无法理解伟大艺术家自私、奔放、狂野、无道德约束的灵魂的，更别说那些食不果腹的日子。有人说，这时高更人物传记。我也不了解。抛却不能理解的部分，故事本事还是很精彩的。不剧透，有兴趣自己了解。" }, { "title": "读书 - 《活着》", "url": "/posts/2016-10-03/book-huo-zhe/", "categories": "Reading", "tags": "book", "date": "2016-10-03 21:35:21 +0800", "snippet": " 文/大橙子没什么好说的，白花花的语言，依托中国抗日战后至今的时代背景，以富贵的经历叙述了很多中国式悲哀。富二代的富贵，吃喝嫖赌，散尽家财，老爹气死。搬出豪宅，交出家财，开始辛勤劳作，不料老丈人八抬大轿把嫁出去的女儿接了回去。媳妇终究还是回来了，这时的母亲却生病了。去城里请医生，却被国民党抓了去做炮兵。仗也没怎么打。日本鬼子撤出中国，继而开始了国共内战。战场上的每个人都想活着，都想活着回家...", "content": " 文/大橙子没什么好说的，白花花的语言，依托中国抗日战后至今的时代背景，以富贵的经历叙述了很多中国式悲哀。富二代的富贵，吃喝嫖赌，散尽家财，老爹气死。搬出豪宅，交出家财，开始辛勤劳作，不料老丈人八抬大轿把嫁出去的女儿接了回去。媳妇终究还是回来了，这时的母亲却生病了。去城里请医生，却被国民党抓了去做炮兵。仗也没怎么打。日本鬼子撤出中国，继而开始了国共内战。战场上的每个人都想活着，都想活着回家去。后国军被围，被俘虏。共军优待俘虏，给了路费，富贵回家了。回家后发现老母已不再，女儿凤霞不会说话了。想带着老婆儿女好好过日子，发现挣得太少，没法让儿子上学。心生一妙计，把女儿送给大户人家，就供得起儿子上学了。好不容易送走的女儿，最后还是偷偷跑回来了，心一横，还是自己养着吧。这时候，村里搞炼钢铁，收了每户人家的锅。还收了儿子的羊，说是从此以后吃食堂了，再也不用自己家做饭了，方便啊。儿子在学校跑步跑的好，体育老师说可以训练，日后出国比赛，为国争光。富贵不懂，硬是阻止了。富贵带着老婆、女儿，一家三个轻壮年劳动，日子倒也可以。不料老婆却病了，身体一天比一天差。国庆节来的时候，富贵一家守着锅炉，终于把铁给融化了。村长高高兴兴带着一帮人去县里汇报。富贵背着老婆去城里看病。天有不测风云，儿子学校的校长，县长的老婆，生孩子大出血。学校把他们年级的孩子都拉到医院，不料只有富贵儿子的血型匹配，医生心一横，抽血往死里抽，最后出了人命。儿子死了，老婆的病更加重了，眼看一天天不行了，却撑住了。村里人娶媳妇嫁女儿，看得凤霞眼红，虽然她不会说话，也是羡慕别人家的。富贵托村长给凤霞介绍婚事，村长还真找来了，就是头有点偏，人在城里还有正经工作。好在偏头对凤霞挺好，不久还怀上了。不料凤霞生孩子时难产，又挂了。到这时，富贵老婆终于顶不住，也归西了。富贵就经常去看偏头和外孙，没想一天偏头干活时被砸死，留下外孙一人。富贵把外孙接回家一同过。一天，收棉花时，外孙不舒服，富贵就把他送回家，还给他煮了好多豆子。真是，屋漏偏逢连夜雨，富贵回家发现外孙吃豆子噎死了，嘴里塞着豆子。最后，富贵买了头牛，相依相伴。不太愿意相信，富贵是集所有悲剧于一身的人。故事太刻意了些，不推荐。" }, { "title": "读书 - 《无声告白》", "url": "/posts/2016-10-02/book-everthing-i-told-you/", "categories": "Reading", "tags": "book", "date": "2016-10-02 17:35:21 +0800", "snippet": " 文/大橙子故事以莉迪亚之死为主线，讲述了 Lee 一家的故事，父母对子女教育的失败，父母婚姻的失败。故事中的母亲玛莉琳，从小就是个特别的孩子，虽是个女孩，却异于其他女孩，立志长大做一名医生。这与她的母亲期望一直相悖，母亲一直希望她成为一个家庭主妇，有房子、老公、孩子。当玛莉琳接到哈佛的录用通知书时，母亲也是那样告诉她的：你在那里会遇见你未来老公的。故事中的父亲 Lee 先生是为亚裔，从小...", "content": " 文/大橙子故事以莉迪亚之死为主线，讲述了 Lee 一家的故事，父母对子女教育的失败，父母婚姻的失败。故事中的母亲玛莉琳，从小就是个特别的孩子，虽是个女孩，却异于其他女孩，立志长大做一名医生。这与她的母亲期望一直相悖，母亲一直希望她成为一个家庭主妇，有房子、老公、孩子。当玛莉琳接到哈佛的录用通知书时，母亲也是那样告诉她的：你在那里会遇见你未来老公的。故事中的父亲 Lee 先生是为亚裔，从小与周围环境格格不入。同时由于父亲是学校里扫地的，母亲是学校厨房里的帮工，是他常年累月的压抑着自卑的情绪，没有朋友，没有社交。Lee 虽没有俊朗的外表，却深深吸引了玛莉琳。那时 Lee 在哈佛做助教，玛莉琳来听他的课。黑头发、黑眼睛的 Lee 在极短的时间里吸引了玛莉琳的注意，俩人迅速确定了恋爱关系。由于玛莉琳怀孕了，她不得不放弃未完成的大四学业。Lee 在哈佛攻读博士，毕业后却未能如期取得哈佛教授的工作。那时候他们的婚姻是不合法的，不被祝福的。当玛莉琳的母亲得知她要结婚时非常高兴，却因 Lee 的种族问题，对他们的婚姻表示反对。导致母女二人后来的 8 年联系中断。玛莉琳再次回到母亲家时，是在母亲去世后。她想起母亲对她的期待，想想自己现在的生活，不就是母亲所期待的吗？不，这是不对的，玛莉琳想，我的理想是做一名医生。想到隔壁那位单亲妈妈，听说她是一位医生，玛莉琳不由得羡慕。当她回家以后，玛莉琳去了医院拜访了隔壁那位医生。对职业医生的向往，让她酝酿了一次离家出走。她买了书，用母亲留给她的积蓄，租了一间公寓，她要在那里为自己未完成的学业努力。可是她却没有把事情告诉 Lee，以及两个孩子：内斯和莉迪亚。玛莉琳是自私的，她忘却了老公和孩子，她从没有想过她莫名的失踪会给家人带来什么样的影响，尽管她坚持自己理想的心也无可厚非。Lee 和孩子们的失落是她无法想象的。直至她再次因怀孕放弃她的计划。当她回到家时，她发现莉迪亚是个很聪明，有天赋的孩子，于是她把自己的全部心思压在了莉迪亚身上，她认为莉迪亚会成为一个出色的医生，没错，她那么优秀呢。此时的莉迪亚再也不想失去母亲，于是只要母亲想让她做的，她都会迎合母亲，都会去做。而她的这种迎合，玛莉琳却没有察觉。母亲给她买各种各样的自然科学的书，带她去看自然展览，只要玛莉琳觉得对莉迪亚有帮助，她都会不惜一切代价去做。莉迪亚不想做医生，她也不爱自然科学。于此同时，Lee 也把重心放在莉迪亚的身上，她觉得莉迪亚那么优秀，有那么多朋友，真是很不错呢。他不爱他的儿子内斯，因为他觉得内斯不管做什么事情，都是自己小时候的缩影，看到内斯，他有种厌恶感。其实莉迪亚也不爱交朋友，她的同学都觉得她是个性格孤僻的孩子。她只是为了迎合父亲的期望，假装自己有很多朋友，假装自己很开心。这样的生活过了好久，直至莉迪亚发现哥哥内斯的哈佛录用通知书。在这个家里，内斯是缺乏父母关心的，内斯也是见证莉迪亚在父母的压力下成长的人。内斯羡慕莉迪亚在这个家里的地位，却也深知，父母的过多的期望成了莉迪亚不能承受之重。内斯和莉迪亚相互了解，相互安慰。她不愿意面对哥哥即将离家的现实。于是她把哈佛寄过来的一封封录用通知书藏起来，她以为这样内斯就不会离开家。直至隔壁的邻居把又一封通知书送到他们家里。内斯难以抑制的激动，这次他终于可以离开这个家了，他一分钟都不想再呆了。莉迪亚很失落，她的成绩也出现了问题，可是没人帮她。她知道自己没那种天赋，物理的不及格不是偶然。可是母亲却不愿意面对。母亲相信这是个偶然。莉迪亚和隔壁的坏孩子杰克做了朋友，当她发现杰克喜欢哥哥内斯说，俩人发生了争执。在莉迪亚生日那天，在发现父亲的婚外情后，终于发现再也无力承担这一切：父母的期望、哥哥的离去、家庭的压抑。那天晚上，她独自坐在湖岸边，想明白了一切。她想对父母坦白，说她不想做医生，不想社交。想对哥哥坦白，说她愿意哥哥离去。没关系，莉迪亚想，我可以独自生活。她想做个告别，于是她爬上了小船，划到湖心，莉迪亚是不会游泳的。她举起双手，她想跳入湖中，想象自己只要努力踢这双腿，就可以游到岸边，像内斯教她那样，努力踢着双腿。她告诉自己，可以的，自己能做到。莉迪亚死了，玛莉琳和 Lee，花了好长时间，才明白，自己才是害了莉迪亚的凶手。过多的期待，让莉迪亚绝望，也让另外两个孩子内斯和汉娜长久的被冷落。汉娜还那么小，她总是像个可怜的小狗一样，躲在拐角里期望父母能注意到她，能给予她多一点点的爱。现在，他们终于注意到她了，汉娜原来是那么可爱，如同她姐姐莉迪亚小时那样。此故事是父母坑害孩子的经典著作，建议父母们都可以看看。" }, { "title": "两个鸡蛋的问题", "url": "/posts/2016-10-01/egg-test/", "categories": "Quiz", "tags": "quiz", "date": "2016-10-01 23:32:52 +0800", "snippet": "前段时间有个朋友在问了这个关于鸡蛋和楼层的问题。一开始我也是懵逼的，没弄明白说的是什么意思，且让我从头细细道来。问题描述假如给你两个完全一样的鸡蛋，现在有n层楼高的房子，鸡蛋最高可以从t层掉下来不会碎，再往上加一层就碎了。请问，最少需要尝试多少次可以得知t是多少层？解题思路如果我没在题目中着重说明是两个鸡蛋，很多人看到题目是都是茫然的。假设你忽略了鸡蛋个数的约束，得到的方案有可能是千变万化的...", "content": "前段时间有个朋友在问了这个关于鸡蛋和楼层的问题。一开始我也是懵逼的，没弄明白说的是什么意思，且让我从头细细道来。问题描述假如给你两个完全一样的鸡蛋，现在有n层楼高的房子，鸡蛋最高可以从t层掉下来不会碎，再往上加一层就碎了。请问，最少需要尝试多少次可以得知t是多少层？解题思路如果我没在题目中着重说明是两个鸡蛋，很多人看到题目是都是茫然的。假设你忽略了鸡蛋个数的约束，得到的方案有可能是千变万化的。因为只有两个鸡蛋，所以大家且用且珍惜，一旦碎了，尝试的机会就会大大减少。另外，只要蛋还没碎，是可以重复利用的。最直观的办法 - 二分法相信大部分人看到这个问题想到的第一个方法应该是二分法。我们把问题具体化，假如n=100，那么我们要找的答案就是二分法最坏的情况需要扔多少次。举例说明，第一次就从 50 层开始扔第一个鸡蛋。 假如没碎，我们再从 75 层扔第二次。以此类推 假如碎了，那么我们只剩一个鸡蛋了，那么我们只能从第 1 层开始尝试扔第二个鸡蛋，一直扔到到它碎为止。我们把第二次扔碎蛋的楼层指定为x，那么t=x-1。二分法最坏的情况应该在分支 2 出现，当x=50时情况最坏。也就说，第一个蛋在 50 层碎了，然后我们很苦逼地从第 1 层开始往上扔，第二个蛋扔到 49 层还没碎。那么说明t就是坑爹的 49，这时候我们可以得出二分法最坏的结果是n/2。进阶的办法 - 等分法从二分法我们可以看出，其实那并不是一个很好的方案。我们可以在此基础上使用等分的方法来改进。具体的例子如下。 将n等分为x等分，使x的平方大于或等于n 在n=100的例子里，我们使x=10 第一个鸡蛋从第 1 个等分开始扔 如果碎了，那么我们从第 1 层开始尝试，最多还需要尝试x-1次。 如果没碎，我们从第二个等分再扔一次。 不管碎了还是没碎，跟外面一层的思路一样。 等分法最坏的情况应该是在最后一个等分出现，比如 100 层楼，当扔到最后一个等分时，也就是 100 层时鸡蛋碎了，那么我们只能从第 91 层开始扔第二个鸡蛋，一直扔到 99 层，蛋没碎，那么最多尝试了2x次，也就是 20 次。所以等分法最坏的情况是2x，并且x**2&gt;=n最优的解法 - 动态规划说了这么多，应该到揭示 BOSS 解法的时候了。最优的解法需要动态规划楼层。我们回到实际的问题中，假如从x层开始扔第一次，如果碎了就需要再从下往上试x-1次。这是无论如何也不能避免的事实。那如果没碎呢，我们可以考虑就往上加x-1层，如果碎了就从x层一直尝试到x+(x-1)层，最多还是x次。现在的问题就可以转化为x+(x-1)+(x-2)+...+1大于或者等于最高楼层。这个加法是不是有一点眼熟，你没看错，其实这就是从 1 一直加到x，我们可以用初中时学习过的高斯公式表示为x(x+1)/2 ≥ n。如果n是 100 层的话，x的最小值就是 14，我们开始扔鸡蛋。 从14楼扔第一次，如果碎了你懂的，从第 1 层开始。 如果没碎就往14+13层扔，如果碎了你懂的，从第 15 层开始。 如果没碎就往14+13+12层扔，以此类推。 最多尝试次数会小于等于x。写在最后其实这道题目是一道挺出名的面试题，据说是 Google 家的。如你没能想出完美的办法也是正常的。祝大家国庆玩的开心。" }, { "title": "读书 - 《挪威的森林》", "url": "/posts/2016-10-01/book-nuo-wei-de-sen-lin/", "categories": "Reading", "tags": "book", "date": "2016-10-01 17:32:21 +0800", "snippet": " 文/大橙子不清楚村上在表达什么，故事里的木月、直子、直子的姐姐、永泽的女朋友初美，以及哪所疗养院里的许许多多的人，忧郁、自杀。那么多人死了，也没有交代原因，我想这应该是那个年代日本社会经常发生的事情。故事里也又例外，像永泽这样的不缺钱的富二代，头脑清楚，目标明确，即使在考取公务员后，回到宿舍还自学班牙语，即使他已经自学掌握了好几门外语了。永泽的私生活，涉及到另外一个话题，性。整个故事里，...", "content": " 文/大橙子不清楚村上在表达什么，故事里的木月、直子、直子的姐姐、永泽的女朋友初美，以及哪所疗养院里的许许多多的人，忧郁、自杀。那么多人死了，也没有交代原因，我想这应该是那个年代日本社会经常发生的事情。故事里也又例外，像永泽这样的不缺钱的富二代，头脑清楚，目标明确，即使在考取公务员后，回到宿舍还自学班牙语，即使他已经自学掌握了好几门外语了。永泽的私生活，涉及到另外一个话题，性。整个故事里，对性的开放程度也是令人惊讶。不过在青少年成长时期，这也是没法回避的一个话题。还有一个人，就是绿子，虽然经历种种挫折，也始终没有放弃对爱情的追求，这个姑娘还是蛮讨人喜爱的，她也是为数不多的精神正常的人。村上的文字真是令人受不了，虽有幽默，却低沉的让人受不了。如果说那是一座森林，有人在森林里迷失了，有些人再也没有出来过，如木月等人；有些人在迷失中走出来了，如疗养院里走出的玲子；也有些人，生活好也罢、坏也罢，始终向前行走，如绿子、渡边。青春，就是这样。" }, { "title": "读书 - 《西厢记》", "url": "/posts/2016-10-01/book-xi-xiang-ji/", "categories": "Reading", "tags": "book", "date": "2016-10-01 07:58:56 +0800", "snippet": " 文/大橙子 这本书是某人要求我读的，啊。故事以崔莺莺和张生的爱情展开，毫无疑问，故事的主题就是歌颂爱情。整个故事中，给人印象最深，让人最喜欢的要数红娘，这也是故事得以发展的最重要的线索。没有红娘的机智与聪慧，任凭张生才高有八斗十斗，任凭小姐有多聪慧有多貌美，最终都不可能得到圆满的结局。另有一个巴掌拍不响，若不是初次见面崔莺莺眉目传情，张生也不会痴心妄想，以至于相思病病入膏肓。故事告诉大...", "content": " 文/大橙子 这本书是某人要求我读的，啊。故事以崔莺莺和张生的爱情展开，毫无疑问，故事的主题就是歌颂爱情。整个故事中，给人印象最深，让人最喜欢的要数红娘，这也是故事得以发展的最重要的线索。没有红娘的机智与聪慧，任凭张生才高有八斗十斗，任凭小姐有多聪慧有多貌美，最终都不可能得到圆满的结局。另有一个巴掌拍不响，若不是初次见面崔莺莺眉目传情，张生也不会痴心妄想，以至于相思病病入膏肓。故事告诉大家，在爱情面前，畏首畏尾，是修不成正果的。纵使张生一无所有，他勇敢追求爱情的心，是他成功的另一种要点。艺高人胆大，哈哈。白富美就在那里，看你有没有胆去追求了。张生虽有潘安之貌，状元之才，却由于门第原因，不被相爷夫人看中。像张生那样的穷酸，要出人头地，也是万分艰难，后崔老夫人打发张生进京赶考，也交代过，考取功名之事，也是要看时运的。其实这同当代的公务员考试是同理的，时运不济，考个十年八年也未必能成，哈哈，历史总是惊人的相似。故事的转机是孙飞虎围攻普救寺，相爷夫人当众承诺许婚。此时张生想起自己还有一位挚友白马将军杜确，没有此人相助，活捉孙飞虎是不敢想的。后崔老夫人在强行将莺莺许配与自己侄儿之时，若非白马将军及时现身，张生能不能同莺莺在一起，还未可知。由此可见，朋友，关键时刻可以帮忙，这也是非常重要的。当然，最后张生考中状元之后，京城岁美女如云，达官贵人遍地开花，却一心要回家娶莺莺。作者在此此告诫世人，功名利禄虽可诱惑人心，仍须警醒，不忘初心，不忘糟糠之妻，才是最重要的。" }, { "title": "读书 - 《解忧杂货店》", "url": "/posts/2016-10-01/book-jie-you-za-huo-dian/", "categories": "Reading", "tags": "book", "date": "2016-10-01 07:14:53 +0800", "snippet": " 文/大橙子 五星好评，强烈推荐！这本书让人最惊叹的地方，在于作者的逻辑安排，整本书以几个独立的故事铺展开来，各个故事之间却紧密相连，环环相扣。同时，作者想要表达的人生感悟，在故事中缓缓道来。第一个是关于击剑女运动员静子的故事，也是关于爱情与理想的故事。男朋友重病，却在男友与奥运梦之间是无从选择。虽然杂货店里人，从后人角度看到，那届奥运会在后来由于日本对俄罗斯入侵阿富汗的不满而遭到日本政...", "content": " 文/大橙子 五星好评，强烈推荐！这本书让人最惊叹的地方，在于作者的逻辑安排，整本书以几个独立的故事铺展开来，各个故事之间却紧密相连，环环相扣。同时，作者想要表达的人生感悟，在故事中缓缓道来。第一个是关于击剑女运动员静子的故事，也是关于爱情与理想的故事。男朋友重病，却在男友与奥运梦之间是无从选择。虽然杂货店里人，从后人角度看到，那届奥运会在后来由于日本对俄罗斯入侵阿富汗的不满而遭到日本政府的抵制，坚持奥运梦，最后肯定是徒劳。虽然回信建议她放弃奥运梦，可她并没有放弃，回过头看，她也并没有为当日的选择后悔。爱情同理想，对人们都是那么重要，那么不管在什么时候，坚持对理解的追求，不放弃，日后才不会后悔。纵使知道结局的人告诉你，这条路会很艰辛，没有结果，但自己没有走过，又怎能知道其中滋味呢？生活是需要亲身体会的。静子斜对面的小妹妹，武藤晴美，从小父母双亡，被奶奶的姐姐田村秀代收养。后由于田村秀代女婿破产，全家搬到田村家同住，晴美不得已在丸光园呆了几年。后再次回到田村秀代家时，境况不如从前，秀代的劳动患病，晴美想报答收养之恩，企图放弃学业做陪酒女郎。后杂货店回信，告诉她不要放弃学业，陪酒可以作为一段时间的谋生手段，但绝不是长远之计。后晴美听从建议，投资房产，在顺应时代的前提下，走向成功。这个故事告诉我们，不断的学习是非常重要的事情，在时代的发展中谋求个人发展才是正确的选择，不要逆风向行驶，所谓站在风口的猪也能飞起来，哈哈。后丸光园着火，晴子前去看望，遇见儿时伙伴藤川博，其真名为和久浩介。由于表哥去世，浩介要回了表哥的披头士唱片，从此开始对披头士的喜爱。后浩介的父亲生意失败，全家计划逃走。心智尚不成熟的浩介，选择离开父母。父母为了保护浩介自杀，让人以为浩介也一同自杀。真可谓父母之爱子女，则为之计深远。可是年轻的浩介并没有选择同父母在一起渡过艰难的阶段。如一家人在一起，浩介的父母无论如何也不会选择自杀的。亲情，长大成人的浩介想必也会为此后悔一生。由于晴美和浩介是丸光园里的伙伴，在丸光园失火后，两人同来看望。后忆起前任院长皆月晓子，杂货店主人浪矢雄治年轻时追求的人。那时候的雄治是个穷小子，被皆月家父母所反对，后两人私奔未果。后雄治遇到丸光园现任院长皆月晓子弟弟，为当年的鲁莽像皆月家里道歉。在丸光园的火灾中，松岗克朗救人牺牲。此人同静子和晴美住在同一个地方，年轻时为追求音乐梦想，与父母意见不合，放弃大学。但在奶奶过世时回家悼念时，父亲却鼓励他坚持下去。就算父亲身体不好，就算克朗在音乐上并没有什么天赋，父母还是鼓励他继续为他的理想努力。父母之爱子女，则为之计深远。克朗后并未成名，却在每年圣诞节时坚持去丸光园义演。其中有个孩子水芹原，由于火灾时克朗救了她的弟弟。日后的水芹原成为著名歌手，为了感怀克朗，将克朗的歌发扬并传承。而杂货店的三人组，由于了解水芹原的故事，了解了克朗对水芹原的影响，知道了他的努力并不会白白付出，所以鼓励克朗坚持：你对音乐的追求，并不会白白付出，将会有人因为你的歌而得到救赎，你创作的音乐也必将流传下去。虽然克朗最后的结局让人唏嘘不已，但朝圣的路上，注定要有人牺牲，注定要有人成为殉道者。水芹原的经纪人，川边绿的孩子，也同样在丸光园长大。川边绿由于与有妇之夫有染，怀孕，犹豫要不要生下孩子，并前来咨询杂货店。后川边绿意外坠海，孩子长大后一直以为当年母亲不想要他。多年以后孩子看到当年杂货店的信件，知道当年杂货店鼓励其母亲勇敢活下去，知道母亲并不是想放弃自己，特写信感恩杂货店。这一点应该是呼应了浪矢爷爷的初衷。浪矢交代，33 年时空再开启，其实就是想知道，当年他所做的努力，有没有真正帮助别人。而川边绿孩子的回答，无疑是肯定的。最后，丸光园失火，富有的晴美来看望，让在丸光园长大的杂货店三人组误以为晴美要买了丸光园另作它用，一气之下闯入晴美的家，抢劫。而此时的晴美在回家取东西之时，想赶在时光之门关闭之前，投递她的感谢信。不料车里的感谢信被劫走。而杂货店三人组看了后，才明白，他们抢的人，原来就是 33 年前来信咨询的迷途的小狗，三人不禁唏嘘。并决定将物归原主，从此以后再也不做小偷了。纵观全书，所有人都向杂货店咨询烦恼，而所有人（除静子外）均与丸光园有着不解的渊源。杂货店的主人浪矢雄治，丸光园的创始人皆月晓子，俩人的爱情在当年并未开花结果，但杂货店同丸光园却始终缠绕在一起。实在有趣。" }, { "title": "一行代码让浏览器变成记事本", "url": "/posts/2016-09-28/one-line-browser-as-notepad/", "categories": "Tech", "tags": "javascript, tips", "date": "2016-09-28 23:02:46 +0800", "snippet": "有时候你为了测试富文本的显示效果，需要新建一个 html 或者 word？太麻烦了。把下面这行代码贴到 Chrome 浏览器地址栏，按下回车，一切都搞定了，so easy！data:text/html,&lt;html contenteditable&gt;现在你可以往浏览器里输入任何内容，爽不？其实这也不是什么核武器，只是让浏览器直接执行一下它本身就支持的东西。这这个例子我们用的是Data...", "content": "有时候你为了测试富文本的显示效果，需要新建一个 html 或者 word？太麻烦了。把下面这行代码贴到 Chrome 浏览器地址栏，按下回车，一切都搞定了，so easy！data:text/html,&lt;html contenteditable&gt;现在你可以往浏览器里输入任何内容，爽不？其实这也不是什么核武器，只是让浏览器直接执行一下它本身就支持的东西。这这个例子我们用的是Data:这个 URI 格式，当然你还可以用javascript:这个 URI 格式让浏览器立马执行一段 js 脚本，比如这样。javascript: alert('牛逼大了！')" }, { "title": "读书 - 《傲慢与偏见》", "url": "/posts/2016-09-28/book-pride-and-prejudice/", "categories": "Reading", "tags": "book", "date": "2016-09-28 17:29:27 +0800", "snippet": " 文/大橙子很经典的爱情故事，情节比较简单，结合英国那个时代背景看会更好，如当时的社交文化，当时遗产继承制度（如无男嗣，则传给亲戚关系里最近的男嗣。由于班纳特夫妇无儿子，因此，班纳特老爷的侄子柯林斯，成为日后继承班纳特家庭财产的人选）。作者比较擅长对人物性格的刻画。伊丽莎白聪慧、漂亮，却对威廉编织的谎言深信不疑，并以此对达西的人格妄下判断。达西英俊、富有，却无法摆脱心中对阶级的偏见。最终俩...", "content": " 文/大橙子很经典的爱情故事，情节比较简单，结合英国那个时代背景看会更好，如当时的社交文化，当时遗产继承制度（如无男嗣，则传给亲戚关系里最近的男嗣。由于班纳特夫妇无儿子，因此，班纳特老爷的侄子柯林斯，成为日后继承班纳特家庭财产的人选）。作者比较擅长对人物性格的刻画。伊丽莎白聪慧、漂亮，却对威廉编织的谎言深信不疑，并以此对达西的人格妄下判断。达西英俊、富有，却无法摆脱心中对阶级的偏见。最终俩人摆脱心中的傲慢与偏见，结合在一起。性格决定命运。纵观这样一个乡绅家庭，五个女儿，愣是一个都没嫁出去，愁死这个老母亲班纳特太太。她的恨嫁之心，毛不夸张的说，超出了她任何一个女儿。大女儿吉英，年龄近 30，待嫁。其美丽无可言喻，加上过分的善良，在爱情里总是容易轻信别人。在其老爹看来，她就是缺脑子。而彬格莱的出现刚好拯救了她，两人为对方的容貌、对方的善良相互吸引。二女儿伊丽莎白，年龄稍小一点，待嫁。相貌平常，聪慧，见识、胆量均是这五姐妹中最出色的一个，也是姐妹在中唯一一个让班纳特老爷喜欢的。有着所有姑娘一样的小虚荣心，却也有着故事里所有姑娘都不具备的自尊自爱的心。当他的表格柯林斯怀着高高在上的心想她求婚时，她断然拒绝。柯林斯虽有舒适的生活，稳定的职业，她却不为所动，因为她看到了柯林斯有着贫穷的灵魂，丑陋的外表，却深不自知。而她的闺蜜夏绿蒂却甘心忍受这些，为后半生的衣食无忧，依然决定嫁给柯林斯。这让伊丽莎白在一段时间内无法接受。自负的柯林斯说以后不可能再有人向她求婚了，她再也嫁不出去。这让人觉得真是生气，求婚不成，还诅咒人嫁不出去，足见有多么自私狭隘。而当班纳特太太也这么想时，她请求班纳特老爷同她一起给伊丽莎白施压，让她答应求婚。出人意料，班纳特老爷却这么回答： 丽萃，你可怎么办是好呢，你现在面临一个很艰难的选择。你要是不嫁给柯林斯，你妈妈就再也不见你了。而如果你嫁给柯林斯，我就再也不见你了。听到父亲这话的回答，伊丽莎白兴奋无比。班纳特老爷再次让夫人衰弱的神经崩溃，尽管他说班纳特太太的脆弱神经是他 20 年的老朋友。当伊丽莎白面对彬格莱家姐妹的高高在上，从容淡定。当她面对达西姨妈包尔夫人的颐指气使，不卑不亢。当达西第一次向她求婚时，达西表达了自己克服心中的偏见、家族的期望，期望能与她在一起时，却让伊丽莎白愤怒。在她看来，如果爱情需要有这么多的附加条件，爱一个人不是出于本能，这又能算是什么爱情呢。无疑，这次的拒绝，让达西痛定思痛，同时让他对伊丽莎白有了更深刻的认识：她不是普通的姑娘，不是那种为了财富、地位会随便屈从的姑娘。她有着自己的爱情观，独立、自爱。虽然她的家庭，她的母亲、妹妹，无处不表现出不得体，让她自己也颇感尴尬，但她却是那样的与众不同。而后达西意识到，自己也有不得体的亲戚，比如包尔姨妈，他有什么理由对她的家庭表现出那样的傲慢呢。伊丽莎白最终明白自己有多么愚蠢，轻信了威廉编织的谎言，一直对达西心存偏见，多么不应该啊。达西的感情变化是比较有意思的。从开始默默暗恋女主，到表白被拒，再到默默为女主付出，最后当有一线生机时，毫不犹豫再次跟女主表白。个人觉得作者的女性视角比较突出。所谓每个女人心中都住着个高富帅，达西就是作者心中的白马王子，哈哈。除了不自爱的夏绿蒂，还有女主的妹妹丽迪亚，不顾礼义廉耻，和兵官们成天混在一起，最后还私奔了。害的全家人替她担忧、擦屁股。这是一本值得女性拜读的故事。" }, { "title": "使用教育邮箱激活JetBrains全家桶", "url": "/posts/2016-09-27/get-jetbrains-student-licence/", "categories": "Tech", "tags": "JetBrains, tips", "date": "2016-09-27 23:27:14 +0800", "snippet": "如果你还有在校时的邮箱，比如your_name@xxx.edu或者your_name@xxx.edu.cn的邮箱，那么你可以免费激活 JetBrains 全家桶。JetBrains Toolbox 专业开发工具 学生免费授权计划 工欲善其事，必先利其器。无论是学习 Java，PHP，Ruby，Python，JavaScript，Objective-C，.NET 任何一种开发技术，国际知名且...", "content": "如果你还有在校时的邮箱，比如your_name@xxx.edu或者your_name@xxx.edu.cn的邮箱，那么你可以免费激活 JetBrains 全家桶。JetBrains Toolbox 专业开发工具 学生免费授权计划 工欲善其事，必先利其器。无论是学习 Java，PHP，Ruby，Python，JavaScript，Objective-C，.NET 任何一种开发技术，国际知名且年年获奖的 JetBrains 专业开发工具都能有效帮助您。更棒的是：您可以完全免费使用！地址：https://www.jetbrains.com/student/免费学生计划里保护 JetBrains 所有专业版开发工具： IntelliJ IDEA Ultimate，ReSharper Ultimate 和所有集成开发工具。取得方式很简单，学生只要提供校园邮箱。更多的申请说明请参考：常见问题。备注 学生授权是一种免费的永久授权吗？ 不是的。学生授权每次是一年的效期，可以申请延长但不提供永久授权。在学生授权过期后只要还具有学生身份就可以再申请延长，毕业生可以选择购买授权。 如何申请延长学生授权？ 只要还具有学生身份，欢迎您利用 JetBrains account 内的链接申请延长。在学生授权即将到期的前一周我们会寄出提醒邮件，在该邮件中也带有申请延长用的链接。 " }, { "title": "读书 - 《一个人的朝圣》", "url": "/posts/2016-09-27/book-unlikely-pilgrimage-of-harold-fry/", "categories": "Reading", "tags": "book", "date": "2016-09-27 22:15:53 +0800", "snippet": " 文/大橙子 四星好评，不错哦！哎哟喂，写作手法很有意思，故事从头到尾都很平淡。本是带着疑惑上路的，一个退休的 65 岁的老头，莫名其妙的想靠走路的精神力量去拯救生命垂危的故人奎妮。想知道哈罗德跟奎妮之间到底是什么样的关系，是情人吗？他老婆莫林跟邻居都深以为然，哈罗德为了旧情人将老婆一个人抛弃在家！更别提后文，当媒体大肆的报道哈罗德这位朝圣者时，哈罗德同奎妮之间的关系，在吃瓜观众面前越来...", "content": " 文/大橙子 四星好评，不错哦！哎哟喂，写作手法很有意思，故事从头到尾都很平淡。本是带着疑惑上路的，一个退休的 65 岁的老头，莫名其妙的想靠走路的精神力量去拯救生命垂危的故人奎妮。想知道哈罗德跟奎妮之间到底是什么样的关系，是情人吗？他老婆莫林跟邻居都深以为然，哈罗德为了旧情人将老婆一个人抛弃在家！更别提后文，当媒体大肆的报道哈罗德这位朝圣者时，哈罗德同奎妮之间的关系，在吃瓜观众面前越来越微妙！不过当我们细细梳理时，又发现不是那么回事。从哈罗德徒步的第一天开始，他每天都会给老婆莫林打电话，每次购买纪念品时，除了给奎妮带去的，一定还会有莫林的那一份。哈罗德心理深深的爱着他的妻子莫林。哈罗德的妻子莫林，一直在同他们的儿子戴维对话。她告诉儿子哈罗德做了疯狂的决定，要徒步去看奎妮，儿子说他知道奎妮。她告诉儿子，今天她一个人去医院看病了，儿子说可以陪她去的。而在哈罗德的回忆中，好似他同儿子之间有不可逾越的鸿沟；好似因为这道鸿沟，导致他同妻子的关系也出现了问题，最终导致了哈罗德的离家出走。不过你真要这么以为，就错啦。最后你会明白，他们儿子戴维，很多年前因为抑郁症自杀。什么，惊天霹雳！原来莫林是有精神病哟，一直在跟死人对话！NO，作者给你的回答要委婉一点，人家只不过思念儿子，多年了养成了这个习惯而已。那么奎妮又是为什么呢？原来是当初丧子的哈罗德在悲愤之中所犯下的过错，奎妮默默的替他承担了后果，而哈罗德却连声谢谢都没来得及对她说过。这才是他不顾一切踏上这道路的原因，不是爱情！哈罗德在将近 3 个月的时间里，600 度英里的路上，回顾了他的一生，他的父母，他的妻子莫林，他的儿子戴维。他们匆忙的一生，他们来不及做的事情，他们所亏欠的事情，他们所怨恨的事情。最终莫林明白，这么多年，她盲目的将儿子的问题归咎于哈罗德，是不对的。当她仔细去回忆，去查看，戴维的成长过程是有哈罗德的陪伴的！奎妮的死是无法避免的结局，哈罗德同莫林，在经历这么多年的相互埋怨之后，终于相互原谅了对方。人生路上，我们会遇到很多形形色色的人，他们来了，又走了。但终会有人陪伴你走完全程。" }, { "title": "读书 - 《追风筝的人》", "url": "/posts/2016-09-27/book-kite-runner/", "categories": "Reading", "tags": "book", "date": "2016-09-27 21:14:53 +0800", "snippet": " 文/大橙子 五星好评，强烈推荐！贯穿整本书的是作者（阿米尔）的懦弱与自私，整个故事，直至最后，当阿米尔决定去挽救哈桑的儿子叫索拉博时，才是救赎的开始。整个故事的背景是俄罗斯入侵阿富汗，以及后来的阿富汗内战，以及种族问题。善良的哈桑被人始终被对立种族看不起，内战也是因为种族对立的问题。战争带来的是可怕的毁灭，尤其对儿童的造成的毁灭性影响，世人值得惊醒。善良的人，应该被世界善待。拉辛汗是位...", "content": " 文/大橙子 五星好评，强烈推荐！贯穿整本书的是作者（阿米尔）的懦弱与自私，整个故事，直至最后，当阿米尔决定去挽救哈桑的儿子叫索拉博时，才是救赎的开始。整个故事的背景是俄罗斯入侵阿富汗，以及后来的阿富汗内战，以及种族问题。善良的哈桑被人始终被对立种族看不起，内战也是因为种族对立的问题。战争带来的是可怕的毁灭，尤其对儿童的造成的毁灭性影响，世人值得惊醒。善良的人，应该被世界善待。拉辛汗是位智者：当阿米尔还是个孩子的时候，在屡屡被父亲忽视的时候，拉辛汗鼓励他读书、写作，这也会日后阿米尔的写作奠定了基础；当阿米尔的父子逃难离开美国后，拉辛汗找到了哈桑，并接回一同住；最后也是拉辛汗，将远隔千山万水，大洋彼岸的阿米尔拉回阿富汗，开始救赎的路。哈桑写给阿米尔的信真让人心碎。信里有他们的童年，童年时的阿富汗，阿富汗天空下那一群群追着风筝跑的孩子。信里有现在的阿富汗，满目疮痍。信里有哈桑的儿子索拉博，聪明的索拉博、会识字的索拉博、开心的索拉博。信里有病重的拉辛汗，一个令人敬爱的男人。信里有哈桑的梦，鲜花盛开的喀布尔街头、风筝再次在天空飞翔，而他的朋友阿米尔再次回到他们儿时的土地。读完哈桑的信，有种特别想哭的冲动。 “如果你回来，你会发现有个忠诚的老朋友在等着你。愿安拉永远与你用在”。故事的最后，哈桑原谅了从出生那天起就抛弃了自己的母亲，并陪伴她终老。拉辛汗说主会原谅你的父亲，而最终阿米尔承认了那些年自己和父亲所犯下的错，而当他决心为他们曾经的过错做出弥补的时候，他便原谅了父亲，开始了救赎的道路。 为你，千千万万遍。" }, { "title": "从C#到Python - 语言特性和概览", "url": "/posts/2016-09-27/from-csharp-to-python-overview/", "categories": "Tech", "tags": "C#, python", "date": "2016-09-27 17:35:13 +0800", "snippet": "因为工作的原因，目前主力编程语言从 C#转移到 Python，所以在此记录这两种语言的一些异同点和自己的感悟收获。本系列文章数量不限，随想随写。语言特性和特点C#C#是微软公司主推的编程语言，在 Windows 平台的首选开发语言，需要.net framework 的支持，非微软平台支持目前并不完善。主要特点是语法简单，IDE 强悍(VS 是我用过最强悍和人性化的 IDE，没有之一)，C#是...", "content": "因为工作的原因，目前主力编程语言从 C#转移到 Python，所以在此记录这两种语言的一些异同点和自己的感悟收获。本系列文章数量不限，随想随写。语言特性和特点C#C#是微软公司主推的编程语言，在 Windows 平台的首选开发语言，需要.net framework 的支持，非微软平台支持目前并不完善。主要特点是语法简单，IDE 强悍(VS 是我用过最强悍和人性化的 IDE，没有之一)，C#是强类型高级编程语言。Python是开源的动态解释型语言，由 Guido van Rossum 于 1989 年发明。它天生具有跨平台的能力，默认集成在 MacOS 和 Linux 系统中。Windows 平台需要单独安装。主要特点是语法简洁，第三方类库丰富强大，数据处理能力异常优秀。漫谈瞎扯我使用 C#编程的时间大概有 5 年左右，对于它的各种特性还算比较了解。接触 Python 大概只有三个多月，不过三观已经被刷新。限于我个人水平，本文对 C#和 Python 特别深入的东西不会特别介绍，仅从我个人的角度来帮助 C#的程序猿认识 Python。很明显我感觉 C#是简单，但 Python 是简洁。两个不完全一样的概念，简洁之中蕴含了简单，但是简洁也意味着信息的省略和丢失。举一些具体的例子标识语句块C#用花括号，和大多数编程语言一样。using System;namespace csharp_example{ internal class Program { private static void Main(string[] args) { Console.WriteLine(\"Hello C#!\"); } }}而 Python 用的是缩进。def say_hello(name=None): if name is None: name = 'python!' print \"hello\", nameif __name__ == '__main__': say_hello()命名规则C#对文件系统的命名空间是 System.IO。using System.IO;Python 只有 io，只有两个字母，还是小写的！import os迭代语句C#中 for 迭代是这样的，已经很简洁了。var list = new List&lt;int&gt;() { 1,, 3, 4, 5, 5, 5, 6 };foreach (var item in list){ Console.WriteLine(item);}Python 是这样的，真的不能再简洁了。list = [1, 2, 3, 4, 4, 5, 5, 6]for i in list: print i其他还有不少细节的地方在你接触 Python 之后也一定深有体会。 比如为了不切换大小写，Python 推荐使用全小写的命名规范（类命名除外） Python 要求省略句尾的分号 Python 不推荐在逻辑判断后使用括号，比如 if i &gt; 0: 而不是 if (i &gt; 0):这样的例子枚不胜举，如果语意可读性上来说，我比较喜欢 C#的做法，因为使用驼峰命名规则，基本上一个语句就是一小段英文。而且从命名规范上来说，C#推荐使用完整的英文单词来命名变量和类名。Python 就不见得了，很多类库和命名都是极度简洁的，比如pytz, wrapt, isalnum()。最令人发指的是居然连中间的下划线也省了，比如altsep, execl, getcwdu, spawnle，尼玛，这些是什么鬼，这一点也不考虑其他人的感受，很多时候你只能 yy 或者查文档，这就是简洁的代价。不过话说回来，正因为 Python 这也省布料，所以使用 Python 实现与 C#，JAVA 相同功能，至少可以少 20%的代码量。夸张的说法甚至 60%到 80%，我保留意见，但不得不承认是极有可能的。最后从动态语言和非动态语言的角度简单说一下，动态语言的特点就是程序在运行时才能确定类型和行为，动态语言也叫鸭子类型ducking typing，源自于来自 James Whitcomb Riley 这句有名的话。 If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck. 如果它看起来像一只鸭子，游起来也像鸭子，而且还会像鸭子一样叫，那么它极有可能就是一只鸭子。在动态语言里变量只是一个标记，具体的行为可以在程序运行时才确定，比如两个变量相加，Python 可以这样写：def add(a, b): return a + b你不需要也不能指定这个 a, b 的类型，当程序在运行时，他们的相加行为会根据传入的具体类型确定。&gt;&gt;&gt; add(1, 2)3&gt;&gt;&gt; add([1,2,3], [4,5,6])[1, 2, 3, 4, 5, 6]&gt;&gt;&gt; add('hi ', 'toby')'hi toby'&gt;&gt;&gt; add('hi', 1)Traceback (most recent call last): File \"&lt;pyshell#7&gt;\", line 1, in &lt;module&gt; add('hi', 1) File \"&lt;pyshell#2&gt;\", line 2, in add return a+bTypeError: cannot concatenate 'str' and 'int' objects&gt;&gt;&gt;反观 C#，Visual Studio 会对你的语法进行检查，没有泛型之前，你只能这样写。public int AddInt(int a, int b){ return a + b;}public string AddString(string a, string b){ return a + b;}有泛型和 dynamic 类型之后，情况好一些。public T Add&lt;T&gt;(T a, T b){ dynamic x = a; dynamic y = b; return x + y;}然而这种和 C#本身格格不入的编码方式并不流行，而且 IDE 支持也不好。或许你能从这个小例子明白动态语言的厉害之处。小结写了那么多，希望你对 Python 有一个比较直观的印象。两种语言各有特点，不能说谁好谁坏。具体用哪个一般只有一个原因，工作环境和项目需求。但就学习而言，如果已经熟悉 C#，转而学习 Python 还是比较简单和容易接受的，因为做的的减法。但是如果之前是 Python 而后转到 C#，就不是那么好受了，因为做的是加法。Python 的作者有处女情节，所以处处都要追求优雅，简单，完美。想适应这种情节真的需要刷三观，费半条命。而且写 Python 的人一般都短命，因为喜欢 Python 的人都喜欢这句话。Life is short, I use Python. （人生苦短，我用Python） 本文源码地址：https://github.com/tobyqin/csharp_vs_python" }, { "title": "Python：将数组中的元素导出到变量中 (unpacking)", "url": "/posts/2016-09-25/python-unpack-list-elements/", "categories": "Tech", "tags": "python, python list, tips", "date": "2016-09-25 07:03:34 +0800", "snippet": "Python 算法备忘。问题描述你需要将数组（list）或元组（tuple）中的一些元素导出到N个变量中。可能你并不希望通过遍历的方式。解决方案任何序列都可以通过简单的变量赋值方式将其元素分配到对应的变量中，唯一的要求就是变量的数量和结构需要和序列中的结构完全一致。p = (1, 2)x, y = p# x = 1# y = 2data = ['google', 100.1, (2016, ...", "content": "Python 算法备忘。问题描述你需要将数组（list）或元组（tuple）中的一些元素导出到N个变量中。可能你并不希望通过遍历的方式。解决方案任何序列都可以通过简单的变量赋值方式将其元素分配到对应的变量中，唯一的要求就是变量的数量和结构需要和序列中的结构完全一致。p = (1, 2)x, y = p# x = 1# y = 2data = ['google', 100.1, (2016, 5, 31)]name, price, date = data# name = 'google'# price = 100.1# date = (2016, 5, 31)name, price, (year, month, day) = data# name = 'google'# price = 100.1# year = 2016# month = 5# day = 31如果变量结构和元素结构不一致，你将会遇到以下错误：p = (1, 2)x, y, z = pTraceback (most recent call last): File \"&lt;pyshell#12&gt;\", line 1, in &lt;module&gt; x, y, z = pValueError: not enough values to unpack (expected 3, got 2)其实这样的操作不限于元组和数组，在字符串中也是可以用的。Unpacking 支持大多数我们常见的序列，比如文件迭代，各种生成器等等。s = 'Hello'a,b,c,d,e = s# a = 'H'# b = 'e'如果导出过程中你想丢掉一些元素，其实 Python 并不支持这样的语法，不过你可以指定一些不常用的变量来达到你的目的。data = ['google', 100.1, (2016, 5, 31)]name, _, (_,month,_) = data# name = 'google'# month = '5'# other fileds will be discarded本文主要是为了测试 Markdown 排版工具，微信公众号里的高亮代码一直是很麻烦的事情，让我头疼了很长一段时间。现在看起来不错哦。" }, { "title": "编程语录", "url": "/posts/2016-09-25/programming-notes/", "categories": "Tech", "tags": "programming, tips", "date": "2016-09-25 06:14:44 +0800", "snippet": " 编程语言的最终目的是什么？是为了让编程更容易。 人们对编程语言有一个必然要求，就是能为公共的模式命名，建立抽象，然后直接在抽象的层次上工作。 动态语言之所以很流行，就是因为人们可以在很短的时间内建立起一种原型。 编程应该有一整套系统，包括人，技能，库，框架，工具。 如何才能让程序功能更加丰富，如何才能让它更加有趣，如何组织代码。 人们总是尝试做着软件...", "content": " 编程语言的最终目的是什么？是为了让编程更容易。 人们对编程语言有一个必然要求，就是能为公共的模式命名，建立抽象，然后直接在抽象的层次上工作。 动态语言之所以很流行，就是因为人们可以在很短的时间内建立起一种原型。 编程应该有一整套系统，包括人，技能，库，框架，工具。 如何才能让程序功能更加丰富，如何才能让它更加有趣，如何组织代码。 人们总是尝试做着软件的模块化结构，并且这种手段越来越先进。 编程技术的历史，首先是使用机器码，然后是符号化的汇编语言，接下来是高级语言，后面是结构化编程，现在又来到了面向对象的时代。 在我设计困难算法的经验中，我发现了一个扩展自己能力的方法。一个具有挑战性的问题解决之后，我从头再做一遍，回顾之前方法中的关键点。重复这么做，直到解决方案如我所希望的那样明确和直接。然后我们考虑类似问题的通用准则，这将促使我在起初的时候更有效的解决问题。通常，这样的法则具有永恒的价值。 递归，编程工具库中一件最强大的工具。 优秀程序员的一个衡量标准，必须有所进展，还得能加以改进。 就基本技能而言，编程所包含的就是逻辑和数学，我们应当学会逻辑思考，学会清晰的思考。 建设性的懒惰，坚持复用，遵循 DRY（Don’t Repeat Yourself）原则，拒绝编写重复的胶合代码。 所谓的主流，实际上是以实效为主导。 培养构建大型应用程序的能力，因为写大程序非常耗时费力，这需要我们发明新方法，以减轻由于大程序的功能和细节而引起的沉重负担。 实现复杂度——代码的数量很重要，因为开发一个程序所耗费的时间主要取决于程序的长度。 面向对象编程只是程度不同的问题，事实上只有两种，某些语言允许以这种方式编程，另一些语言则强迫你一定要这样编程。 有了对象，我们就可以对任何事物建模；用对象做模拟是威力强大的，因为它非常符合我们对身处其中并与之交互的世界的看法。 Duck Typing (generic programming) ——如果它走路像鸭子，而且叫起来像鸭子，我就会称之为鸭子。 " }, { "title": "设置 Python Selenium 中的Log显示信息", "url": "/posts/2016-09-25/Turn-off-logging-in-python-selenium/", "categories": "Tech", "tags": "python, selenium, logging, tips", "date": "2016-09-25 06:14:44 +0800", "snippet": "Python Selenium 默认会往控制台和 Log 文件里写入大量的 DEBUG 信息，比如下面这张图。这样的相信在测试过程中有一定帮助，但大部分情况下都是没有营养的，而且会把你自己打印的 Log 信息淹没在汪洋大海中。如果想要停止显示或者关闭 Selenium 中的 Log，你可以通过以下代码更改其默认 LOGGER 的级别。import loggingfrom selenium.w...", "content": "Python Selenium 默认会往控制台和 Log 文件里写入大量的 DEBUG 信息，比如下面这张图。这样的相信在测试过程中有一定帮助，但大部分情况下都是没有营养的，而且会把你自己打印的 Log 信息淹没在汪洋大海中。如果想要停止显示或者关闭 Selenium 中的 Log，你可以通过以下代码更改其默认 LOGGER 的级别。import loggingfrom selenium.webdriver.remote.remote_connection import LOGGERLOGGER.setLevel(logging.WARNING)注意：以上代码一定要在初始化WebDriver前进行。" }, { "title": "Turn off logging in python selenium", "url": "/posts/2016-09-25/Turn-off-logging-in-python-selenium-en/", "categories": "Tech", "tags": "python, selenium, logging, tips", "date": "2016-09-25 06:14:44 +0800", "snippet": "Python selenium will print a lot of debug info for selenium driver, which will mess up important information for your testing.To turn it off, please add bellow code before test case.from selenium.w...", "content": "Python selenium will print a lot of debug info for selenium driver, which will mess up important information for your testing.To turn it off, please add bellow code before test case.from selenium.webdriver.remote.remote_connection import LOGGERLOGGER.setLevel(logging.WARNING)Note: above code should be put before webdriver initialization." }, { "title": "关于软件稳定性测试的思路", "url": "/posts/2014-10-19/how-to-make-sure-system-is-stable/", "categories": "Tech", "tags": "software testing", "date": "2014-10-19 00:00:00 +0800", "snippet": "如何测试软件的稳定性其实是很难的，按照常规思路，只有长期的用户场景测试才能一定程度上保证软件的稳定性是可靠的，但并不能百分之百确定软件就是稳定的。软件测试本身就是由局限和尽头的，无穷的测试只能带来高成本的投入和无限期的计划延长。其实，可以从反面角度来看待软件的稳定性，我们从一个简单的数学定理入手： 原命题成立，则逆否命题也成立。 原命题：软件没有明显缺陷，所以是足够稳定的。 逆否命题：...", "content": "如何测试软件的稳定性其实是很难的，按照常规思路，只有长期的用户场景测试才能一定程度上保证软件的稳定性是可靠的，但并不能百分之百确定软件就是稳定的。软件测试本身就是由局限和尽头的，无穷的测试只能带来高成本的投入和无限期的计划延长。其实，可以从反面角度来看待软件的稳定性，我们从一个简单的数学定理入手： 原命题成立，则逆否命题也成立。 原命题：软件没有明显缺陷，所以是足够稳定的。 逆否命题：软件并不是很稳定，所以有明显的缺陷。假设原命题是正确的，那么你否命题应该也是正确的。我们从原命题出发，很难说服团队去相信软件是足够稳定的，因为稳定的软件是没有明显缺陷的，没有数据的支撑和客观的事实，简单的例子就是，一我们不可能发现软件中所有的缺陷；二我们不可能花 2~3 个月不定地运行软件然后生成报告说经过长时间的实验软件十分稳定，时间不允许，就算时间允许我们也不敢保证 3 个月后程序是否还继续稳定如初。从逆否命题出发会简单许多，我们可以短时间内投入足够的精力去想办法证明软件很不稳定，比如让软件在高负荷下持续运行，给不同的压力和并发请求，进行破坏操作等等，如果软件没有出现明显的缺陷那么说明原命题也是成立的，从这个角度思考就可以从容地解决软件稳定性验证的问题。" }, { "title": "那些打鸡血的人生", "url": "/posts/2013-07-16/do-the-right-thing/", "categories": "Life", "tags": "AHU", "date": "2013-07-16 00:00:00 +0800", "snippet": "聊天的时候，总会有人一腔热血的向我推荐，“这部电影太励志了”，“这本书讲正能量诶”，或者是“昨天那个讲座我听得热血澎湃，讲的太有道理了”，刚开始我还会说，这些都是骗人的，后来，每次我都是摸摸我的狗头笑了，我明白，这些人都得了一种病，一种叫做鸡血狂躁症的沉疴，一种会间歇性发作的痼疾。这种病会让人免疫退化，犹如习武之人内力全失，让你在亢奋和低落之间跌宕起伏，而且传染力极强，会让你头脑发热。这样的...", "content": "聊天的时候，总会有人一腔热血的向我推荐，“这部电影太励志了”，“这本书讲正能量诶”，或者是“昨天那个讲座我听得热血澎湃，讲的太有道理了”，刚开始我还会说，这些都是骗人的，后来，每次我都是摸摸我的狗头笑了，我明白，这些人都得了一种病，一种叫做鸡血狂躁症的沉疴，一种会间歇性发作的痼疾。这种病会让人免疫退化，犹如习武之人内力全失，让你在亢奋和低落之间跌宕起伏，而且传染力极强，会让你头脑发热。这样的病人，究竟是怎样的一群人呢？当我看到他们每次学习的时候书都是从第一页翻起的时候，我若有所思，有所悟。按照熵的社会学解释，人总是会慢慢衰落，消亡，可是这些人，总是在追赶最后一趟火车。他们有雄心壮志，最后往往半途夭折。他们拥有的是表面的热情，深藏的却是内心的狂躁，他们营造着自欺欺人的假象，让自己在岁月的杀猪刀下消亡殆尽。人生总是逃脱不了与生俱来的困境，很多打鸡血的人，往往深陷泥潭却不自知，他们从来不去思考自身的困境，把自己逼进了进退维谷的地步，最后却寄希望于天上掉馅饼，馅饼掉下来了，你接得住吗？期待着武侠小说的情怀，到头来却是拔剑四顾心茫然，欲渡黄河冰塞川，将登太行雪满山。总有那么一群人，在一个慵懒的午后，满心期待着通过一两本书，一两部电影，一两场讲座，希望从中得到所谓的真传，让自己脱胎换骨，顿悟法门，那你做梦去吧！ “即便你真的能排除思想上的障碍，将计划付诸行动，在过个程中，也有无数这样那样的困难，挡住你前进的道路——这是一个漫长而艰苦的过程，决不是一时意气就能坚持下来的。”在现在这个糟糕的时代，打鸡血变换着各种戏法，作恶江湖，无孔不入，所谓的成功学，励志，正能量，不都是他披上的新装吗？ “只要有信心，人永远不会挫败”“人生的道路很长，但关键的时候，往往只有几步”，经常在海报上，网路上看到这样的文字，乍眼一看，觉得是无可辩驳的箴言，让人内心澎湃，仿佛是人生的福音书，仔细一想，又是如此的理所当然，用冯唐的话来讲，顿觉心头肿胀，然而，认真思考却是如此的荒谬与戏谑，就让他们扯淡去吧！看看你的身边，你会发现，那些过早放弃的人，往往是对于未来很乐观的人，现实世界的糟糕会让他们过早的退出循环，那些鸡血打得最多的人，呐喊得最强烈的人，往往是最先逃跑的人，而那些能够一直坚持到底的人，往往是清楚地认识到前路所会遇到的苦难但是坚信自己的人，就是我们所谓的“呆子”，“nerd”，我不知道为什么，世界总是偏爱青睐那些“偏执”的人，想到这里，不禁让我唏嘘的纳闷:上帝是 nerd 吗？如果上帝不是 nerd，又为什么对于“nerd”钟爱有加呢？《大学》云：“知止而后有定，定而后能静，静而后能安，安而后能虑，虑而后能得。”不知止，何以定，不定不静不安，孰能得？知止者，又何用打鸡血？那些打了鸡血的人生终究会变得很狗血！想想那些昨天还跟你满腔热血，高谈阔论”励志“，”正能量“的人吧，大梦初醒时，天依旧清亮，风依旧分明，他应该都不记得他昨天说过什么吧，或许只记得昨天吃了什么吧！" }, { "title": "走得太远，忘记了为什么出发", "url": "/posts/2011-03-14/forget-why-start/", "categories": "Life", "tags": "Reading", "date": "2011-03-14 00:00:00 +0800", "snippet": " 可以颠覆掉所有的春天 用一小片枯薄了的秋叶 而昨夜犹在梦中 所以围脖和小火炉 还搁在去年的架上 去年还搁在 小小的记忆里", "content": " 可以颠覆掉所有的春天 用一小片枯薄了的秋叶 而昨夜犹在梦中 所以围脖和小火炉 还搁在去年的架上 去年还搁在 小小的记忆里" } ]
